Requirement already satisfied: torch in /lustre/home/debnathk/.local/lib/python3.9/site-packages (2.2.0)
Requirement already satisfied: torchvision in /lustre/home/debnathk/.local/lib/python3.9/site-packages (0.17.0)
Requirement already satisfied: torchaudio in /lustre/home/debnathk/.local/lib/python3.9/site-packages (2.2.0)
Requirement already satisfied: networkx in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (3.2.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: fsspec in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (2023.12.2)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch) (3.1.3)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (2.19.3)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: filelock in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (3.13.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/site-packages (from torch) (4.9.0)
Requirement already satisfied: triton==2.2.0 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (2.2.0)
Requirement already satisfied: sympy in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (1.12)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib64/python3.9/site-packages (from torchvision) (10.2.0)
Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchvision) (2.31.0)
Requirement already satisfied: numpy in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torchvision) (1.26.3)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch) (2.1.4)
Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests->torchvision) (2.10)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.9/site-packages (from requests->torchvision) (3.3.2)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->torchvision) (1.26.5)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchvision) (2023.11.17)
Requirement already satisfied: mpmath>=0.19 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from sympy->torch) (1.3.0)
WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>
distutils: /lustre/home/debnathk/.local/lib/python3.9/site-packages
sysconfig: /lustre/home/debnathk/.local/lib64/python3.9/site-packages
WARNING: Additional context:
user = True
home = None
root = None
prefix = None
Requirement already satisfied: torch_geometric in /lustre/home/debnathk/.local/lib/python3.9/site-packages (2.4.0)
Requirement already satisfied: numpy in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch_geometric) (1.26.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch_geometric) (3.1.3)
Requirement already satisfied: scikit-learn in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch_geometric) (1.4.0)
Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torch_geometric) (2.31.0)
Requirement already satisfied: pyparsing in /usr/lib/python3.9/site-packages (from torch_geometric) (2.4.7)
Requirement already satisfied: tqdm in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch_geometric) (4.66.1)
Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib64/python3.9/site-packages (from torch_geometric) (5.9.8)
Requirement already satisfied: scipy in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from torch_geometric) (1.12.0)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch_geometric) (2.1.4)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.9/site-packages (from requests->torch_geometric) (3.3.2)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torch_geometric) (2023.11.17)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->torch_geometric) (1.26.5)
Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests->torch_geometric) (2.10)
Requirement already satisfied: threadpoolctl>=2.0.0 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from scikit-learn->torch_geometric) (3.2.0)
Requirement already satisfied: joblib>=1.2.0 in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from scikit-learn->torch_geometric) (1.3.2)
WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>
distutils: /lustre/home/debnathk/.local/lib/python3.9/site-packages
sysconfig: /lustre/home/debnathk/.local/lib64/python3.9/site-packages
WARNING: Additional context:
user = True
home = None
root = None
prefix = None
Requirement already satisfied: rdkit-pypi in /lustre/home/debnathk/.local/lib/python3.9/site-packages (2022.9.5)
Requirement already satisfied: numpy in /lustre/home/debnathk/.local/lib/python3.9/site-packages (from rdkit-pypi) (1.26.3)
Requirement already satisfied: Pillow in /usr/local/lib64/python3.9/site-packages (from rdkit-pypi) (10.2.0)
WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>
distutils: /lustre/home/debnathk/.local/lib/python3.9/site-packages
sysconfig: /lustre/home/debnathk/.local/lib64/python3.9/site-packages
WARNING: Additional context:
user = True
home = None
root = None
prefix = None
/lustre/home/debnathk/ondemand/data/sys/myjobs/projects/default/6/training.py:2: DeprecationWarning: 
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466
        
  import pandas as pd
/lustre/home/debnathk/.local/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
cuda_name: cuda:0
Learning rate:  0.0005
Epochs:  1000

running on  GINConvNet_davis
Pre-processed data found: data/processed/davis_train.pt, loading ...
Pre-processed data found: data/processed/davis_test.pt, loading ...
Training on 25046 samples...
Train epoch: 1 [0/25046 (0%)]	Loss: 28.206390
Train epoch: 1 [327560/25046 (41%)]	Loss: 1.000891
Train epoch: 1 [657560/25046 (82%)]	Loss: 0.930345
Make prediction for 5010 samples...
rmse improved at epoch  1 ; best_mse,best_ci: 470.83603 0.5498597657713924 GINConvNet davis
Training on 25046 samples...
Train epoch: 2 [0/25046 (0%)]	Loss: 0.770248
Train epoch: 2 [332860/25046 (41%)]	Loss: 0.723975
Train epoch: 2 [654240/25046 (82%)]	Loss: 0.579367
Make prediction for 5010 samples...
rmse improved at epoch  2 ; best_mse,best_ci: 0.68600833 0.7465360315359695 GINConvNet davis
Training on 25046 samples...
Train epoch: 3 [0/25046 (0%)]	Loss: 0.723944
Train epoch: 3 [330480/25046 (41%)]	Loss: 0.573072
Train epoch: 3 [654080/25046 (82%)]	Loss: 0.636519
Make prediction for 5010 samples...
1.1030489 No improvement since epoch  2 ; best_mse,best_ci: 0.68600833 0.7465360315359695 GINConvNet davis
Training on 25046 samples...
Train epoch: 4 [0/25046 (0%)]	Loss: 0.749134
Train epoch: 4 [329120/25046 (41%)]	Loss: 0.517171
Train epoch: 4 [669480/25046 (82%)]	Loss: 0.651287
Make prediction for 5010 samples...
0.80212355 No improvement since epoch  2 ; best_mse,best_ci: 0.68600833 0.7465360315359695 GINConvNet davis
Training on 25046 samples...
Train epoch: 5 [0/25046 (0%)]	Loss: 0.590577
Train epoch: 5 [329500/25046 (41%)]	Loss: 0.569445
Train epoch: 5 [653920/25046 (82%)]	Loss: 0.555387
Make prediction for 5010 samples...
rmse improved at epoch  5 ; best_mse,best_ci: 0.66661143 0.7931457448142893 GINConvNet davis
Training on 25046 samples...
Train epoch: 6 [0/25046 (0%)]	Loss: 0.566522
Train epoch: 6 [331760/25046 (41%)]	Loss: 0.545321
Train epoch: 6 [649200/25046 (82%)]	Loss: 0.482808
Make prediction for 5010 samples...
rmse improved at epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 7 [0/25046 (0%)]	Loss: 0.614142
Train epoch: 7 [328800/25046 (41%)]	Loss: 0.450272
Train epoch: 7 [659920/25046 (82%)]	Loss: 0.543009
Make prediction for 5010 samples...
0.65856236 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 8 [0/25046 (0%)]	Loss: 0.516606
Train epoch: 8 [324760/25046 (41%)]	Loss: 0.521243
Train epoch: 8 [647800/25046 (82%)]	Loss: 0.558544
Make prediction for 5010 samples...
0.5682179 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 9 [0/25046 (0%)]	Loss: 0.435209
Train epoch: 9 [324520/25046 (41%)]	Loss: 0.408665
Train epoch: 9 [662520/25046 (82%)]	Loss: 0.590342
Make prediction for 5010 samples...
0.58280283 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 10 [0/25046 (0%)]	Loss: 0.522462
Train epoch: 10 [329760/25046 (41%)]	Loss: 0.550649
Train epoch: 10 [647880/25046 (82%)]	Loss: 0.532671
Make prediction for 5010 samples...
0.75504 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 11 [0/25046 (0%)]	Loss: 0.486124
Train epoch: 11 [324620/25046 (41%)]	Loss: 0.428520
Train epoch: 11 [645600/25046 (82%)]	Loss: 0.427985
Make prediction for 5010 samples...
0.84454745 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 12 [0/25046 (0%)]	Loss: 0.451344
Train epoch: 12 [328500/25046 (41%)]	Loss: 0.403046
Train epoch: 12 [653360/25046 (82%)]	Loss: 0.502261
Make prediction for 5010 samples...
0.7343325 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 13 [0/25046 (0%)]	Loss: 0.474058
Train epoch: 13 [329100/25046 (41%)]	Loss: 0.406686
Train epoch: 13 [649480/25046 (82%)]	Loss: 0.395808
Make prediction for 5010 samples...
0.5761249 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 14 [0/25046 (0%)]	Loss: 0.488444
Train epoch: 14 [328580/25046 (41%)]	Loss: 0.419725
Train epoch: 14 [654400/25046 (82%)]	Loss: 0.506650
Make prediction for 5010 samples...
0.6380723 No improvement since epoch  6 ; best_mse,best_ci: 0.51010966 0.7984283627690184 GINConvNet davis
Training on 25046 samples...
Train epoch: 15 [0/25046 (0%)]	Loss: 0.486973
Train epoch: 15 [328360/25046 (41%)]	Loss: 0.333231
Train epoch: 15 [656720/25046 (82%)]	Loss: 0.457101
Make prediction for 5010 samples...
rmse improved at epoch  15 ; best_mse,best_ci: 0.43088427 0.8502898337420722 GINConvNet davis
Training on 25046 samples...
Train epoch: 16 [0/25046 (0%)]	Loss: 0.368811
Train epoch: 16 [335740/25046 (41%)]	Loss: 0.441574
Train epoch: 16 [660760/25046 (82%)]	Loss: 0.393419
Make prediction for 5010 samples...
0.5103166 No improvement since epoch  15 ; best_mse,best_ci: 0.43088427 0.8502898337420722 GINConvNet davis
Training on 25046 samples...
Train epoch: 17 [0/25046 (0%)]	Loss: 0.404865
Train epoch: 17 [325900/25046 (41%)]	Loss: 0.417040
Train epoch: 17 [655960/25046 (82%)]	Loss: 0.439525
Make prediction for 5010 samples...
0.46972877 No improvement since epoch  15 ; best_mse,best_ci: 0.43088427 0.8502898337420722 GINConvNet davis
Training on 25046 samples...
Train epoch: 18 [0/25046 (0%)]	Loss: 0.342450
Train epoch: 18 [325100/25046 (41%)]	Loss: 0.420992
Train epoch: 18 [653440/25046 (82%)]	Loss: 0.455038
Make prediction for 5010 samples...
rmse improved at epoch  18 ; best_mse,best_ci: 0.39845455 0.8490993015779471 GINConvNet davis
Training on 25046 samples...
Train epoch: 19 [0/25046 (0%)]	Loss: 0.432780
Train epoch: 19 [327620/25046 (41%)]	Loss: 0.388727
Train epoch: 19 [667240/25046 (82%)]	Loss: 0.359649
Make prediction for 5010 samples...
0.42414653 No improvement since epoch  18 ; best_mse,best_ci: 0.39845455 0.8490993015779471 GINConvNet davis
Training on 25046 samples...
Train epoch: 20 [0/25046 (0%)]	Loss: 0.343681
Train epoch: 20 [328440/25046 (41%)]	Loss: 0.360384
Train epoch: 20 [667760/25046 (82%)]	Loss: 0.370662
Make prediction for 5010 samples...
0.53408766 No improvement since epoch  18 ; best_mse,best_ci: 0.39845455 0.8490993015779471 GINConvNet davis
Training on 25046 samples...
Train epoch: 21 [0/25046 (0%)]	Loss: 0.370371
Train epoch: 21 [327880/25046 (41%)]	Loss: 0.356749
Train epoch: 21 [652200/25046 (82%)]	Loss: 0.418038
Make prediction for 5010 samples...
rmse improved at epoch  21 ; best_mse,best_ci: 0.37602106 0.8506943099040912 GINConvNet davis
Training on 25046 samples...
Train epoch: 22 [0/25046 (0%)]	Loss: 0.396136
Train epoch: 22 [322580/25046 (41%)]	Loss: 0.321748
Train epoch: 22 [661760/25046 (82%)]	Loss: 0.432514
Make prediction for 5010 samples...
0.6243799 No improvement since epoch  21 ; best_mse,best_ci: 0.37602106 0.8506943099040912 GINConvNet davis
Training on 25046 samples...
Train epoch: 23 [0/25046 (0%)]	Loss: 0.323653
Train epoch: 23 [327560/25046 (41%)]	Loss: 0.330685
Train epoch: 23 [649920/25046 (82%)]	Loss: 0.363598
Make prediction for 5010 samples...
0.6114442 No improvement since epoch  21 ; best_mse,best_ci: 0.37602106 0.8506943099040912 GINConvNet davis
Training on 25046 samples...
Train epoch: 24 [0/25046 (0%)]	Loss: 0.344509
Train epoch: 24 [328680/25046 (41%)]	Loss: 0.333188
Train epoch: 24 [644080/25046 (82%)]	Loss: 0.447929
Make prediction for 5010 samples...
0.4716807 No improvement since epoch  21 ; best_mse,best_ci: 0.37602106 0.8506943099040912 GINConvNet davis
Training on 25046 samples...
Train epoch: 25 [0/25046 (0%)]	Loss: 0.343264
Train epoch: 25 [330980/25046 (41%)]	Loss: 0.300540
Train epoch: 25 [657560/25046 (82%)]	Loss: 0.301683
Make prediction for 5010 samples...
0.5973527 No improvement since epoch  21 ; best_mse,best_ci: 0.37602106 0.8506943099040912 GINConvNet davis
Training on 25046 samples...
Train epoch: 26 [0/25046 (0%)]	Loss: 0.332523
Train epoch: 26 [330780/25046 (41%)]	Loss: 0.318672
Train epoch: 26 [650560/25046 (82%)]	Loss: 0.286990
Make prediction for 5010 samples...
rmse improved at epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 27 [0/25046 (0%)]	Loss: 0.369221
Train epoch: 27 [331780/25046 (41%)]	Loss: 0.285833
Train epoch: 27 [656080/25046 (82%)]	Loss: 0.281069
Make prediction for 5010 samples...
0.51720244 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 28 [0/25046 (0%)]	Loss: 0.346708
Train epoch: 28 [332220/25046 (41%)]	Loss: 0.312270
Train epoch: 28 [655520/25046 (82%)]	Loss: 0.284358
Make prediction for 5010 samples...
0.48080128 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 29 [0/25046 (0%)]	Loss: 0.232475
Train epoch: 29 [332540/25046 (41%)]	Loss: 0.268928
Train epoch: 29 [654760/25046 (82%)]	Loss: 0.258066
Make prediction for 5010 samples...
0.4502303 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 30 [0/25046 (0%)]	Loss: 0.267680
Train epoch: 30 [325800/25046 (41%)]	Loss: 0.285988
Train epoch: 30 [651200/25046 (82%)]	Loss: 0.326335
Make prediction for 5010 samples...
0.45364702 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 31 [0/25046 (0%)]	Loss: 0.295356
Train epoch: 31 [326280/25046 (41%)]	Loss: 0.255115
Train epoch: 31 [651840/25046 (82%)]	Loss: 0.282871
Make prediction for 5010 samples...
0.47665212 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 32 [0/25046 (0%)]	Loss: 0.301303
Train epoch: 32 [330860/25046 (41%)]	Loss: 0.301440
Train epoch: 32 [653960/25046 (82%)]	Loss: 0.329865
Make prediction for 5010 samples...
0.4585472 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 33 [0/25046 (0%)]	Loss: 0.259224
Train epoch: 33 [323980/25046 (41%)]	Loss: 0.276216
Train epoch: 33 [655320/25046 (82%)]	Loss: 0.298757
Make prediction for 5010 samples...
0.48745546 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 34 [0/25046 (0%)]	Loss: 0.279324
Train epoch: 34 [331880/25046 (41%)]	Loss: 0.262081
Train epoch: 34 [658880/25046 (82%)]	Loss: 0.239187
Make prediction for 5010 samples...
0.39448115 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 35 [0/25046 (0%)]	Loss: 0.266152
Train epoch: 35 [329060/25046 (41%)]	Loss: 0.313619
Train epoch: 35 [658560/25046 (82%)]	Loss: 0.261859
Make prediction for 5010 samples...
0.4335702 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 36 [0/25046 (0%)]	Loss: 0.260013
Train epoch: 36 [322260/25046 (41%)]	Loss: 0.300789
Train epoch: 36 [658280/25046 (82%)]	Loss: 0.420447
Make prediction for 5010 samples...
0.399165 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 37 [0/25046 (0%)]	Loss: 0.226074
Train epoch: 37 [327180/25046 (41%)]	Loss: 0.366503
Train epoch: 37 [649440/25046 (82%)]	Loss: 0.280679
Make prediction for 5010 samples...
0.42951632 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 38 [0/25046 (0%)]	Loss: 0.207325
Train epoch: 38 [326760/25046 (41%)]	Loss: 0.288109
Train epoch: 38 [648320/25046 (82%)]	Loss: 0.235828
Make prediction for 5010 samples...
0.39736554 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 39 [0/25046 (0%)]	Loss: 0.256207
Train epoch: 39 [328920/25046 (41%)]	Loss: 0.221263
Train epoch: 39 [659520/25046 (82%)]	Loss: 0.281284
Make prediction for 5010 samples...
0.48081484 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 40 [0/25046 (0%)]	Loss: 0.326818
Train epoch: 40 [326520/25046 (41%)]	Loss: 0.251144
Train epoch: 40 [657960/25046 (82%)]	Loss: 0.253168
Make prediction for 5010 samples...
0.39805034 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 41 [0/25046 (0%)]	Loss: 0.239790
Train epoch: 41 [330560/25046 (41%)]	Loss: 0.272316
Train epoch: 41 [665640/25046 (82%)]	Loss: 0.294302
Make prediction for 5010 samples...
0.53020024 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 42 [0/25046 (0%)]	Loss: 0.321649
Train epoch: 42 [331260/25046 (41%)]	Loss: 0.276709
Train epoch: 42 [658680/25046 (82%)]	Loss: 0.272505
Make prediction for 5010 samples...
0.42529076 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 43 [0/25046 (0%)]	Loss: 0.206086
Train epoch: 43 [325180/25046 (41%)]	Loss: 0.237817
Train epoch: 43 [647360/25046 (82%)]	Loss: 0.317848
Make prediction for 5010 samples...
0.44334427 No improvement since epoch  26 ; best_mse,best_ci: 0.3445696 0.845448142281267 GINConvNet davis
Training on 25046 samples...
Train epoch: 44 [0/25046 (0%)]	Loss: 0.262736
Train epoch: 44 [323740/25046 (41%)]	Loss: 0.247953
Train epoch: 44 [666320/25046 (82%)]	Loss: 0.258140
Make prediction for 5010 samples...
rmse improved at epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 45 [0/25046 (0%)]	Loss: 0.289860
Train epoch: 45 [333260/25046 (41%)]	Loss: 0.242718
Train epoch: 45 [654720/25046 (82%)]	Loss: 0.283533
Make prediction for 5010 samples...
0.4602317 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 46 [0/25046 (0%)]	Loss: 0.269360
Train epoch: 46 [331740/25046 (41%)]	Loss: 0.278491
Train epoch: 46 [650960/25046 (82%)]	Loss: 0.321835
Make prediction for 5010 samples...
0.41253108 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 47 [0/25046 (0%)]	Loss: 0.198336
Train epoch: 47 [322200/25046 (41%)]	Loss: 0.265770
Train epoch: 47 [662040/25046 (82%)]	Loss: 0.299013
Make prediction for 5010 samples...
0.42876756 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 48 [0/25046 (0%)]	Loss: 0.276468
Train epoch: 48 [326460/25046 (41%)]	Loss: 0.216335
Train epoch: 48 [656760/25046 (82%)]	Loss: 0.252605
Make prediction for 5010 samples...
0.46554932 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 49 [0/25046 (0%)]	Loss: 0.243536
Train epoch: 49 [325180/25046 (41%)]	Loss: 0.259928
Train epoch: 49 [651320/25046 (82%)]	Loss: 0.223540
Make prediction for 5010 samples...
0.38495752 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 50 [0/25046 (0%)]	Loss: 0.231627
Train epoch: 50 [327280/25046 (41%)]	Loss: 0.219585
Train epoch: 50 [656760/25046 (82%)]	Loss: 0.247781
Make prediction for 5010 samples...
0.3659284 No improvement since epoch  44 ; best_mse,best_ci: 0.3361753 0.8472822984782905 GINConvNet davis
Training on 25046 samples...
Train epoch: 51 [0/25046 (0%)]	Loss: 0.246403
Train epoch: 51 [324840/25046 (41%)]	Loss: 0.228765
Train epoch: 51 [657240/25046 (82%)]	Loss: 0.256872
Make prediction for 5010 samples...
rmse improved at epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 52 [0/25046 (0%)]	Loss: 0.228081
Train epoch: 52 [332680/25046 (41%)]	Loss: 0.252540
Train epoch: 52 [649880/25046 (82%)]	Loss: 0.244309
Make prediction for 5010 samples...
0.45650125 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 53 [0/25046 (0%)]	Loss: 0.219968
Train epoch: 53 [334640/25046 (41%)]	Loss: 0.243807
Train epoch: 53 [657040/25046 (82%)]	Loss: 0.187036
Make prediction for 5010 samples...
0.41476277 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 54 [0/25046 (0%)]	Loss: 0.192064
Train epoch: 54 [325660/25046 (41%)]	Loss: 0.238895
Train epoch: 54 [654520/25046 (82%)]	Loss: 0.250201
Make prediction for 5010 samples...
0.5076914 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 55 [0/25046 (0%)]	Loss: 0.284304
Train epoch: 55 [326960/25046 (41%)]	Loss: 0.219001
Train epoch: 55 [656000/25046 (82%)]	Loss: 0.247220
Make prediction for 5010 samples...
0.3316924 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 56 [0/25046 (0%)]	Loss: 0.198694
Train epoch: 56 [328880/25046 (41%)]	Loss: 0.168725
Train epoch: 56 [659360/25046 (82%)]	Loss: 0.270051
Make prediction for 5010 samples...
0.4579535 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 57 [0/25046 (0%)]	Loss: 0.210057
Train epoch: 57 [324820/25046 (41%)]	Loss: 0.250014
Train epoch: 57 [660040/25046 (82%)]	Loss: 0.229274
Make prediction for 5010 samples...
0.33898404 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 58 [0/25046 (0%)]	Loss: 0.195293
Train epoch: 58 [329960/25046 (41%)]	Loss: 0.255480
Train epoch: 58 [662600/25046 (82%)]	Loss: 0.262370
Make prediction for 5010 samples...
0.42273164 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 59 [0/25046 (0%)]	Loss: 0.248569
Train epoch: 59 [326140/25046 (41%)]	Loss: 0.202855
Train epoch: 59 [654920/25046 (82%)]	Loss: 0.200567
Make prediction for 5010 samples...
0.4508405 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 60 [0/25046 (0%)]	Loss: 0.232750
Train epoch: 60 [329380/25046 (41%)]	Loss: 0.216403
Train epoch: 60 [652760/25046 (82%)]	Loss: 0.227009
Make prediction for 5010 samples...
0.39234528 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 61 [0/25046 (0%)]	Loss: 0.191416
Train epoch: 61 [320460/25046 (41%)]	Loss: 0.305777
Train epoch: 61 [651400/25046 (82%)]	Loss: 0.217295
Make prediction for 5010 samples...
0.34763983 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 62 [0/25046 (0%)]	Loss: 0.176173
Train epoch: 62 [328860/25046 (41%)]	Loss: 0.211486
Train epoch: 62 [654200/25046 (82%)]	Loss: 0.241347
Make prediction for 5010 samples...
0.34142622 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 63 [0/25046 (0%)]	Loss: 0.165666
Train epoch: 63 [329500/25046 (41%)]	Loss: 0.205969
Train epoch: 63 [651080/25046 (82%)]	Loss: 0.319943
Make prediction for 5010 samples...
0.4114151 No improvement since epoch  51 ; best_mse,best_ci: 0.31849515 0.8608179301326777 GINConvNet davis
Training on 25046 samples...
Train epoch: 64 [0/25046 (0%)]	Loss: 0.206491
Train epoch: 64 [331240/25046 (41%)]	Loss: 0.196363
Train epoch: 64 [653720/25046 (82%)]	Loss: 0.204958
Make prediction for 5010 samples...
rmse improved at epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 65 [0/25046 (0%)]	Loss: 0.214130
Train epoch: 65 [328600/25046 (41%)]	Loss: 0.226469
Train epoch: 65 [662160/25046 (82%)]	Loss: 0.190806
Make prediction for 5010 samples...
0.36544234 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 66 [0/25046 (0%)]	Loss: 0.176143
Train epoch: 66 [330300/25046 (41%)]	Loss: 0.194861
Train epoch: 66 [655920/25046 (82%)]	Loss: 0.249452
Make prediction for 5010 samples...
0.4024282 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 67 [0/25046 (0%)]	Loss: 0.183365
Train epoch: 67 [331860/25046 (41%)]	Loss: 0.204109
Train epoch: 67 [665880/25046 (82%)]	Loss: 0.198796
Make prediction for 5010 samples...
0.33446512 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 68 [0/25046 (0%)]	Loss: 0.201649
Train epoch: 68 [328960/25046 (41%)]	Loss: 0.234265
Train epoch: 68 [668680/25046 (82%)]	Loss: 0.241200
Make prediction for 5010 samples...
0.40520632 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 69 [0/25046 (0%)]	Loss: 0.190266
Train epoch: 69 [326720/25046 (41%)]	Loss: 0.225402
Train epoch: 69 [658840/25046 (82%)]	Loss: 0.248560
Make prediction for 5010 samples...
0.38375816 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 70 [0/25046 (0%)]	Loss: 0.227901
Train epoch: 70 [327220/25046 (41%)]	Loss: 0.200246
Train epoch: 70 [657960/25046 (82%)]	Loss: 0.224478
Make prediction for 5010 samples...
0.29855868 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 71 [0/25046 (0%)]	Loss: 0.201716
Train epoch: 71 [322680/25046 (41%)]	Loss: 0.203038
Train epoch: 71 [658240/25046 (82%)]	Loss: 0.314048
Make prediction for 5010 samples...
0.2946004 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 72 [0/25046 (0%)]	Loss: 0.217383
Train epoch: 72 [333280/25046 (41%)]	Loss: 0.209319
Train epoch: 72 [653440/25046 (82%)]	Loss: 0.192921
Make prediction for 5010 samples...
0.34629428 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 73 [0/25046 (0%)]	Loss: 0.192525
Train epoch: 73 [332260/25046 (41%)]	Loss: 0.183252
Train epoch: 73 [649920/25046 (82%)]	Loss: 0.211378
Make prediction for 5010 samples...
0.3583135 No improvement since epoch  64 ; best_mse,best_ci: 0.28285986 0.8735690373115093 GINConvNet davis
Training on 25046 samples...
Train epoch: 74 [0/25046 (0%)]	Loss: 0.180390
Train epoch: 74 [324420/25046 (41%)]	Loss: 0.215553
Train epoch: 74 [649120/25046 (82%)]	Loss: 0.169695
Make prediction for 5010 samples...
rmse improved at epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 75 [0/25046 (0%)]	Loss: 0.196200
Train epoch: 75 [329080/25046 (41%)]	Loss: 0.169839
Train epoch: 75 [656000/25046 (82%)]	Loss: 0.190900
Make prediction for 5010 samples...
0.31101367 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 76 [0/25046 (0%)]	Loss: 0.154808
Train epoch: 76 [327520/25046 (41%)]	Loss: 0.208698
Train epoch: 76 [649480/25046 (82%)]	Loss: 0.191397
Make prediction for 5010 samples...
0.28614447 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 77 [0/25046 (0%)]	Loss: 0.210791
Train epoch: 77 [325840/25046 (41%)]	Loss: 0.174057
Train epoch: 77 [666760/25046 (82%)]	Loss: 0.219073
Make prediction for 5010 samples...
0.31515393 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 78 [0/25046 (0%)]	Loss: 0.191342
Train epoch: 78 [325060/25046 (41%)]	Loss: 0.179301
Train epoch: 78 [653760/25046 (82%)]	Loss: 0.187738
Make prediction for 5010 samples...
0.35245168 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 79 [0/25046 (0%)]	Loss: 0.163195
Train epoch: 79 [332180/25046 (41%)]	Loss: 0.222784
Train epoch: 79 [661160/25046 (82%)]	Loss: 0.235326
Make prediction for 5010 samples...
0.34019485 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 80 [0/25046 (0%)]	Loss: 0.189460
Train epoch: 80 [327940/25046 (41%)]	Loss: 0.184572
Train epoch: 80 [650040/25046 (82%)]	Loss: 0.196417
Make prediction for 5010 samples...
0.34888834 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 81 [0/25046 (0%)]	Loss: 0.227132
Train epoch: 81 [332400/25046 (41%)]	Loss: 0.174873
Train epoch: 81 [657880/25046 (82%)]	Loss: 0.166037
Make prediction for 5010 samples...
0.30199766 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 82 [0/25046 (0%)]	Loss: 0.143745
Train epoch: 82 [331200/25046 (41%)]	Loss: 0.177898
Train epoch: 82 [657000/25046 (82%)]	Loss: 0.216580
Make prediction for 5010 samples...
0.31246972 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 83 [0/25046 (0%)]	Loss: 0.170483
Train epoch: 83 [326200/25046 (41%)]	Loss: 0.198014
Train epoch: 83 [649960/25046 (82%)]	Loss: 0.178632
Make prediction for 5010 samples...
0.3094168 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 84 [0/25046 (0%)]	Loss: 0.145013
Train epoch: 84 [324480/25046 (41%)]	Loss: 0.188120
Train epoch: 84 [652760/25046 (82%)]	Loss: 0.208457
Make prediction for 5010 samples...
0.2846259 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 85 [0/25046 (0%)]	Loss: 0.151298
Train epoch: 85 [330200/25046 (41%)]	Loss: 0.160615
Train epoch: 85 [663960/25046 (82%)]	Loss: 0.185874
Make prediction for 5010 samples...
0.3255778 No improvement since epoch  74 ; best_mse,best_ci: 0.26971775 0.8739921980974459 GINConvNet davis
Training on 25046 samples...
Train epoch: 86 [0/25046 (0%)]	Loss: 0.184510
Train epoch: 86 [328780/25046 (41%)]	Loss: 0.194260
Train epoch: 86 [657960/25046 (82%)]	Loss: 0.193040
Make prediction for 5010 samples...
rmse improved at epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 87 [0/25046 (0%)]	Loss: 0.246997
Train epoch: 87 [328520/25046 (41%)]	Loss: 0.237722
Train epoch: 87 [654600/25046 (82%)]	Loss: 0.183515
Make prediction for 5010 samples...
0.30670556 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 88 [0/25046 (0%)]	Loss: 0.197577
Train epoch: 88 [327520/25046 (41%)]	Loss: 0.186859
Train epoch: 88 [664200/25046 (82%)]	Loss: 0.204191
Make prediction for 5010 samples...
0.30554247 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 89 [0/25046 (0%)]	Loss: 0.146264
Train epoch: 89 [330800/25046 (41%)]	Loss: 0.210662
Train epoch: 89 [656280/25046 (82%)]	Loss: 0.177591
Make prediction for 5010 samples...
0.3120731 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 90 [0/25046 (0%)]	Loss: 0.159870
Train epoch: 90 [328140/25046 (41%)]	Loss: 0.150068
Train epoch: 90 [662960/25046 (82%)]	Loss: 0.190730
Make prediction for 5010 samples...
0.30447683 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 91 [0/25046 (0%)]	Loss: 0.166138
Train epoch: 91 [330520/25046 (41%)]	Loss: 0.163294
Train epoch: 91 [653520/25046 (82%)]	Loss: 0.216727
Make prediction for 5010 samples...
0.37176424 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 92 [0/25046 (0%)]	Loss: 0.211316
Train epoch: 92 [326780/25046 (41%)]	Loss: 0.211789
Train epoch: 92 [656680/25046 (82%)]	Loss: 0.176590
Make prediction for 5010 samples...
0.32239336 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 93 [0/25046 (0%)]	Loss: 0.163402
Train epoch: 93 [333060/25046 (41%)]	Loss: 0.198940
Train epoch: 93 [652520/25046 (82%)]	Loss: 0.190003
Make prediction for 5010 samples...
0.36204648 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 94 [0/25046 (0%)]	Loss: 0.205043
Train epoch: 94 [322140/25046 (41%)]	Loss: 0.164716
Train epoch: 94 [656200/25046 (82%)]	Loss: 0.185061
Make prediction for 5010 samples...
0.2750789 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 95 [0/25046 (0%)]	Loss: 0.175303
Train epoch: 95 [329760/25046 (41%)]	Loss: 0.229181
Train epoch: 95 [645680/25046 (82%)]	Loss: 0.174380
Make prediction for 5010 samples...
0.2942341 No improvement since epoch  86 ; best_mse,best_ci: 0.2652736 0.8675192011312468 GINConvNet davis
Training on 25046 samples...
Train epoch: 96 [0/25046 (0%)]	Loss: 0.146555
Train epoch: 96 [327020/25046 (41%)]	Loss: 0.167262
Train epoch: 96 [657560/25046 (82%)]	Loss: 0.178745
Make prediction for 5010 samples...
rmse improved at epoch  96 ; best_mse,best_ci: 0.2579199 0.8708193345425246 GINConvNet davis
Training on 25046 samples...
Train epoch: 97 [0/25046 (0%)]	Loss: 0.202441
Train epoch: 97 [330280/25046 (41%)]	Loss: 0.158232
Train epoch: 97 [658400/25046 (82%)]	Loss: 0.174811
Make prediction for 5010 samples...
0.32667276 No improvement since epoch  96 ; best_mse,best_ci: 0.2579199 0.8708193345425246 GINConvNet davis
Training on 25046 samples...
Train epoch: 98 [0/25046 (0%)]	Loss: 0.185955
Train epoch: 98 [330900/25046 (41%)]	Loss: 0.224483
Train epoch: 98 [647560/25046 (82%)]	Loss: 0.179848
Make prediction for 5010 samples...
0.27052274 No improvement since epoch  96 ; best_mse,best_ci: 0.2579199 0.8708193345425246 GINConvNet davis
Training on 25046 samples...
Train epoch: 99 [0/25046 (0%)]	Loss: 0.176368
Train epoch: 99 [329440/25046 (41%)]	Loss: 0.202776
Train epoch: 99 [652600/25046 (82%)]	Loss: 0.186229
Make prediction for 5010 samples...
0.41439953 No improvement since epoch  96 ; best_mse,best_ci: 0.2579199 0.8708193345425246 GINConvNet davis
Training on 25046 samples...
Train epoch: 100 [0/25046 (0%)]	Loss: 0.209953
Train epoch: 100 [331940/25046 (41%)]	Loss: 0.209580
Train epoch: 100 [660640/25046 (82%)]	Loss: 0.165275
Make prediction for 5010 samples...
0.3393752 No improvement since epoch  96 ; best_mse,best_ci: 0.2579199 0.8708193345425246 GINConvNet davis
Training on 25046 samples...
Train epoch: 101 [0/25046 (0%)]	Loss: 0.193074
Train epoch: 101 [324960/25046 (41%)]	Loss: 0.208238
Train epoch: 101 [656840/25046 (82%)]	Loss: 0.157796
Make prediction for 5010 samples...
rmse improved at epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 102 [0/25046 (0%)]	Loss: 0.178472
Train epoch: 102 [325300/25046 (41%)]	Loss: 0.203080
Train epoch: 102 [652240/25046 (82%)]	Loss: 0.208528
Make prediction for 5010 samples...
0.28188077 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 103 [0/25046 (0%)]	Loss: 0.185040
Train epoch: 103 [335080/25046 (41%)]	Loss: 0.181989
Train epoch: 103 [663120/25046 (82%)]	Loss: 0.168015
Make prediction for 5010 samples...
0.260787 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 104 [0/25046 (0%)]	Loss: 0.176704
Train epoch: 104 [325780/25046 (41%)]	Loss: 0.198164
Train epoch: 104 [660240/25046 (82%)]	Loss: 0.192719
Make prediction for 5010 samples...
0.2685247 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 105 [0/25046 (0%)]	Loss: 0.183380
Train epoch: 105 [326360/25046 (41%)]	Loss: 0.178750
Train epoch: 105 [660400/25046 (82%)]	Loss: 0.191622
Make prediction for 5010 samples...
0.30819696 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 106 [0/25046 (0%)]	Loss: 0.146996
Train epoch: 106 [328020/25046 (41%)]	Loss: 0.199778
Train epoch: 106 [655120/25046 (82%)]	Loss: 0.175550
Make prediction for 5010 samples...
0.27803686 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 107 [0/25046 (0%)]	Loss: 0.170878
Train epoch: 107 [330580/25046 (41%)]	Loss: 0.176743
Train epoch: 107 [641640/25046 (82%)]	Loss: 0.150939
Make prediction for 5010 samples...
0.25792384 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 108 [0/25046 (0%)]	Loss: 0.232683
Train epoch: 108 [332880/25046 (41%)]	Loss: 0.179743
Train epoch: 108 [657080/25046 (82%)]	Loss: 0.156759
Make prediction for 5010 samples...
0.3151135 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 109 [0/25046 (0%)]	Loss: 0.187732
Train epoch: 109 [324600/25046 (41%)]	Loss: 0.153652
Train epoch: 109 [651320/25046 (82%)]	Loss: 0.225420
Make prediction for 5010 samples...
0.32840842 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 110 [0/25046 (0%)]	Loss: 0.161360
Train epoch: 110 [328880/25046 (41%)]	Loss: 0.202873
Train epoch: 110 [661280/25046 (82%)]	Loss: 0.160151
Make prediction for 5010 samples...
0.26500964 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 111 [0/25046 (0%)]	Loss: 0.179466
Train epoch: 111 [324980/25046 (41%)]	Loss: 0.172510
Train epoch: 111 [655280/25046 (82%)]	Loss: 0.165512
Make prediction for 5010 samples...
0.2869453 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 112 [0/25046 (0%)]	Loss: 0.187850
Train epoch: 112 [332800/25046 (41%)]	Loss: 0.214654
Train epoch: 112 [647720/25046 (82%)]	Loss: 0.224096
Make prediction for 5010 samples...
0.25720912 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 113 [0/25046 (0%)]	Loss: 0.156245
Train epoch: 113 [330240/25046 (41%)]	Loss: 0.169968
Train epoch: 113 [659320/25046 (82%)]	Loss: 0.165061
Make prediction for 5010 samples...
0.267961 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 114 [0/25046 (0%)]	Loss: 0.159030
Train epoch: 114 [329080/25046 (41%)]	Loss: 0.268864
Train epoch: 114 [663920/25046 (82%)]	Loss: 0.172624
Make prediction for 5010 samples...
0.3204295 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 115 [0/25046 (0%)]	Loss: 0.173869
Train epoch: 115 [326860/25046 (41%)]	Loss: 0.160746
Train epoch: 115 [653120/25046 (82%)]	Loss: 0.176247
Make prediction for 5010 samples...
0.28800923 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 116 [0/25046 (0%)]	Loss: 0.147476
Train epoch: 116 [325940/25046 (41%)]	Loss: 0.128208
Train epoch: 116 [658240/25046 (82%)]	Loss: 0.185260
Make prediction for 5010 samples...
0.29365197 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 117 [0/25046 (0%)]	Loss: 0.134773
Train epoch: 117 [327740/25046 (41%)]	Loss: 0.220968
Train epoch: 117 [649840/25046 (82%)]	Loss: 0.170015
Make prediction for 5010 samples...
0.26419833 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 118 [0/25046 (0%)]	Loss: 0.164664
Train epoch: 118 [330480/25046 (41%)]	Loss: 0.173204
Train epoch: 118 [657760/25046 (82%)]	Loss: 0.167241
Make prediction for 5010 samples...
0.28591207 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 119 [0/25046 (0%)]	Loss: 0.170901
Train epoch: 119 [321620/25046 (41%)]	Loss: 0.149708
Train epoch: 119 [661320/25046 (82%)]	Loss: 0.163012
Make prediction for 5010 samples...
0.2584698 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 120 [0/25046 (0%)]	Loss: 0.167397
Train epoch: 120 [327420/25046 (41%)]	Loss: 0.193480
Train epoch: 120 [648760/25046 (82%)]	Loss: 0.190072
Make prediction for 5010 samples...
0.30171815 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 121 [0/25046 (0%)]	Loss: 0.154167
Train epoch: 121 [332320/25046 (41%)]	Loss: 0.151812
Train epoch: 121 [651840/25046 (82%)]	Loss: 0.189365
Make prediction for 5010 samples...
0.27785778 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 122 [0/25046 (0%)]	Loss: 0.141021
Train epoch: 122 [334100/25046 (41%)]	Loss: 0.187262
Train epoch: 122 [662760/25046 (82%)]	Loss: 0.166148
Make prediction for 5010 samples...
0.27467078 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 123 [0/25046 (0%)]	Loss: 0.145533
Train epoch: 123 [327340/25046 (41%)]	Loss: 0.197643
Train epoch: 123 [653960/25046 (82%)]	Loss: 0.176530
Make prediction for 5010 samples...
0.26339856 No improvement since epoch  101 ; best_mse,best_ci: 0.25671655 0.8814403180184252 GINConvNet davis
Training on 25046 samples...
Train epoch: 124 [0/25046 (0%)]	Loss: 0.164629
Train epoch: 124 [329540/25046 (41%)]	Loss: 0.175737
Train epoch: 124 [658760/25046 (82%)]	Loss: 0.164776
Make prediction for 5010 samples...
rmse improved at epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 125 [0/25046 (0%)]	Loss: 0.183490
Train epoch: 125 [326780/25046 (41%)]	Loss: 0.137894
Train epoch: 125 [659200/25046 (82%)]	Loss: 0.201192
Make prediction for 5010 samples...
0.28869912 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 126 [0/25046 (0%)]	Loss: 0.132173
Train epoch: 126 [330260/25046 (41%)]	Loss: 0.185587
Train epoch: 126 [656640/25046 (82%)]	Loss: 0.203705
Make prediction for 5010 samples...
0.26932833 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 127 [0/25046 (0%)]	Loss: 0.160004
Train epoch: 127 [325840/25046 (41%)]	Loss: 0.153755
Train epoch: 127 [661120/25046 (82%)]	Loss: 0.177114
Make prediction for 5010 samples...
0.2625587 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 128 [0/25046 (0%)]	Loss: 0.132357
Train epoch: 128 [329260/25046 (41%)]	Loss: 0.145065
Train epoch: 128 [662440/25046 (82%)]	Loss: 0.191914
Make prediction for 5010 samples...
0.27483284 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 129 [0/25046 (0%)]	Loss: 0.150707
Train epoch: 129 [327120/25046 (41%)]	Loss: 0.182370
Train epoch: 129 [648160/25046 (82%)]	Loss: 0.172890
Make prediction for 5010 samples...
0.26263314 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 130 [0/25046 (0%)]	Loss: 0.189188
Train epoch: 130 [326940/25046 (41%)]	Loss: 0.156616
Train epoch: 130 [650960/25046 (82%)]	Loss: 0.164694
Make prediction for 5010 samples...
0.26333284 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 131 [0/25046 (0%)]	Loss: 0.202175
Train epoch: 131 [327480/25046 (41%)]	Loss: 0.158253
Train epoch: 131 [653000/25046 (82%)]	Loss: 0.217475
Make prediction for 5010 samples...
0.27727982 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 132 [0/25046 (0%)]	Loss: 0.152776
Train epoch: 132 [326040/25046 (41%)]	Loss: 0.187443
Train epoch: 132 [654000/25046 (82%)]	Loss: 0.175817
Make prediction for 5010 samples...
0.2587875 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 133 [0/25046 (0%)]	Loss: 0.166429
Train epoch: 133 [331160/25046 (41%)]	Loss: 0.162612
Train epoch: 133 [650920/25046 (82%)]	Loss: 0.186882
Make prediction for 5010 samples...
0.26261458 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 134 [0/25046 (0%)]	Loss: 0.165931
Train epoch: 134 [326360/25046 (41%)]	Loss: 0.194903
Train epoch: 134 [655200/25046 (82%)]	Loss: 0.135506
Make prediction for 5010 samples...
0.27269977 No improvement since epoch  124 ; best_mse,best_ci: 0.25261256 0.8813295886488153 GINConvNet davis
Training on 25046 samples...
Train epoch: 135 [0/25046 (0%)]	Loss: 0.134719
Train epoch: 135 [324720/25046 (41%)]	Loss: 0.183664
Train epoch: 135 [664800/25046 (82%)]	Loss: 0.199195
Make prediction for 5010 samples...
rmse improved at epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 136 [0/25046 (0%)]	Loss: 0.211380
Train epoch: 136 [325520/25046 (41%)]	Loss: 0.187180
Train epoch: 136 [655320/25046 (82%)]	Loss: 0.144404
Make prediction for 5010 samples...
0.26389456 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 137 [0/25046 (0%)]	Loss: 0.159588
Train epoch: 137 [331380/25046 (41%)]	Loss: 0.203630
Train epoch: 137 [664640/25046 (82%)]	Loss: 0.158086
Make prediction for 5010 samples...
0.25420696 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 138 [0/25046 (0%)]	Loss: 0.169142
Train epoch: 138 [322840/25046 (41%)]	Loss: 0.157866
Train epoch: 138 [648000/25046 (82%)]	Loss: 0.162424
Make prediction for 5010 samples...
0.3145019 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 139 [0/25046 (0%)]	Loss: 0.151623
Train epoch: 139 [321960/25046 (41%)]	Loss: 0.159879
Train epoch: 139 [653080/25046 (82%)]	Loss: 0.162650
Make prediction for 5010 samples...
0.27367657 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 140 [0/25046 (0%)]	Loss: 0.119944
Train epoch: 140 [330840/25046 (41%)]	Loss: 0.159371
Train epoch: 140 [657160/25046 (82%)]	Loss: 0.211033
Make prediction for 5010 samples...
0.26802626 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 141 [0/25046 (0%)]	Loss: 0.139933
Train epoch: 141 [331100/25046 (41%)]	Loss: 0.159426
Train epoch: 141 [656600/25046 (82%)]	Loss: 0.161633
Make prediction for 5010 samples...
0.26361287 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 142 [0/25046 (0%)]	Loss: 0.148578
Train epoch: 142 [324760/25046 (41%)]	Loss: 0.180472
Train epoch: 142 [652640/25046 (82%)]	Loss: 0.146526
Make prediction for 5010 samples...
0.27888238 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 143 [0/25046 (0%)]	Loss: 0.159817
Train epoch: 143 [334700/25046 (41%)]	Loss: 0.182331
Train epoch: 143 [666800/25046 (82%)]	Loss: 0.149730
Make prediction for 5010 samples...
0.25716057 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 144 [0/25046 (0%)]	Loss: 0.136461
Train epoch: 144 [329800/25046 (41%)]	Loss: 0.161172
Train epoch: 144 [656480/25046 (82%)]	Loss: 0.162483
Make prediction for 5010 samples...
0.2540205 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 145 [0/25046 (0%)]	Loss: 0.200270
Train epoch: 145 [330460/25046 (41%)]	Loss: 0.137817
Train epoch: 145 [653080/25046 (82%)]	Loss: 0.161782
Make prediction for 5010 samples...
0.27991036 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 146 [0/25046 (0%)]	Loss: 0.152624
Train epoch: 146 [330480/25046 (41%)]	Loss: 0.130314
Train epoch: 146 [668480/25046 (82%)]	Loss: 0.164368
Make prediction for 5010 samples...
0.262814 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 147 [0/25046 (0%)]	Loss: 0.145294
Train epoch: 147 [327600/25046 (41%)]	Loss: 0.145942
Train epoch: 147 [657200/25046 (82%)]	Loss: 0.215073
Make prediction for 5010 samples...
0.31688833 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 148 [0/25046 (0%)]	Loss: 0.190482
Train epoch: 148 [330800/25046 (41%)]	Loss: 0.165910
Train epoch: 148 [655920/25046 (82%)]	Loss: 0.159832
Make prediction for 5010 samples...
0.2930312 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 149 [0/25046 (0%)]	Loss: 0.150745
Train epoch: 149 [331940/25046 (41%)]	Loss: 0.182095
Train epoch: 149 [650600/25046 (82%)]	Loss: 0.170488
Make prediction for 5010 samples...
0.32546744 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 150 [0/25046 (0%)]	Loss: 0.153823
Train epoch: 150 [330560/25046 (41%)]	Loss: 0.162228
Train epoch: 150 [652400/25046 (82%)]	Loss: 0.138337
Make prediction for 5010 samples...
0.25510034 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 151 [0/25046 (0%)]	Loss: 0.163937
Train epoch: 151 [325360/25046 (41%)]	Loss: 0.132638
Train epoch: 151 [654080/25046 (82%)]	Loss: 0.196762
Make prediction for 5010 samples...
0.3471082 No improvement since epoch  135 ; best_mse,best_ci: 0.25249848 0.875549147988807 GINConvNet davis
Training on 25046 samples...
Train epoch: 152 [0/25046 (0%)]	Loss: 0.206281
Train epoch: 152 [336040/25046 (41%)]	Loss: 0.144035
Train epoch: 152 [655480/25046 (82%)]	Loss: 0.171045
Make prediction for 5010 samples...
rmse improved at epoch  152 ; best_mse,best_ci: 0.25101298 0.87271360315666 GINConvNet davis
Training on 25046 samples...
Train epoch: 153 [0/25046 (0%)]	Loss: 0.150090
Train epoch: 153 [328800/25046 (41%)]	Loss: 0.189344
Train epoch: 153 [661520/25046 (82%)]	Loss: 0.143124
Make prediction for 5010 samples...
rmse improved at epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 154 [0/25046 (0%)]	Loss: 0.159719
Train epoch: 154 [332020/25046 (41%)]	Loss: 0.157461
Train epoch: 154 [659040/25046 (82%)]	Loss: 0.126705
Make prediction for 5010 samples...
0.2752212 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 155 [0/25046 (0%)]	Loss: 0.141106
Train epoch: 155 [327940/25046 (41%)]	Loss: 0.137441
Train epoch: 155 [658200/25046 (82%)]	Loss: 0.151437
Make prediction for 5010 samples...
0.26600486 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 156 [0/25046 (0%)]	Loss: 0.126966
Train epoch: 156 [331520/25046 (41%)]	Loss: 0.149622
Train epoch: 156 [661680/25046 (82%)]	Loss: 0.153468
Make prediction for 5010 samples...
0.28681898 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 157 [0/25046 (0%)]	Loss: 0.158808
Train epoch: 157 [331460/25046 (41%)]	Loss: 0.156067
Train epoch: 157 [646040/25046 (82%)]	Loss: 0.165391
Make prediction for 5010 samples...
0.28775266 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 158 [0/25046 (0%)]	Loss: 0.129864
Train epoch: 158 [328220/25046 (41%)]	Loss: 0.170539
Train epoch: 158 [652320/25046 (82%)]	Loss: 0.162798
Make prediction for 5010 samples...
0.32208392 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 159 [0/25046 (0%)]	Loss: 0.160578
Train epoch: 159 [334300/25046 (41%)]	Loss: 0.158188
Train epoch: 159 [667360/25046 (82%)]	Loss: 0.180696
Make prediction for 5010 samples...
0.27085567 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 160 [0/25046 (0%)]	Loss: 0.123661
Train epoch: 160 [327000/25046 (41%)]	Loss: 0.157454
Train epoch: 160 [659720/25046 (82%)]	Loss: 0.180182
Make prediction for 5010 samples...
0.27140608 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 161 [0/25046 (0%)]	Loss: 0.151520
Train epoch: 161 [323240/25046 (41%)]	Loss: 0.128502
Train epoch: 161 [646280/25046 (82%)]	Loss: 0.121946
Make prediction for 5010 samples...
0.26477733 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 162 [0/25046 (0%)]	Loss: 0.133877
Train epoch: 162 [331280/25046 (41%)]	Loss: 0.179477
Train epoch: 162 [658680/25046 (82%)]	Loss: 0.156060
Make prediction for 5010 samples...
0.2541613 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 163 [0/25046 (0%)]	Loss: 0.146359
Train epoch: 163 [334520/25046 (41%)]	Loss: 0.231921
Train epoch: 163 [659560/25046 (82%)]	Loss: 0.193320
Make prediction for 5010 samples...
0.2554493 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 164 [0/25046 (0%)]	Loss: 0.156052
Train epoch: 164 [329380/25046 (41%)]	Loss: 0.194650
Train epoch: 164 [664000/25046 (82%)]	Loss: 0.152373
Make prediction for 5010 samples...
0.25767353 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 165 [0/25046 (0%)]	Loss: 0.148783
Train epoch: 165 [330980/25046 (41%)]	Loss: 0.204407
Train epoch: 165 [652160/25046 (82%)]	Loss: 0.157652
Make prediction for 5010 samples...
0.26838648 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 166 [0/25046 (0%)]	Loss: 0.148777
Train epoch: 166 [331260/25046 (41%)]	Loss: 0.153280
Train epoch: 166 [655520/25046 (82%)]	Loss: 0.161856
Make prediction for 5010 samples...
0.28317302 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 167 [0/25046 (0%)]	Loss: 0.143306
Train epoch: 167 [329420/25046 (41%)]	Loss: 0.152439
Train epoch: 167 [647000/25046 (82%)]	Loss: 0.160135
Make prediction for 5010 samples...
0.32375625 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 168 [0/25046 (0%)]	Loss: 0.130668
Train epoch: 168 [326760/25046 (41%)]	Loss: 0.136028
Train epoch: 168 [666560/25046 (82%)]	Loss: 0.176553
Make prediction for 5010 samples...
0.26607248 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 169 [0/25046 (0%)]	Loss: 0.121386
Train epoch: 169 [332920/25046 (41%)]	Loss: 0.151721
Train epoch: 169 [659720/25046 (82%)]	Loss: 0.132987
Make prediction for 5010 samples...
0.25151598 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 170 [0/25046 (0%)]	Loss: 0.103955
Train epoch: 170 [332060/25046 (41%)]	Loss: 0.171104
Train epoch: 170 [651240/25046 (82%)]	Loss: 0.140266
Make prediction for 5010 samples...
0.29405683 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 171 [0/25046 (0%)]	Loss: 0.137830
Train epoch: 171 [328980/25046 (41%)]	Loss: 0.190083
Train epoch: 171 [649240/25046 (82%)]	Loss: 0.153134
Make prediction for 5010 samples...
0.45365316 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 172 [0/25046 (0%)]	Loss: 0.262738
Train epoch: 172 [328180/25046 (41%)]	Loss: 0.148962
Train epoch: 172 [654640/25046 (82%)]	Loss: 0.143716
Make prediction for 5010 samples...
0.27241588 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 173 [0/25046 (0%)]	Loss: 0.103887
Train epoch: 173 [330280/25046 (41%)]	Loss: 0.171512
Train epoch: 173 [648880/25046 (82%)]	Loss: 0.156128
Make prediction for 5010 samples...
0.33542326 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 174 [0/25046 (0%)]	Loss: 0.179992
Train epoch: 174 [330240/25046 (41%)]	Loss: 0.134441
Train epoch: 174 [650600/25046 (82%)]	Loss: 0.153981
Make prediction for 5010 samples...
0.2537563 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 175 [0/25046 (0%)]	Loss: 0.148628
Train epoch: 175 [329900/25046 (41%)]	Loss: 0.153223
Train epoch: 175 [655960/25046 (82%)]	Loss: 0.143214
Make prediction for 5010 samples...
0.25201702 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 176 [0/25046 (0%)]	Loss: 0.148680
Train epoch: 176 [332040/25046 (41%)]	Loss: 0.134356
Train epoch: 176 [657680/25046 (82%)]	Loss: 0.117916
Make prediction for 5010 samples...
0.26218897 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 177 [0/25046 (0%)]	Loss: 0.147792
Train epoch: 177 [325320/25046 (41%)]	Loss: 0.177561
Train epoch: 177 [665640/25046 (82%)]	Loss: 0.150859
Make prediction for 5010 samples...
0.26368278 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 178 [0/25046 (0%)]	Loss: 0.165515
Train epoch: 178 [332580/25046 (41%)]	Loss: 0.160319
Train epoch: 178 [664000/25046 (82%)]	Loss: 0.127295
Make prediction for 5010 samples...
0.3391088 No improvement since epoch  153 ; best_mse,best_ci: 0.2496771 0.8836467117435771 GINConvNet davis
Training on 25046 samples...
Train epoch: 179 [0/25046 (0%)]	Loss: 0.186595
Train epoch: 179 [327240/25046 (41%)]	Loss: 0.149903
Train epoch: 179 [658440/25046 (82%)]	Loss: 0.153908
Make prediction for 5010 samples...
rmse improved at epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 180 [0/25046 (0%)]	Loss: 0.141575
Train epoch: 180 [329300/25046 (41%)]	Loss: 0.144719
Train epoch: 180 [658000/25046 (82%)]	Loss: 0.164887
Make prediction for 5010 samples...
0.25673142 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 181 [0/25046 (0%)]	Loss: 0.141627
Train epoch: 181 [325100/25046 (41%)]	Loss: 0.131788
Train epoch: 181 [651360/25046 (82%)]	Loss: 0.130489
Make prediction for 5010 samples...
0.26961306 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 182 [0/25046 (0%)]	Loss: 0.158596
Train epoch: 182 [326540/25046 (41%)]	Loss: 0.157860
Train epoch: 182 [656440/25046 (82%)]	Loss: 0.137669
Make prediction for 5010 samples...
0.25567517 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 183 [0/25046 (0%)]	Loss: 0.138493
Train epoch: 183 [332200/25046 (41%)]	Loss: 0.180664
Train epoch: 183 [660760/25046 (82%)]	Loss: 0.160135
Make prediction for 5010 samples...
0.25811362 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 184 [0/25046 (0%)]	Loss: 0.114764
Train epoch: 184 [331320/25046 (41%)]	Loss: 0.140116
Train epoch: 184 [648880/25046 (82%)]	Loss: 0.162476
Make prediction for 5010 samples...
0.28127778 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 185 [0/25046 (0%)]	Loss: 0.163108
Train epoch: 185 [334760/25046 (41%)]	Loss: 0.142570
Train epoch: 185 [654520/25046 (82%)]	Loss: 0.121364
Make prediction for 5010 samples...
0.2512277 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 186 [0/25046 (0%)]	Loss: 0.151259
Train epoch: 186 [328880/25046 (41%)]	Loss: 0.155262
Train epoch: 186 [667280/25046 (82%)]	Loss: 0.143294
Make prediction for 5010 samples...
0.2693608 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 187 [0/25046 (0%)]	Loss: 0.147773
Train epoch: 187 [329640/25046 (41%)]	Loss: 0.162832
Train epoch: 187 [647720/25046 (82%)]	Loss: 0.144679
Make prediction for 5010 samples...
0.26711288 No improvement since epoch  179 ; best_mse,best_ci: 0.24451803 0.8802796506220372 GINConvNet davis
Training on 25046 samples...
Train epoch: 188 [0/25046 (0%)]	Loss: 0.134130
Train epoch: 188 [326740/25046 (41%)]	Loss: 0.159472
Train epoch: 188 [654440/25046 (82%)]	Loss: 0.200797
Make prediction for 5010 samples...
rmse improved at epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 189 [0/25046 (0%)]	Loss: 0.149792
Train epoch: 189 [326920/25046 (41%)]	Loss: 0.200022
Train epoch: 189 [656800/25046 (82%)]	Loss: 0.151940
Make prediction for 5010 samples...
0.3306848 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 190 [0/25046 (0%)]	Loss: 0.133634
Train epoch: 190 [334460/25046 (41%)]	Loss: 0.138251
Train epoch: 190 [648280/25046 (82%)]	Loss: 0.159869
Make prediction for 5010 samples...
0.2519082 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 191 [0/25046 (0%)]	Loss: 0.133442
Train epoch: 191 [328000/25046 (41%)]	Loss: 0.113722
Train epoch: 191 [651040/25046 (82%)]	Loss: 0.151180
Make prediction for 5010 samples...
0.25812113 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 192 [0/25046 (0%)]	Loss: 0.128664
Train epoch: 192 [325420/25046 (41%)]	Loss: 0.149609
Train epoch: 192 [655560/25046 (82%)]	Loss: 0.120209
Make prediction for 5010 samples...
0.25033286 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 193 [0/25046 (0%)]	Loss: 0.137221
Train epoch: 193 [325800/25046 (41%)]	Loss: 0.150667
Train epoch: 193 [642400/25046 (82%)]	Loss: 0.143657
Make prediction for 5010 samples...
0.24397767 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 194 [0/25046 (0%)]	Loss: 0.146891
Train epoch: 194 [329200/25046 (41%)]	Loss: 0.145425
Train epoch: 194 [661360/25046 (82%)]	Loss: 0.155808
Make prediction for 5010 samples...
0.2643898 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 195 [0/25046 (0%)]	Loss: 0.126601
Train epoch: 195 [328280/25046 (41%)]	Loss: 0.129240
Train epoch: 195 [662480/25046 (82%)]	Loss: 0.200116
Make prediction for 5010 samples...
0.26962522 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 196 [0/25046 (0%)]	Loss: 0.129784
Train epoch: 196 [332500/25046 (41%)]	Loss: 0.114542
Train epoch: 196 [663640/25046 (82%)]	Loss: 0.193468
Make prediction for 5010 samples...
0.3116616 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 197 [0/25046 (0%)]	Loss: 0.168957
Train epoch: 197 [324180/25046 (41%)]	Loss: 0.125909
Train epoch: 197 [654640/25046 (82%)]	Loss: 0.116399
Make prediction for 5010 samples...
0.2636666 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 198 [0/25046 (0%)]	Loss: 0.121396
Train epoch: 198 [330020/25046 (41%)]	Loss: 0.130314
Train epoch: 198 [660080/25046 (82%)]	Loss: 0.151207
Make prediction for 5010 samples...
0.2594998 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 199 [0/25046 (0%)]	Loss: 0.129127
Train epoch: 199 [330280/25046 (41%)]	Loss: 0.133676
Train epoch: 199 [652800/25046 (82%)]	Loss: 0.140648
Make prediction for 5010 samples...
0.2892566 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 200 [0/25046 (0%)]	Loss: 0.126901
Train epoch: 200 [326620/25046 (41%)]	Loss: 0.146367
Train epoch: 200 [666280/25046 (82%)]	Loss: 0.152685
Make prediction for 5010 samples...
0.25614777 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 201 [0/25046 (0%)]	Loss: 0.130868
Train epoch: 201 [324780/25046 (41%)]	Loss: 0.136943
Train epoch: 201 [661480/25046 (82%)]	Loss: 0.129803
Make prediction for 5010 samples...
0.24553123 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 202 [0/25046 (0%)]	Loss: 0.156635
Train epoch: 202 [327300/25046 (41%)]	Loss: 0.168328
Train epoch: 202 [669800/25046 (82%)]	Loss: 0.126631
Make prediction for 5010 samples...
0.2789565 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 203 [0/25046 (0%)]	Loss: 0.108907
Train epoch: 203 [326080/25046 (41%)]	Loss: 0.149524
Train epoch: 203 [660600/25046 (82%)]	Loss: 0.142370
Make prediction for 5010 samples...
0.25074983 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 204 [0/25046 (0%)]	Loss: 0.123250
Train epoch: 204 [327980/25046 (41%)]	Loss: 0.149542
Train epoch: 204 [642840/25046 (82%)]	Loss: 0.128675
Make prediction for 5010 samples...
0.24450813 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 205 [0/25046 (0%)]	Loss: 0.141498
Train epoch: 205 [326560/25046 (41%)]	Loss: 0.145268
Train epoch: 205 [659320/25046 (82%)]	Loss: 0.133648
Make prediction for 5010 samples...
0.26284707 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 206 [0/25046 (0%)]	Loss: 0.123987
Train epoch: 206 [330840/25046 (41%)]	Loss: 0.141373
Train epoch: 206 [656440/25046 (82%)]	Loss: 0.132577
Make prediction for 5010 samples...
0.2593684 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 207 [0/25046 (0%)]	Loss: 0.149007
Train epoch: 207 [329660/25046 (41%)]	Loss: 0.149853
Train epoch: 207 [645000/25046 (82%)]	Loss: 0.240777
Make prediction for 5010 samples...
0.25120887 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 208 [0/25046 (0%)]	Loss: 0.143549
Train epoch: 208 [333260/25046 (41%)]	Loss: 0.134687
Train epoch: 208 [669600/25046 (82%)]	Loss: 0.138982
Make prediction for 5010 samples...
0.28062344 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 209 [0/25046 (0%)]	Loss: 0.140617
Train epoch: 209 [333140/25046 (41%)]	Loss: 0.155488
Train epoch: 209 [669400/25046 (82%)]	Loss: 0.130640
Make prediction for 5010 samples...
0.25580987 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 210 [0/25046 (0%)]	Loss: 0.126647
Train epoch: 210 [325800/25046 (41%)]	Loss: 0.153781
Train epoch: 210 [655600/25046 (82%)]	Loss: 0.148485
Make prediction for 5010 samples...
0.24522415 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 211 [0/25046 (0%)]	Loss: 0.156994
Train epoch: 211 [326460/25046 (41%)]	Loss: 0.117913
Train epoch: 211 [654560/25046 (82%)]	Loss: 0.127547
Make prediction for 5010 samples...
0.25447273 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 212 [0/25046 (0%)]	Loss: 0.132967
Train epoch: 212 [326360/25046 (41%)]	Loss: 0.128507
Train epoch: 212 [660440/25046 (82%)]	Loss: 0.170517
Make prediction for 5010 samples...
0.24943891 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 213 [0/25046 (0%)]	Loss: 0.149159
Train epoch: 213 [330980/25046 (41%)]	Loss: 0.145798
Train epoch: 213 [652520/25046 (82%)]	Loss: 0.132418
Make prediction for 5010 samples...
0.24802661 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 214 [0/25046 (0%)]	Loss: 0.160936
Train epoch: 214 [330760/25046 (41%)]	Loss: 0.132078
Train epoch: 214 [639320/25046 (82%)]	Loss: 0.126778
Make prediction for 5010 samples...
0.24773787 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 215 [0/25046 (0%)]	Loss: 0.121830
Train epoch: 215 [331540/25046 (41%)]	Loss: 0.116155
Train epoch: 215 [656600/25046 (82%)]	Loss: 0.139108
Make prediction for 5010 samples...
0.24673636 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 216 [0/25046 (0%)]	Loss: 0.120414
Train epoch: 216 [329900/25046 (41%)]	Loss: 0.128252
Train epoch: 216 [658040/25046 (82%)]	Loss: 0.114776
Make prediction for 5010 samples...
0.2488039 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 217 [0/25046 (0%)]	Loss: 0.110933
Train epoch: 217 [325340/25046 (41%)]	Loss: 0.169688
Train epoch: 217 [656760/25046 (82%)]	Loss: 0.133287
Make prediction for 5010 samples...
0.28893024 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 218 [0/25046 (0%)]	Loss: 0.147658
Train epoch: 218 [334640/25046 (41%)]	Loss: 0.154258
Train epoch: 218 [657640/25046 (82%)]	Loss: 0.145406
Make prediction for 5010 samples...
0.2552708 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 219 [0/25046 (0%)]	Loss: 0.136573
Train epoch: 219 [328060/25046 (41%)]	Loss: 0.147848
Train epoch: 219 [669280/25046 (82%)]	Loss: 0.130360
Make prediction for 5010 samples...
0.26662567 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 220 [0/25046 (0%)]	Loss: 0.147733
Train epoch: 220 [328860/25046 (41%)]	Loss: 0.130847
Train epoch: 220 [653480/25046 (82%)]	Loss: 0.136019
Make prediction for 5010 samples...
0.2663451 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 221 [0/25046 (0%)]	Loss: 0.137834
Train epoch: 221 [330580/25046 (41%)]	Loss: 0.116389
Train epoch: 221 [664400/25046 (82%)]	Loss: 0.135571
Make prediction for 5010 samples...
0.24783556 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 222 [0/25046 (0%)]	Loss: 0.137385
Train epoch: 222 [328500/25046 (41%)]	Loss: 0.137265
Train epoch: 222 [661360/25046 (82%)]	Loss: 0.143708
Make prediction for 5010 samples...
0.25203407 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 223 [0/25046 (0%)]	Loss: 0.154926
Train epoch: 223 [331160/25046 (41%)]	Loss: 0.152021
Train epoch: 223 [660280/25046 (82%)]	Loss: 0.160552
Make prediction for 5010 samples...
0.2490468 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 224 [0/25046 (0%)]	Loss: 0.119073
Train epoch: 224 [330280/25046 (41%)]	Loss: 0.164997
Train epoch: 224 [648880/25046 (82%)]	Loss: 0.109788
Make prediction for 5010 samples...
0.26024634 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 225 [0/25046 (0%)]	Loss: 0.124652
Train epoch: 225 [328180/25046 (41%)]	Loss: 0.140014
Train epoch: 225 [662000/25046 (82%)]	Loss: 0.099827
Make prediction for 5010 samples...
0.25092798 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 226 [0/25046 (0%)]	Loss: 0.143333
Train epoch: 226 [330920/25046 (41%)]	Loss: 0.130334
Train epoch: 226 [653520/25046 (82%)]	Loss: 0.159828
Make prediction for 5010 samples...
0.2908764 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 227 [0/25046 (0%)]	Loss: 0.124483
Train epoch: 227 [326000/25046 (41%)]	Loss: 0.143630
Train epoch: 227 [648440/25046 (82%)]	Loss: 0.117973
Make prediction for 5010 samples...
0.246086 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 228 [0/25046 (0%)]	Loss: 0.139476
Train epoch: 228 [331680/25046 (41%)]	Loss: 0.116035
Train epoch: 228 [647720/25046 (82%)]	Loss: 0.167289
Make prediction for 5010 samples...
0.27626017 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 229 [0/25046 (0%)]	Loss: 0.111310
Train epoch: 229 [330340/25046 (41%)]	Loss: 0.112402
Train epoch: 229 [660920/25046 (82%)]	Loss: 0.170061
Make prediction for 5010 samples...
0.24402975 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 230 [0/25046 (0%)]	Loss: 0.124696
Train epoch: 230 [326160/25046 (41%)]	Loss: 0.120807
Train epoch: 230 [660760/25046 (82%)]	Loss: 0.163864
Make prediction for 5010 samples...
0.25405595 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 231 [0/25046 (0%)]	Loss: 0.141053
Train epoch: 231 [331700/25046 (41%)]	Loss: 0.159546
Train epoch: 231 [666560/25046 (82%)]	Loss: 0.149378
Make prediction for 5010 samples...
0.24236488 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 232 [0/25046 (0%)]	Loss: 0.140778
Train epoch: 232 [331680/25046 (41%)]	Loss: 0.142658
Train epoch: 232 [658600/25046 (82%)]	Loss: 0.119668
Make prediction for 5010 samples...
0.2664725 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 233 [0/25046 (0%)]	Loss: 0.135427
Train epoch: 233 [326020/25046 (41%)]	Loss: 0.119751
Train epoch: 233 [650880/25046 (82%)]	Loss: 0.146523
Make prediction for 5010 samples...
0.30247828 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 234 [0/25046 (0%)]	Loss: 0.156547
Train epoch: 234 [327340/25046 (41%)]	Loss: 0.146834
Train epoch: 234 [655440/25046 (82%)]	Loss: 0.140078
Make prediction for 5010 samples...
0.27598193 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 235 [0/25046 (0%)]	Loss: 0.136914
Train epoch: 235 [334320/25046 (41%)]	Loss: 0.117693
Train epoch: 235 [657520/25046 (82%)]	Loss: 0.138100
Make prediction for 5010 samples...
0.2537644 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 236 [0/25046 (0%)]	Loss: 0.170430
Train epoch: 236 [324760/25046 (41%)]	Loss: 0.129716
Train epoch: 236 [659200/25046 (82%)]	Loss: 0.120591
Make prediction for 5010 samples...
0.24770755 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 237 [0/25046 (0%)]	Loss: 0.141633
Train epoch: 237 [332920/25046 (41%)]	Loss: 0.161818
Train epoch: 237 [659440/25046 (82%)]	Loss: 0.124315
Make prediction for 5010 samples...
0.24463639 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 238 [0/25046 (0%)]	Loss: 0.200418
Train epoch: 238 [326800/25046 (41%)]	Loss: 0.117544
Train epoch: 238 [645640/25046 (82%)]	Loss: 0.116392
Make prediction for 5010 samples...
0.24607499 No improvement since epoch  188 ; best_mse,best_ci: 0.24130319 0.8871967137115887 GINConvNet davis
Training on 25046 samples...
Train epoch: 239 [0/25046 (0%)]	Loss: 0.141192
Train epoch: 239 [328920/25046 (41%)]	Loss: 0.141451
Train epoch: 239 [651800/25046 (82%)]	Loss: 0.130411
Make prediction for 5010 samples...
rmse improved at epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 240 [0/25046 (0%)]	Loss: 0.134373
Train epoch: 240 [323500/25046 (41%)]	Loss: 0.132619
Train epoch: 240 [658680/25046 (82%)]	Loss: 0.131768
Make prediction for 5010 samples...
0.24515094 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 241 [0/25046 (0%)]	Loss: 0.118036
Train epoch: 241 [329900/25046 (41%)]	Loss: 0.119891
Train epoch: 241 [661560/25046 (82%)]	Loss: 0.104222
Make prediction for 5010 samples...
0.28160495 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 242 [0/25046 (0%)]	Loss: 0.119778
Train epoch: 242 [325820/25046 (41%)]	Loss: 0.122315
Train epoch: 242 [660840/25046 (82%)]	Loss: 0.142067
Make prediction for 5010 samples...
0.2544761 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 243 [0/25046 (0%)]	Loss: 0.131280
Train epoch: 243 [330180/25046 (41%)]	Loss: 0.140015
Train epoch: 243 [654640/25046 (82%)]	Loss: 0.136017
Make prediction for 5010 samples...
0.25189826 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 244 [0/25046 (0%)]	Loss: 0.143239
Train epoch: 244 [330560/25046 (41%)]	Loss: 0.124028
Train epoch: 244 [655040/25046 (82%)]	Loss: 0.129230
Make prediction for 5010 samples...
0.33832672 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 245 [0/25046 (0%)]	Loss: 0.183013
Train epoch: 245 [327900/25046 (41%)]	Loss: 0.130072
Train epoch: 245 [654040/25046 (82%)]	Loss: 0.135726
Make prediction for 5010 samples...
0.25170943 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 246 [0/25046 (0%)]	Loss: 0.107786
Train epoch: 246 [323960/25046 (41%)]	Loss: 0.183855
Train epoch: 246 [656680/25046 (82%)]	Loss: 0.149774
Make prediction for 5010 samples...
0.24200912 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 247 [0/25046 (0%)]	Loss: 0.141751
Train epoch: 247 [329140/25046 (41%)]	Loss: 0.129130
Train epoch: 247 [661600/25046 (82%)]	Loss: 0.153451
Make prediction for 5010 samples...
0.30046183 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 248 [0/25046 (0%)]	Loss: 0.176466
Train epoch: 248 [328220/25046 (41%)]	Loss: 0.149317
Train epoch: 248 [655360/25046 (82%)]	Loss: 0.126173
Make prediction for 5010 samples...
0.24644276 No improvement since epoch  239 ; best_mse,best_ci: 0.24004509 0.8887792400963452 GINConvNet davis
Training on 25046 samples...
Train epoch: 249 [0/25046 (0%)]	Loss: 0.105028
Train epoch: 249 [332060/25046 (41%)]	Loss: 0.143207
Train epoch: 249 [667640/25046 (82%)]	Loss: 0.130829
Make prediction for 5010 samples...
rmse improved at epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 250 [0/25046 (0%)]	Loss: 0.139524
Train epoch: 250 [329700/25046 (41%)]	Loss: 0.128000
Train epoch: 250 [662160/25046 (82%)]	Loss: 0.127388
Make prediction for 5010 samples...
0.26659167 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 251 [0/25046 (0%)]	Loss: 0.139588
Train epoch: 251 [324920/25046 (41%)]	Loss: 0.133125
Train epoch: 251 [658240/25046 (82%)]	Loss: 0.144411
Make prediction for 5010 samples...
0.30441424 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 252 [0/25046 (0%)]	Loss: 0.161030
Train epoch: 252 [336620/25046 (41%)]	Loss: 0.118303
Train epoch: 252 [660920/25046 (82%)]	Loss: 0.121993
Make prediction for 5010 samples...
0.26037326 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 253 [0/25046 (0%)]	Loss: 0.116449
Train epoch: 253 [323320/25046 (41%)]	Loss: 0.124723
Train epoch: 253 [654880/25046 (82%)]	Loss: 0.163404
Make prediction for 5010 samples...
0.24069424 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 254 [0/25046 (0%)]	Loss: 0.124479
Train epoch: 254 [333040/25046 (41%)]	Loss: 0.121032
Train epoch: 254 [667000/25046 (82%)]	Loss: 0.129714
Make prediction for 5010 samples...
0.2401357 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 255 [0/25046 (0%)]	Loss: 0.114000
Train epoch: 255 [332860/25046 (41%)]	Loss: 0.098987
Train epoch: 255 [662360/25046 (82%)]	Loss: 0.138691
Make prediction for 5010 samples...
0.30569607 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 256 [0/25046 (0%)]	Loss: 0.150559
Train epoch: 256 [327380/25046 (41%)]	Loss: 0.175040
Train epoch: 256 [653400/25046 (82%)]	Loss: 0.140383
Make prediction for 5010 samples...
0.26206702 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 257 [0/25046 (0%)]	Loss: 0.106573
Train epoch: 257 [323880/25046 (41%)]	Loss: 0.139710
Train epoch: 257 [657320/25046 (82%)]	Loss: 0.148031
Make prediction for 5010 samples...
0.23984848 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 258 [0/25046 (0%)]	Loss: 0.147669
Train epoch: 258 [328260/25046 (41%)]	Loss: 0.123265
Train epoch: 258 [659800/25046 (82%)]	Loss: 0.131642
Make prediction for 5010 samples...
0.3425319 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 259 [0/25046 (0%)]	Loss: 0.192926
Train epoch: 259 [329400/25046 (41%)]	Loss: 0.133717
Train epoch: 259 [661680/25046 (82%)]	Loss: 0.134437
Make prediction for 5010 samples...
0.26327202 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 260 [0/25046 (0%)]	Loss: 0.125495
Train epoch: 260 [325760/25046 (41%)]	Loss: 0.128637
Train epoch: 260 [663720/25046 (82%)]	Loss: 0.114273
Make prediction for 5010 samples...
0.26650426 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 261 [0/25046 (0%)]	Loss: 0.137045
Train epoch: 261 [332660/25046 (41%)]	Loss: 0.173821
Train epoch: 261 [657120/25046 (82%)]	Loss: 0.140351
Make prediction for 5010 samples...
0.25350085 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 262 [0/25046 (0%)]	Loss: 0.115192
Train epoch: 262 [325820/25046 (41%)]	Loss: 0.126456
Train epoch: 262 [657520/25046 (82%)]	Loss: 0.115594
Make prediction for 5010 samples...
0.2486181 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 263 [0/25046 (0%)]	Loss: 0.112373
Train epoch: 263 [327560/25046 (41%)]	Loss: 0.095386
Train epoch: 263 [664000/25046 (82%)]	Loss: 0.146906
Make prediction for 5010 samples...
0.24448858 No improvement since epoch  249 ; best_mse,best_ci: 0.23733848 0.8811530802138562 GINConvNet davis
Training on 25046 samples...
Train epoch: 264 [0/25046 (0%)]	Loss: 0.142193
Train epoch: 264 [326400/25046 (41%)]	Loss: 0.111154
Train epoch: 264 [656120/25046 (82%)]	Loss: 0.118110
Make prediction for 5010 samples...
rmse improved at epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 265 [0/25046 (0%)]	Loss: 0.130164
Train epoch: 265 [336640/25046 (41%)]	Loss: 0.114190
Train epoch: 265 [654160/25046 (82%)]	Loss: 0.162251
Make prediction for 5010 samples...
0.24534279 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 266 [0/25046 (0%)]	Loss: 0.131653
Train epoch: 266 [332180/25046 (41%)]	Loss: 0.135099
Train epoch: 266 [662280/25046 (82%)]	Loss: 0.112180
Make prediction for 5010 samples...
0.24060173 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 267 [0/25046 (0%)]	Loss: 0.114270
Train epoch: 267 [330360/25046 (41%)]	Loss: 0.120974
Train epoch: 267 [655800/25046 (82%)]	Loss: 0.127267
Make prediction for 5010 samples...
0.2480634 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 268 [0/25046 (0%)]	Loss: 0.152220
Train epoch: 268 [329740/25046 (41%)]	Loss: 0.128559
Train epoch: 268 [658080/25046 (82%)]	Loss: 0.144939
Make prediction for 5010 samples...
0.3202017 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 269 [0/25046 (0%)]	Loss: 0.158102
Train epoch: 269 [328600/25046 (41%)]	Loss: 0.142191
Train epoch: 269 [661280/25046 (82%)]	Loss: 0.112997
Make prediction for 5010 samples...
0.2374505 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 270 [0/25046 (0%)]	Loss: 0.121909
Train epoch: 270 [329380/25046 (41%)]	Loss: 0.166133
Train epoch: 270 [661600/25046 (82%)]	Loss: 0.119710
Make prediction for 5010 samples...
0.25434628 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 271 [0/25046 (0%)]	Loss: 0.132305
Train epoch: 271 [333380/25046 (41%)]	Loss: 0.144802
Train epoch: 271 [657000/25046 (82%)]	Loss: 0.149032
Make prediction for 5010 samples...
0.26468128 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 272 [0/25046 (0%)]	Loss: 0.111769
Train epoch: 272 [329880/25046 (41%)]	Loss: 0.144404
Train epoch: 272 [661880/25046 (82%)]	Loss: 0.131048
Make prediction for 5010 samples...
0.2766131 No improvement since epoch  264 ; best_mse,best_ci: 0.23688239 0.8855414398156777 GINConvNet davis
Training on 25046 samples...
Train epoch: 273 [0/25046 (0%)]	Loss: 0.159761
Train epoch: 273 [331040/25046 (41%)]	Loss: 0.140346
Train epoch: 273 [659840/25046 (82%)]	Loss: 0.135385
Make prediction for 5010 samples...
rmse improved at epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 274 [0/25046 (0%)]	Loss: 0.150593
Train epoch: 274 [326140/25046 (41%)]	Loss: 0.129367
Train epoch: 274 [655080/25046 (82%)]	Loss: 0.150826
Make prediction for 5010 samples...
0.2690699 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 275 [0/25046 (0%)]	Loss: 0.116416
Train epoch: 275 [330680/25046 (41%)]	Loss: 0.146097
Train epoch: 275 [646840/25046 (82%)]	Loss: 0.109880
Make prediction for 5010 samples...
0.25238013 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 276 [0/25046 (0%)]	Loss: 0.124001
Train epoch: 276 [328760/25046 (41%)]	Loss: 0.144118
Train epoch: 276 [646080/25046 (82%)]	Loss: 0.223718
Make prediction for 5010 samples...
0.24430217 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 277 [0/25046 (0%)]	Loss: 0.131580
Train epoch: 277 [332100/25046 (41%)]	Loss: 0.131740
Train epoch: 277 [660560/25046 (82%)]	Loss: 0.112209
Make prediction for 5010 samples...
0.24598722 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 278 [0/25046 (0%)]	Loss: 0.119085
Train epoch: 278 [330420/25046 (41%)]	Loss: 0.140779
Train epoch: 278 [652600/25046 (82%)]	Loss: 0.133730
Make prediction for 5010 samples...
0.24487673 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 279 [0/25046 (0%)]	Loss: 0.123379
Train epoch: 279 [326340/25046 (41%)]	Loss: 0.133717
Train epoch: 279 [652040/25046 (82%)]	Loss: 0.131839
Make prediction for 5010 samples...
0.26001406 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 280 [0/25046 (0%)]	Loss: 0.151260
Train epoch: 280 [327720/25046 (41%)]	Loss: 0.084762
Train epoch: 280 [657600/25046 (82%)]	Loss: 0.131495
Make prediction for 5010 samples...
0.24775067 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 281 [0/25046 (0%)]	Loss: 0.096307
Train epoch: 281 [331620/25046 (41%)]	Loss: 0.111549
Train epoch: 281 [653400/25046 (82%)]	Loss: 0.127553
Make prediction for 5010 samples...
0.26084444 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 282 [0/25046 (0%)]	Loss: 0.120819
Train epoch: 282 [329820/25046 (41%)]	Loss: 0.181740
Train epoch: 282 [655840/25046 (82%)]	Loss: 0.137323
Make prediction for 5010 samples...
0.23697098 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 283 [0/25046 (0%)]	Loss: 0.111650
Train epoch: 283 [330020/25046 (41%)]	Loss: 0.165784
Train epoch: 283 [660400/25046 (82%)]	Loss: 0.101881
Make prediction for 5010 samples...
0.2612945 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 284 [0/25046 (0%)]	Loss: 0.142843
Train epoch: 284 [328680/25046 (41%)]	Loss: 0.132026
Train epoch: 284 [666920/25046 (82%)]	Loss: 0.117950
Make prediction for 5010 samples...
0.23325583 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 285 [0/25046 (0%)]	Loss: 0.104163
Train epoch: 285 [332500/25046 (41%)]	Loss: 0.135251
Train epoch: 285 [659560/25046 (82%)]	Loss: 0.125137
Make prediction for 5010 samples...
0.33175215 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 286 [0/25046 (0%)]	Loss: 0.152956
Train epoch: 286 [327000/25046 (41%)]	Loss: 0.119968
Train epoch: 286 [662920/25046 (82%)]	Loss: 0.141964
Make prediction for 5010 samples...
0.23476134 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 287 [0/25046 (0%)]	Loss: 0.113937
Train epoch: 287 [326240/25046 (41%)]	Loss: 0.146275
Train epoch: 287 [641560/25046 (82%)]	Loss: 0.139918
Make prediction for 5010 samples...
0.2806346 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 288 [0/25046 (0%)]	Loss: 0.121538
Train epoch: 288 [328380/25046 (41%)]	Loss: 0.152242
Train epoch: 288 [653160/25046 (82%)]	Loss: 0.136542
Make prediction for 5010 samples...
0.24054094 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 289 [0/25046 (0%)]	Loss: 0.139423
Train epoch: 289 [332920/25046 (41%)]	Loss: 0.123048
Train epoch: 289 [662840/25046 (82%)]	Loss: 0.132587
Make prediction for 5010 samples...
0.24417576 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 290 [0/25046 (0%)]	Loss: 0.108628
Train epoch: 290 [325980/25046 (41%)]	Loss: 0.124067
Train epoch: 290 [653560/25046 (82%)]	Loss: 0.119042
Make prediction for 5010 samples...
0.2650941 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 291 [0/25046 (0%)]	Loss: 0.117375
Train epoch: 291 [326480/25046 (41%)]	Loss: 0.135378
Train epoch: 291 [657600/25046 (82%)]	Loss: 0.146407
Make prediction for 5010 samples...
0.24148522 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 292 [0/25046 (0%)]	Loss: 0.103123
Train epoch: 292 [329060/25046 (41%)]	Loss: 0.141607
Train epoch: 292 [659720/25046 (82%)]	Loss: 0.134973
Make prediction for 5010 samples...
0.25105968 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 293 [0/25046 (0%)]	Loss: 0.116331
Train epoch: 293 [326800/25046 (41%)]	Loss: 0.123596
Train epoch: 293 [655560/25046 (82%)]	Loss: 0.112433
Make prediction for 5010 samples...
0.23796971 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 294 [0/25046 (0%)]	Loss: 0.102665
Train epoch: 294 [330120/25046 (41%)]	Loss: 0.169891
Train epoch: 294 [660520/25046 (82%)]	Loss: 0.148445
Make prediction for 5010 samples...
0.24220109 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 295 [0/25046 (0%)]	Loss: 0.115046
Train epoch: 295 [328780/25046 (41%)]	Loss: 0.118872
Train epoch: 295 [654320/25046 (82%)]	Loss: 0.100244
Make prediction for 5010 samples...
0.2498055 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 296 [0/25046 (0%)]	Loss: 0.094997
Train epoch: 296 [332240/25046 (41%)]	Loss: 0.138974
Train epoch: 296 [654720/25046 (82%)]	Loss: 0.118329
Make prediction for 5010 samples...
0.28579897 No improvement since epoch  273 ; best_mse,best_ci: 0.23308524 0.8939251693064314 GINConvNet davis
Training on 25046 samples...
Train epoch: 297 [0/25046 (0%)]	Loss: 0.122579
Train epoch: 297 [324520/25046 (41%)]	Loss: 0.102388
Train epoch: 297 [653200/25046 (82%)]	Loss: 0.099192
Make prediction for 5010 samples...
rmse improved at epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 298 [0/25046 (0%)]	Loss: 0.167213
Train epoch: 298 [325220/25046 (41%)]	Loss: 0.113156
Train epoch: 298 [659760/25046 (82%)]	Loss: 0.116617
Make prediction for 5010 samples...
0.24764878 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 299 [0/25046 (0%)]	Loss: 0.115816
Train epoch: 299 [328680/25046 (41%)]	Loss: 0.118793
Train epoch: 299 [663720/25046 (82%)]	Loss: 0.134100
Make prediction for 5010 samples...
0.24926846 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 300 [0/25046 (0%)]	Loss: 0.115713
Train epoch: 300 [331560/25046 (41%)]	Loss: 0.119542
Train epoch: 300 [661600/25046 (82%)]	Loss: 0.117292
Make prediction for 5010 samples...
0.24194029 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 301 [0/25046 (0%)]	Loss: 0.132225
Train epoch: 301 [327120/25046 (41%)]	Loss: 0.124263
Train epoch: 301 [654360/25046 (82%)]	Loss: 0.106408
Make prediction for 5010 samples...
0.30619642 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 302 [0/25046 (0%)]	Loss: 0.131730
Train epoch: 302 [332280/25046 (41%)]	Loss: 0.132967
Train epoch: 302 [649920/25046 (82%)]	Loss: 0.125954
Make prediction for 5010 samples...
0.25798935 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 303 [0/25046 (0%)]	Loss: 0.109154
Train epoch: 303 [325260/25046 (41%)]	Loss: 0.140907
Train epoch: 303 [654200/25046 (82%)]	Loss: 0.134599
Make prediction for 5010 samples...
0.261881 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 304 [0/25046 (0%)]	Loss: 0.145755
Train epoch: 304 [328020/25046 (41%)]	Loss: 0.133192
Train epoch: 304 [648480/25046 (82%)]	Loss: 0.094857
Make prediction for 5010 samples...
0.25629216 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 305 [0/25046 (0%)]	Loss: 0.123726
Train epoch: 305 [329520/25046 (41%)]	Loss: 0.129603
Train epoch: 305 [659640/25046 (82%)]	Loss: 0.118466
Make prediction for 5010 samples...
0.23343818 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 306 [0/25046 (0%)]	Loss: 0.118822
Train epoch: 306 [327980/25046 (41%)]	Loss: 0.117460
Train epoch: 306 [659800/25046 (82%)]	Loss: 0.125594
Make prediction for 5010 samples...
0.23583531 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 307 [0/25046 (0%)]	Loss: 0.095707
Train epoch: 307 [327200/25046 (41%)]	Loss: 0.106129
Train epoch: 307 [657640/25046 (82%)]	Loss: 0.146290
Make prediction for 5010 samples...
0.24244353 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 308 [0/25046 (0%)]	Loss: 0.092630
Train epoch: 308 [325060/25046 (41%)]	Loss: 0.132338
Train epoch: 308 [657560/25046 (82%)]	Loss: 0.099560
Make prediction for 5010 samples...
0.2678617 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 309 [0/25046 (0%)]	Loss: 0.146689
Train epoch: 309 [322660/25046 (41%)]	Loss: 0.107483
Train epoch: 309 [654160/25046 (82%)]	Loss: 0.113623
Make prediction for 5010 samples...
0.27137405 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 310 [0/25046 (0%)]	Loss: 0.163028
Train epoch: 310 [330380/25046 (41%)]	Loss: 0.116472
Train epoch: 310 [662480/25046 (82%)]	Loss: 0.180487
Make prediction for 5010 samples...
0.27321568 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 311 [0/25046 (0%)]	Loss: 0.184258
Train epoch: 311 [326460/25046 (41%)]	Loss: 0.108183
Train epoch: 311 [651120/25046 (82%)]	Loss: 0.111136
Make prediction for 5010 samples...
0.2556145 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 312 [0/25046 (0%)]	Loss: 0.097412
Train epoch: 312 [329020/25046 (41%)]	Loss: 0.106421
Train epoch: 312 [658680/25046 (82%)]	Loss: 0.136311
Make prediction for 5010 samples...
0.23601623 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 313 [0/25046 (0%)]	Loss: 0.108900
Train epoch: 313 [328140/25046 (41%)]	Loss: 0.127757
Train epoch: 313 [651000/25046 (82%)]	Loss: 0.123432
Make prediction for 5010 samples...
0.23557039 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 314 [0/25046 (0%)]	Loss: 0.137263
Train epoch: 314 [327660/25046 (41%)]	Loss: 0.129677
Train epoch: 314 [648880/25046 (82%)]	Loss: 0.111921
Make prediction for 5010 samples...
0.2420347 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 315 [0/25046 (0%)]	Loss: 0.106989
Train epoch: 315 [329360/25046 (41%)]	Loss: 0.131881
Train epoch: 315 [651080/25046 (82%)]	Loss: 0.106248
Make prediction for 5010 samples...
0.24321869 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 316 [0/25046 (0%)]	Loss: 0.112222
Train epoch: 316 [329400/25046 (41%)]	Loss: 0.115460
Train epoch: 316 [665240/25046 (82%)]	Loss: 0.121297
Make prediction for 5010 samples...
0.24911547 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 317 [0/25046 (0%)]	Loss: 0.120020
Train epoch: 317 [327180/25046 (41%)]	Loss: 0.116631
Train epoch: 317 [662200/25046 (82%)]	Loss: 0.134874
Make prediction for 5010 samples...
0.33153337 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 318 [0/25046 (0%)]	Loss: 0.143068
Train epoch: 318 [328300/25046 (41%)]	Loss: 0.126340
Train epoch: 318 [663160/25046 (82%)]	Loss: 0.118702
Make prediction for 5010 samples...
0.24913691 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 319 [0/25046 (0%)]	Loss: 0.113334
Train epoch: 319 [322240/25046 (41%)]	Loss: 0.113244
Train epoch: 319 [657680/25046 (82%)]	Loss: 0.108242
Make prediction for 5010 samples...
0.27654797 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 320 [0/25046 (0%)]	Loss: 0.135689
Train epoch: 320 [320920/25046 (41%)]	Loss: 0.117390
Train epoch: 320 [662320/25046 (82%)]	Loss: 0.154168
Make prediction for 5010 samples...
0.24081972 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 321 [0/25046 (0%)]	Loss: 0.116313
Train epoch: 321 [328280/25046 (41%)]	Loss: 0.120704
Train epoch: 321 [658160/25046 (82%)]	Loss: 0.090821
Make prediction for 5010 samples...
0.24428195 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 322 [0/25046 (0%)]	Loss: 0.122384
Train epoch: 322 [327060/25046 (41%)]	Loss: 0.138350
Train epoch: 322 [658720/25046 (82%)]	Loss: 0.099839
Make prediction for 5010 samples...
0.24552476 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 323 [0/25046 (0%)]	Loss: 0.108968
Train epoch: 323 [328380/25046 (41%)]	Loss: 0.136374
Train epoch: 323 [666360/25046 (82%)]	Loss: 0.120680
Make prediction for 5010 samples...
0.2744206 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 324 [0/25046 (0%)]	Loss: 0.103513
Train epoch: 324 [330700/25046 (41%)]	Loss: 0.115334
Train epoch: 324 [653000/25046 (82%)]	Loss: 0.105424
Make prediction for 5010 samples...
0.2392867 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 325 [0/25046 (0%)]	Loss: 0.137525
Train epoch: 325 [328160/25046 (41%)]	Loss: 0.103923
Train epoch: 325 [656480/25046 (82%)]	Loss: 0.111296
Make prediction for 5010 samples...
0.24517873 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 326 [0/25046 (0%)]	Loss: 0.117686
Train epoch: 326 [332160/25046 (41%)]	Loss: 0.109482
Train epoch: 326 [647640/25046 (82%)]	Loss: 0.137088
Make prediction for 5010 samples...
0.23631585 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 327 [0/25046 (0%)]	Loss: 0.102809
Train epoch: 327 [325860/25046 (41%)]	Loss: 0.121194
Train epoch: 327 [654640/25046 (82%)]	Loss: 0.093176
Make prediction for 5010 samples...
0.24468192 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 328 [0/25046 (0%)]	Loss: 0.118260
Train epoch: 328 [329620/25046 (41%)]	Loss: 0.094776
Train epoch: 328 [663120/25046 (82%)]	Loss: 0.106597
Make prediction for 5010 samples...
0.24472098 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 329 [0/25046 (0%)]	Loss: 0.107397
Train epoch: 329 [331760/25046 (41%)]	Loss: 0.109613
Train epoch: 329 [650000/25046 (82%)]	Loss: 0.151813
Make prediction for 5010 samples...
0.24425419 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 330 [0/25046 (0%)]	Loss: 0.114570
Train epoch: 330 [331440/25046 (41%)]	Loss: 0.125871
Train epoch: 330 [663240/25046 (82%)]	Loss: 0.126208
Make prediction for 5010 samples...
0.24463251 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 331 [0/25046 (0%)]	Loss: 0.150286
Train epoch: 331 [329120/25046 (41%)]	Loss: 0.139925
Train epoch: 331 [657960/25046 (82%)]	Loss: 0.114434
Make prediction for 5010 samples...
0.29204342 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 332 [0/25046 (0%)]	Loss: 0.121151
Train epoch: 332 [326420/25046 (41%)]	Loss: 0.115296
Train epoch: 332 [659160/25046 (82%)]	Loss: 0.128724
Make prediction for 5010 samples...
0.26517352 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 333 [0/25046 (0%)]	Loss: 0.117049
Train epoch: 333 [333100/25046 (41%)]	Loss: 0.173010
Train epoch: 333 [655440/25046 (82%)]	Loss: 0.118246
Make prediction for 5010 samples...
0.24578013 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 334 [0/25046 (0%)]	Loss: 0.127276
Train epoch: 334 [329400/25046 (41%)]	Loss: 0.129933
Train epoch: 334 [667000/25046 (82%)]	Loss: 0.130268
Make prediction for 5010 samples...
0.26880583 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 335 [0/25046 (0%)]	Loss: 0.101439
Train epoch: 335 [328080/25046 (41%)]	Loss: 0.116310
Train epoch: 335 [657680/25046 (82%)]	Loss: 0.123463
Make prediction for 5010 samples...
0.24475402 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 336 [0/25046 (0%)]	Loss: 0.096090
Train epoch: 336 [328620/25046 (41%)]	Loss: 0.116865
Train epoch: 336 [659720/25046 (82%)]	Loss: 0.124115
Make prediction for 5010 samples...
0.23734309 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 337 [0/25046 (0%)]	Loss: 0.097765
Train epoch: 337 [328600/25046 (41%)]	Loss: 0.138418
Train epoch: 337 [661280/25046 (82%)]	Loss: 0.143769
Make prediction for 5010 samples...
0.24101268 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 338 [0/25046 (0%)]	Loss: 0.101138
Train epoch: 338 [330220/25046 (41%)]	Loss: 0.129170
Train epoch: 338 [661520/25046 (82%)]	Loss: 0.117515
Make prediction for 5010 samples...
0.24385862 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 339 [0/25046 (0%)]	Loss: 0.121172
Train epoch: 339 [331840/25046 (41%)]	Loss: 0.092775
Train epoch: 339 [655560/25046 (82%)]	Loss: 0.135538
Make prediction for 5010 samples...
0.24680637 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 340 [0/25046 (0%)]	Loss: 0.091022
Train epoch: 340 [328460/25046 (41%)]	Loss: 0.140211
Train epoch: 340 [668480/25046 (82%)]	Loss: 0.109877
Make prediction for 5010 samples...
0.24927878 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 341 [0/25046 (0%)]	Loss: 0.112626
Train epoch: 341 [333160/25046 (41%)]	Loss: 0.108462
Train epoch: 341 [645760/25046 (82%)]	Loss: 0.185541
Make prediction for 5010 samples...
0.25978556 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 342 [0/25046 (0%)]	Loss: 0.165957
Train epoch: 342 [327680/25046 (41%)]	Loss: 0.088645
Train epoch: 342 [663520/25046 (82%)]	Loss: 0.140827
Make prediction for 5010 samples...
0.23815815 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 343 [0/25046 (0%)]	Loss: 0.108842
Train epoch: 343 [327540/25046 (41%)]	Loss: 0.104933
Train epoch: 343 [648880/25046 (82%)]	Loss: 0.095342
Make prediction for 5010 samples...
0.24580461 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 344 [0/25046 (0%)]	Loss: 0.117411
Train epoch: 344 [329580/25046 (41%)]	Loss: 0.142967
Train epoch: 344 [660920/25046 (82%)]	Loss: 0.088787
Make prediction for 5010 samples...
0.24439855 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 345 [0/25046 (0%)]	Loss: 0.122449
Train epoch: 345 [326080/25046 (41%)]	Loss: 0.090055
Train epoch: 345 [659360/25046 (82%)]	Loss: 0.119155
Make prediction for 5010 samples...
0.27343372 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 346 [0/25046 (0%)]	Loss: 0.187574
Train epoch: 346 [332220/25046 (41%)]	Loss: 0.110324
Train epoch: 346 [648160/25046 (82%)]	Loss: 0.098607
Make prediction for 5010 samples...
0.24404672 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 347 [0/25046 (0%)]	Loss: 0.097787
Train epoch: 347 [327040/25046 (41%)]	Loss: 0.101702
Train epoch: 347 [656080/25046 (82%)]	Loss: 0.120619
Make prediction for 5010 samples...
0.2497892 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 348 [0/25046 (0%)]	Loss: 0.095995
Train epoch: 348 [324240/25046 (41%)]	Loss: 0.112582
Train epoch: 348 [657040/25046 (82%)]	Loss: 0.126505
Make prediction for 5010 samples...
0.2577189 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 349 [0/25046 (0%)]	Loss: 0.101370
Train epoch: 349 [326580/25046 (41%)]	Loss: 0.124418
Train epoch: 349 [647920/25046 (82%)]	Loss: 0.112769
Make prediction for 5010 samples...
0.2496049 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 350 [0/25046 (0%)]	Loss: 0.140837
Train epoch: 350 [328440/25046 (41%)]	Loss: 0.105552
Train epoch: 350 [651040/25046 (82%)]	Loss: 0.111738
Make prediction for 5010 samples...
0.24470921 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 351 [0/25046 (0%)]	Loss: 0.138517
Train epoch: 351 [328040/25046 (41%)]	Loss: 0.118299
Train epoch: 351 [660720/25046 (82%)]	Loss: 0.080073
Make prediction for 5010 samples...
0.23804578 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 352 [0/25046 (0%)]	Loss: 0.091529
Train epoch: 352 [324360/25046 (41%)]	Loss: 0.127759
Train epoch: 352 [653720/25046 (82%)]	Loss: 0.131504
Make prediction for 5010 samples...
0.25501165 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 353 [0/25046 (0%)]	Loss: 0.161115
Train epoch: 353 [325780/25046 (41%)]	Loss: 0.139696
Train epoch: 353 [666720/25046 (82%)]	Loss: 0.119247
Make prediction for 5010 samples...
0.24332128 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 354 [0/25046 (0%)]	Loss: 0.087114
Train epoch: 354 [328180/25046 (41%)]	Loss: 0.104960
Train epoch: 354 [665480/25046 (82%)]	Loss: 0.122248
Make prediction for 5010 samples...
0.24067022 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 355 [0/25046 (0%)]	Loss: 0.137870
Train epoch: 355 [328760/25046 (41%)]	Loss: 0.106837
Train epoch: 355 [656480/25046 (82%)]	Loss: 0.115136
Make prediction for 5010 samples...
0.2427904 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 356 [0/25046 (0%)]	Loss: 0.099360
Train epoch: 356 [332420/25046 (41%)]	Loss: 0.143871
Train epoch: 356 [658280/25046 (82%)]	Loss: 0.130737
Make prediction for 5010 samples...
0.23972476 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 357 [0/25046 (0%)]	Loss: 0.097482
Train epoch: 357 [325380/25046 (41%)]	Loss: 0.115215
Train epoch: 357 [656320/25046 (82%)]	Loss: 0.132279
Make prediction for 5010 samples...
0.2408117 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 358 [0/25046 (0%)]	Loss: 0.103667
Train epoch: 358 [329960/25046 (41%)]	Loss: 0.121775
Train epoch: 358 [656200/25046 (82%)]	Loss: 0.114810
Make prediction for 5010 samples...
0.2586281 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 359 [0/25046 (0%)]	Loss: 0.165876
Train epoch: 359 [329780/25046 (41%)]	Loss: 0.132769
Train epoch: 359 [657760/25046 (82%)]	Loss: 0.108777
Make prediction for 5010 samples...
0.239001 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 360 [0/25046 (0%)]	Loss: 0.094133
Train epoch: 360 [325560/25046 (41%)]	Loss: 0.138185
Train epoch: 360 [650320/25046 (82%)]	Loss: 0.120118
Make prediction for 5010 samples...
0.2432103 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 361 [0/25046 (0%)]	Loss: 0.115867
Train epoch: 361 [328260/25046 (41%)]	Loss: 0.117279
Train epoch: 361 [662200/25046 (82%)]	Loss: 0.080756
Make prediction for 5010 samples...
0.2885636 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 362 [0/25046 (0%)]	Loss: 0.126722
Train epoch: 362 [327300/25046 (41%)]	Loss: 0.131186
Train epoch: 362 [655680/25046 (82%)]	Loss: 0.137508
Make prediction for 5010 samples...
0.24234967 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 363 [0/25046 (0%)]	Loss: 0.110089
Train epoch: 363 [327580/25046 (41%)]	Loss: 0.094044
Train epoch: 363 [657240/25046 (82%)]	Loss: 0.136203
Make prediction for 5010 samples...
0.2806519 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 364 [0/25046 (0%)]	Loss: 0.123130
Train epoch: 364 [328120/25046 (41%)]	Loss: 0.101037
Train epoch: 364 [664880/25046 (82%)]	Loss: 0.116023
Make prediction for 5010 samples...
0.24059561 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 365 [0/25046 (0%)]	Loss: 0.132297
Train epoch: 365 [327600/25046 (41%)]	Loss: 0.153628
Train epoch: 365 [655320/25046 (82%)]	Loss: 0.080524
Make prediction for 5010 samples...
0.23924802 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 366 [0/25046 (0%)]	Loss: 0.105357
Train epoch: 366 [326600/25046 (41%)]	Loss: 0.106678
Train epoch: 366 [657440/25046 (82%)]	Loss: 0.148998
Make prediction for 5010 samples...
0.25078645 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 367 [0/25046 (0%)]	Loss: 0.085207
Train epoch: 367 [328900/25046 (41%)]	Loss: 0.132761
Train epoch: 367 [653640/25046 (82%)]	Loss: 0.135378
Make prediction for 5010 samples...
0.23517145 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 368 [0/25046 (0%)]	Loss: 0.099369
Train epoch: 368 [327500/25046 (41%)]	Loss: 0.097390
Train epoch: 368 [646960/25046 (82%)]	Loss: 0.115367
Make prediction for 5010 samples...
0.24672243 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 369 [0/25046 (0%)]	Loss: 0.081208
Train epoch: 369 [326200/25046 (41%)]	Loss: 0.101704
Train epoch: 369 [656000/25046 (82%)]	Loss: 0.107458
Make prediction for 5010 samples...
0.2650237 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 370 [0/25046 (0%)]	Loss: 0.123241
Train epoch: 370 [326540/25046 (41%)]	Loss: 0.121431
Train epoch: 370 [646520/25046 (82%)]	Loss: 0.113653
Make prediction for 5010 samples...
0.24358387 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 371 [0/25046 (0%)]	Loss: 0.093181
Train epoch: 371 [326060/25046 (41%)]	Loss: 0.111561
Train epoch: 371 [658560/25046 (82%)]	Loss: 0.121189
Make prediction for 5010 samples...
0.2333462 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 372 [0/25046 (0%)]	Loss: 0.113080
Train epoch: 372 [328160/25046 (41%)]	Loss: 0.131362
Train epoch: 372 [660320/25046 (82%)]	Loss: 0.105251
Make prediction for 5010 samples...
0.26411793 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 373 [0/25046 (0%)]	Loss: 0.115849
Train epoch: 373 [327200/25046 (41%)]	Loss: 0.122839
Train epoch: 373 [664160/25046 (82%)]	Loss: 0.122445
Make prediction for 5010 samples...
0.23611084 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 374 [0/25046 (0%)]	Loss: 0.130764
Train epoch: 374 [327300/25046 (41%)]	Loss: 0.126732
Train epoch: 374 [647960/25046 (82%)]	Loss: 0.109674
Make prediction for 5010 samples...
0.24191071 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 375 [0/25046 (0%)]	Loss: 0.107890
Train epoch: 375 [331060/25046 (41%)]	Loss: 0.111980
Train epoch: 375 [665960/25046 (82%)]	Loss: 0.101700
Make prediction for 5010 samples...
0.23926534 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 376 [0/25046 (0%)]	Loss: 0.083582
Train epoch: 376 [327240/25046 (41%)]	Loss: 0.126807
Train epoch: 376 [662720/25046 (82%)]	Loss: 0.122477
Make prediction for 5010 samples...
0.24439494 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 377 [0/25046 (0%)]	Loss: 0.121815
Train epoch: 377 [328640/25046 (41%)]	Loss: 0.103772
Train epoch: 377 [648320/25046 (82%)]	Loss: 0.140089
Make prediction for 5010 samples...
0.25494552 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 378 [0/25046 (0%)]	Loss: 0.118805
Train epoch: 378 [328840/25046 (41%)]	Loss: 0.110463
Train epoch: 378 [659000/25046 (82%)]	Loss: 0.125363
Make prediction for 5010 samples...
0.24152416 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 379 [0/25046 (0%)]	Loss: 0.122829
Train epoch: 379 [325240/25046 (41%)]	Loss: 0.082872
Train epoch: 379 [645360/25046 (82%)]	Loss: 0.169269
Make prediction for 5010 samples...
0.23669307 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 380 [0/25046 (0%)]	Loss: 0.120881
Train epoch: 380 [326300/25046 (41%)]	Loss: 0.110596
Train epoch: 380 [651600/25046 (82%)]	Loss: 0.119455
Make prediction for 5010 samples...
0.23706657 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 381 [0/25046 (0%)]	Loss: 0.092938
Train epoch: 381 [327880/25046 (41%)]	Loss: 0.107483
Train epoch: 381 [652560/25046 (82%)]	Loss: 0.100992
Make prediction for 5010 samples...
0.2630373 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 382 [0/25046 (0%)]	Loss: 0.106542
Train epoch: 382 [328320/25046 (41%)]	Loss: 0.088985
Train epoch: 382 [658760/25046 (82%)]	Loss: 0.110145
Make prediction for 5010 samples...
0.24026123 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 383 [0/25046 (0%)]	Loss: 0.098326
Train epoch: 383 [328200/25046 (41%)]	Loss: 0.104828
Train epoch: 383 [662360/25046 (82%)]	Loss: 0.128394
Make prediction for 5010 samples...
0.23713037 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 384 [0/25046 (0%)]	Loss: 0.127194
Train epoch: 384 [328840/25046 (41%)]	Loss: 0.084777
Train epoch: 384 [656280/25046 (82%)]	Loss: 0.135382
Make prediction for 5010 samples...
0.3176031 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 385 [0/25046 (0%)]	Loss: 0.204206
Train epoch: 385 [331680/25046 (41%)]	Loss: 0.120383
Train epoch: 385 [648560/25046 (82%)]	Loss: 0.115086
Make prediction for 5010 samples...
0.24411815 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 386 [0/25046 (0%)]	Loss: 0.125966
Train epoch: 386 [328220/25046 (41%)]	Loss: 0.120783
Train epoch: 386 [659720/25046 (82%)]	Loss: 0.147892
Make prediction for 5010 samples...
0.23704651 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 387 [0/25046 (0%)]	Loss: 0.122426
Train epoch: 387 [329740/25046 (41%)]	Loss: 0.097988
Train epoch: 387 [656840/25046 (82%)]	Loss: 0.098999
Make prediction for 5010 samples...
0.2358483 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 388 [0/25046 (0%)]	Loss: 0.107402
Train epoch: 388 [326260/25046 (41%)]	Loss: 0.118845
Train epoch: 388 [657440/25046 (82%)]	Loss: 0.124060
Make prediction for 5010 samples...
0.2400383 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 389 [0/25046 (0%)]	Loss: 0.135612
Train epoch: 389 [331020/25046 (41%)]	Loss: 0.118480
Train epoch: 389 [662640/25046 (82%)]	Loss: 0.141489
Make prediction for 5010 samples...
0.2357568 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 390 [0/25046 (0%)]	Loss: 0.102146
Train epoch: 390 [323560/25046 (41%)]	Loss: 0.120681
Train epoch: 390 [658200/25046 (82%)]	Loss: 0.144561
Make prediction for 5010 samples...
0.24007468 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 391 [0/25046 (0%)]	Loss: 0.121952
Train epoch: 391 [326220/25046 (41%)]	Loss: 0.117352
Train epoch: 391 [652760/25046 (82%)]	Loss: 0.104002
Make prediction for 5010 samples...
0.25458583 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 392 [0/25046 (0%)]	Loss: 0.108646
Train epoch: 392 [326900/25046 (41%)]	Loss: 0.153482
Train epoch: 392 [648600/25046 (82%)]	Loss: 0.097242
Make prediction for 5010 samples...
0.2591505 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 393 [0/25046 (0%)]	Loss: 0.103810
Train epoch: 393 [330380/25046 (41%)]	Loss: 0.125879
Train epoch: 393 [660600/25046 (82%)]	Loss: 0.120915
Make prediction for 5010 samples...
0.23904832 No improvement since epoch  297 ; best_mse,best_ci: 0.23274988 0.8918388472628481 GINConvNet davis
Training on 25046 samples...
Train epoch: 394 [0/25046 (0%)]	Loss: 0.101311
Train epoch: 394 [324540/25046 (41%)]	Loss: 0.087520
Train epoch: 394 [658480/25046 (82%)]	Loss: 0.094279
Make prediction for 5010 samples...
rmse improved at epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 395 [0/25046 (0%)]	Loss: 0.109316
Train epoch: 395 [326940/25046 (41%)]	Loss: 0.096335
Train epoch: 395 [650480/25046 (82%)]	Loss: 0.084392
Make prediction for 5010 samples...
0.315095 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 396 [0/25046 (0%)]	Loss: 0.150397
Train epoch: 396 [327360/25046 (41%)]	Loss: 0.097104
Train epoch: 396 [653040/25046 (82%)]	Loss: 0.119703
Make prediction for 5010 samples...
0.23750556 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 397 [0/25046 (0%)]	Loss: 0.094805
Train epoch: 397 [330980/25046 (41%)]	Loss: 0.115563
Train epoch: 397 [655240/25046 (82%)]	Loss: 0.090204
Make prediction for 5010 samples...
0.25175774 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 398 [0/25046 (0%)]	Loss: 0.118075
Train epoch: 398 [328280/25046 (41%)]	Loss: 0.105855
Train epoch: 398 [659040/25046 (82%)]	Loss: 0.097631
Make prediction for 5010 samples...
0.256751 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 399 [0/25046 (0%)]	Loss: 0.109296
Train epoch: 399 [330440/25046 (41%)]	Loss: 0.103683
Train epoch: 399 [662320/25046 (82%)]	Loss: 0.104799
Make prediction for 5010 samples...
0.24760608 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 400 [0/25046 (0%)]	Loss: 0.090648
Train epoch: 400 [325320/25046 (41%)]	Loss: 0.103995
Train epoch: 400 [653960/25046 (82%)]	Loss: 0.175900
Make prediction for 5010 samples...
0.24221632 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 401 [0/25046 (0%)]	Loss: 0.096895
Train epoch: 401 [325060/25046 (41%)]	Loss: 0.118718
Train epoch: 401 [661680/25046 (82%)]	Loss: 0.119266
Make prediction for 5010 samples...
0.23987807 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 402 [0/25046 (0%)]	Loss: 0.119709
Train epoch: 402 [324380/25046 (41%)]	Loss: 0.101467
Train epoch: 402 [650680/25046 (82%)]	Loss: 0.098907
Make prediction for 5010 samples...
0.24947992 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 403 [0/25046 (0%)]	Loss: 0.093332
Train epoch: 403 [328800/25046 (41%)]	Loss: 0.096605
Train epoch: 403 [658920/25046 (82%)]	Loss: 0.121179
Make prediction for 5010 samples...
0.2391184 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 404 [0/25046 (0%)]	Loss: 0.110959
Train epoch: 404 [329180/25046 (41%)]	Loss: 0.127160
Train epoch: 404 [662120/25046 (82%)]	Loss: 0.109313
Make prediction for 5010 samples...
0.2447001 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 405 [0/25046 (0%)]	Loss: 0.128037
Train epoch: 405 [328180/25046 (41%)]	Loss: 0.090614
Train epoch: 405 [670320/25046 (82%)]	Loss: 0.125561
Make prediction for 5010 samples...
0.24016935 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 406 [0/25046 (0%)]	Loss: 0.083177
Train epoch: 406 [329580/25046 (41%)]	Loss: 0.082088
Train epoch: 406 [673000/25046 (82%)]	Loss: 0.116381
Make prediction for 5010 samples...
0.23181508 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 407 [0/25046 (0%)]	Loss: 0.108715
Train epoch: 407 [326200/25046 (41%)]	Loss: 0.086538
Train epoch: 407 [650840/25046 (82%)]	Loss: 0.118583
Make prediction for 5010 samples...
0.25528213 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 408 [0/25046 (0%)]	Loss: 0.094589
Train epoch: 408 [329120/25046 (41%)]	Loss: 0.087154
Train epoch: 408 [656120/25046 (82%)]	Loss: 0.123093
Make prediction for 5010 samples...
0.24278979 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 409 [0/25046 (0%)]	Loss: 0.078946
Train epoch: 409 [332900/25046 (41%)]	Loss: 0.093188
Train epoch: 409 [662040/25046 (82%)]	Loss: 0.096897
Make prediction for 5010 samples...
0.2612515 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 410 [0/25046 (0%)]	Loss: 0.106627
Train epoch: 410 [327920/25046 (41%)]	Loss: 0.111694
Train epoch: 410 [658040/25046 (82%)]	Loss: 0.174160
Make prediction for 5010 samples...
0.24744369 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 411 [0/25046 (0%)]	Loss: 0.150384
Train epoch: 411 [327560/25046 (41%)]	Loss: 0.081619
Train epoch: 411 [651000/25046 (82%)]	Loss: 0.111854
Make prediction for 5010 samples...
0.26004013 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 412 [0/25046 (0%)]	Loss: 0.109318
Train epoch: 412 [327160/25046 (41%)]	Loss: 0.087142
Train epoch: 412 [658000/25046 (82%)]	Loss: 0.094216
Make prediction for 5010 samples...
0.236691 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 413 [0/25046 (0%)]	Loss: 0.180415
Train epoch: 413 [325720/25046 (41%)]	Loss: 0.099333
Train epoch: 413 [654920/25046 (82%)]	Loss: 0.082581
Make prediction for 5010 samples...
0.25463152 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 414 [0/25046 (0%)]	Loss: 0.105526
Train epoch: 414 [330460/25046 (41%)]	Loss: 0.105343
Train epoch: 414 [651480/25046 (82%)]	Loss: 0.117611
Make prediction for 5010 samples...
0.24822387 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 415 [0/25046 (0%)]	Loss: 0.098530
Train epoch: 415 [328760/25046 (41%)]	Loss: 0.087982
Train epoch: 415 [650480/25046 (82%)]	Loss: 0.074987
Make prediction for 5010 samples...
0.23815753 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 416 [0/25046 (0%)]	Loss: 0.095441
Train epoch: 416 [326040/25046 (41%)]	Loss: 0.106969
Train epoch: 416 [648240/25046 (82%)]	Loss: 0.088229
Make prediction for 5010 samples...
0.23477608 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 417 [0/25046 (0%)]	Loss: 0.118910
Train epoch: 417 [330120/25046 (41%)]	Loss: 0.115860
Train epoch: 417 [652680/25046 (82%)]	Loss: 0.095696
Make prediction for 5010 samples...
0.27183616 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 418 [0/25046 (0%)]	Loss: 0.103010
Train epoch: 418 [331460/25046 (41%)]	Loss: 0.120072
Train epoch: 418 [656080/25046 (82%)]	Loss: 0.131887
Make prediction for 5010 samples...
0.24803998 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 419 [0/25046 (0%)]	Loss: 0.149981
Train epoch: 419 [328060/25046 (41%)]	Loss: 0.099920
Train epoch: 419 [642760/25046 (82%)]	Loss: 0.100542
Make prediction for 5010 samples...
0.23510063 No improvement since epoch  394 ; best_mse,best_ci: 0.23080109 0.8899394480347681 GINConvNet davis
Training on 25046 samples...
Train epoch: 420 [0/25046 (0%)]	Loss: 0.125299
Train epoch: 420 [331880/25046 (41%)]	Loss: 0.134667
Train epoch: 420 [667720/25046 (82%)]	Loss: 0.109992
Make prediction for 5010 samples...
rmse improved at epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 421 [0/25046 (0%)]	Loss: 0.089884
Train epoch: 421 [327540/25046 (41%)]	Loss: 0.128846
Train epoch: 421 [657320/25046 (82%)]	Loss: 0.120012
Make prediction for 5010 samples...
0.24712382 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 422 [0/25046 (0%)]	Loss: 0.106001
Train epoch: 422 [322140/25046 (41%)]	Loss: 0.094019
Train epoch: 422 [651920/25046 (82%)]	Loss: 0.112041
Make prediction for 5010 samples...
0.31783062 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 423 [0/25046 (0%)]	Loss: 0.162299
Train epoch: 423 [325500/25046 (41%)]	Loss: 0.109618
Train epoch: 423 [656080/25046 (82%)]	Loss: 0.113434
Make prediction for 5010 samples...
0.23524484 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 424 [0/25046 (0%)]	Loss: 0.117821
Train epoch: 424 [327060/25046 (41%)]	Loss: 0.114999
Train epoch: 424 [652960/25046 (82%)]	Loss: 0.096838
Make prediction for 5010 samples...
0.260917 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 425 [0/25046 (0%)]	Loss: 0.097419
Train epoch: 425 [325960/25046 (41%)]	Loss: 0.141388
Train epoch: 425 [663680/25046 (82%)]	Loss: 0.163802
Make prediction for 5010 samples...
0.24542716 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 426 [0/25046 (0%)]	Loss: 0.100875
Train epoch: 426 [329520/25046 (41%)]	Loss: 0.118943
Train epoch: 426 [655000/25046 (82%)]	Loss: 0.118018
Make prediction for 5010 samples...
0.25727466 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 427 [0/25046 (0%)]	Loss: 0.116910
Train epoch: 427 [324000/25046 (41%)]	Loss: 0.117362
Train epoch: 427 [661760/25046 (82%)]	Loss: 0.130439
Make prediction for 5010 samples...
0.25338334 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 428 [0/25046 (0%)]	Loss: 0.082733
Train epoch: 428 [327800/25046 (41%)]	Loss: 0.119199
Train epoch: 428 [652600/25046 (82%)]	Loss: 0.106938
Make prediction for 5010 samples...
0.24555464 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 429 [0/25046 (0%)]	Loss: 0.092276
Train epoch: 429 [327260/25046 (41%)]	Loss: 0.124750
Train epoch: 429 [655640/25046 (82%)]	Loss: 0.109002
Make prediction for 5010 samples...
0.2343396 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 430 [0/25046 (0%)]	Loss: 0.121888
Train epoch: 430 [329300/25046 (41%)]	Loss: 0.081310
Train epoch: 430 [657280/25046 (82%)]	Loss: 0.084177
Make prediction for 5010 samples...
0.2501443 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 431 [0/25046 (0%)]	Loss: 0.100447
Train epoch: 431 [320900/25046 (41%)]	Loss: 0.090476
Train epoch: 431 [659320/25046 (82%)]	Loss: 0.116265
Make prediction for 5010 samples...
0.23192355 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 432 [0/25046 (0%)]	Loss: 0.101503
Train epoch: 432 [321400/25046 (41%)]	Loss: 0.106838
Train epoch: 432 [657040/25046 (82%)]	Loss: 0.092497
Make prediction for 5010 samples...
0.25216028 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 433 [0/25046 (0%)]	Loss: 0.091597
Train epoch: 433 [330960/25046 (41%)]	Loss: 0.115992
Train epoch: 433 [654720/25046 (82%)]	Loss: 0.124681
Make prediction for 5010 samples...
0.24848175 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 434 [0/25046 (0%)]	Loss: 0.104511
Train epoch: 434 [328240/25046 (41%)]	Loss: 0.118766
Train epoch: 434 [654240/25046 (82%)]	Loss: 0.122710
Make prediction for 5010 samples...
0.24164045 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 435 [0/25046 (0%)]	Loss: 0.112764
Train epoch: 435 [328380/25046 (41%)]	Loss: 0.112894
Train epoch: 435 [654840/25046 (82%)]	Loss: 0.073570
Make prediction for 5010 samples...
0.24063729 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 436 [0/25046 (0%)]	Loss: 0.095664
Train epoch: 436 [325940/25046 (41%)]	Loss: 0.131573
Train epoch: 436 [657240/25046 (82%)]	Loss: 0.093619
Make prediction for 5010 samples...
0.24081512 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 437 [0/25046 (0%)]	Loss: 0.088030
Train epoch: 437 [327680/25046 (41%)]	Loss: 0.089238
Train epoch: 437 [654560/25046 (82%)]	Loss: 0.095494
Make prediction for 5010 samples...
0.24388604 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 438 [0/25046 (0%)]	Loss: 0.093775
Train epoch: 438 [326520/25046 (41%)]	Loss: 0.097977
Train epoch: 438 [658960/25046 (82%)]	Loss: 0.104463
Make prediction for 5010 samples...
0.3238119 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 439 [0/25046 (0%)]	Loss: 0.155022
Train epoch: 439 [324420/25046 (41%)]	Loss: 0.101481
Train epoch: 439 [654040/25046 (82%)]	Loss: 0.094323
Make prediction for 5010 samples...
0.25645867 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 440 [0/25046 (0%)]	Loss: 0.079251
Train epoch: 440 [323080/25046 (41%)]	Loss: 0.079545
Train epoch: 440 [654320/25046 (82%)]	Loss: 0.114830
Make prediction for 5010 samples...
0.25859457 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 441 [0/25046 (0%)]	Loss: 0.131522
Train epoch: 441 [325140/25046 (41%)]	Loss: 0.108890
Train epoch: 441 [656080/25046 (82%)]	Loss: 0.095421
Make prediction for 5010 samples...
0.2660284 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 442 [0/25046 (0%)]	Loss: 0.104419
Train epoch: 442 [325900/25046 (41%)]	Loss: 0.106231
Train epoch: 442 [660400/25046 (82%)]	Loss: 0.125232
Make prediction for 5010 samples...
0.2639023 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 443 [0/25046 (0%)]	Loss: 0.106828
Train epoch: 443 [332460/25046 (41%)]	Loss: 0.095799
Train epoch: 443 [655280/25046 (82%)]	Loss: 0.137417
Make prediction for 5010 samples...
0.23217946 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 444 [0/25046 (0%)]	Loss: 0.100928
Train epoch: 444 [331560/25046 (41%)]	Loss: 0.117492
Train epoch: 444 [661280/25046 (82%)]	Loss: 0.104083
Make prediction for 5010 samples...
0.28147924 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 445 [0/25046 (0%)]	Loss: 0.100723
Train epoch: 445 [321380/25046 (41%)]	Loss: 0.104450
Train epoch: 445 [658080/25046 (82%)]	Loss: 0.106536
Make prediction for 5010 samples...
0.23390183 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 446 [0/25046 (0%)]	Loss: 0.140190
Train epoch: 446 [333680/25046 (41%)]	Loss: 0.117760
Train epoch: 446 [657360/25046 (82%)]	Loss: 0.098281
Make prediction for 5010 samples...
0.23409703 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 447 [0/25046 (0%)]	Loss: 0.083827
Train epoch: 447 [328060/25046 (41%)]	Loss: 0.086052
Train epoch: 447 [658400/25046 (82%)]	Loss: 0.087356
Make prediction for 5010 samples...
0.24951506 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 448 [0/25046 (0%)]	Loss: 0.093722
Train epoch: 448 [329000/25046 (41%)]	Loss: 0.129439
Train epoch: 448 [659720/25046 (82%)]	Loss: 0.112846
Make prediction for 5010 samples...
0.24049939 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 449 [0/25046 (0%)]	Loss: 0.117135
Train epoch: 449 [325940/25046 (41%)]	Loss: 0.096136
Train epoch: 449 [658680/25046 (82%)]	Loss: 0.118861
Make prediction for 5010 samples...
0.28830835 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 450 [0/25046 (0%)]	Loss: 0.125557
Train epoch: 450 [327620/25046 (41%)]	Loss: 0.109691
Train epoch: 450 [659320/25046 (82%)]	Loss: 0.095826
Make prediction for 5010 samples...
0.23729986 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 451 [0/25046 (0%)]	Loss: 0.089748
Train epoch: 451 [325740/25046 (41%)]	Loss: 0.092645
Train epoch: 451 [655560/25046 (82%)]	Loss: 0.105518
Make prediction for 5010 samples...
0.27190432 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 452 [0/25046 (0%)]	Loss: 0.129924
Train epoch: 452 [328860/25046 (41%)]	Loss: 0.086966
Train epoch: 452 [649680/25046 (82%)]	Loss: 0.114442
Make prediction for 5010 samples...
0.24141419 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 453 [0/25046 (0%)]	Loss: 0.094931
Train epoch: 453 [326620/25046 (41%)]	Loss: 0.109147
Train epoch: 453 [649480/25046 (82%)]	Loss: 0.102789
Make prediction for 5010 samples...
0.23601834 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 454 [0/25046 (0%)]	Loss: 0.125116
Train epoch: 454 [326820/25046 (41%)]	Loss: 0.110453
Train epoch: 454 [658240/25046 (82%)]	Loss: 0.101201
Make prediction for 5010 samples...
0.24591978 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 455 [0/25046 (0%)]	Loss: 0.157439
Train epoch: 455 [327920/25046 (41%)]	Loss: 0.158857
Train epoch: 455 [659160/25046 (82%)]	Loss: 0.106755
Make prediction for 5010 samples...
0.23633188 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 456 [0/25046 (0%)]	Loss: 0.112720
Train epoch: 456 [327420/25046 (41%)]	Loss: 0.098201
Train epoch: 456 [648480/25046 (82%)]	Loss: 0.116999
Make prediction for 5010 samples...
0.238233 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 457 [0/25046 (0%)]	Loss: 0.084800
Train epoch: 457 [332720/25046 (41%)]	Loss: 0.126864
Train epoch: 457 [661760/25046 (82%)]	Loss: 0.136122
Make prediction for 5010 samples...
0.2511211 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 458 [0/25046 (0%)]	Loss: 0.097351
Train epoch: 458 [329520/25046 (41%)]	Loss: 0.118361
Train epoch: 458 [644200/25046 (82%)]	Loss: 0.126333
Make prediction for 5010 samples...
0.24041818 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 459 [0/25046 (0%)]	Loss: 0.105390
Train epoch: 459 [328020/25046 (41%)]	Loss: 0.123502
Train epoch: 459 [666080/25046 (82%)]	Loss: 0.106767
Make prediction for 5010 samples...
0.23892844 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 460 [0/25046 (0%)]	Loss: 0.101016
Train epoch: 460 [327460/25046 (41%)]	Loss: 0.090370
Train epoch: 460 [655480/25046 (82%)]	Loss: 0.100811
Make prediction for 5010 samples...
0.25380746 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 461 [0/25046 (0%)]	Loss: 0.116452
Train epoch: 461 [329840/25046 (41%)]	Loss: 0.093012
Train epoch: 461 [661320/25046 (82%)]	Loss: 0.106827
Make prediction for 5010 samples...
0.23961808 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 462 [0/25046 (0%)]	Loss: 0.097658
Train epoch: 462 [325900/25046 (41%)]	Loss: 0.096100
Train epoch: 462 [656800/25046 (82%)]	Loss: 0.103138
Make prediction for 5010 samples...
0.23962079 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 463 [0/25046 (0%)]	Loss: 0.095222
Train epoch: 463 [333760/25046 (41%)]	Loss: 0.108945
Train epoch: 463 [656920/25046 (82%)]	Loss: 0.123190
Make prediction for 5010 samples...
0.23374121 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 464 [0/25046 (0%)]	Loss: 0.082261
Train epoch: 464 [329920/25046 (41%)]	Loss: 0.104963
Train epoch: 464 [658920/25046 (82%)]	Loss: 0.078554
Make prediction for 5010 samples...
0.23366778 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 465 [0/25046 (0%)]	Loss: 0.118934
Train epoch: 465 [330920/25046 (41%)]	Loss: 0.105314
Train epoch: 465 [668080/25046 (82%)]	Loss: 0.116347
Make prediction for 5010 samples...
0.24324481 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 466 [0/25046 (0%)]	Loss: 0.092737
Train epoch: 466 [329740/25046 (41%)]	Loss: 0.127280
Train epoch: 466 [651640/25046 (82%)]	Loss: 0.115343
Make prediction for 5010 samples...
0.2359562 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 467 [0/25046 (0%)]	Loss: 0.083325
Train epoch: 467 [329600/25046 (41%)]	Loss: 0.088127
Train epoch: 467 [647360/25046 (82%)]	Loss: 0.096402
Make prediction for 5010 samples...
0.23646262 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 468 [0/25046 (0%)]	Loss: 0.088432
Train epoch: 468 [331220/25046 (41%)]	Loss: 0.138664
Train epoch: 468 [657240/25046 (82%)]	Loss: 0.128234
Make prediction for 5010 samples...
0.26516247 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 469 [0/25046 (0%)]	Loss: 0.095045
Train epoch: 469 [324940/25046 (41%)]	Loss: 0.150099
Train epoch: 469 [661480/25046 (82%)]	Loss: 0.140894
Make prediction for 5010 samples...
0.23695597 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 470 [0/25046 (0%)]	Loss: 0.092240
Train epoch: 470 [324240/25046 (41%)]	Loss: 0.099870
Train epoch: 470 [660080/25046 (82%)]	Loss: 0.094409
Make prediction for 5010 samples...
0.26777622 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 471 [0/25046 (0%)]	Loss: 0.091646
Train epoch: 471 [327160/25046 (41%)]	Loss: 0.100273
Train epoch: 471 [652880/25046 (82%)]	Loss: 0.097521
Make prediction for 5010 samples...
0.24668907 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 472 [0/25046 (0%)]	Loss: 0.079964
Train epoch: 472 [330280/25046 (41%)]	Loss: 0.101569
Train epoch: 472 [661000/25046 (82%)]	Loss: 0.116112
Make prediction for 5010 samples...
0.23166306 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 473 [0/25046 (0%)]	Loss: 0.092865
Train epoch: 473 [325920/25046 (41%)]	Loss: 0.101382
Train epoch: 473 [658280/25046 (82%)]	Loss: 0.091840
Make prediction for 5010 samples...
0.25677907 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 474 [0/25046 (0%)]	Loss: 0.093394
Train epoch: 474 [327720/25046 (41%)]	Loss: 0.119500
Train epoch: 474 [658280/25046 (82%)]	Loss: 0.136188
Make prediction for 5010 samples...
0.25550857 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 475 [0/25046 (0%)]	Loss: 0.114117
Train epoch: 475 [331140/25046 (41%)]	Loss: 0.122082
Train epoch: 475 [664320/25046 (82%)]	Loss: 0.077944
Make prediction for 5010 samples...
0.24262491 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 476 [0/25046 (0%)]	Loss: 0.114841
Train epoch: 476 [327820/25046 (41%)]	Loss: 0.115860
Train epoch: 476 [647640/25046 (82%)]	Loss: 0.116364
Make prediction for 5010 samples...
0.26581097 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 477 [0/25046 (0%)]	Loss: 0.100961
Train epoch: 477 [327020/25046 (41%)]	Loss: 0.090364
Train epoch: 477 [658520/25046 (82%)]	Loss: 0.104913
Make prediction for 5010 samples...
0.24514677 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 478 [0/25046 (0%)]	Loss: 0.096477
Train epoch: 478 [329940/25046 (41%)]	Loss: 0.109836
Train epoch: 478 [656560/25046 (82%)]	Loss: 0.134184
Make prediction for 5010 samples...
0.23352392 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 479 [0/25046 (0%)]	Loss: 0.088862
Train epoch: 479 [328660/25046 (41%)]	Loss: 0.091501
Train epoch: 479 [654240/25046 (82%)]	Loss: 0.108031
Make prediction for 5010 samples...
0.23785865 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 480 [0/25046 (0%)]	Loss: 0.086128
Train epoch: 480 [326760/25046 (41%)]	Loss: 0.122978
Train epoch: 480 [653240/25046 (82%)]	Loss: 0.105230
Make prediction for 5010 samples...
0.23439917 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 481 [0/25046 (0%)]	Loss: 0.085845
Train epoch: 481 [333820/25046 (41%)]	Loss: 0.114619
Train epoch: 481 [655720/25046 (82%)]	Loss: 0.093082
Make prediction for 5010 samples...
0.23404267 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 482 [0/25046 (0%)]	Loss: 0.114362
Train epoch: 482 [327880/25046 (41%)]	Loss: 0.107775
Train epoch: 482 [657480/25046 (82%)]	Loss: 0.085254
Make prediction for 5010 samples...
0.25170404 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 483 [0/25046 (0%)]	Loss: 0.092256
Train epoch: 483 [326400/25046 (41%)]	Loss: 0.113290
Train epoch: 483 [656680/25046 (82%)]	Loss: 0.091319
Make prediction for 5010 samples...
0.24687313 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 484 [0/25046 (0%)]	Loss: 0.090963
Train epoch: 484 [328040/25046 (41%)]	Loss: 0.083001
Train epoch: 484 [661040/25046 (82%)]	Loss: 0.118478
Make prediction for 5010 samples...
0.24675722 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 485 [0/25046 (0%)]	Loss: 0.070258
Train epoch: 485 [327140/25046 (41%)]	Loss: 0.094763
Train epoch: 485 [659600/25046 (82%)]	Loss: 0.131973
Make prediction for 5010 samples...
0.23831955 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 486 [0/25046 (0%)]	Loss: 0.100258
Train epoch: 486 [329160/25046 (41%)]	Loss: 0.104674
Train epoch: 486 [663600/25046 (82%)]	Loss: 0.115422
Make prediction for 5010 samples...
0.25287676 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 487 [0/25046 (0%)]	Loss: 0.110609
Train epoch: 487 [330040/25046 (41%)]	Loss: 0.123956
Train epoch: 487 [657080/25046 (82%)]	Loss: 0.106919
Make prediction for 5010 samples...
0.24927905 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 488 [0/25046 (0%)]	Loss: 0.099681
Train epoch: 488 [327240/25046 (41%)]	Loss: 0.097570
Train epoch: 488 [666000/25046 (82%)]	Loss: 0.101974
Make prediction for 5010 samples...
0.23805802 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 489 [0/25046 (0%)]	Loss: 0.085794
Train epoch: 489 [326060/25046 (41%)]	Loss: 0.104441
Train epoch: 489 [651840/25046 (82%)]	Loss: 0.109977
Make prediction for 5010 samples...
0.23506883 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 490 [0/25046 (0%)]	Loss: 0.088402
Train epoch: 490 [331460/25046 (41%)]	Loss: 0.095172
Train epoch: 490 [647200/25046 (82%)]	Loss: 0.084702
Make prediction for 5010 samples...
0.29937738 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 491 [0/25046 (0%)]	Loss: 0.123871
Train epoch: 491 [324260/25046 (41%)]	Loss: 0.111631
Train epoch: 491 [659320/25046 (82%)]	Loss: 0.109451
Make prediction for 5010 samples...
0.24546333 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 492 [0/25046 (0%)]	Loss: 0.089801
Train epoch: 492 [327380/25046 (41%)]	Loss: 0.093824
Train epoch: 492 [655120/25046 (82%)]	Loss: 0.089823
Make prediction for 5010 samples...
0.23976256 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 493 [0/25046 (0%)]	Loss: 0.088982
Train epoch: 493 [333140/25046 (41%)]	Loss: 0.089062
Train epoch: 493 [648120/25046 (82%)]	Loss: 0.083908
Make prediction for 5010 samples...
0.24333754 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 494 [0/25046 (0%)]	Loss: 0.108293
Train epoch: 494 [330060/25046 (41%)]	Loss: 0.086809
Train epoch: 494 [664080/25046 (82%)]	Loss: 0.086722
Make prediction for 5010 samples...
0.24354358 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 495 [0/25046 (0%)]	Loss: 0.100921
Train epoch: 495 [334560/25046 (41%)]	Loss: 0.112875
Train epoch: 495 [654720/25046 (82%)]	Loss: 0.098419
Make prediction for 5010 samples...
0.23385648 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 496 [0/25046 (0%)]	Loss: 0.089759
Train epoch: 496 [328260/25046 (41%)]	Loss: 0.097577
Train epoch: 496 [663240/25046 (82%)]	Loss: 0.099967
Make prediction for 5010 samples...
0.24011791 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 497 [0/25046 (0%)]	Loss: 0.078236
Train epoch: 497 [327140/25046 (41%)]	Loss: 0.118879
Train epoch: 497 [652080/25046 (82%)]	Loss: 0.111654
Make prediction for 5010 samples...
0.23959403 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 498 [0/25046 (0%)]	Loss: 0.099580
Train epoch: 498 [328860/25046 (41%)]	Loss: 0.099596
Train epoch: 498 [662960/25046 (82%)]	Loss: 0.078685
Make prediction for 5010 samples...
0.24170198 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 499 [0/25046 (0%)]	Loss: 0.102706
Train epoch: 499 [326000/25046 (41%)]	Loss: 0.117590
Train epoch: 499 [665560/25046 (82%)]	Loss: 0.110386
Make prediction for 5010 samples...
0.23891792 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 500 [0/25046 (0%)]	Loss: 0.096890
Train epoch: 500 [323300/25046 (41%)]	Loss: 0.096833
Train epoch: 500 [662080/25046 (82%)]	Loss: 0.119830
Make prediction for 5010 samples...
0.23955037 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 501 [0/25046 (0%)]	Loss: 0.088905
Train epoch: 501 [334120/25046 (41%)]	Loss: 0.094752
Train epoch: 501 [661080/25046 (82%)]	Loss: 0.146797
Make prediction for 5010 samples...
0.23638685 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 502 [0/25046 (0%)]	Loss: 0.078136
Train epoch: 502 [339060/25046 (41%)]	Loss: 0.078992
Train epoch: 502 [662440/25046 (82%)]	Loss: 0.092693
Make prediction for 5010 samples...
0.23392577 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 503 [0/25046 (0%)]	Loss: 0.101548
Train epoch: 503 [329100/25046 (41%)]	Loss: 0.109735
Train epoch: 503 [669040/25046 (82%)]	Loss: 0.119031
Make prediction for 5010 samples...
0.24810779 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 504 [0/25046 (0%)]	Loss: 0.096797
Train epoch: 504 [327860/25046 (41%)]	Loss: 0.140357
Train epoch: 504 [644160/25046 (82%)]	Loss: 0.097181
Make prediction for 5010 samples...
0.23797074 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 505 [0/25046 (0%)]	Loss: 0.080842
Train epoch: 505 [327280/25046 (41%)]	Loss: 0.082429
Train epoch: 505 [654880/25046 (82%)]	Loss: 0.149254
Make prediction for 5010 samples...
0.27769104 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 506 [0/25046 (0%)]	Loss: 0.086211
Train epoch: 506 [329240/25046 (41%)]	Loss: 0.101079
Train epoch: 506 [650520/25046 (82%)]	Loss: 0.085747
Make prediction for 5010 samples...
0.24006811 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 507 [0/25046 (0%)]	Loss: 0.092969
Train epoch: 507 [328200/25046 (41%)]	Loss: 0.112615
Train epoch: 507 [658400/25046 (82%)]	Loss: 0.087540
Make prediction for 5010 samples...
0.24492143 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 508 [0/25046 (0%)]	Loss: 0.091319
Train epoch: 508 [327280/25046 (41%)]	Loss: 0.133064
Train epoch: 508 [654240/25046 (82%)]	Loss: 0.086439
Make prediction for 5010 samples...
0.24028267 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 509 [0/25046 (0%)]	Loss: 0.099828
Train epoch: 509 [328620/25046 (41%)]	Loss: 0.090969
Train epoch: 509 [662960/25046 (82%)]	Loss: 0.110869
Make prediction for 5010 samples...
0.24616289 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 510 [0/25046 (0%)]	Loss: 0.091348
Train epoch: 510 [329040/25046 (41%)]	Loss: 0.095567
Train epoch: 510 [660000/25046 (82%)]	Loss: 0.078672
Make prediction for 5010 samples...
0.2617914 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 511 [0/25046 (0%)]	Loss: 0.104733
Train epoch: 511 [333380/25046 (41%)]	Loss: 0.082956
Train epoch: 511 [661960/25046 (82%)]	Loss: 0.101621
Make prediction for 5010 samples...
0.28833562 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 512 [0/25046 (0%)]	Loss: 0.124363
Train epoch: 512 [320160/25046 (41%)]	Loss: 0.125208
Train epoch: 512 [657960/25046 (82%)]	Loss: 0.090934
Make prediction for 5010 samples...
0.2477336 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 513 [0/25046 (0%)]	Loss: 0.069762
Train epoch: 513 [329540/25046 (41%)]	Loss: 0.095573
Train epoch: 513 [668200/25046 (82%)]	Loss: 0.123411
Make prediction for 5010 samples...
0.25427735 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 514 [0/25046 (0%)]	Loss: 0.102765
Train epoch: 514 [330480/25046 (41%)]	Loss: 0.104778
Train epoch: 514 [659080/25046 (82%)]	Loss: 0.095338
Make prediction for 5010 samples...
0.24265264 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 515 [0/25046 (0%)]	Loss: 0.107902
Train epoch: 515 [325080/25046 (41%)]	Loss: 0.105123
Train epoch: 515 [666480/25046 (82%)]	Loss: 0.068816
Make prediction for 5010 samples...
0.23305182 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 516 [0/25046 (0%)]	Loss: 0.116036
Train epoch: 516 [330180/25046 (41%)]	Loss: 0.089014
Train epoch: 516 [657320/25046 (82%)]	Loss: 0.149883
Make prediction for 5010 samples...
0.23485537 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 517 [0/25046 (0%)]	Loss: 0.082710
Train epoch: 517 [332200/25046 (41%)]	Loss: 0.117318
Train epoch: 517 [666520/25046 (82%)]	Loss: 0.120651
Make prediction for 5010 samples...
0.23416853 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 518 [0/25046 (0%)]	Loss: 0.087988
Train epoch: 518 [326480/25046 (41%)]	Loss: 0.108572
Train epoch: 518 [664920/25046 (82%)]	Loss: 0.090622
Make prediction for 5010 samples...
0.23999637 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 519 [0/25046 (0%)]	Loss: 0.066303
Train epoch: 519 [327120/25046 (41%)]	Loss: 0.129603
Train epoch: 519 [654400/25046 (82%)]	Loss: 0.081817
Make prediction for 5010 samples...
0.23320074 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 520 [0/25046 (0%)]	Loss: 0.081463
Train epoch: 520 [329680/25046 (41%)]	Loss: 0.093200
Train epoch: 520 [652000/25046 (82%)]	Loss: 0.116462
Make prediction for 5010 samples...
0.24023841 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 521 [0/25046 (0%)]	Loss: 0.100097
Train epoch: 521 [324980/25046 (41%)]	Loss: 0.065570
Train epoch: 521 [655240/25046 (82%)]	Loss: 0.083848
Make prediction for 5010 samples...
0.23771808 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 522 [0/25046 (0%)]	Loss: 0.096905
Train epoch: 522 [326500/25046 (41%)]	Loss: 0.100135
Train epoch: 522 [663080/25046 (82%)]	Loss: 0.093160
Make prediction for 5010 samples...
0.24628909 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 523 [0/25046 (0%)]	Loss: 0.092545
Train epoch: 523 [328240/25046 (41%)]	Loss: 0.118459
Train epoch: 523 [661240/25046 (82%)]	Loss: 0.095173
Make prediction for 5010 samples...
0.25577155 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 524 [0/25046 (0%)]	Loss: 0.097670
Train epoch: 524 [332400/25046 (41%)]	Loss: 0.092836
Train epoch: 524 [662440/25046 (82%)]	Loss: 0.099999
Make prediction for 5010 samples...
0.23567435 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 525 [0/25046 (0%)]	Loss: 0.085489
Train epoch: 525 [329680/25046 (41%)]	Loss: 0.096766
Train epoch: 525 [657160/25046 (82%)]	Loss: 0.084963
Make prediction for 5010 samples...
0.23844104 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 526 [0/25046 (0%)]	Loss: 0.084322
Train epoch: 526 [330840/25046 (41%)]	Loss: 0.156731
Train epoch: 526 [657560/25046 (82%)]	Loss: 0.130229
Make prediction for 5010 samples...
0.2860678 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 527 [0/25046 (0%)]	Loss: 0.139629
Train epoch: 527 [326380/25046 (41%)]	Loss: 0.083065
Train epoch: 527 [654120/25046 (82%)]	Loss: 0.071223
Make prediction for 5010 samples...
0.23480208 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 528 [0/25046 (0%)]	Loss: 0.064425
Train epoch: 528 [326360/25046 (41%)]	Loss: 0.074457
Train epoch: 528 [658200/25046 (82%)]	Loss: 0.100280
Make prediction for 5010 samples...
0.2330618 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 529 [0/25046 (0%)]	Loss: 0.096427
Train epoch: 529 [323380/25046 (41%)]	Loss: 0.077578
Train epoch: 529 [656160/25046 (82%)]	Loss: 0.145752
Make prediction for 5010 samples...
0.2532981 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 530 [0/25046 (0%)]	Loss: 0.080492
Train epoch: 530 [325200/25046 (41%)]	Loss: 0.079552
Train epoch: 530 [664240/25046 (82%)]	Loss: 0.101692
Make prediction for 5010 samples...
0.26591566 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 531 [0/25046 (0%)]	Loss: 0.130752
Train epoch: 531 [324740/25046 (41%)]	Loss: 0.102336
Train epoch: 531 [666360/25046 (82%)]	Loss: 0.096520
Make prediction for 5010 samples...
0.24212919 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 532 [0/25046 (0%)]	Loss: 0.075397
Train epoch: 532 [330280/25046 (41%)]	Loss: 0.077541
Train epoch: 532 [649960/25046 (82%)]	Loss: 0.090466
Make prediction for 5010 samples...
0.24228494 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 533 [0/25046 (0%)]	Loss: 0.076558
Train epoch: 533 [332400/25046 (41%)]	Loss: 0.074596
Train epoch: 533 [653960/25046 (82%)]	Loss: 0.078605
Make prediction for 5010 samples...
0.24240088 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 534 [0/25046 (0%)]	Loss: 0.087261
Train epoch: 534 [326660/25046 (41%)]	Loss: 0.076349
Train epoch: 534 [655240/25046 (82%)]	Loss: 0.103702
Make prediction for 5010 samples...
0.23603223 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 535 [0/25046 (0%)]	Loss: 0.094989
Train epoch: 535 [328640/25046 (41%)]	Loss: 0.108420
Train epoch: 535 [648760/25046 (82%)]	Loss: 0.071196
Make prediction for 5010 samples...
0.23259293 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 536 [0/25046 (0%)]	Loss: 0.102542
Train epoch: 536 [329960/25046 (41%)]	Loss: 0.113009
Train epoch: 536 [653080/25046 (82%)]	Loss: 0.092813
Make prediction for 5010 samples...
0.23744844 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 537 [0/25046 (0%)]	Loss: 0.104887
Train epoch: 537 [325060/25046 (41%)]	Loss: 0.132231
Train epoch: 537 [655800/25046 (82%)]	Loss: 0.126775
Make prediction for 5010 samples...
0.23603342 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 538 [0/25046 (0%)]	Loss: 0.109785
Train epoch: 538 [326840/25046 (41%)]	Loss: 0.117929
Train epoch: 538 [662480/25046 (82%)]	Loss: 0.118594
Make prediction for 5010 samples...
0.23673907 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 539 [0/25046 (0%)]	Loss: 0.111392
Train epoch: 539 [328500/25046 (41%)]	Loss: 0.087875
Train epoch: 539 [660040/25046 (82%)]	Loss: 0.079954
Make prediction for 5010 samples...
0.23422968 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 540 [0/25046 (0%)]	Loss: 0.086706
Train epoch: 540 [329700/25046 (41%)]	Loss: 0.074014
Train epoch: 540 [650720/25046 (82%)]	Loss: 0.089376
Make prediction for 5010 samples...
0.23912124 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 541 [0/25046 (0%)]	Loss: 0.101283
Train epoch: 541 [325020/25046 (41%)]	Loss: 0.074554
Train epoch: 541 [658720/25046 (82%)]	Loss: 0.101692
Make prediction for 5010 samples...
0.23787092 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 542 [0/25046 (0%)]	Loss: 0.093050
Train epoch: 542 [330040/25046 (41%)]	Loss: 0.103600
Train epoch: 542 [660640/25046 (82%)]	Loss: 0.091363
Make prediction for 5010 samples...
0.24348888 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 543 [0/25046 (0%)]	Loss: 0.059443
Train epoch: 543 [326360/25046 (41%)]	Loss: 0.085250
Train epoch: 543 [660440/25046 (82%)]	Loss: 0.095824
Make prediction for 5010 samples...
0.23797792 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 544 [0/25046 (0%)]	Loss: 0.106925
Train epoch: 544 [325320/25046 (41%)]	Loss: 0.085304
Train epoch: 544 [669680/25046 (82%)]	Loss: 0.094671
Make prediction for 5010 samples...
0.24432604 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 545 [0/25046 (0%)]	Loss: 0.086758
Train epoch: 545 [325020/25046 (41%)]	Loss: 0.092517
Train epoch: 545 [655280/25046 (82%)]	Loss: 0.069409
Make prediction for 5010 samples...
0.24040703 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 546 [0/25046 (0%)]	Loss: 0.077487
Train epoch: 546 [323820/25046 (41%)]	Loss: 0.072350
Train epoch: 546 [665400/25046 (82%)]	Loss: 0.101554
Make prediction for 5010 samples...
0.23343499 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 547 [0/25046 (0%)]	Loss: 0.103315
Train epoch: 547 [326460/25046 (41%)]	Loss: 0.089884
Train epoch: 547 [649520/25046 (82%)]	Loss: 0.098717
Make prediction for 5010 samples...
0.24995334 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 548 [0/25046 (0%)]	Loss: 0.091970
Train epoch: 548 [329760/25046 (41%)]	Loss: 0.097090
Train epoch: 548 [657040/25046 (82%)]	Loss: 0.101396
Make prediction for 5010 samples...
0.24051419 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 549 [0/25046 (0%)]	Loss: 0.117104
Train epoch: 549 [330820/25046 (41%)]	Loss: 0.074091
Train epoch: 549 [653920/25046 (82%)]	Loss: 0.090481
Make prediction for 5010 samples...
0.25536826 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 550 [0/25046 (0%)]	Loss: 0.101713
Train epoch: 550 [324540/25046 (41%)]	Loss: 0.122113
Train epoch: 550 [661400/25046 (82%)]	Loss: 0.069893
Make prediction for 5010 samples...
0.26302996 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 551 [0/25046 (0%)]	Loss: 0.092849
Train epoch: 551 [328700/25046 (41%)]	Loss: 0.087788
Train epoch: 551 [658680/25046 (82%)]	Loss: 0.117939
Make prediction for 5010 samples...
0.23266299 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 552 [0/25046 (0%)]	Loss: 0.110857
Train epoch: 552 [330720/25046 (41%)]	Loss: 0.095914
Train epoch: 552 [650240/25046 (82%)]	Loss: 0.081092
Make prediction for 5010 samples...
0.23218563 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 553 [0/25046 (0%)]	Loss: 0.106781
Train epoch: 553 [327540/25046 (41%)]	Loss: 0.097974
Train epoch: 553 [660960/25046 (82%)]	Loss: 0.095763
Make prediction for 5010 samples...
0.2352143 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 554 [0/25046 (0%)]	Loss: 0.086661
Train epoch: 554 [327080/25046 (41%)]	Loss: 0.102876
Train epoch: 554 [652160/25046 (82%)]	Loss: 0.125778
Make prediction for 5010 samples...
0.28544605 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 555 [0/25046 (0%)]	Loss: 0.113447
Train epoch: 555 [326840/25046 (41%)]	Loss: 0.090211
Train epoch: 555 [657720/25046 (82%)]	Loss: 0.088730
Make prediction for 5010 samples...
0.28216788 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 556 [0/25046 (0%)]	Loss: 0.097502
Train epoch: 556 [327760/25046 (41%)]	Loss: 0.106504
Train epoch: 556 [656600/25046 (82%)]	Loss: 0.097035
Make prediction for 5010 samples...
0.271872 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 557 [0/25046 (0%)]	Loss: 0.103287
Train epoch: 557 [328440/25046 (41%)]	Loss: 0.125786
Train epoch: 557 [654560/25046 (82%)]	Loss: 0.071219
Make prediction for 5010 samples...
0.23711781 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 558 [0/25046 (0%)]	Loss: 0.073958
Train epoch: 558 [327560/25046 (41%)]	Loss: 0.106033
Train epoch: 558 [651960/25046 (82%)]	Loss: 0.131147
Make prediction for 5010 samples...
0.23846543 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 559 [0/25046 (0%)]	Loss: 0.094847
Train epoch: 559 [330360/25046 (41%)]	Loss: 0.076956
Train epoch: 559 [660000/25046 (82%)]	Loss: 0.091186
Make prediction for 5010 samples...
0.26676685 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 560 [0/25046 (0%)]	Loss: 0.096292
Train epoch: 560 [330020/25046 (41%)]	Loss: 0.083221
Train epoch: 560 [644560/25046 (82%)]	Loss: 0.142401
Make prediction for 5010 samples...
0.24505097 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 561 [0/25046 (0%)]	Loss: 0.112557
Train epoch: 561 [323740/25046 (41%)]	Loss: 0.118161
Train epoch: 561 [656440/25046 (82%)]	Loss: 0.091847
Make prediction for 5010 samples...
0.27582586 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 562 [0/25046 (0%)]	Loss: 0.096991
Train epoch: 562 [330100/25046 (41%)]	Loss: 0.089237
Train epoch: 562 [651200/25046 (82%)]	Loss: 0.098257
Make prediction for 5010 samples...
0.24639882 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 563 [0/25046 (0%)]	Loss: 0.066995
Train epoch: 563 [328380/25046 (41%)]	Loss: 0.083553
Train epoch: 563 [664880/25046 (82%)]	Loss: 0.095872
Make prediction for 5010 samples...
0.23945376 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 564 [0/25046 (0%)]	Loss: 0.128218
Train epoch: 564 [330580/25046 (41%)]	Loss: 0.150122
Train epoch: 564 [658240/25046 (82%)]	Loss: 0.084519
Make prediction for 5010 samples...
0.23911935 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 565 [0/25046 (0%)]	Loss: 0.081896
Train epoch: 565 [330700/25046 (41%)]	Loss: 0.156029
Train epoch: 565 [660360/25046 (82%)]	Loss: 0.088825
Make prediction for 5010 samples...
0.25899416 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 566 [0/25046 (0%)]	Loss: 0.068340
Train epoch: 566 [325740/25046 (41%)]	Loss: 0.108287
Train epoch: 566 [655480/25046 (82%)]	Loss: 0.103592
Make prediction for 5010 samples...
0.24359441 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 567 [0/25046 (0%)]	Loss: 0.074070
Train epoch: 567 [328320/25046 (41%)]	Loss: 0.095353
Train epoch: 567 [658280/25046 (82%)]	Loss: 0.099960
Make prediction for 5010 samples...
0.24593028 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 568 [0/25046 (0%)]	Loss: 0.090699
Train epoch: 568 [323600/25046 (41%)]	Loss: 0.106749
Train epoch: 568 [644120/25046 (82%)]	Loss: 0.084318
Make prediction for 5010 samples...
0.23819807 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 569 [0/25046 (0%)]	Loss: 0.073229
Train epoch: 569 [324980/25046 (41%)]	Loss: 0.071130
Train epoch: 569 [653440/25046 (82%)]	Loss: 0.098446
Make prediction for 5010 samples...
0.2525565 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 570 [0/25046 (0%)]	Loss: 0.103130
Train epoch: 570 [327120/25046 (41%)]	Loss: 0.093117
Train epoch: 570 [663440/25046 (82%)]	Loss: 0.091427
Make prediction for 5010 samples...
0.24761058 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 571 [0/25046 (0%)]	Loss: 0.122921
Train epoch: 571 [325340/25046 (41%)]	Loss: 0.081749
Train epoch: 571 [654120/25046 (82%)]	Loss: 0.138096
Make prediction for 5010 samples...
0.24529204 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 572 [0/25046 (0%)]	Loss: 0.105890
Train epoch: 572 [332940/25046 (41%)]	Loss: 0.078267
Train epoch: 572 [658840/25046 (82%)]	Loss: 0.098955
Make prediction for 5010 samples...
0.23725785 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 573 [0/25046 (0%)]	Loss: 0.074750
Train epoch: 573 [326860/25046 (41%)]	Loss: 0.136539
Train epoch: 573 [658720/25046 (82%)]	Loss: 0.102066
Make prediction for 5010 samples...
0.23530975 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 574 [0/25046 (0%)]	Loss: 0.135863
Train epoch: 574 [330620/25046 (41%)]	Loss: 0.075152
Train epoch: 574 [655560/25046 (82%)]	Loss: 0.079234
Make prediction for 5010 samples...
0.28480178 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 575 [0/25046 (0%)]	Loss: 0.115837
Train epoch: 575 [325460/25046 (41%)]	Loss: 0.089939
Train epoch: 575 [659920/25046 (82%)]	Loss: 0.092903
Make prediction for 5010 samples...
0.23474026 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 576 [0/25046 (0%)]	Loss: 0.096446
Train epoch: 576 [327580/25046 (41%)]	Loss: 0.087249
Train epoch: 576 [649280/25046 (82%)]	Loss: 0.121666
Make prediction for 5010 samples...
0.24448356 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 577 [0/25046 (0%)]	Loss: 0.085061
Train epoch: 577 [327240/25046 (41%)]	Loss: 0.103148
Train epoch: 577 [659480/25046 (82%)]	Loss: 0.095591
Make prediction for 5010 samples...
0.23934086 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 578 [0/25046 (0%)]	Loss: 0.088905
Train epoch: 578 [323780/25046 (41%)]	Loss: 0.132888
Train epoch: 578 [662800/25046 (82%)]	Loss: 0.099516
Make prediction for 5010 samples...
0.240532 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 579 [0/25046 (0%)]	Loss: 0.090645
Train epoch: 579 [333580/25046 (41%)]	Loss: 0.167687
Train epoch: 579 [659360/25046 (82%)]	Loss: 0.100199
Make prediction for 5010 samples...
0.24147736 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 580 [0/25046 (0%)]	Loss: 0.067370
Train epoch: 580 [328820/25046 (41%)]	Loss: 0.082263
Train epoch: 580 [655360/25046 (82%)]	Loss: 0.100408
Make prediction for 5010 samples...
0.2480728 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 581 [0/25046 (0%)]	Loss: 0.087493
Train epoch: 581 [326840/25046 (41%)]	Loss: 0.068277
Train epoch: 581 [653080/25046 (82%)]	Loss: 0.095278
Make prediction for 5010 samples...
0.24109769 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 582 [0/25046 (0%)]	Loss: 0.098449
Train epoch: 582 [330640/25046 (41%)]	Loss: 0.109779
Train epoch: 582 [657960/25046 (82%)]	Loss: 0.077704
Make prediction for 5010 samples...
0.23513213 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 583 [0/25046 (0%)]	Loss: 0.078548
Train epoch: 583 [324320/25046 (41%)]	Loss: 0.077849
Train epoch: 583 [667560/25046 (82%)]	Loss: 0.093925
Make prediction for 5010 samples...
0.23680356 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 584 [0/25046 (0%)]	Loss: 0.086235
Train epoch: 584 [331360/25046 (41%)]	Loss: 0.083451
Train epoch: 584 [660880/25046 (82%)]	Loss: 0.106168
Make prediction for 5010 samples...
0.2344185 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 585 [0/25046 (0%)]	Loss: 0.073879
Train epoch: 585 [329340/25046 (41%)]	Loss: 0.077458
Train epoch: 585 [654640/25046 (82%)]	Loss: 0.089689
Make prediction for 5010 samples...
0.24297927 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 586 [0/25046 (0%)]	Loss: 0.093028
Train epoch: 586 [325500/25046 (41%)]	Loss: 0.083049
Train epoch: 586 [663840/25046 (82%)]	Loss: 0.085760
Make prediction for 5010 samples...
0.23619753 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 587 [0/25046 (0%)]	Loss: 0.082517
Train epoch: 587 [333380/25046 (41%)]	Loss: 0.118219
Train epoch: 587 [664720/25046 (82%)]	Loss: 0.078857
Make prediction for 5010 samples...
0.2494135 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 588 [0/25046 (0%)]	Loss: 0.072927
Train epoch: 588 [328240/25046 (41%)]	Loss: 0.087057
Train epoch: 588 [666000/25046 (82%)]	Loss: 0.093360
Make prediction for 5010 samples...
0.24431963 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 589 [0/25046 (0%)]	Loss: 0.073932
Train epoch: 589 [328000/25046 (41%)]	Loss: 0.086328
Train epoch: 589 [661560/25046 (82%)]	Loss: 0.077580
Make prediction for 5010 samples...
0.2375854 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 590 [0/25046 (0%)]	Loss: 0.067900
Train epoch: 590 [327640/25046 (41%)]	Loss: 0.082612
Train epoch: 590 [673040/25046 (82%)]	Loss: 0.088429
Make prediction for 5010 samples...
0.23432758 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 591 [0/25046 (0%)]	Loss: 0.098623
Train epoch: 591 [330760/25046 (41%)]	Loss: 0.094099
Train epoch: 591 [646400/25046 (82%)]	Loss: 0.102410
Make prediction for 5010 samples...
0.27984557 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 592 [0/25046 (0%)]	Loss: 0.107419
Train epoch: 592 [328180/25046 (41%)]	Loss: 0.086749
Train epoch: 592 [654400/25046 (82%)]	Loss: 0.096419
Make prediction for 5010 samples...
0.28866047 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 593 [0/25046 (0%)]	Loss: 0.105901
Train epoch: 593 [324760/25046 (41%)]	Loss: 0.080016
Train epoch: 593 [665320/25046 (82%)]	Loss: 0.088551
Make prediction for 5010 samples...
0.2501082 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 594 [0/25046 (0%)]	Loss: 0.083869
Train epoch: 594 [327660/25046 (41%)]	Loss: 0.065275
Train epoch: 594 [663800/25046 (82%)]	Loss: 0.107093
Make prediction for 5010 samples...
0.2388634 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 595 [0/25046 (0%)]	Loss: 0.075489
Train epoch: 595 [329020/25046 (41%)]	Loss: 0.096640
Train epoch: 595 [651400/25046 (82%)]	Loss: 0.081245
Make prediction for 5010 samples...
0.2480481 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 596 [0/25046 (0%)]	Loss: 0.088341
Train epoch: 596 [326980/25046 (41%)]	Loss: 0.107436
Train epoch: 596 [670920/25046 (82%)]	Loss: 0.074826
Make prediction for 5010 samples...
0.23747912 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 597 [0/25046 (0%)]	Loss: 0.073018
Train epoch: 597 [327280/25046 (41%)]	Loss: 0.087474
Train epoch: 597 [650960/25046 (82%)]	Loss: 0.090008
Make prediction for 5010 samples...
0.26629406 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 598 [0/25046 (0%)]	Loss: 0.119068
Train epoch: 598 [331460/25046 (41%)]	Loss: 0.100270
Train epoch: 598 [654600/25046 (82%)]	Loss: 0.084240
Make prediction for 5010 samples...
0.24945539 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 599 [0/25046 (0%)]	Loss: 0.066933
Train epoch: 599 [328040/25046 (41%)]	Loss: 0.117241
Train epoch: 599 [662960/25046 (82%)]	Loss: 0.081179
Make prediction for 5010 samples...
0.24199821 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 600 [0/25046 (0%)]	Loss: 0.095019
Train epoch: 600 [324000/25046 (41%)]	Loss: 0.075589
Train epoch: 600 [658560/25046 (82%)]	Loss: 0.113733
Make prediction for 5010 samples...
0.23675145 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 601 [0/25046 (0%)]	Loss: 0.089608
Train epoch: 601 [328800/25046 (41%)]	Loss: 0.087043
Train epoch: 601 [656160/25046 (82%)]	Loss: 0.070884
Make prediction for 5010 samples...
0.24832697 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 602 [0/25046 (0%)]	Loss: 0.087560
Train epoch: 602 [328940/25046 (41%)]	Loss: 0.086630
Train epoch: 602 [653440/25046 (82%)]	Loss: 0.087583
Make prediction for 5010 samples...
0.23874037 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 603 [0/25046 (0%)]	Loss: 0.067664
Train epoch: 603 [323600/25046 (41%)]	Loss: 0.066087
Train epoch: 603 [655320/25046 (82%)]	Loss: 0.085740
Make prediction for 5010 samples...
0.25336933 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 604 [0/25046 (0%)]	Loss: 0.105885
Train epoch: 604 [324760/25046 (41%)]	Loss: 0.085506
Train epoch: 604 [663640/25046 (82%)]	Loss: 0.090562
Make prediction for 5010 samples...
0.266607 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 605 [0/25046 (0%)]	Loss: 0.113223
Train epoch: 605 [328900/25046 (41%)]	Loss: 0.076677
Train epoch: 605 [656280/25046 (82%)]	Loss: 0.112210
Make prediction for 5010 samples...
0.25505093 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 606 [0/25046 (0%)]	Loss: 0.084771
Train epoch: 606 [330240/25046 (41%)]	Loss: 0.092465
Train epoch: 606 [664440/25046 (82%)]	Loss: 0.108758
Make prediction for 5010 samples...
0.23698178 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 607 [0/25046 (0%)]	Loss: 0.072798
Train epoch: 607 [331460/25046 (41%)]	Loss: 0.071477
Train epoch: 607 [654120/25046 (82%)]	Loss: 0.092605
Make prediction for 5010 samples...
0.23504382 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 608 [0/25046 (0%)]	Loss: 0.094417
Train epoch: 608 [330800/25046 (41%)]	Loss: 0.073821
Train epoch: 608 [649960/25046 (82%)]	Loss: 0.105282
Make prediction for 5010 samples...
0.23676953 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 609 [0/25046 (0%)]	Loss: 0.072123
Train epoch: 609 [327460/25046 (41%)]	Loss: 0.081487
Train epoch: 609 [660360/25046 (82%)]	Loss: 0.085934
Make prediction for 5010 samples...
0.24055555 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 610 [0/25046 (0%)]	Loss: 0.080859
Train epoch: 610 [331980/25046 (41%)]	Loss: 0.085043
Train epoch: 610 [653680/25046 (82%)]	Loss: 0.079584
Make prediction for 5010 samples...
0.24319515 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 611 [0/25046 (0%)]	Loss: 0.075750
Train epoch: 611 [331160/25046 (41%)]	Loss: 0.107164
Train epoch: 611 [660800/25046 (82%)]	Loss: 0.069208
Make prediction for 5010 samples...
0.24734603 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 612 [0/25046 (0%)]	Loss: 0.106835
Train epoch: 612 [324880/25046 (41%)]	Loss: 0.072762
Train epoch: 612 [657120/25046 (82%)]	Loss: 0.128490
Make prediction for 5010 samples...
0.27022633 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 613 [0/25046 (0%)]	Loss: 0.105094
Train epoch: 613 [326940/25046 (41%)]	Loss: 0.063677
Train epoch: 613 [663960/25046 (82%)]	Loss: 0.082751
Make prediction for 5010 samples...
0.24821378 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 614 [0/25046 (0%)]	Loss: 0.078979
Train epoch: 614 [332180/25046 (41%)]	Loss: 0.094272
Train epoch: 614 [654600/25046 (82%)]	Loss: 0.091678
Make prediction for 5010 samples...
0.23599227 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 615 [0/25046 (0%)]	Loss: 0.081904
Train epoch: 615 [324660/25046 (41%)]	Loss: 0.101656
Train epoch: 615 [658000/25046 (82%)]	Loss: 0.071823
Make prediction for 5010 samples...
0.24126376 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 616 [0/25046 (0%)]	Loss: 0.064454
Train epoch: 616 [326980/25046 (41%)]	Loss: 0.083708
Train epoch: 616 [643880/25046 (82%)]	Loss: 0.087196
Make prediction for 5010 samples...
0.24605772 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 617 [0/25046 (0%)]	Loss: 0.072983
Train epoch: 617 [327600/25046 (41%)]	Loss: 0.083501
Train epoch: 617 [650720/25046 (82%)]	Loss: 0.090222
Make prediction for 5010 samples...
0.23976329 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 618 [0/25046 (0%)]	Loss: 0.090066
Train epoch: 618 [329600/25046 (41%)]	Loss: 0.078227
Train epoch: 618 [658360/25046 (82%)]	Loss: 0.075498
Make prediction for 5010 samples...
0.23286586 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 619 [0/25046 (0%)]	Loss: 0.075672
Train epoch: 619 [323760/25046 (41%)]	Loss: 0.094478
Train epoch: 619 [656240/25046 (82%)]	Loss: 0.068505
Make prediction for 5010 samples...
0.24581398 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 620 [0/25046 (0%)]	Loss: 0.077615
Train epoch: 620 [331380/25046 (41%)]	Loss: 0.084881
Train epoch: 620 [659600/25046 (82%)]	Loss: 0.072712
Make prediction for 5010 samples...
0.25979453 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 621 [0/25046 (0%)]	Loss: 0.080333
Train epoch: 621 [327780/25046 (41%)]	Loss: 0.089811
Train epoch: 621 [662760/25046 (82%)]	Loss: 0.091937
Make prediction for 5010 samples...
0.24782169 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 622 [0/25046 (0%)]	Loss: 0.072252
Train epoch: 622 [329280/25046 (41%)]	Loss: 0.086265
Train epoch: 622 [661080/25046 (82%)]	Loss: 0.088500
Make prediction for 5010 samples...
0.23780422 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 623 [0/25046 (0%)]	Loss: 0.112748
Train epoch: 623 [327880/25046 (41%)]	Loss: 0.071709
Train epoch: 623 [644320/25046 (82%)]	Loss: 0.084466
Make prediction for 5010 samples...
0.23679347 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 624 [0/25046 (0%)]	Loss: 0.053200
Train epoch: 624 [331820/25046 (41%)]	Loss: 0.086653
Train epoch: 624 [655520/25046 (82%)]	Loss: 0.102140
Make prediction for 5010 samples...
0.24173038 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 625 [0/25046 (0%)]	Loss: 0.079185
Train epoch: 625 [322640/25046 (41%)]	Loss: 0.076414
Train epoch: 625 [656920/25046 (82%)]	Loss: 0.107042
Make prediction for 5010 samples...
0.23214318 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 626 [0/25046 (0%)]	Loss: 0.091585
Train epoch: 626 [330720/25046 (41%)]	Loss: 0.079603
Train epoch: 626 [660320/25046 (82%)]	Loss: 0.096095
Make prediction for 5010 samples...
0.23317136 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 627 [0/25046 (0%)]	Loss: 0.086755
Train epoch: 627 [329340/25046 (41%)]	Loss: 0.059804
Train epoch: 627 [657840/25046 (82%)]	Loss: 0.091433
Make prediction for 5010 samples...
0.24096236 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 628 [0/25046 (0%)]	Loss: 0.107216
Train epoch: 628 [330020/25046 (41%)]	Loss: 0.083532
Train epoch: 628 [663200/25046 (82%)]	Loss: 0.087650
Make prediction for 5010 samples...
0.28986177 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 629 [0/25046 (0%)]	Loss: 0.114618
Train epoch: 629 [326600/25046 (41%)]	Loss: 0.088099
Train epoch: 629 [647000/25046 (82%)]	Loss: 0.086488
Make prediction for 5010 samples...
0.2923603 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 630 [0/25046 (0%)]	Loss: 0.106687
Train epoch: 630 [329800/25046 (41%)]	Loss: 0.102178
Train epoch: 630 [653200/25046 (82%)]	Loss: 0.086008
Make prediction for 5010 samples...
0.23268977 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 631 [0/25046 (0%)]	Loss: 0.081443
Train epoch: 631 [326700/25046 (41%)]	Loss: 0.073614
Train epoch: 631 [658400/25046 (82%)]	Loss: 0.098167
Make prediction for 5010 samples...
0.2492457 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 632 [0/25046 (0%)]	Loss: 0.098668
Train epoch: 632 [321620/25046 (41%)]	Loss: 0.086513
Train epoch: 632 [660320/25046 (82%)]	Loss: 0.078480
Make prediction for 5010 samples...
0.2366143 No improvement since epoch  420 ; best_mse,best_ci: 0.22957502 0.8884498853116343 GINConvNet davis
Training on 25046 samples...
Train epoch: 633 [0/25046 (0%)]	Loss: 0.090152
Train epoch: 633 [331360/25046 (41%)]	Loss: 0.088904
Train epoch: 633 [647520/25046 (82%)]	Loss: 0.097499
Make prediction for 5010 samples...
rmse improved at epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 634 [0/25046 (0%)]	Loss: 0.071336
Train epoch: 634 [328360/25046 (41%)]	Loss: 0.121918
Train epoch: 634 [649680/25046 (82%)]	Loss: 0.090999
Make prediction for 5010 samples...
0.23824948 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 635 [0/25046 (0%)]	Loss: 0.060128
Train epoch: 635 [328600/25046 (41%)]	Loss: 0.091396
Train epoch: 635 [662040/25046 (82%)]	Loss: 0.084242
Make prediction for 5010 samples...
0.23495689 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 636 [0/25046 (0%)]	Loss: 0.125783
Train epoch: 636 [323440/25046 (41%)]	Loss: 0.101090
Train epoch: 636 [654000/25046 (82%)]	Loss: 0.081119
Make prediction for 5010 samples...
0.2503241 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 637 [0/25046 (0%)]	Loss: 0.101086
Train epoch: 637 [327940/25046 (41%)]	Loss: 0.092109
Train epoch: 637 [657960/25046 (82%)]	Loss: 0.075747
Make prediction for 5010 samples...
0.23353717 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 638 [0/25046 (0%)]	Loss: 0.062029
Train epoch: 638 [332080/25046 (41%)]	Loss: 0.089808
Train epoch: 638 [659640/25046 (82%)]	Loss: 0.086197
Make prediction for 5010 samples...
0.2411387 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 639 [0/25046 (0%)]	Loss: 0.084203
Train epoch: 639 [326020/25046 (41%)]	Loss: 0.088333
Train epoch: 639 [658800/25046 (82%)]	Loss: 0.086193
Make prediction for 5010 samples...
0.23669083 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 640 [0/25046 (0%)]	Loss: 0.098223
Train epoch: 640 [328880/25046 (41%)]	Loss: 0.084507
Train epoch: 640 [654280/25046 (82%)]	Loss: 0.096277
Make prediction for 5010 samples...
0.27642286 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 641 [0/25046 (0%)]	Loss: 0.093929
Train epoch: 641 [327560/25046 (41%)]	Loss: 0.066395
Train epoch: 641 [663040/25046 (82%)]	Loss: 0.068831
Make prediction for 5010 samples...
0.2394751 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 642 [0/25046 (0%)]	Loss: 0.084286
Train epoch: 642 [325300/25046 (41%)]	Loss: 0.090888
Train epoch: 642 [657480/25046 (82%)]	Loss: 0.109520
Make prediction for 5010 samples...
0.24744773 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 643 [0/25046 (0%)]	Loss: 0.112522
Train epoch: 643 [327060/25046 (41%)]	Loss: 0.079593
Train epoch: 643 [659240/25046 (82%)]	Loss: 0.121199
Make prediction for 5010 samples...
0.25004187 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 644 [0/25046 (0%)]	Loss: 0.111396
Train epoch: 644 [327040/25046 (41%)]	Loss: 0.084962
Train epoch: 644 [655760/25046 (82%)]	Loss: 0.084397
Make prediction for 5010 samples...
0.2597865 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 645 [0/25046 (0%)]	Loss: 0.075754
Train epoch: 645 [329000/25046 (41%)]	Loss: 0.088319
Train epoch: 645 [659480/25046 (82%)]	Loss: 0.074408
Make prediction for 5010 samples...
0.28599787 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 646 [0/25046 (0%)]	Loss: 0.113710
Train epoch: 646 [323980/25046 (41%)]	Loss: 0.106186
Train epoch: 646 [652640/25046 (82%)]	Loss: 0.108497
Make prediction for 5010 samples...
0.23494427 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 647 [0/25046 (0%)]	Loss: 0.071597
Train epoch: 647 [325800/25046 (41%)]	Loss: 0.103221
Train epoch: 647 [652240/25046 (82%)]	Loss: 0.075057
Make prediction for 5010 samples...
0.2518019 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 648 [0/25046 (0%)]	Loss: 0.087654
Train epoch: 648 [326640/25046 (41%)]	Loss: 0.160492
Train epoch: 648 [658840/25046 (82%)]	Loss: 0.074729
Make prediction for 5010 samples...
0.24936758 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 649 [0/25046 (0%)]	Loss: 0.075704
Train epoch: 649 [328280/25046 (41%)]	Loss: 0.071214
Train epoch: 649 [659160/25046 (82%)]	Loss: 0.059899
Make prediction for 5010 samples...
0.24324797 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 650 [0/25046 (0%)]	Loss: 0.077551
Train epoch: 650 [332400/25046 (41%)]	Loss: 0.061043
Train epoch: 650 [652360/25046 (82%)]	Loss: 0.105193
Make prediction for 5010 samples...
0.23960485 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 651 [0/25046 (0%)]	Loss: 0.102247
Train epoch: 651 [323480/25046 (41%)]	Loss: 0.098669
Train epoch: 651 [662560/25046 (82%)]	Loss: 0.064819
Make prediction for 5010 samples...
0.23689851 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 652 [0/25046 (0%)]	Loss: 0.092208
Train epoch: 652 [324480/25046 (41%)]	Loss: 0.094870
Train epoch: 652 [656480/25046 (82%)]	Loss: 0.082834
Make prediction for 5010 samples...
0.24536198 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 653 [0/25046 (0%)]	Loss: 0.090851
Train epoch: 653 [328140/25046 (41%)]	Loss: 0.083286
Train epoch: 653 [663040/25046 (82%)]	Loss: 0.083701
Make prediction for 5010 samples...
0.23442277 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 654 [0/25046 (0%)]	Loss: 0.070107
Train epoch: 654 [325200/25046 (41%)]	Loss: 0.113134
Train epoch: 654 [652200/25046 (82%)]	Loss: 0.079932
Make prediction for 5010 samples...
0.24975985 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 655 [0/25046 (0%)]	Loss: 0.080629
Train epoch: 655 [328440/25046 (41%)]	Loss: 0.084412
Train epoch: 655 [646440/25046 (82%)]	Loss: 0.094500
Make prediction for 5010 samples...
0.23491979 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 656 [0/25046 (0%)]	Loss: 0.088736
Train epoch: 656 [322780/25046 (41%)]	Loss: 0.078142
Train epoch: 656 [660400/25046 (82%)]	Loss: 0.081504
Make prediction for 5010 samples...
0.2615886 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 657 [0/25046 (0%)]	Loss: 0.085168
Train epoch: 657 [330400/25046 (41%)]	Loss: 0.071136
Train epoch: 657 [657000/25046 (82%)]	Loss: 0.088218
Make prediction for 5010 samples...
0.23903006 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 658 [0/25046 (0%)]	Loss: 0.114546
Train epoch: 658 [326400/25046 (41%)]	Loss: 0.098007
Train epoch: 658 [663240/25046 (82%)]	Loss: 0.068091
Make prediction for 5010 samples...
0.24043754 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 659 [0/25046 (0%)]	Loss: 0.073001
Train epoch: 659 [329080/25046 (41%)]	Loss: 0.073678
Train epoch: 659 [661320/25046 (82%)]	Loss: 0.087441
Make prediction for 5010 samples...
0.2494745 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 660 [0/25046 (0%)]	Loss: 0.072045
Train epoch: 660 [329080/25046 (41%)]	Loss: 0.072592
Train epoch: 660 [659840/25046 (82%)]	Loss: 0.115087
Make prediction for 5010 samples...
0.2373795 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 661 [0/25046 (0%)]	Loss: 0.073582
Train epoch: 661 [330380/25046 (41%)]	Loss: 0.113267
Train epoch: 661 [667800/25046 (82%)]	Loss: 0.084989
Make prediction for 5010 samples...
0.23767255 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 662 [0/25046 (0%)]	Loss: 0.102602
Train epoch: 662 [325420/25046 (41%)]	Loss: 0.085843
Train epoch: 662 [653120/25046 (82%)]	Loss: 0.075352
Make prediction for 5010 samples...
0.23805176 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 663 [0/25046 (0%)]	Loss: 0.079097
Train epoch: 663 [329940/25046 (41%)]	Loss: 0.071615
Train epoch: 663 [654920/25046 (82%)]	Loss: 0.071726
Make prediction for 5010 samples...
0.24242868 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 664 [0/25046 (0%)]	Loss: 0.083647
Train epoch: 664 [328020/25046 (41%)]	Loss: 0.072660
Train epoch: 664 [653800/25046 (82%)]	Loss: 0.084164
Make prediction for 5010 samples...
0.23564121 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 665 [0/25046 (0%)]	Loss: 0.065205
Train epoch: 665 [326480/25046 (41%)]	Loss: 0.067858
Train epoch: 665 [664800/25046 (82%)]	Loss: 0.101631
Make prediction for 5010 samples...
0.24871877 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 666 [0/25046 (0%)]	Loss: 0.067647
Train epoch: 666 [327340/25046 (41%)]	Loss: 0.096055
Train epoch: 666 [661160/25046 (82%)]	Loss: 0.071820
Make prediction for 5010 samples...
0.23234113 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 667 [0/25046 (0%)]	Loss: 0.082249
Train epoch: 667 [326880/25046 (41%)]	Loss: 0.118072
Train epoch: 667 [655360/25046 (82%)]	Loss: 0.079375
Make prediction for 5010 samples...
0.23864059 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 668 [0/25046 (0%)]	Loss: 0.074545
Train epoch: 668 [328900/25046 (41%)]	Loss: 0.087968
Train epoch: 668 [658440/25046 (82%)]	Loss: 0.083082
Make prediction for 5010 samples...
0.24180092 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 669 [0/25046 (0%)]	Loss: 0.109117
Train epoch: 669 [329640/25046 (41%)]	Loss: 0.090950
Train epoch: 669 [662120/25046 (82%)]	Loss: 0.115348
Make prediction for 5010 samples...
0.24466406 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 670 [0/25046 (0%)]	Loss: 0.076671
Train epoch: 670 [330360/25046 (41%)]	Loss: 0.069746
Train epoch: 670 [664160/25046 (82%)]	Loss: 0.087660
Make prediction for 5010 samples...
0.23500733 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 671 [0/25046 (0%)]	Loss: 0.077759
Train epoch: 671 [328040/25046 (41%)]	Loss: 0.073631
Train epoch: 671 [651720/25046 (82%)]	Loss: 0.075936
Make prediction for 5010 samples...
0.23928751 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 672 [0/25046 (0%)]	Loss: 0.082122
Train epoch: 672 [327120/25046 (41%)]	Loss: 0.081918
Train epoch: 672 [651480/25046 (82%)]	Loss: 0.078583
Make prediction for 5010 samples...
0.23382224 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 673 [0/25046 (0%)]	Loss: 0.058258
Train epoch: 673 [327140/25046 (41%)]	Loss: 0.085326
Train epoch: 673 [658760/25046 (82%)]	Loss: 0.094077
Make prediction for 5010 samples...
0.28710768 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 674 [0/25046 (0%)]	Loss: 0.104652
Train epoch: 674 [324380/25046 (41%)]	Loss: 0.079522
Train epoch: 674 [660120/25046 (82%)]	Loss: 0.060843
Make prediction for 5010 samples...
0.25299212 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 675 [0/25046 (0%)]	Loss: 0.083833
Train epoch: 675 [327820/25046 (41%)]	Loss: 0.106010
Train epoch: 675 [657800/25046 (82%)]	Loss: 0.097563
Make prediction for 5010 samples...
0.23344088 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 676 [0/25046 (0%)]	Loss: 0.086574
Train epoch: 676 [329960/25046 (41%)]	Loss: 0.069460
Train epoch: 676 [658680/25046 (82%)]	Loss: 0.077994
Make prediction for 5010 samples...
0.24616107 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 677 [0/25046 (0%)]	Loss: 0.075709
Train epoch: 677 [323340/25046 (41%)]	Loss: 0.063230
Train epoch: 677 [653840/25046 (82%)]	Loss: 0.106162
Make prediction for 5010 samples...
0.2418794 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 678 [0/25046 (0%)]	Loss: 0.065772
Train epoch: 678 [328980/25046 (41%)]	Loss: 0.081915
Train epoch: 678 [658120/25046 (82%)]	Loss: 0.071314
Make prediction for 5010 samples...
0.23980363 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 679 [0/25046 (0%)]	Loss: 0.079874
Train epoch: 679 [330940/25046 (41%)]	Loss: 0.080175
Train epoch: 679 [653000/25046 (82%)]	Loss: 0.071487
Make prediction for 5010 samples...
0.23925494 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 680 [0/25046 (0%)]	Loss: 0.079227
Train epoch: 680 [324000/25046 (41%)]	Loss: 0.098322
Train epoch: 680 [649480/25046 (82%)]	Loss: 0.082543
Make prediction for 5010 samples...
0.23457806 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 681 [0/25046 (0%)]	Loss: 0.060929
Train epoch: 681 [330700/25046 (41%)]	Loss: 0.072345
Train epoch: 681 [658200/25046 (82%)]	Loss: 0.097918
Make prediction for 5010 samples...
0.23974383 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 682 [0/25046 (0%)]	Loss: 0.077525
Train epoch: 682 [331560/25046 (41%)]	Loss: 0.072541
Train epoch: 682 [651960/25046 (82%)]	Loss: 0.058576
Make prediction for 5010 samples...
0.25337118 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 683 [0/25046 (0%)]	Loss: 0.067254
Train epoch: 683 [327080/25046 (41%)]	Loss: 0.084172
Train epoch: 683 [642720/25046 (82%)]	Loss: 0.077151
Make prediction for 5010 samples...
0.23480295 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 684 [0/25046 (0%)]	Loss: 0.068423
Train epoch: 684 [330380/25046 (41%)]	Loss: 0.084821
Train epoch: 684 [662400/25046 (82%)]	Loss: 0.104455
Make prediction for 5010 samples...
0.24438794 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 685 [0/25046 (0%)]	Loss: 0.069978
Train epoch: 685 [331160/25046 (41%)]	Loss: 0.065570
Train epoch: 685 [658440/25046 (82%)]	Loss: 0.115291
Make prediction for 5010 samples...
0.23588604 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 686 [0/25046 (0%)]	Loss: 0.068217
Train epoch: 686 [326860/25046 (41%)]	Loss: 0.083665
Train epoch: 686 [664240/25046 (82%)]	Loss: 0.093683
Make prediction for 5010 samples...
0.24374922 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 687 [0/25046 (0%)]	Loss: 0.068668
Train epoch: 687 [328980/25046 (41%)]	Loss: 0.086275
Train epoch: 687 [658120/25046 (82%)]	Loss: 0.075214
Make prediction for 5010 samples...
0.27023834 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 688 [0/25046 (0%)]	Loss: 0.091708
Train epoch: 688 [325740/25046 (41%)]	Loss: 0.096091
Train epoch: 688 [658240/25046 (82%)]	Loss: 0.080104
Make prediction for 5010 samples...
0.23748596 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 689 [0/25046 (0%)]	Loss: 0.070693
Train epoch: 689 [328960/25046 (41%)]	Loss: 0.066650
Train epoch: 689 [651280/25046 (82%)]	Loss: 0.104899
Make prediction for 5010 samples...
0.2706661 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 690 [0/25046 (0%)]	Loss: 0.086890
Train epoch: 690 [330280/25046 (41%)]	Loss: 0.110798
Train epoch: 690 [654720/25046 (82%)]	Loss: 0.105009
Make prediction for 5010 samples...
0.24235477 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 691 [0/25046 (0%)]	Loss: 0.074952
Train epoch: 691 [323380/25046 (41%)]	Loss: 0.079464
Train epoch: 691 [657080/25046 (82%)]	Loss: 0.087136
Make prediction for 5010 samples...
0.23247251 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 692 [0/25046 (0%)]	Loss: 0.066320
Train epoch: 692 [331280/25046 (41%)]	Loss: 0.122100
Train epoch: 692 [655440/25046 (82%)]	Loss: 0.076087
Make prediction for 5010 samples...
0.2522469 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 693 [0/25046 (0%)]	Loss: 0.091318
Train epoch: 693 [329100/25046 (41%)]	Loss: 0.085625
Train epoch: 693 [654840/25046 (82%)]	Loss: 0.121354
Make prediction for 5010 samples...
0.27207154 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 694 [0/25046 (0%)]	Loss: 0.095440
Train epoch: 694 [330500/25046 (41%)]	Loss: 0.086016
Train epoch: 694 [661600/25046 (82%)]	Loss: 0.058771
Make prediction for 5010 samples...
0.23746017 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 695 [0/25046 (0%)]	Loss: 0.094760
Train epoch: 695 [329420/25046 (41%)]	Loss: 0.069277
Train epoch: 695 [655080/25046 (82%)]	Loss: 0.071447
Make prediction for 5010 samples...
0.23227252 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 696 [0/25046 (0%)]	Loss: 0.081573
Train epoch: 696 [335460/25046 (41%)]	Loss: 0.122394
Train epoch: 696 [654920/25046 (82%)]	Loss: 0.072693
Make prediction for 5010 samples...
0.23750287 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 697 [0/25046 (0%)]	Loss: 0.078747
Train epoch: 697 [326400/25046 (41%)]	Loss: 0.092509
Train epoch: 697 [657520/25046 (82%)]	Loss: 0.083079
Make prediction for 5010 samples...
0.23888938 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 698 [0/25046 (0%)]	Loss: 0.075024
Train epoch: 698 [324760/25046 (41%)]	Loss: 0.065362
Train epoch: 698 [653800/25046 (82%)]	Loss: 0.058745
Make prediction for 5010 samples...
0.24044977 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 699 [0/25046 (0%)]	Loss: 0.079709
Train epoch: 699 [331880/25046 (41%)]	Loss: 0.079999
Train epoch: 699 [657360/25046 (82%)]	Loss: 0.104778
Make prediction for 5010 samples...
0.30297217 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 700 [0/25046 (0%)]	Loss: 0.121674
Train epoch: 700 [328940/25046 (41%)]	Loss: 0.082721
Train epoch: 700 [653960/25046 (82%)]	Loss: 0.061543
Make prediction for 5010 samples...
0.23443772 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 701 [0/25046 (0%)]	Loss: 0.063637
Train epoch: 701 [327840/25046 (41%)]	Loss: 0.086641
Train epoch: 701 [661920/25046 (82%)]	Loss: 0.089601
Make prediction for 5010 samples...
0.27137253 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 702 [0/25046 (0%)]	Loss: 0.096466
Train epoch: 702 [329420/25046 (41%)]	Loss: 0.079917
Train epoch: 702 [657080/25046 (82%)]	Loss: 0.089574
Make prediction for 5010 samples...
0.23558138 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 703 [0/25046 (0%)]	Loss: 0.086271
Train epoch: 703 [325500/25046 (41%)]	Loss: 0.057987
Train epoch: 703 [648640/25046 (82%)]	Loss: 0.121021
Make prediction for 5010 samples...
0.23602858 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 704 [0/25046 (0%)]	Loss: 0.086942
Train epoch: 704 [324660/25046 (41%)]	Loss: 0.071236
Train epoch: 704 [651680/25046 (82%)]	Loss: 0.071235
Make prediction for 5010 samples...
0.23346366 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 705 [0/25046 (0%)]	Loss: 0.074185
Train epoch: 705 [326300/25046 (41%)]	Loss: 0.062809
Train epoch: 705 [660920/25046 (82%)]	Loss: 0.074895
Make prediction for 5010 samples...
0.26295647 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 706 [0/25046 (0%)]	Loss: 0.092368
Train epoch: 706 [326120/25046 (41%)]	Loss: 0.092249
Train epoch: 706 [648680/25046 (82%)]	Loss: 0.079022
Make prediction for 5010 samples...
0.24155907 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 707 [0/25046 (0%)]	Loss: 0.081134
Train epoch: 707 [324920/25046 (41%)]	Loss: 0.100989
Train epoch: 707 [650440/25046 (82%)]	Loss: 0.077725
Make prediction for 5010 samples...
0.23180676 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 708 [0/25046 (0%)]	Loss: 0.069427
Train epoch: 708 [331860/25046 (41%)]	Loss: 0.072120
Train epoch: 708 [650560/25046 (82%)]	Loss: 0.107319
Make prediction for 5010 samples...
0.23649259 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 709 [0/25046 (0%)]	Loss: 0.109800
Train epoch: 709 [321740/25046 (41%)]	Loss: 0.064417
Train epoch: 709 [653200/25046 (82%)]	Loss: 0.072553
Make prediction for 5010 samples...
0.25514472 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 710 [0/25046 (0%)]	Loss: 0.064362
Train epoch: 710 [330320/25046 (41%)]	Loss: 0.090991
Train epoch: 710 [662520/25046 (82%)]	Loss: 0.073188
Make prediction for 5010 samples...
0.24005598 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 711 [0/25046 (0%)]	Loss: 0.091911
Train epoch: 711 [325060/25046 (41%)]	Loss: 0.065721
Train epoch: 711 [662560/25046 (82%)]	Loss: 0.087741
Make prediction for 5010 samples...
0.23673216 No improvement since epoch  633 ; best_mse,best_ci: 0.22894076 0.8913415605918615 GINConvNet davis
Training on 25046 samples...
Train epoch: 712 [0/25046 (0%)]	Loss: 0.081643
Train epoch: 712 [326740/25046 (41%)]	Loss: 0.054701
Train epoch: 712 [652280/25046 (82%)]	Loss: 0.069724
Make prediction for 5010 samples...
rmse improved at epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 713 [0/25046 (0%)]	Loss: 0.062007
Train epoch: 713 [333320/25046 (41%)]	Loss: 0.084490
Train epoch: 713 [660800/25046 (82%)]	Loss: 0.095917
Make prediction for 5010 samples...
0.25045395 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 714 [0/25046 (0%)]	Loss: 0.081899
Train epoch: 714 [328180/25046 (41%)]	Loss: 0.088233
Train epoch: 714 [663800/25046 (82%)]	Loss: 0.081300
Make prediction for 5010 samples...
0.23877993 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 715 [0/25046 (0%)]	Loss: 0.054643
Train epoch: 715 [322420/25046 (41%)]	Loss: 0.096508
Train epoch: 715 [658560/25046 (82%)]	Loss: 0.092325
Make prediction for 5010 samples...
0.24258073 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 716 [0/25046 (0%)]	Loss: 0.076292
Train epoch: 716 [325900/25046 (41%)]	Loss: 0.117812
Train epoch: 716 [647800/25046 (82%)]	Loss: 0.096672
Make prediction for 5010 samples...
0.23893878 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 717 [0/25046 (0%)]	Loss: 0.107438
Train epoch: 717 [324660/25046 (41%)]	Loss: 0.107339
Train epoch: 717 [655240/25046 (82%)]	Loss: 0.071137
Make prediction for 5010 samples...
0.23619561 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 718 [0/25046 (0%)]	Loss: 0.077371
Train epoch: 718 [330040/25046 (41%)]	Loss: 0.110711
Train epoch: 718 [651840/25046 (82%)]	Loss: 0.078252
Make prediction for 5010 samples...
0.27155128 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 719 [0/25046 (0%)]	Loss: 0.116208
Train epoch: 719 [333740/25046 (41%)]	Loss: 0.075909
Train epoch: 719 [663720/25046 (82%)]	Loss: 0.046888
Make prediction for 5010 samples...
0.24414408 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 720 [0/25046 (0%)]	Loss: 0.060730
Train epoch: 720 [326540/25046 (41%)]	Loss: 0.097035
Train epoch: 720 [658320/25046 (82%)]	Loss: 0.066522
Make prediction for 5010 samples...
0.24236964 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 721 [0/25046 (0%)]	Loss: 0.107116
Train epoch: 721 [331160/25046 (41%)]	Loss: 0.097273
Train epoch: 721 [654760/25046 (82%)]	Loss: 0.051392
Make prediction for 5010 samples...
0.26188907 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 722 [0/25046 (0%)]	Loss: 0.081127
Train epoch: 722 [330340/25046 (41%)]	Loss: 0.094683
Train epoch: 722 [659880/25046 (82%)]	Loss: 0.095650
Make prediction for 5010 samples...
0.24645773 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 723 [0/25046 (0%)]	Loss: 0.052539
Train epoch: 723 [324540/25046 (41%)]	Loss: 0.097785
Train epoch: 723 [654320/25046 (82%)]	Loss: 0.069208
Make prediction for 5010 samples...
0.25238672 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 724 [0/25046 (0%)]	Loss: 0.067954
Train epoch: 724 [326720/25046 (41%)]	Loss: 0.071106
Train epoch: 724 [658800/25046 (82%)]	Loss: 0.084034
Make prediction for 5010 samples...
0.23232712 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 725 [0/25046 (0%)]	Loss: 0.072137
Train epoch: 725 [324240/25046 (41%)]	Loss: 0.069741
Train epoch: 725 [655920/25046 (82%)]	Loss: 0.109377
Make prediction for 5010 samples...
0.31521428 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 726 [0/25046 (0%)]	Loss: 0.111572
Train epoch: 726 [327660/25046 (41%)]	Loss: 0.086208
Train epoch: 726 [659480/25046 (82%)]	Loss: 0.087673
Make prediction for 5010 samples...
0.24666098 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 727 [0/25046 (0%)]	Loss: 0.087661
Train epoch: 727 [329980/25046 (41%)]	Loss: 0.066762
Train epoch: 727 [653760/25046 (82%)]	Loss: 0.056403
Make prediction for 5010 samples...
0.23157136 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 728 [0/25046 (0%)]	Loss: 0.078850
Train epoch: 728 [328840/25046 (41%)]	Loss: 0.084860
Train epoch: 728 [651520/25046 (82%)]	Loss: 0.112366
Make prediction for 5010 samples...
0.24906836 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 729 [0/25046 (0%)]	Loss: 0.050813
Train epoch: 729 [330360/25046 (41%)]	Loss: 0.087275
Train epoch: 729 [656880/25046 (82%)]	Loss: 0.078550
Make prediction for 5010 samples...
0.23087195 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 730 [0/25046 (0%)]	Loss: 0.079748
Train epoch: 730 [328920/25046 (41%)]	Loss: 0.091457
Train epoch: 730 [653200/25046 (82%)]	Loss: 0.079660
Make prediction for 5010 samples...
0.242082 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 731 [0/25046 (0%)]	Loss: 0.092760
Train epoch: 731 [328820/25046 (41%)]	Loss: 0.081487
Train epoch: 731 [655640/25046 (82%)]	Loss: 0.073432
Make prediction for 5010 samples...
0.24765538 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 732 [0/25046 (0%)]	Loss: 0.079021
Train epoch: 732 [328540/25046 (41%)]	Loss: 0.072216
Train epoch: 732 [660440/25046 (82%)]	Loss: 0.106983
Make prediction for 5010 samples...
0.24195276 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 733 [0/25046 (0%)]	Loss: 0.089890
Train epoch: 733 [324280/25046 (41%)]	Loss: 0.065003
Train epoch: 733 [664320/25046 (82%)]	Loss: 0.067958
Make prediction for 5010 samples...
0.29536596 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 734 [0/25046 (0%)]	Loss: 0.099593
Train epoch: 734 [327420/25046 (41%)]	Loss: 0.098536
Train epoch: 734 [656560/25046 (82%)]	Loss: 0.073080
Make prediction for 5010 samples...
0.24236761 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 735 [0/25046 (0%)]	Loss: 0.055005
Train epoch: 735 [323620/25046 (41%)]	Loss: 0.065519
Train epoch: 735 [646120/25046 (82%)]	Loss: 0.110123
Make prediction for 5010 samples...
0.25820225 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 736 [0/25046 (0%)]	Loss: 0.076226
Train epoch: 736 [329700/25046 (41%)]	Loss: 0.105210
Train epoch: 736 [665640/25046 (82%)]	Loss: 0.083729
Make prediction for 5010 samples...
0.25368866 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 737 [0/25046 (0%)]	Loss: 0.075401
Train epoch: 737 [329380/25046 (41%)]	Loss: 0.073495
Train epoch: 737 [660600/25046 (82%)]	Loss: 0.095319
Make prediction for 5010 samples...
0.2314091 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 738 [0/25046 (0%)]	Loss: 0.063514
Train epoch: 738 [329780/25046 (41%)]	Loss: 0.097368
Train epoch: 738 [662360/25046 (82%)]	Loss: 0.053344
Make prediction for 5010 samples...
0.23784365 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 739 [0/25046 (0%)]	Loss: 0.075802
Train epoch: 739 [328760/25046 (41%)]	Loss: 0.081840
Train epoch: 739 [655320/25046 (82%)]	Loss: 0.089409
Make prediction for 5010 samples...
0.23213363 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 740 [0/25046 (0%)]	Loss: 0.050947
Train epoch: 740 [325900/25046 (41%)]	Loss: 0.064671
Train epoch: 740 [655080/25046 (82%)]	Loss: 0.086829
Make prediction for 5010 samples...
0.23317343 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 741 [0/25046 (0%)]	Loss: 0.078331
Train epoch: 741 [334080/25046 (41%)]	Loss: 0.064257
Train epoch: 741 [666280/25046 (82%)]	Loss: 0.077647
Make prediction for 5010 samples...
0.23038352 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 742 [0/25046 (0%)]	Loss: 0.071642
Train epoch: 742 [325820/25046 (41%)]	Loss: 0.104317
Train epoch: 742 [654400/25046 (82%)]	Loss: 0.066585
Make prediction for 5010 samples...
0.24648497 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 743 [0/25046 (0%)]	Loss: 0.073338
Train epoch: 743 [328280/25046 (41%)]	Loss: 0.094624
Train epoch: 743 [653040/25046 (82%)]	Loss: 0.066376
Make prediction for 5010 samples...
0.23509054 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 744 [0/25046 (0%)]	Loss: 0.064279
Train epoch: 744 [328760/25046 (41%)]	Loss: 0.072360
Train epoch: 744 [652760/25046 (82%)]	Loss: 0.106597
Make prediction for 5010 samples...
0.23450425 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 745 [0/25046 (0%)]	Loss: 0.065497
Train epoch: 745 [330820/25046 (41%)]	Loss: 0.064310
Train epoch: 745 [656360/25046 (82%)]	Loss: 0.085884
Make prediction for 5010 samples...
0.23127252 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 746 [0/25046 (0%)]	Loss: 0.070430
Train epoch: 746 [330540/25046 (41%)]	Loss: 0.075090
Train epoch: 746 [654280/25046 (82%)]	Loss: 0.076887
Make prediction for 5010 samples...
0.23780957 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 747 [0/25046 (0%)]	Loss: 0.084397
Train epoch: 747 [333960/25046 (41%)]	Loss: 0.063857
Train epoch: 747 [653520/25046 (82%)]	Loss: 0.085068
Make prediction for 5010 samples...
0.24815759 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 748 [0/25046 (0%)]	Loss: 0.089226
Train epoch: 748 [330620/25046 (41%)]	Loss: 0.087307
Train epoch: 748 [660600/25046 (82%)]	Loss: 0.075291
Make prediction for 5010 samples...
0.23771326 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 749 [0/25046 (0%)]	Loss: 0.090844
Train epoch: 749 [326680/25046 (41%)]	Loss: 0.079939
Train epoch: 749 [659440/25046 (82%)]	Loss: 0.101425
Make prediction for 5010 samples...
0.23301454 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 750 [0/25046 (0%)]	Loss: 0.069043
Train epoch: 750 [332020/25046 (41%)]	Loss: 0.058944
Train epoch: 750 [659120/25046 (82%)]	Loss: 0.096541
Make prediction for 5010 samples...
0.23574287 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 751 [0/25046 (0%)]	Loss: 0.081510
Train epoch: 751 [329880/25046 (41%)]	Loss: 0.088074
Train epoch: 751 [655240/25046 (82%)]	Loss: 0.066896
Make prediction for 5010 samples...
0.25065103 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 752 [0/25046 (0%)]	Loss: 0.069138
Train epoch: 752 [324000/25046 (41%)]	Loss: 0.075330
Train epoch: 752 [657880/25046 (82%)]	Loss: 0.069180
Make prediction for 5010 samples...
0.22951375 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 753 [0/25046 (0%)]	Loss: 0.104420
Train epoch: 753 [324060/25046 (41%)]	Loss: 0.069347
Train epoch: 753 [653320/25046 (82%)]	Loss: 0.076161
Make prediction for 5010 samples...
0.23496708 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 754 [0/25046 (0%)]	Loss: 0.081644
Train epoch: 754 [329900/25046 (41%)]	Loss: 0.055653
Train epoch: 754 [653560/25046 (82%)]	Loss: 0.101293
Make prediction for 5010 samples...
0.23326226 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 755 [0/25046 (0%)]	Loss: 0.085604
Train epoch: 755 [328300/25046 (41%)]	Loss: 0.096148
Train epoch: 755 [656520/25046 (82%)]	Loss: 0.068342
Make prediction for 5010 samples...
0.24232277 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 756 [0/25046 (0%)]	Loss: 0.109599
Train epoch: 756 [324540/25046 (41%)]	Loss: 0.053769
Train epoch: 756 [656120/25046 (82%)]	Loss: 0.090899
Make prediction for 5010 samples...
0.23495531 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 757 [0/25046 (0%)]	Loss: 0.086235
Train epoch: 757 [327420/25046 (41%)]	Loss: 0.106663
Train epoch: 757 [658360/25046 (82%)]	Loss: 0.062698
Make prediction for 5010 samples...
0.25162157 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 758 [0/25046 (0%)]	Loss: 0.076041
Train epoch: 758 [325580/25046 (41%)]	Loss: 0.064096
Train epoch: 758 [656600/25046 (82%)]	Loss: 0.056440
Make prediction for 5010 samples...
0.24696097 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 759 [0/25046 (0%)]	Loss: 0.092895
Train epoch: 759 [325900/25046 (41%)]	Loss: 0.053015
Train epoch: 759 [650960/25046 (82%)]	Loss: 0.070017
Make prediction for 5010 samples...
0.26358166 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 760 [0/25046 (0%)]	Loss: 0.091476
Train epoch: 760 [330260/25046 (41%)]	Loss: 0.075862
Train epoch: 760 [666920/25046 (82%)]	Loss: 0.071155
Make prediction for 5010 samples...
0.23907118 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 761 [0/25046 (0%)]	Loss: 0.086791
Train epoch: 761 [324180/25046 (41%)]	Loss: 0.075917
Train epoch: 761 [653160/25046 (82%)]	Loss: 0.096230
Make prediction for 5010 samples...
0.23934402 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 762 [0/25046 (0%)]	Loss: 0.053447
Train epoch: 762 [326840/25046 (41%)]	Loss: 0.061413
Train epoch: 762 [649760/25046 (82%)]	Loss: 0.077312
Make prediction for 5010 samples...
0.23211585 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 763 [0/25046 (0%)]	Loss: 0.085009
Train epoch: 763 [320660/25046 (41%)]	Loss: 0.066425
Train epoch: 763 [650360/25046 (82%)]	Loss: 0.066706
Make prediction for 5010 samples...
0.23481022 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 764 [0/25046 (0%)]	Loss: 0.070977
Train epoch: 764 [331820/25046 (41%)]	Loss: 0.058608
Train epoch: 764 [652720/25046 (82%)]	Loss: 0.058149
Make prediction for 5010 samples...
0.27210835 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 765 [0/25046 (0%)]	Loss: 0.099175
Train epoch: 765 [330760/25046 (41%)]	Loss: 0.068943
Train epoch: 765 [656760/25046 (82%)]	Loss: 0.081091
Make prediction for 5010 samples...
0.24544695 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 766 [0/25046 (0%)]	Loss: 0.097182
Train epoch: 766 [331400/25046 (41%)]	Loss: 0.122138
Train epoch: 766 [663920/25046 (82%)]	Loss: 0.088757
Make prediction for 5010 samples...
0.25744843 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 767 [0/25046 (0%)]	Loss: 0.087896
Train epoch: 767 [327580/25046 (41%)]	Loss: 0.089799
Train epoch: 767 [660680/25046 (82%)]	Loss: 0.074310
Make prediction for 5010 samples...
0.23519547 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 768 [0/25046 (0%)]	Loss: 0.057350
Train epoch: 768 [329900/25046 (41%)]	Loss: 0.061455
Train epoch: 768 [648720/25046 (82%)]	Loss: 0.070937
Make prediction for 5010 samples...
0.23826875 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 769 [0/25046 (0%)]	Loss: 0.073727
Train epoch: 769 [329840/25046 (41%)]	Loss: 0.089387
Train epoch: 769 [645480/25046 (82%)]	Loss: 0.061596
Make prediction for 5010 samples...
0.23285362 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 770 [0/25046 (0%)]	Loss: 0.064330
Train epoch: 770 [332200/25046 (41%)]	Loss: 0.075971
Train epoch: 770 [661080/25046 (82%)]	Loss: 0.074352
Make prediction for 5010 samples...
0.24900357 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 771 [0/25046 (0%)]	Loss: 0.058399
Train epoch: 771 [332420/25046 (41%)]	Loss: 0.085742
Train epoch: 771 [657720/25046 (82%)]	Loss: 0.113907
Make prediction for 5010 samples...
0.267506 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 772 [0/25046 (0%)]	Loss: 0.122200
Train epoch: 772 [323640/25046 (41%)]	Loss: 0.098788
Train epoch: 772 [656520/25046 (82%)]	Loss: 0.064961
Make prediction for 5010 samples...
0.2457273 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 773 [0/25046 (0%)]	Loss: 0.070851
Train epoch: 773 [327560/25046 (41%)]	Loss: 0.072733
Train epoch: 773 [657720/25046 (82%)]	Loss: 0.068733
Make prediction for 5010 samples...
0.23802365 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 774 [0/25046 (0%)]	Loss: 0.068445
Train epoch: 774 [330720/25046 (41%)]	Loss: 0.060762
Train epoch: 774 [661280/25046 (82%)]	Loss: 0.058030
Make prediction for 5010 samples...
0.23426665 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 775 [0/25046 (0%)]	Loss: 0.065999
Train epoch: 775 [328920/25046 (41%)]	Loss: 0.083895
Train epoch: 775 [658640/25046 (82%)]	Loss: 0.080966
Make prediction for 5010 samples...
0.24549785 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 776 [0/25046 (0%)]	Loss: 0.104039
Train epoch: 776 [328520/25046 (41%)]	Loss: 0.067059
Train epoch: 776 [656440/25046 (82%)]	Loss: 0.094817
Make prediction for 5010 samples...
0.23566379 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 777 [0/25046 (0%)]	Loss: 0.086489
Train epoch: 777 [329540/25046 (41%)]	Loss: 0.059331
Train epoch: 777 [668160/25046 (82%)]	Loss: 0.071097
Make prediction for 5010 samples...
0.24817969 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 778 [0/25046 (0%)]	Loss: 0.072009
Train epoch: 778 [328780/25046 (41%)]	Loss: 0.085428
Train epoch: 778 [652320/25046 (82%)]	Loss: 0.098915
Make prediction for 5010 samples...
0.24340475 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 779 [0/25046 (0%)]	Loss: 0.075994
Train epoch: 779 [332120/25046 (41%)]	Loss: 0.099680
Train epoch: 779 [661480/25046 (82%)]	Loss: 0.067455
Make prediction for 5010 samples...
0.23696077 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 780 [0/25046 (0%)]	Loss: 0.080849
Train epoch: 780 [331360/25046 (41%)]	Loss: 0.095966
Train epoch: 780 [652680/25046 (82%)]	Loss: 0.107141
Make prediction for 5010 samples...
0.24393469 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 781 [0/25046 (0%)]	Loss: 0.054450
Train epoch: 781 [329360/25046 (41%)]	Loss: 0.102603
Train epoch: 781 [662720/25046 (82%)]	Loss: 0.092341
Make prediction for 5010 samples...
0.2550179 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 782 [0/25046 (0%)]	Loss: 0.069747
Train epoch: 782 [334520/25046 (41%)]	Loss: 0.095615
Train epoch: 782 [660520/25046 (82%)]	Loss: 0.067564
Make prediction for 5010 samples...
0.23894419 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 783 [0/25046 (0%)]	Loss: 0.060891
Train epoch: 783 [331660/25046 (41%)]	Loss: 0.073672
Train epoch: 783 [648840/25046 (82%)]	Loss: 0.100589
Make prediction for 5010 samples...
0.23528577 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 784 [0/25046 (0%)]	Loss: 0.056514
Train epoch: 784 [328800/25046 (41%)]	Loss: 0.071403
Train epoch: 784 [649280/25046 (82%)]	Loss: 0.095068
Make prediction for 5010 samples...
0.23711453 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 785 [0/25046 (0%)]	Loss: 0.084935
Train epoch: 785 [330200/25046 (41%)]	Loss: 0.069244
Train epoch: 785 [652560/25046 (82%)]	Loss: 0.087085
Make prediction for 5010 samples...
0.23468088 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 786 [0/25046 (0%)]	Loss: 0.075030
Train epoch: 786 [324100/25046 (41%)]	Loss: 0.055913
Train epoch: 786 [657520/25046 (82%)]	Loss: 0.063548
Make prediction for 5010 samples...
0.24319187 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 787 [0/25046 (0%)]	Loss: 0.073107
Train epoch: 787 [326160/25046 (41%)]	Loss: 0.085620
Train epoch: 787 [655000/25046 (82%)]	Loss: 0.101333
Make prediction for 5010 samples...
0.24868271 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 788 [0/25046 (0%)]	Loss: 0.108514
Train epoch: 788 [330660/25046 (41%)]	Loss: 0.061130
Train epoch: 788 [661120/25046 (82%)]	Loss: 0.063904
Make prediction for 5010 samples...
0.24587923 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 789 [0/25046 (0%)]	Loss: 0.061469
Train epoch: 789 [334180/25046 (41%)]	Loss: 0.058704
Train epoch: 789 [673080/25046 (82%)]	Loss: 0.103447
Make prediction for 5010 samples...
0.24186885 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 790 [0/25046 (0%)]	Loss: 0.085393
Train epoch: 790 [327660/25046 (41%)]	Loss: 0.071268
Train epoch: 790 [649960/25046 (82%)]	Loss: 0.075114
Make prediction for 5010 samples...
0.24630782 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 791 [0/25046 (0%)]	Loss: 0.091087
Train epoch: 791 [327140/25046 (41%)]	Loss: 0.056394
Train epoch: 791 [654440/25046 (82%)]	Loss: 0.078735
Make prediction for 5010 samples...
0.23927328 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 792 [0/25046 (0%)]	Loss: 0.065735
Train epoch: 792 [330980/25046 (41%)]	Loss: 0.114803
Train epoch: 792 [652560/25046 (82%)]	Loss: 0.069749
Make prediction for 5010 samples...
0.23590855 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 793 [0/25046 (0%)]	Loss: 0.083168
Train epoch: 793 [329940/25046 (41%)]	Loss: 0.081250
Train epoch: 793 [659880/25046 (82%)]	Loss: 0.097375
Make prediction for 5010 samples...
0.23252942 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 794 [0/25046 (0%)]	Loss: 0.070045
Train epoch: 794 [331020/25046 (41%)]	Loss: 0.074178
Train epoch: 794 [655720/25046 (82%)]	Loss: 0.072124
Make prediction for 5010 samples...
0.25259557 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 795 [0/25046 (0%)]	Loss: 0.094573
Train epoch: 795 [330400/25046 (41%)]	Loss: 0.075472
Train epoch: 795 [656600/25046 (82%)]	Loss: 0.109027
Make prediction for 5010 samples...
0.25043187 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 796 [0/25046 (0%)]	Loss: 0.052799
Train epoch: 796 [329660/25046 (41%)]	Loss: 0.082294
Train epoch: 796 [649120/25046 (82%)]	Loss: 0.075260
Make prediction for 5010 samples...
0.26585215 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 797 [0/25046 (0%)]	Loss: 0.063896
Train epoch: 797 [327260/25046 (41%)]	Loss: 0.080514
Train epoch: 797 [656520/25046 (82%)]	Loss: 0.058263
Make prediction for 5010 samples...
0.25350603 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 798 [0/25046 (0%)]	Loss: 0.083786
Train epoch: 798 [328500/25046 (41%)]	Loss: 0.063234
Train epoch: 798 [650680/25046 (82%)]	Loss: 0.063267
Make prediction for 5010 samples...
0.24122566 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 799 [0/25046 (0%)]	Loss: 0.058931
Train epoch: 799 [329880/25046 (41%)]	Loss: 0.082426
Train epoch: 799 [653320/25046 (82%)]	Loss: 0.086244
Make prediction for 5010 samples...
0.24068756 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 800 [0/25046 (0%)]	Loss: 0.075579
Train epoch: 800 [324360/25046 (41%)]	Loss: 0.070267
Train epoch: 800 [649240/25046 (82%)]	Loss: 0.065188
Make prediction for 5010 samples...
0.23561451 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 801 [0/25046 (0%)]	Loss: 0.083471
Train epoch: 801 [330540/25046 (41%)]	Loss: 0.077686
Train epoch: 801 [655000/25046 (82%)]	Loss: 0.055388
Make prediction for 5010 samples...
0.24385063 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 802 [0/25046 (0%)]	Loss: 0.050364
Train epoch: 802 [322840/25046 (41%)]	Loss: 0.065897
Train epoch: 802 [655320/25046 (82%)]	Loss: 0.090175
Make prediction for 5010 samples...
0.244827 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 803 [0/25046 (0%)]	Loss: 0.062770
Train epoch: 803 [324860/25046 (41%)]	Loss: 0.066852
Train epoch: 803 [656360/25046 (82%)]	Loss: 0.089633
Make prediction for 5010 samples...
0.2615681 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 804 [0/25046 (0%)]	Loss: 0.062926
Train epoch: 804 [329960/25046 (41%)]	Loss: 0.069749
Train epoch: 804 [652880/25046 (82%)]	Loss: 0.055962
Make prediction for 5010 samples...
0.2419092 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 805 [0/25046 (0%)]	Loss: 0.090834
Train epoch: 805 [329820/25046 (41%)]	Loss: 0.058343
Train epoch: 805 [653200/25046 (82%)]	Loss: 0.067199
Make prediction for 5010 samples...
0.25067323 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 806 [0/25046 (0%)]	Loss: 0.065347
Train epoch: 806 [330620/25046 (41%)]	Loss: 0.061303
Train epoch: 806 [654120/25046 (82%)]	Loss: 0.090195
Make prediction for 5010 samples...
0.25861245 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 807 [0/25046 (0%)]	Loss: 0.079621
Train epoch: 807 [326200/25046 (41%)]	Loss: 0.081067
Train epoch: 807 [658000/25046 (82%)]	Loss: 0.065989
Make prediction for 5010 samples...
0.25392106 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 808 [0/25046 (0%)]	Loss: 0.080784
Train epoch: 808 [325360/25046 (41%)]	Loss: 0.099735
Train epoch: 808 [661120/25046 (82%)]	Loss: 0.086380
Make prediction for 5010 samples...
0.24205658 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 809 [0/25046 (0%)]	Loss: 0.061942
Train epoch: 809 [328920/25046 (41%)]	Loss: 0.071946
Train epoch: 809 [655040/25046 (82%)]	Loss: 0.074712
Make prediction for 5010 samples...
0.26573807 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 810 [0/25046 (0%)]	Loss: 0.068238
Train epoch: 810 [329860/25046 (41%)]	Loss: 0.080750
Train epoch: 810 [653520/25046 (82%)]	Loss: 0.086480
Make prediction for 5010 samples...
0.23984526 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 811 [0/25046 (0%)]	Loss: 0.062464
Train epoch: 811 [339040/25046 (41%)]	Loss: 0.066307
Train epoch: 811 [653880/25046 (82%)]	Loss: 0.059456
Make prediction for 5010 samples...
0.23468488 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 812 [0/25046 (0%)]	Loss: 0.067173
Train epoch: 812 [331460/25046 (41%)]	Loss: 0.090276
Train epoch: 812 [664280/25046 (82%)]	Loss: 0.050485
Make prediction for 5010 samples...
0.26938733 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 813 [0/25046 (0%)]	Loss: 0.082729
Train epoch: 813 [331480/25046 (41%)]	Loss: 0.068470
Train epoch: 813 [649280/25046 (82%)]	Loss: 0.092276
Make prediction for 5010 samples...
0.23940727 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 814 [0/25046 (0%)]	Loss: 0.055425
Train epoch: 814 [327420/25046 (41%)]	Loss: 0.068994
Train epoch: 814 [646920/25046 (82%)]	Loss: 0.072210
Make prediction for 5010 samples...
0.23455031 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 815 [0/25046 (0%)]	Loss: 0.087481
Train epoch: 815 [329300/25046 (41%)]	Loss: 0.088198
Train epoch: 815 [657360/25046 (82%)]	Loss: 0.075852
Make prediction for 5010 samples...
0.23467138 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 816 [0/25046 (0%)]	Loss: 0.060247
Train epoch: 816 [330380/25046 (41%)]	Loss: 0.053474
Train epoch: 816 [664680/25046 (82%)]	Loss: 0.074141
Make prediction for 5010 samples...
0.24555169 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 817 [0/25046 (0%)]	Loss: 0.071554
Train epoch: 817 [330640/25046 (41%)]	Loss: 0.057455
Train epoch: 817 [653400/25046 (82%)]	Loss: 0.078330
Make prediction for 5010 samples...
0.25401384 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 818 [0/25046 (0%)]	Loss: 0.052395
Train epoch: 818 [327160/25046 (41%)]	Loss: 0.069769
Train epoch: 818 [661960/25046 (82%)]	Loss: 0.081403
Make prediction for 5010 samples...
0.23721322 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 819 [0/25046 (0%)]	Loss: 0.071476
Train epoch: 819 [326940/25046 (41%)]	Loss: 0.077305
Train epoch: 819 [652680/25046 (82%)]	Loss: 0.058461
Make prediction for 5010 samples...
0.2555923 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 820 [0/25046 (0%)]	Loss: 0.064179
Train epoch: 820 [329980/25046 (41%)]	Loss: 0.086850
Train epoch: 820 [654880/25046 (82%)]	Loss: 0.099909
Make prediction for 5010 samples...
0.23786993 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 821 [0/25046 (0%)]	Loss: 0.063253
Train epoch: 821 [325700/25046 (41%)]	Loss: 0.047883
Train epoch: 821 [653440/25046 (82%)]	Loss: 0.060290
Make prediction for 5010 samples...
0.24885575 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 822 [0/25046 (0%)]	Loss: 0.057943
Train epoch: 822 [327560/25046 (41%)]	Loss: 0.079836
Train epoch: 822 [649920/25046 (82%)]	Loss: 0.059106
Make prediction for 5010 samples...
0.24291681 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 823 [0/25046 (0%)]	Loss: 0.085832
Train epoch: 823 [328240/25046 (41%)]	Loss: 0.073956
Train epoch: 823 [659120/25046 (82%)]	Loss: 0.080467
Make prediction for 5010 samples...
0.23567016 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 824 [0/25046 (0%)]	Loss: 0.073366
Train epoch: 824 [330520/25046 (41%)]	Loss: 0.069056
Train epoch: 824 [658880/25046 (82%)]	Loss: 0.102507
Make prediction for 5010 samples...
0.24941538 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 825 [0/25046 (0%)]	Loss: 0.076454
Train epoch: 825 [330840/25046 (41%)]	Loss: 0.092125
Train epoch: 825 [648240/25046 (82%)]	Loss: 0.091454
Make prediction for 5010 samples...
0.24124028 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 826 [0/25046 (0%)]	Loss: 0.053920
Train epoch: 826 [327220/25046 (41%)]	Loss: 0.080573
Train epoch: 826 [664120/25046 (82%)]	Loss: 0.086522
Make prediction for 5010 samples...
0.23517637 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 827 [0/25046 (0%)]	Loss: 0.071167
Train epoch: 827 [326960/25046 (41%)]	Loss: 0.056461
Train epoch: 827 [669080/25046 (82%)]	Loss: 0.077634
Make prediction for 5010 samples...
0.25061187 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 828 [0/25046 (0%)]	Loss: 0.061578
Train epoch: 828 [329580/25046 (41%)]	Loss: 0.100714
Train epoch: 828 [656960/25046 (82%)]	Loss: 0.080855
Make prediction for 5010 samples...
0.2321269 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 829 [0/25046 (0%)]	Loss: 0.064690
Train epoch: 829 [327980/25046 (41%)]	Loss: 0.064727
Train epoch: 829 [652800/25046 (82%)]	Loss: 0.077554
Make prediction for 5010 samples...
0.23967475 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 830 [0/25046 (0%)]	Loss: 0.065715
Train epoch: 830 [331920/25046 (41%)]	Loss: 0.102996
Train epoch: 830 [652520/25046 (82%)]	Loss: 0.080291
Make prediction for 5010 samples...
0.26372257 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 831 [0/25046 (0%)]	Loss: 0.069295
Train epoch: 831 [324740/25046 (41%)]	Loss: 0.067510
Train epoch: 831 [648160/25046 (82%)]	Loss: 0.054735
Make prediction for 5010 samples...
0.23288745 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 832 [0/25046 (0%)]	Loss: 0.053459
Train epoch: 832 [329260/25046 (41%)]	Loss: 0.056657
Train epoch: 832 [661760/25046 (82%)]	Loss: 0.067948
Make prediction for 5010 samples...
0.23327921 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 833 [0/25046 (0%)]	Loss: 0.069991
Train epoch: 833 [326540/25046 (41%)]	Loss: 0.067712
Train epoch: 833 [654800/25046 (82%)]	Loss: 0.119525
Make prediction for 5010 samples...
0.23787552 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 834 [0/25046 (0%)]	Loss: 0.092316
Train epoch: 834 [327600/25046 (41%)]	Loss: 0.081204
Train epoch: 834 [647480/25046 (82%)]	Loss: 0.067192
Make prediction for 5010 samples...
0.23663361 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 835 [0/25046 (0%)]	Loss: 0.055166
Train epoch: 835 [329200/25046 (41%)]	Loss: 0.062708
Train epoch: 835 [650880/25046 (82%)]	Loss: 0.078234
Make prediction for 5010 samples...
0.24216348 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 836 [0/25046 (0%)]	Loss: 0.075899
Train epoch: 836 [328520/25046 (41%)]	Loss: 0.062982
Train epoch: 836 [655920/25046 (82%)]	Loss: 0.079996
Make prediction for 5010 samples...
0.24739344 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 837 [0/25046 (0%)]	Loss: 0.064489
Train epoch: 837 [325580/25046 (41%)]	Loss: 0.050845
Train epoch: 837 [654680/25046 (82%)]	Loss: 0.091464
Make prediction for 5010 samples...
0.24219821 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 838 [0/25046 (0%)]	Loss: 0.070231
Train epoch: 838 [328680/25046 (41%)]	Loss: 0.075221
Train epoch: 838 [657400/25046 (82%)]	Loss: 0.075668
Make prediction for 5010 samples...
0.24450888 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 839 [0/25046 (0%)]	Loss: 0.061875
Train epoch: 839 [327280/25046 (41%)]	Loss: 0.105634
Train epoch: 839 [664800/25046 (82%)]	Loss: 0.095273
Make prediction for 5010 samples...
0.23403741 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 840 [0/25046 (0%)]	Loss: 0.074018
Train epoch: 840 [331060/25046 (41%)]	Loss: 0.083100
Train epoch: 840 [667480/25046 (82%)]	Loss: 0.082979
Make prediction for 5010 samples...
0.23993312 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 841 [0/25046 (0%)]	Loss: 0.052235
Train epoch: 841 [326080/25046 (41%)]	Loss: 0.065786
Train epoch: 841 [661800/25046 (82%)]	Loss: 0.067665
Make prediction for 5010 samples...
0.23706411 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 842 [0/25046 (0%)]	Loss: 0.061776
Train epoch: 842 [332080/25046 (41%)]	Loss: 0.079370
Train epoch: 842 [650040/25046 (82%)]	Loss: 0.057719
Make prediction for 5010 samples...
0.23422174 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 843 [0/25046 (0%)]	Loss: 0.067501
Train epoch: 843 [328500/25046 (41%)]	Loss: 0.074723
Train epoch: 843 [658480/25046 (82%)]	Loss: 0.082452
Make prediction for 5010 samples...
0.26397645 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 844 [0/25046 (0%)]	Loss: 0.075841
Train epoch: 844 [324060/25046 (41%)]	Loss: 0.085629
Train epoch: 844 [662800/25046 (82%)]	Loss: 0.074788
Make prediction for 5010 samples...
0.23882745 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 845 [0/25046 (0%)]	Loss: 0.090493
Train epoch: 845 [331360/25046 (41%)]	Loss: 0.057493
Train epoch: 845 [651560/25046 (82%)]	Loss: 0.055745
Make prediction for 5010 samples...
0.2355894 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 846 [0/25046 (0%)]	Loss: 0.065104
Train epoch: 846 [325760/25046 (41%)]	Loss: 0.058282
Train epoch: 846 [654480/25046 (82%)]	Loss: 0.059586
Make prediction for 5010 samples...
0.23893344 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 847 [0/25046 (0%)]	Loss: 0.058531
Train epoch: 847 [327900/25046 (41%)]	Loss: 0.069960
Train epoch: 847 [654320/25046 (82%)]	Loss: 0.078269
Make prediction for 5010 samples...
0.23331949 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 848 [0/25046 (0%)]	Loss: 0.051494
Train epoch: 848 [326320/25046 (41%)]	Loss: 0.064432
Train epoch: 848 [661120/25046 (82%)]	Loss: 0.074183
Make prediction for 5010 samples...
0.25076756 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 849 [0/25046 (0%)]	Loss: 0.094612
Train epoch: 849 [329000/25046 (41%)]	Loss: 0.056079
Train epoch: 849 [648360/25046 (82%)]	Loss: 0.074855
Make prediction for 5010 samples...
0.23567969 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 850 [0/25046 (0%)]	Loss: 0.076098
Train epoch: 850 [329340/25046 (41%)]	Loss: 0.055439
Train epoch: 850 [650760/25046 (82%)]	Loss: 0.078166
Make prediction for 5010 samples...
0.25765362 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 851 [0/25046 (0%)]	Loss: 0.071266
Train epoch: 851 [325920/25046 (41%)]	Loss: 0.078268
Train epoch: 851 [661640/25046 (82%)]	Loss: 0.087215
Make prediction for 5010 samples...
0.23986475 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 852 [0/25046 (0%)]	Loss: 0.054426
Train epoch: 852 [333580/25046 (41%)]	Loss: 0.066755
Train epoch: 852 [655680/25046 (82%)]	Loss: 0.060667
Make prediction for 5010 samples...
0.24206787 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 853 [0/25046 (0%)]	Loss: 0.069822
Train epoch: 853 [324700/25046 (41%)]	Loss: 0.072851
Train epoch: 853 [658000/25046 (82%)]	Loss: 0.108719
Make prediction for 5010 samples...
0.22823684 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 854 [0/25046 (0%)]	Loss: 0.114605
Train epoch: 854 [327000/25046 (41%)]	Loss: 0.083302
Train epoch: 854 [662760/25046 (82%)]	Loss: 0.054998
Make prediction for 5010 samples...
0.24657248 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 855 [0/25046 (0%)]	Loss: 0.080831
Train epoch: 855 [336640/25046 (41%)]	Loss: 0.084405
Train epoch: 855 [659720/25046 (82%)]	Loss: 0.062039
Make prediction for 5010 samples...
0.23742127 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 856 [0/25046 (0%)]	Loss: 0.080146
Train epoch: 856 [326200/25046 (41%)]	Loss: 0.091151
Train epoch: 856 [658880/25046 (82%)]	Loss: 0.078777
Make prediction for 5010 samples...
0.24066219 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 857 [0/25046 (0%)]	Loss: 0.071080
Train epoch: 857 [330420/25046 (41%)]	Loss: 0.061266
Train epoch: 857 [661080/25046 (82%)]	Loss: 0.059405
Make prediction for 5010 samples...
0.23192243 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 858 [0/25046 (0%)]	Loss: 0.074704
Train epoch: 858 [327200/25046 (41%)]	Loss: 0.071177
Train epoch: 858 [658920/25046 (82%)]	Loss: 0.065327
Make prediction for 5010 samples...
0.23792976 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 859 [0/25046 (0%)]	Loss: 0.049110
Train epoch: 859 [331560/25046 (41%)]	Loss: 0.098710
Train epoch: 859 [657600/25046 (82%)]	Loss: 0.078686
Make prediction for 5010 samples...
0.2404085 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 860 [0/25046 (0%)]	Loss: 0.049173
Train epoch: 860 [327060/25046 (41%)]	Loss: 0.062371
Train epoch: 860 [661840/25046 (82%)]	Loss: 0.052114
Make prediction for 5010 samples...
0.23888162 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 861 [0/25046 (0%)]	Loss: 0.069349
Train epoch: 861 [327100/25046 (41%)]	Loss: 0.074388
Train epoch: 861 [652480/25046 (82%)]	Loss: 0.080798
Make prediction for 5010 samples...
0.23402046 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 862 [0/25046 (0%)]	Loss: 0.048079
Train epoch: 862 [326700/25046 (41%)]	Loss: 0.064328
Train epoch: 862 [662520/25046 (82%)]	Loss: 0.060417
Make prediction for 5010 samples...
0.24693799 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 863 [0/25046 (0%)]	Loss: 0.083831
Train epoch: 863 [332760/25046 (41%)]	Loss: 0.064679
Train epoch: 863 [663400/25046 (82%)]	Loss: 0.069638
Make prediction for 5010 samples...
0.2355707 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 864 [0/25046 (0%)]	Loss: 0.067993
Train epoch: 864 [332320/25046 (41%)]	Loss: 0.052321
Train epoch: 864 [651760/25046 (82%)]	Loss: 0.097899
Make prediction for 5010 samples...
0.2351729 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 865 [0/25046 (0%)]	Loss: 0.064291
Train epoch: 865 [327960/25046 (41%)]	Loss: 0.080309
Train epoch: 865 [658720/25046 (82%)]	Loss: 0.072615
Make prediction for 5010 samples...
0.2363697 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 866 [0/25046 (0%)]	Loss: 0.063755
Train epoch: 866 [331320/25046 (41%)]	Loss: 0.061958
Train epoch: 866 [662240/25046 (82%)]	Loss: 0.061849
Make prediction for 5010 samples...
0.23740128 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 867 [0/25046 (0%)]	Loss: 0.080642
Train epoch: 867 [331080/25046 (41%)]	Loss: 0.056220
Train epoch: 867 [655800/25046 (82%)]	Loss: 0.079848
Make prediction for 5010 samples...
0.22855885 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 868 [0/25046 (0%)]	Loss: 0.066847
Train epoch: 868 [326580/25046 (41%)]	Loss: 0.083093
Train epoch: 868 [659720/25046 (82%)]	Loss: 0.088034
Make prediction for 5010 samples...
0.23758908 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 869 [0/25046 (0%)]	Loss: 0.059423
Train epoch: 869 [328780/25046 (41%)]	Loss: 0.091691
Train epoch: 869 [657280/25046 (82%)]	Loss: 0.051327
Make prediction for 5010 samples...
0.25705537 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 870 [0/25046 (0%)]	Loss: 0.092583
Train epoch: 870 [324660/25046 (41%)]	Loss: 0.078468
Train epoch: 870 [659200/25046 (82%)]	Loss: 0.072537
Make prediction for 5010 samples...
0.23505 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 871 [0/25046 (0%)]	Loss: 0.076004
Train epoch: 871 [327700/25046 (41%)]	Loss: 0.072514
Train epoch: 871 [658480/25046 (82%)]	Loss: 0.078904
Make prediction for 5010 samples...
0.23426424 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 872 [0/25046 (0%)]	Loss: 0.083991
Train epoch: 872 [329620/25046 (41%)]	Loss: 0.061160
Train epoch: 872 [656520/25046 (82%)]	Loss: 0.078184
Make prediction for 5010 samples...
0.2349787 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 873 [0/25046 (0%)]	Loss: 0.072432
Train epoch: 873 [331480/25046 (41%)]	Loss: 0.083343
Train epoch: 873 [658640/25046 (82%)]	Loss: 0.067662
Make prediction for 5010 samples...
0.2592274 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 874 [0/25046 (0%)]	Loss: 0.069902
Train epoch: 874 [329280/25046 (41%)]	Loss: 0.090691
Train epoch: 874 [653200/25046 (82%)]	Loss: 0.065761
Make prediction for 5010 samples...
0.23693384 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 875 [0/25046 (0%)]	Loss: 0.104209
Train epoch: 875 [329420/25046 (41%)]	Loss: 0.053172
Train epoch: 875 [651680/25046 (82%)]	Loss: 0.101808
Make prediction for 5010 samples...
0.23463352 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 876 [0/25046 (0%)]	Loss: 0.077526
Train epoch: 876 [329920/25046 (41%)]	Loss: 0.060464
Train epoch: 876 [658520/25046 (82%)]	Loss: 0.069745
Make prediction for 5010 samples...
0.23680551 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 877 [0/25046 (0%)]	Loss: 0.065481
Train epoch: 877 [327440/25046 (41%)]	Loss: 0.065118
Train epoch: 877 [653680/25046 (82%)]	Loss: 0.060707
Make prediction for 5010 samples...
0.23957627 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 878 [0/25046 (0%)]	Loss: 0.078963
Train epoch: 878 [325800/25046 (41%)]	Loss: 0.065820
Train epoch: 878 [661680/25046 (82%)]	Loss: 0.063623
Make prediction for 5010 samples...
0.23952055 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 879 [0/25046 (0%)]	Loss: 0.048517
Train epoch: 879 [325660/25046 (41%)]	Loss: 0.082793
Train epoch: 879 [662280/25046 (82%)]	Loss: 0.076450
Make prediction for 5010 samples...
0.23052928 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 880 [0/25046 (0%)]	Loss: 0.064041
Train epoch: 880 [332000/25046 (41%)]	Loss: 0.055790
Train epoch: 880 [651880/25046 (82%)]	Loss: 0.059387
Make prediction for 5010 samples...
0.23114532 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 881 [0/25046 (0%)]	Loss: 0.082696
Train epoch: 881 [329580/25046 (41%)]	Loss: 0.072508
Train epoch: 881 [668840/25046 (82%)]	Loss: 0.055181
Make prediction for 5010 samples...
0.23257191 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 882 [0/25046 (0%)]	Loss: 0.080866
Train epoch: 882 [327240/25046 (41%)]	Loss: 0.072333
Train epoch: 882 [652840/25046 (82%)]	Loss: 0.071504
Make prediction for 5010 samples...
0.27132696 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 883 [0/25046 (0%)]	Loss: 0.087972
Train epoch: 883 [331100/25046 (41%)]	Loss: 0.087675
Train epoch: 883 [660600/25046 (82%)]	Loss: 0.067994
Make prediction for 5010 samples...
0.2345313 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 884 [0/25046 (0%)]	Loss: 0.063146
Train epoch: 884 [326360/25046 (41%)]	Loss: 0.057010
Train epoch: 884 [657400/25046 (82%)]	Loss: 0.079256
Make prediction for 5010 samples...
0.25495955 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 885 [0/25046 (0%)]	Loss: 0.052694
Train epoch: 885 [327760/25046 (41%)]	Loss: 0.094359
Train epoch: 885 [660680/25046 (82%)]	Loss: 0.080072
Make prediction for 5010 samples...
0.23624879 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 886 [0/25046 (0%)]	Loss: 0.075371
Train epoch: 886 [333960/25046 (41%)]	Loss: 0.070670
Train epoch: 886 [656320/25046 (82%)]	Loss: 0.067820
Make prediction for 5010 samples...
0.23183799 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 887 [0/25046 (0%)]	Loss: 0.061694
Train epoch: 887 [324940/25046 (41%)]	Loss: 0.068545
Train epoch: 887 [652360/25046 (82%)]	Loss: 0.061045
Make prediction for 5010 samples...
0.23585305 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 888 [0/25046 (0%)]	Loss: 0.084289
Train epoch: 888 [327460/25046 (41%)]	Loss: 0.082573
Train epoch: 888 [668560/25046 (82%)]	Loss: 0.083238
Make prediction for 5010 samples...
0.23385645 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 889 [0/25046 (0%)]	Loss: 0.081538
Train epoch: 889 [329800/25046 (41%)]	Loss: 0.079363
Train epoch: 889 [650400/25046 (82%)]	Loss: 0.059013
Make prediction for 5010 samples...
0.23541896 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 890 [0/25046 (0%)]	Loss: 0.105705
Train epoch: 890 [329380/25046 (41%)]	Loss: 0.085053
Train epoch: 890 [655880/25046 (82%)]	Loss: 0.099935
Make prediction for 5010 samples...
0.23233996 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 891 [0/25046 (0%)]	Loss: 0.073448
Train epoch: 891 [324940/25046 (41%)]	Loss: 0.058706
Train epoch: 891 [650480/25046 (82%)]	Loss: 0.066673
Make prediction for 5010 samples...
0.26993197 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 892 [0/25046 (0%)]	Loss: 0.082692
Train epoch: 892 [332740/25046 (41%)]	Loss: 0.095955
Train epoch: 892 [651080/25046 (82%)]	Loss: 0.048452
Make prediction for 5010 samples...
0.2329979 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 893 [0/25046 (0%)]	Loss: 0.066146
Train epoch: 893 [326460/25046 (41%)]	Loss: 0.038825
Train epoch: 893 [664960/25046 (82%)]	Loss: 0.063077
Make prediction for 5010 samples...
0.2337912 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 894 [0/25046 (0%)]	Loss: 0.077562
Train epoch: 894 [325740/25046 (41%)]	Loss: 0.043507
Train epoch: 894 [653040/25046 (82%)]	Loss: 0.087477
Make prediction for 5010 samples...
0.25154918 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 895 [0/25046 (0%)]	Loss: 0.068561
Train epoch: 895 [328060/25046 (41%)]	Loss: 0.087819
Train epoch: 895 [660560/25046 (82%)]	Loss: 0.075104
Make prediction for 5010 samples...
0.2517315 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 896 [0/25046 (0%)]	Loss: 0.067249
Train epoch: 896 [333020/25046 (41%)]	Loss: 0.056925
Train epoch: 896 [655720/25046 (82%)]	Loss: 0.105152
Make prediction for 5010 samples...
0.24484551 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 897 [0/25046 (0%)]	Loss: 0.090108
Train epoch: 897 [329720/25046 (41%)]	Loss: 0.051426
Train epoch: 897 [652320/25046 (82%)]	Loss: 0.080461
Make prediction for 5010 samples...
0.24536897 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 898 [0/25046 (0%)]	Loss: 0.072111
Train epoch: 898 [330920/25046 (41%)]	Loss: 0.063803
Train epoch: 898 [654640/25046 (82%)]	Loss: 0.082816
Make prediction for 5010 samples...
0.25657797 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 899 [0/25046 (0%)]	Loss: 0.087677
Train epoch: 899 [325660/25046 (41%)]	Loss: 0.067454
Train epoch: 899 [654960/25046 (82%)]	Loss: 0.062422
Make prediction for 5010 samples...
0.23663557 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 900 [0/25046 (0%)]	Loss: 0.080238
Train epoch: 900 [325280/25046 (41%)]	Loss: 0.062777
Train epoch: 900 [659000/25046 (82%)]	Loss: 0.060695
Make prediction for 5010 samples...
0.23713076 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 901 [0/25046 (0%)]	Loss: 0.054158
Train epoch: 901 [328980/25046 (41%)]	Loss: 0.093857
Train epoch: 901 [661280/25046 (82%)]	Loss: 0.074797
Make prediction for 5010 samples...
0.2425114 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 902 [0/25046 (0%)]	Loss: 0.051247
Train epoch: 902 [327220/25046 (41%)]	Loss: 0.069424
Train epoch: 902 [644480/25046 (82%)]	Loss: 0.043932
Make prediction for 5010 samples...
0.2335726 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 903 [0/25046 (0%)]	Loss: 0.091264
Train epoch: 903 [328800/25046 (41%)]	Loss: 0.075546
Train epoch: 903 [666440/25046 (82%)]	Loss: 0.069873
Make prediction for 5010 samples...
0.2418806 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 904 [0/25046 (0%)]	Loss: 0.051157
Train epoch: 904 [335380/25046 (41%)]	Loss: 0.081476
Train epoch: 904 [646960/25046 (82%)]	Loss: 0.076795
Make prediction for 5010 samples...
0.24649188 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 905 [0/25046 (0%)]	Loss: 0.045009
Train epoch: 905 [329000/25046 (41%)]	Loss: 0.044944
Train epoch: 905 [652120/25046 (82%)]	Loss: 0.086448
Make prediction for 5010 samples...
0.23943432 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 906 [0/25046 (0%)]	Loss: 0.068091
Train epoch: 906 [333200/25046 (41%)]	Loss: 0.080186
Train epoch: 906 [653400/25046 (82%)]	Loss: 0.043556
Make prediction for 5010 samples...
0.23485182 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 907 [0/25046 (0%)]	Loss: 0.067935
Train epoch: 907 [329380/25046 (41%)]	Loss: 0.080821
Train epoch: 907 [655360/25046 (82%)]	Loss: 0.062631
Make prediction for 5010 samples...
0.2641366 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 908 [0/25046 (0%)]	Loss: 0.068624
Train epoch: 908 [331040/25046 (41%)]	Loss: 0.085763
Train epoch: 908 [655480/25046 (82%)]	Loss: 0.044117
Make prediction for 5010 samples...
0.24224535 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 909 [0/25046 (0%)]	Loss: 0.083849
Train epoch: 909 [328580/25046 (41%)]	Loss: 0.107368
Train epoch: 909 [657120/25046 (82%)]	Loss: 0.074503
Make prediction for 5010 samples...
0.23505498 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 910 [0/25046 (0%)]	Loss: 0.069762
Train epoch: 910 [328280/25046 (41%)]	Loss: 0.071063
Train epoch: 910 [656680/25046 (82%)]	Loss: 0.080707
Make prediction for 5010 samples...
0.23092726 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 911 [0/25046 (0%)]	Loss: 0.045361
Train epoch: 911 [327260/25046 (41%)]	Loss: 0.084358
Train epoch: 911 [652680/25046 (82%)]	Loss: 0.054389
Make prediction for 5010 samples...
0.24127892 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 912 [0/25046 (0%)]	Loss: 0.101006
Train epoch: 912 [331300/25046 (41%)]	Loss: 0.069437
Train epoch: 912 [660000/25046 (82%)]	Loss: 0.064818
Make prediction for 5010 samples...
0.24060002 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 913 [0/25046 (0%)]	Loss: 0.081460
Train epoch: 913 [332520/25046 (41%)]	Loss: 0.055792
Train epoch: 913 [661520/25046 (82%)]	Loss: 0.081346
Make prediction for 5010 samples...
0.25296107 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 914 [0/25046 (0%)]	Loss: 0.062875
Train epoch: 914 [326260/25046 (41%)]	Loss: 0.047365
Train epoch: 914 [661600/25046 (82%)]	Loss: 0.062806
Make prediction for 5010 samples...
0.2331063 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 915 [0/25046 (0%)]	Loss: 0.069827
Train epoch: 915 [328040/25046 (41%)]	Loss: 0.061780
Train epoch: 915 [660920/25046 (82%)]	Loss: 0.059371
Make prediction for 5010 samples...
0.25001124 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 916 [0/25046 (0%)]	Loss: 0.063628
Train epoch: 916 [330580/25046 (41%)]	Loss: 0.064579
Train epoch: 916 [662680/25046 (82%)]	Loss: 0.077020
Make prediction for 5010 samples...
0.23724361 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 917 [0/25046 (0%)]	Loss: 0.054899
Train epoch: 917 [329680/25046 (41%)]	Loss: 0.088812
Train epoch: 917 [664880/25046 (82%)]	Loss: 0.081759
Make prediction for 5010 samples...
0.24070857 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 918 [0/25046 (0%)]	Loss: 0.067980
Train epoch: 918 [332240/25046 (41%)]	Loss: 0.047385
Train epoch: 918 [666000/25046 (82%)]	Loss: 0.058541
Make prediction for 5010 samples...
0.23506503 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 919 [0/25046 (0%)]	Loss: 0.056367
Train epoch: 919 [332240/25046 (41%)]	Loss: 0.054922
Train epoch: 919 [661880/25046 (82%)]	Loss: 0.082874
Make prediction for 5010 samples...
0.23928456 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 920 [0/25046 (0%)]	Loss: 0.046541
Train epoch: 920 [327040/25046 (41%)]	Loss: 0.105893
Train epoch: 920 [660480/25046 (82%)]	Loss: 0.059826
Make prediction for 5010 samples...
0.26013052 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 921 [0/25046 (0%)]	Loss: 0.088427
Train epoch: 921 [329980/25046 (41%)]	Loss: 0.065947
Train epoch: 921 [661040/25046 (82%)]	Loss: 0.073804
Make prediction for 5010 samples...
0.24001352 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 922 [0/25046 (0%)]	Loss: 0.056439
Train epoch: 922 [324880/25046 (41%)]	Loss: 0.054004
Train epoch: 922 [645000/25046 (82%)]	Loss: 0.065560
Make prediction for 5010 samples...
0.26097482 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 923 [0/25046 (0%)]	Loss: 0.067601
Train epoch: 923 [322760/25046 (41%)]	Loss: 0.066973
Train epoch: 923 [657720/25046 (82%)]	Loss: 0.091128
Make prediction for 5010 samples...
0.24093848 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 924 [0/25046 (0%)]	Loss: 0.049890
Train epoch: 924 [329100/25046 (41%)]	Loss: 0.082831
Train epoch: 924 [654080/25046 (82%)]	Loss: 0.099290
Make prediction for 5010 samples...
0.25771508 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 925 [0/25046 (0%)]	Loss: 0.074279
Train epoch: 925 [330740/25046 (41%)]	Loss: 0.082676
Train epoch: 925 [659520/25046 (82%)]	Loss: 0.066805
Make prediction for 5010 samples...
0.23860572 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 926 [0/25046 (0%)]	Loss: 0.053381
Train epoch: 926 [329380/25046 (41%)]	Loss: 0.053966
Train epoch: 926 [661560/25046 (82%)]	Loss: 0.068185
Make prediction for 5010 samples...
0.2441227 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 927 [0/25046 (0%)]	Loss: 0.059504
Train epoch: 927 [330020/25046 (41%)]	Loss: 0.068551
Train epoch: 927 [650240/25046 (82%)]	Loss: 0.074228
Make prediction for 5010 samples...
0.23266505 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 928 [0/25046 (0%)]	Loss: 0.052586
Train epoch: 928 [331240/25046 (41%)]	Loss: 0.077634
Train epoch: 928 [654360/25046 (82%)]	Loss: 0.059098
Make prediction for 5010 samples...
0.23561569 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 929 [0/25046 (0%)]	Loss: 0.059544
Train epoch: 929 [325640/25046 (41%)]	Loss: 0.060024
Train epoch: 929 [658440/25046 (82%)]	Loss: 0.072008
Make prediction for 5010 samples...
0.23433456 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 930 [0/25046 (0%)]	Loss: 0.050951
Train epoch: 930 [330040/25046 (41%)]	Loss: 0.048831
Train epoch: 930 [662440/25046 (82%)]	Loss: 0.071423
Make prediction for 5010 samples...
0.23807831 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 931 [0/25046 (0%)]	Loss: 0.053514
Train epoch: 931 [327140/25046 (41%)]	Loss: 0.062753
Train epoch: 931 [648800/25046 (82%)]	Loss: 0.073747
Make prediction for 5010 samples...
0.24456711 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 932 [0/25046 (0%)]	Loss: 0.065810
Train epoch: 932 [327780/25046 (41%)]	Loss: 0.069105
Train epoch: 932 [668200/25046 (82%)]	Loss: 0.077909
Make prediction for 5010 samples...
0.22983822 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 933 [0/25046 (0%)]	Loss: 0.077420
Train epoch: 933 [325820/25046 (41%)]	Loss: 0.054018
Train epoch: 933 [661880/25046 (82%)]	Loss: 0.076407
Make prediction for 5010 samples...
0.24372715 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 934 [0/25046 (0%)]	Loss: 0.097780
Train epoch: 934 [329760/25046 (41%)]	Loss: 0.062566
Train epoch: 934 [660800/25046 (82%)]	Loss: 0.066626
Make prediction for 5010 samples...
0.24528618 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 935 [0/25046 (0%)]	Loss: 0.078290
Train epoch: 935 [329120/25046 (41%)]	Loss: 0.074449
Train epoch: 935 [658000/25046 (82%)]	Loss: 0.093995
Make prediction for 5010 samples...
0.2391436 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 936 [0/25046 (0%)]	Loss: 0.068727
Train epoch: 936 [326600/25046 (41%)]	Loss: 0.053976
Train epoch: 936 [658080/25046 (82%)]	Loss: 0.079277
Make prediction for 5010 samples...
0.25822374 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 937 [0/25046 (0%)]	Loss: 0.053932
Train epoch: 937 [328720/25046 (41%)]	Loss: 0.065070
Train epoch: 937 [651040/25046 (82%)]	Loss: 0.068007
Make prediction for 5010 samples...
0.24194117 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 938 [0/25046 (0%)]	Loss: 0.045585
Train epoch: 938 [326100/25046 (41%)]	Loss: 0.092656
Train epoch: 938 [649920/25046 (82%)]	Loss: 0.074692
Make prediction for 5010 samples...
0.24341527 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 939 [0/25046 (0%)]	Loss: 0.063000
Train epoch: 939 [333080/25046 (41%)]	Loss: 0.049822
Train epoch: 939 [659600/25046 (82%)]	Loss: 0.062911
Make prediction for 5010 samples...
0.23477846 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 940 [0/25046 (0%)]	Loss: 0.064786
Train epoch: 940 [326640/25046 (41%)]	Loss: 0.080533
Train epoch: 940 [660600/25046 (82%)]	Loss: 0.097172
Make prediction for 5010 samples...
0.24196349 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 941 [0/25046 (0%)]	Loss: 0.064661
Train epoch: 941 [327860/25046 (41%)]	Loss: 0.063642
Train epoch: 941 [657600/25046 (82%)]	Loss: 0.065172
Make prediction for 5010 samples...
0.2503955 No improvement since epoch  712 ; best_mse,best_ci: 0.22806662 0.8921982199679512 GINConvNet davis
Training on 25046 samples...
Train epoch: 942 [0/25046 (0%)]	Loss: 0.070948
Train epoch: 942 [320380/25046 (41%)]	Loss: 0.054594
Train epoch: 942 [657480/25046 (82%)]	Loss: 0.071295
Make prediction for 5010 samples...
rmse improved at epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 943 [0/25046 (0%)]	Loss: 0.064761
Train epoch: 943 [323860/25046 (41%)]	Loss: 0.071861
Train epoch: 943 [648360/25046 (82%)]	Loss: 0.045138
Make prediction for 5010 samples...
0.24249558 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 944 [0/25046 (0%)]	Loss: 0.079995
Train epoch: 944 [328540/25046 (41%)]	Loss: 0.070063
Train epoch: 944 [659800/25046 (82%)]	Loss: 0.055740
Make prediction for 5010 samples...
0.260003 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 945 [0/25046 (0%)]	Loss: 0.058163
Train epoch: 945 [331640/25046 (41%)]	Loss: 0.058919
Train epoch: 945 [654000/25046 (82%)]	Loss: 0.056407
Make prediction for 5010 samples...
0.23852858 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 946 [0/25046 (0%)]	Loss: 0.063305
Train epoch: 946 [329620/25046 (41%)]	Loss: 0.061953
Train epoch: 946 [656600/25046 (82%)]	Loss: 0.066437
Make prediction for 5010 samples...
0.25197458 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 947 [0/25046 (0%)]	Loss: 0.054779
Train epoch: 947 [327640/25046 (41%)]	Loss: 0.044924
Train epoch: 947 [651920/25046 (82%)]	Loss: 0.075782
Make prediction for 5010 samples...
0.23302121 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 948 [0/25046 (0%)]	Loss: 0.070954
Train epoch: 948 [326060/25046 (41%)]	Loss: 0.051049
Train epoch: 948 [659400/25046 (82%)]	Loss: 0.071314
Make prediction for 5010 samples...
0.24389572 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 949 [0/25046 (0%)]	Loss: 0.034383
Train epoch: 949 [328180/25046 (41%)]	Loss: 0.055257
Train epoch: 949 [654920/25046 (82%)]	Loss: 0.051658
Make prediction for 5010 samples...
0.24350062 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 950 [0/25046 (0%)]	Loss: 0.052319
Train epoch: 950 [327600/25046 (41%)]	Loss: 0.080998
Train epoch: 950 [646920/25046 (82%)]	Loss: 0.054682
Make prediction for 5010 samples...
0.24869509 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 951 [0/25046 (0%)]	Loss: 0.063526
Train epoch: 951 [325720/25046 (41%)]	Loss: 0.056883
Train epoch: 951 [653480/25046 (82%)]	Loss: 0.062608
Make prediction for 5010 samples...
0.23968874 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 952 [0/25046 (0%)]	Loss: 0.056608
Train epoch: 952 [333140/25046 (41%)]	Loss: 0.056136
Train epoch: 952 [659200/25046 (82%)]	Loss: 0.096832
Make prediction for 5010 samples...
0.24410173 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 953 [0/25046 (0%)]	Loss: 0.051743
Train epoch: 953 [325280/25046 (41%)]	Loss: 0.056730
Train epoch: 953 [662640/25046 (82%)]	Loss: 0.084007
Make prediction for 5010 samples...
0.23898034 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 954 [0/25046 (0%)]	Loss: 0.055732
Train epoch: 954 [331000/25046 (41%)]	Loss: 0.049518
Train epoch: 954 [650800/25046 (82%)]	Loss: 0.059749
Make prediction for 5010 samples...
0.23865424 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 955 [0/25046 (0%)]	Loss: 0.056436
Train epoch: 955 [327320/25046 (41%)]	Loss: 0.063175
Train epoch: 955 [655200/25046 (82%)]	Loss: 0.077233
Make prediction for 5010 samples...
0.25277838 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 956 [0/25046 (0%)]	Loss: 0.053630
Train epoch: 956 [331120/25046 (41%)]	Loss: 0.061989
Train epoch: 956 [657480/25046 (82%)]	Loss: 0.081401
Make prediction for 5010 samples...
0.24813917 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 957 [0/25046 (0%)]	Loss: 0.052794
Train epoch: 957 [329520/25046 (41%)]	Loss: 0.071937
Train epoch: 957 [652000/25046 (82%)]	Loss: 0.062366
Make prediction for 5010 samples...
0.24212003 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 958 [0/25046 (0%)]	Loss: 0.056149
Train epoch: 958 [326640/25046 (41%)]	Loss: 0.060205
Train epoch: 958 [655480/25046 (82%)]	Loss: 0.065599
Make prediction for 5010 samples...
0.23199178 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 959 [0/25046 (0%)]	Loss: 0.056985
Train epoch: 959 [331140/25046 (41%)]	Loss: 0.053643
Train epoch: 959 [657040/25046 (82%)]	Loss: 0.059185
Make prediction for 5010 samples...
0.23773976 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 960 [0/25046 (0%)]	Loss: 0.056874
Train epoch: 960 [328360/25046 (41%)]	Loss: 0.076389
Train epoch: 960 [662920/25046 (82%)]	Loss: 0.056329
Make prediction for 5010 samples...
0.2382145 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 961 [0/25046 (0%)]	Loss: 0.072241
Train epoch: 961 [328400/25046 (41%)]	Loss: 0.059793
Train epoch: 961 [661080/25046 (82%)]	Loss: 0.067471
Make prediction for 5010 samples...
0.2489154 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 962 [0/25046 (0%)]	Loss: 0.066803
Train epoch: 962 [330980/25046 (41%)]	Loss: 0.057228
Train epoch: 962 [658160/25046 (82%)]	Loss: 0.067482
Make prediction for 5010 samples...
0.23144427 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 963 [0/25046 (0%)]	Loss: 0.073344
Train epoch: 963 [328820/25046 (41%)]	Loss: 0.088650
Train epoch: 963 [661960/25046 (82%)]	Loss: 0.058840
Make prediction for 5010 samples...
0.23375732 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 964 [0/25046 (0%)]	Loss: 0.065819
Train epoch: 964 [322960/25046 (41%)]	Loss: 0.081221
Train epoch: 964 [661880/25046 (82%)]	Loss: 0.060427
Make prediction for 5010 samples...
0.24449424 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 965 [0/25046 (0%)]	Loss: 0.081322
Train epoch: 965 [328360/25046 (41%)]	Loss: 0.074062
Train epoch: 965 [649920/25046 (82%)]	Loss: 0.051051
Make prediction for 5010 samples...
0.23214562 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 966 [0/25046 (0%)]	Loss: 0.061255
Train epoch: 966 [327540/25046 (41%)]	Loss: 0.078672
Train epoch: 966 [652280/25046 (82%)]	Loss: 0.071135
Make prediction for 5010 samples...
0.23658362 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 967 [0/25046 (0%)]	Loss: 0.058644
Train epoch: 967 [328760/25046 (41%)]	Loss: 0.065706
Train epoch: 967 [647800/25046 (82%)]	Loss: 0.076746
Make prediction for 5010 samples...
0.23436764 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 968 [0/25046 (0%)]	Loss: 0.056161
Train epoch: 968 [331560/25046 (41%)]	Loss: 0.054836
Train epoch: 968 [659600/25046 (82%)]	Loss: 0.074433
Make prediction for 5010 samples...
0.23862977 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 969 [0/25046 (0%)]	Loss: 0.047056
Train epoch: 969 [325520/25046 (41%)]	Loss: 0.062342
Train epoch: 969 [642640/25046 (82%)]	Loss: 0.043697
Make prediction for 5010 samples...
0.24103582 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 970 [0/25046 (0%)]	Loss: 0.065078
Train epoch: 970 [329620/25046 (41%)]	Loss: 0.056906
Train epoch: 970 [669000/25046 (82%)]	Loss: 0.045406
Make prediction for 5010 samples...
0.23567933 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 971 [0/25046 (0%)]	Loss: 0.056031
Train epoch: 971 [327140/25046 (41%)]	Loss: 0.061601
Train epoch: 971 [661200/25046 (82%)]	Loss: 0.058708
Make prediction for 5010 samples...
0.26660937 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 972 [0/25046 (0%)]	Loss: 0.067281
Train epoch: 972 [323760/25046 (41%)]	Loss: 0.061658
Train epoch: 972 [655360/25046 (82%)]	Loss: 0.070179
Make prediction for 5010 samples...
0.24889795 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 973 [0/25046 (0%)]	Loss: 0.074637
Train epoch: 973 [329480/25046 (41%)]	Loss: 0.060925
Train epoch: 973 [646400/25046 (82%)]	Loss: 0.069546
Make prediction for 5010 samples...
0.23555186 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 974 [0/25046 (0%)]	Loss: 0.074929
Train epoch: 974 [329180/25046 (41%)]	Loss: 0.051779
Train epoch: 974 [656400/25046 (82%)]	Loss: 0.057116
Make prediction for 5010 samples...
0.25444454 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 975 [0/25046 (0%)]	Loss: 0.082976
Train epoch: 975 [326520/25046 (41%)]	Loss: 0.069365
Train epoch: 975 [654200/25046 (82%)]	Loss: 0.055071
Make prediction for 5010 samples...
0.24817511 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 976 [0/25046 (0%)]	Loss: 0.066268
Train epoch: 976 [329240/25046 (41%)]	Loss: 0.112432
Train epoch: 976 [653960/25046 (82%)]	Loss: 0.090764
Make prediction for 5010 samples...
0.23464887 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 977 [0/25046 (0%)]	Loss: 0.064906
Train epoch: 977 [327300/25046 (41%)]	Loss: 0.069475
Train epoch: 977 [656400/25046 (82%)]	Loss: 0.082125
Make prediction for 5010 samples...
0.25032574 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 978 [0/25046 (0%)]	Loss: 0.119422
Train epoch: 978 [326380/25046 (41%)]	Loss: 0.058867
Train epoch: 978 [652280/25046 (82%)]	Loss: 0.085434
Make prediction for 5010 samples...
0.2402794 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 979 [0/25046 (0%)]	Loss: 0.052018
Train epoch: 979 [327420/25046 (41%)]	Loss: 0.045542
Train epoch: 979 [669720/25046 (82%)]	Loss: 0.074190
Make prediction for 5010 samples...
0.23432247 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 980 [0/25046 (0%)]	Loss: 0.060163
Train epoch: 980 [326080/25046 (41%)]	Loss: 0.059114
Train epoch: 980 [653040/25046 (82%)]	Loss: 0.098286
Make prediction for 5010 samples...
0.23290358 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 981 [0/25046 (0%)]	Loss: 0.055991
Train epoch: 981 [324960/25046 (41%)]	Loss: 0.058152
Train epoch: 981 [652040/25046 (82%)]	Loss: 0.076645
Make prediction for 5010 samples...
0.23310827 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 982 [0/25046 (0%)]	Loss: 0.059798
Train epoch: 982 [324760/25046 (41%)]	Loss: 0.061680
Train epoch: 982 [654080/25046 (82%)]	Loss: 0.039028
Make prediction for 5010 samples...
0.24495868 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 983 [0/25046 (0%)]	Loss: 0.063414
Train epoch: 983 [327360/25046 (41%)]	Loss: 0.050763
Train epoch: 983 [655040/25046 (82%)]	Loss: 0.047867
Make prediction for 5010 samples...
0.23959199 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 984 [0/25046 (0%)]	Loss: 0.055513
Train epoch: 984 [326620/25046 (41%)]	Loss: 0.088438
Train epoch: 984 [651160/25046 (82%)]	Loss: 0.049228
Make prediction for 5010 samples...
0.260148 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 985 [0/25046 (0%)]	Loss: 0.059000
Train epoch: 985 [327860/25046 (41%)]	Loss: 0.068731
Train epoch: 985 [664160/25046 (82%)]	Loss: 0.096999
Make prediction for 5010 samples...
0.23578142 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 986 [0/25046 (0%)]	Loss: 0.074251
Train epoch: 986 [330420/25046 (41%)]	Loss: 0.067019
Train epoch: 986 [650680/25046 (82%)]	Loss: 0.060926
Make prediction for 5010 samples...
0.23319006 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 987 [0/25046 (0%)]	Loss: 0.064451
Train epoch: 987 [328240/25046 (41%)]	Loss: 0.092189
Train epoch: 987 [664720/25046 (82%)]	Loss: 0.050191
Make prediction for 5010 samples...
0.24009573 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 988 [0/25046 (0%)]	Loss: 0.062374
Train epoch: 988 [332800/25046 (41%)]	Loss: 0.070838
Train epoch: 988 [656360/25046 (82%)]	Loss: 0.064682
Make prediction for 5010 samples...
0.23392896 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 989 [0/25046 (0%)]	Loss: 0.043246
Train epoch: 989 [330380/25046 (41%)]	Loss: 0.059608
Train epoch: 989 [658000/25046 (82%)]	Loss: 0.058653
Make prediction for 5010 samples...
0.2334462 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 990 [0/25046 (0%)]	Loss: 0.071016
Train epoch: 990 [330120/25046 (41%)]	Loss: 0.073734
Train epoch: 990 [674640/25046 (82%)]	Loss: 0.080954
Make prediction for 5010 samples...
0.24238968 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 991 [0/25046 (0%)]	Loss: 0.061963
Train epoch: 991 [331300/25046 (41%)]	Loss: 0.086835
Train epoch: 991 [650320/25046 (82%)]	Loss: 0.062788
Make prediction for 5010 samples...
0.24332863 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 992 [0/25046 (0%)]	Loss: 0.058713
Train epoch: 992 [324540/25046 (41%)]	Loss: 0.081641
Train epoch: 992 [646960/25046 (82%)]	Loss: 0.075857
Make prediction for 5010 samples...
0.23278517 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 993 [0/25046 (0%)]	Loss: 0.057602
Train epoch: 993 [329400/25046 (41%)]	Loss: 0.077579
Train epoch: 993 [672920/25046 (82%)]	Loss: 0.067828
Make prediction for 5010 samples...
0.2360063 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 994 [0/25046 (0%)]	Loss: 0.064794
Train epoch: 994 [328160/25046 (41%)]	Loss: 0.062315
Train epoch: 994 [659280/25046 (82%)]	Loss: 0.073356
Make prediction for 5010 samples...
0.2347704 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 995 [0/25046 (0%)]	Loss: 0.062536
Train epoch: 995 [328060/25046 (41%)]	Loss: 0.081122
Train epoch: 995 [647160/25046 (82%)]	Loss: 0.061649
Make prediction for 5010 samples...
0.27412722 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 996 [0/25046 (0%)]	Loss: 0.075920
Train epoch: 996 [331700/25046 (41%)]	Loss: 0.045543
Train epoch: 996 [663440/25046 (82%)]	Loss: 0.083512
Make prediction for 5010 samples...
0.25860786 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 997 [0/25046 (0%)]	Loss: 0.066408
Train epoch: 997 [329680/25046 (41%)]	Loss: 0.064236
Train epoch: 997 [668280/25046 (82%)]	Loss: 0.062686
Make prediction for 5010 samples...
0.23743163 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 998 [0/25046 (0%)]	Loss: 0.047738
Train epoch: 998 [326840/25046 (41%)]	Loss: 0.069183
Train epoch: 998 [656000/25046 (82%)]	Loss: 0.061678
Make prediction for 5010 samples...
0.26227623 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 999 [0/25046 (0%)]	Loss: 0.061800
Train epoch: 999 [333180/25046 (41%)]	Loss: 0.060316
Train epoch: 999 [653040/25046 (82%)]	Loss: 0.082481
Make prediction for 5010 samples...
0.23713847 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
Training on 25046 samples...
Train epoch: 1000 [0/25046 (0%)]	Loss: 0.041894
Train epoch: 1000 [328240/25046 (41%)]	Loss: 0.069677
Train epoch: 1000 [657920/25046 (82%)]	Loss: 0.062513
Make prediction for 5010 samples...
0.23188452 No improvement since epoch  942 ; best_mse,best_ci: 0.22753936 0.8935188553125516 GINConvNet davis
