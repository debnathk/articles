Date
Tue Feb  6 09:19:11 PM EST 2024
cuda_name: cuda:0
Learning rate:  0.0005
Epochs:  1000

running on  GINConvNet_davis
Pre-processed data found: data/processed/davis_train.pt, loading ...
Pre-processed data found: data/processed/davis_test.pt, loading ...
Training on 20036 samples...
Train epoch: 1 [0/20036 (0%)]	Loss: 25.821894
Train epoch: 1 [323120/20036 (50%)]	Loss: 0.799873
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  1 ; best_test_mse,best_test_ci: 2.1394858 0.6042916743306808 GINConvNet davis
Training on 20036 samples...
Train epoch: 2 [0/20036 (0%)]	Loss: 1.006376
Train epoch: 2 [330620/20036 (50%)]	Loss: 0.820351
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  2 ; best_test_mse,best_test_ci: 1.0123239 0.6565130540431305 GINConvNet davis
Training on 20036 samples...
Train epoch: 3 [0/20036 (0%)]	Loss: 0.696685
Train epoch: 3 [328460/20036 (50%)]	Loss: 0.712565
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  3 ; best_test_mse,best_test_ci: 0.8028988 0.7623325792607107 GINConvNet davis
Training on 20036 samples...
Train epoch: 4 [0/20036 (0%)]	Loss: 0.628613
Train epoch: 4 [332720/20036 (50%)]	Loss: 0.850770
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  4 ; best_test_mse,best_test_ci: 0.5618395 0.7781805097012252 GINConvNet davis
Training on 20036 samples...
Train epoch: 5 [0/20036 (0%)]	Loss: 0.720425
Train epoch: 5 [329820/20036 (50%)]	Loss: 0.602550
predicting for valid data
Make prediction for 5010 samples...
0.5618395 No improvement since epoch  4 ; best_test_mse,best_test_ci: 0.5618395 0.7781805097012252 GINConvNet davis
Training on 20036 samples...
Train epoch: 6 [0/20036 (0%)]	Loss: 0.778074
Train epoch: 6 [331160/20036 (50%)]	Loss: 0.550732
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  6 ; best_test_mse,best_test_ci: 0.5278406 0.7966265217822129 GINConvNet davis
Training on 20036 samples...
Train epoch: 7 [0/20036 (0%)]	Loss: 0.634574
Train epoch: 7 [328920/20036 (50%)]	Loss: 0.560928
predicting for valid data
Make prediction for 5010 samples...
0.5278406 No improvement since epoch  6 ; best_test_mse,best_test_ci: 0.5278406 0.7966265217822129 GINConvNet davis
Training on 20036 samples...
Train epoch: 8 [0/20036 (0%)]	Loss: 0.601602
Train epoch: 8 [330540/20036 (50%)]	Loss: 0.548747
predicting for valid data
Make prediction for 5010 samples...
0.5278406 No improvement since epoch  6 ; best_test_mse,best_test_ci: 0.5278406 0.7966265217822129 GINConvNet davis
Training on 20036 samples...
Train epoch: 9 [0/20036 (0%)]	Loss: 0.504957
Train epoch: 9 [329660/20036 (50%)]	Loss: 0.499538
predicting for valid data
Make prediction for 5010 samples...
0.5278406 No improvement since epoch  6 ; best_test_mse,best_test_ci: 0.5278406 0.7966265217822129 GINConvNet davis
Training on 20036 samples...
Train epoch: 10 [0/20036 (0%)]	Loss: 0.484391
Train epoch: 10 [330620/20036 (50%)]	Loss: 0.546696
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  10 ; best_test_mse,best_test_ci: 0.50817895 0.8139787941770747 GINConvNet davis
Training on 20036 samples...
Train epoch: 11 [0/20036 (0%)]	Loss: 0.481407
Train epoch: 11 [331120/20036 (50%)]	Loss: 0.391020
predicting for valid data
Make prediction for 5010 samples...
0.50817895 No improvement since epoch  10 ; best_test_mse,best_test_ci: 0.50817895 0.8139787941770747 GINConvNet davis
Training on 20036 samples...
Train epoch: 12 [0/20036 (0%)]	Loss: 0.447409
Train epoch: 12 [329520/20036 (50%)]	Loss: 0.551724
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 13 [0/20036 (0%)]	Loss: 0.568590
Train epoch: 13 [330520/20036 (50%)]	Loss: 0.465940
predicting for valid data
Make prediction for 5010 samples...
0.44615903 No improvement since epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 14 [0/20036 (0%)]	Loss: 0.421062
Train epoch: 14 [331240/20036 (50%)]	Loss: 0.449240
predicting for valid data
Make prediction for 5010 samples...
0.44615903 No improvement since epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 15 [0/20036 (0%)]	Loss: 0.445385
Train epoch: 15 [324600/20036 (50%)]	Loss: 0.395396
predicting for valid data
Make prediction for 5010 samples...
0.44615903 No improvement since epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 16 [0/20036 (0%)]	Loss: 0.435708
Train epoch: 16 [326720/20036 (50%)]	Loss: 0.399376
predicting for valid data
Make prediction for 5010 samples...
0.44615903 No improvement since epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 17 [0/20036 (0%)]	Loss: 0.358627
Train epoch: 17 [327540/20036 (50%)]	Loss: 0.502615
predicting for valid data
Make prediction for 5010 samples...
0.44615903 No improvement since epoch  12 ; best_test_mse,best_test_ci: 0.44615903 0.7997878988880045 GINConvNet davis
Training on 20036 samples...
Train epoch: 18 [0/20036 (0%)]	Loss: 0.394369
Train epoch: 18 [328060/20036 (50%)]	Loss: 0.436687
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 19 [0/20036 (0%)]	Loss: 0.473043
Train epoch: 19 [329220/20036 (50%)]	Loss: 0.376419
predicting for valid data
Make prediction for 5010 samples...
0.41278595 No improvement since epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 20 [0/20036 (0%)]	Loss: 0.378206
Train epoch: 20 [324860/20036 (50%)]	Loss: 0.388836
predicting for valid data
Make prediction for 5010 samples...
0.41278595 No improvement since epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 21 [0/20036 (0%)]	Loss: 0.360674
Train epoch: 21 [330840/20036 (50%)]	Loss: 0.447446
predicting for valid data
Make prediction for 5010 samples...
0.41278595 No improvement since epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 22 [0/20036 (0%)]	Loss: 0.361758
Train epoch: 22 [322300/20036 (50%)]	Loss: 0.415488
predicting for valid data
Make prediction for 5010 samples...
0.41278595 No improvement since epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 23 [0/20036 (0%)]	Loss: 0.378193
Train epoch: 23 [323920/20036 (50%)]	Loss: 0.350134
predicting for valid data
Make prediction for 5010 samples...
0.41278595 No improvement since epoch  18 ; best_test_mse,best_test_ci: 0.41278595 0.8381421480241853 GINConvNet davis
Training on 20036 samples...
Train epoch: 24 [0/20036 (0%)]	Loss: 0.371247
Train epoch: 24 [329600/20036 (50%)]	Loss: 0.411247
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 25 [0/20036 (0%)]	Loss: 0.477665
Train epoch: 25 [331060/20036 (50%)]	Loss: 0.399345
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 26 [0/20036 (0%)]	Loss: 0.340268
Train epoch: 26 [330860/20036 (50%)]	Loss: 0.446361
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 27 [0/20036 (0%)]	Loss: 0.309773
Train epoch: 27 [326740/20036 (50%)]	Loss: 0.321550
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 28 [0/20036 (0%)]	Loss: 0.339000
Train epoch: 28 [330060/20036 (50%)]	Loss: 0.345445
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 29 [0/20036 (0%)]	Loss: 0.680234
Train epoch: 29 [332420/20036 (50%)]	Loss: 0.333370
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 30 [0/20036 (0%)]	Loss: 0.332446
Train epoch: 30 [328240/20036 (50%)]	Loss: 0.293756
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 31 [0/20036 (0%)]	Loss: 0.278347
Train epoch: 31 [322860/20036 (50%)]	Loss: 0.348101
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 32 [0/20036 (0%)]	Loss: 0.292441
Train epoch: 32 [329560/20036 (50%)]	Loss: 0.368100
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 33 [0/20036 (0%)]	Loss: 0.367977
Train epoch: 33 [323840/20036 (50%)]	Loss: 0.322162
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 34 [0/20036 (0%)]	Loss: 0.330498
Train epoch: 34 [328320/20036 (50%)]	Loss: 0.387367
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 35 [0/20036 (0%)]	Loss: 0.316259
Train epoch: 35 [326260/20036 (50%)]	Loss: 0.311657
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 36 [0/20036 (0%)]	Loss: 0.277495
Train epoch: 36 [327580/20036 (50%)]	Loss: 0.324158
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 37 [0/20036 (0%)]	Loss: 0.309480
Train epoch: 37 [333500/20036 (50%)]	Loss: 0.266885
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 38 [0/20036 (0%)]	Loss: 0.256380
Train epoch: 38 [328320/20036 (50%)]	Loss: 0.315987
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 39 [0/20036 (0%)]	Loss: 0.371598
Train epoch: 39 [325080/20036 (50%)]	Loss: 0.275360
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 40 [0/20036 (0%)]	Loss: 0.303266
Train epoch: 40 [333940/20036 (50%)]	Loss: 0.288261
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 41 [0/20036 (0%)]	Loss: 0.258670
Train epoch: 41 [328440/20036 (50%)]	Loss: 0.268332
predicting for valid data
Make prediction for 5010 samples...
0.3569777 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3569777 0.8426766918352635 GINConvNet davis
Training on 20036 samples...
Train epoch: 42 [0/20036 (0%)]	Loss: 0.262873
Train epoch: 42 [330940/20036 (50%)]	Loss: 0.295268
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 43 [0/20036 (0%)]	Loss: 0.386690
Train epoch: 43 [329000/20036 (50%)]	Loss: 0.269608
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 44 [0/20036 (0%)]	Loss: 0.240845
Train epoch: 44 [326060/20036 (50%)]	Loss: 0.225884
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 45 [0/20036 (0%)]	Loss: 0.268515
Train epoch: 45 [324700/20036 (50%)]	Loss: 0.300651
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 46 [0/20036 (0%)]	Loss: 0.319443
Train epoch: 46 [325260/20036 (50%)]	Loss: 0.262783
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 47 [0/20036 (0%)]	Loss: 0.372700
Train epoch: 47 [329040/20036 (50%)]	Loss: 0.320270
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 48 [0/20036 (0%)]	Loss: 0.246123
Train epoch: 48 [330360/20036 (50%)]	Loss: 0.228976
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 49 [0/20036 (0%)]	Loss: 0.224450
Train epoch: 49 [329420/20036 (50%)]	Loss: 0.260750
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 50 [0/20036 (0%)]	Loss: 0.240293
Train epoch: 50 [331860/20036 (50%)]	Loss: 0.254310
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 51 [0/20036 (0%)]	Loss: 0.233222
Train epoch: 51 [324840/20036 (50%)]	Loss: 0.265625
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 52 [0/20036 (0%)]	Loss: 0.232435
Train epoch: 52 [328560/20036 (50%)]	Loss: 0.271564
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 53 [0/20036 (0%)]	Loss: 0.234296
Train epoch: 53 [329700/20036 (50%)]	Loss: 0.278109
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 54 [0/20036 (0%)]	Loss: 0.241188
Train epoch: 54 [325680/20036 (50%)]	Loss: 0.246727
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 55 [0/20036 (0%)]	Loss: 0.255601
Train epoch: 55 [329280/20036 (50%)]	Loss: 0.217544
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 56 [0/20036 (0%)]	Loss: 0.234183
Train epoch: 56 [332180/20036 (50%)]	Loss: 0.262479
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 57 [0/20036 (0%)]	Loss: 0.225969
Train epoch: 57 [328080/20036 (50%)]	Loss: 0.273436
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 58 [0/20036 (0%)]	Loss: 0.252632
Train epoch: 58 [325560/20036 (50%)]	Loss: 0.232867
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 59 [0/20036 (0%)]	Loss: 0.191928
Train epoch: 59 [324760/20036 (50%)]	Loss: 0.312205
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 60 [0/20036 (0%)]	Loss: 0.246480
Train epoch: 60 [324100/20036 (50%)]	Loss: 0.259139
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 61 [0/20036 (0%)]	Loss: 0.197109
Train epoch: 61 [328660/20036 (50%)]	Loss: 0.205978
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 62 [0/20036 (0%)]	Loss: 0.225129
Train epoch: 62 [332200/20036 (50%)]	Loss: 0.188383
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 63 [0/20036 (0%)]	Loss: 0.256328
Train epoch: 63 [326340/20036 (50%)]	Loss: 0.221297
predicting for valid data
Make prediction for 5010 samples...
0.32819426 No improvement since epoch  42 ; best_test_mse,best_test_ci: 0.32819426 0.845197814266568 GINConvNet davis
Training on 20036 samples...
Train epoch: 64 [0/20036 (0%)]	Loss: 0.212568
Train epoch: 64 [328680/20036 (50%)]	Loss: 0.280779
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 65 [0/20036 (0%)]	Loss: 0.258238
Train epoch: 65 [324160/20036 (50%)]	Loss: 0.309660
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 66 [0/20036 (0%)]	Loss: 0.211246
Train epoch: 66 [327140/20036 (50%)]	Loss: 0.216873
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 67 [0/20036 (0%)]	Loss: 0.251162
Train epoch: 67 [330060/20036 (50%)]	Loss: 0.260096
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 68 [0/20036 (0%)]	Loss: 0.235535
Train epoch: 68 [326560/20036 (50%)]	Loss: 0.208338
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 69 [0/20036 (0%)]	Loss: 0.249148
Train epoch: 69 [330420/20036 (50%)]	Loss: 0.208716
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 70 [0/20036 (0%)]	Loss: 0.239626
Train epoch: 70 [326620/20036 (50%)]	Loss: 0.198288
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 71 [0/20036 (0%)]	Loss: 0.219212
Train epoch: 71 [324620/20036 (50%)]	Loss: 0.214933
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 72 [0/20036 (0%)]	Loss: 0.206862
Train epoch: 72 [326500/20036 (50%)]	Loss: 0.203673
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 73 [0/20036 (0%)]	Loss: 0.206945
Train epoch: 73 [331320/20036 (50%)]	Loss: 0.203084
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 74 [0/20036 (0%)]	Loss: 0.350142
Train epoch: 74 [328180/20036 (50%)]	Loss: 0.231277
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 75 [0/20036 (0%)]	Loss: 0.207918
Train epoch: 75 [330820/20036 (50%)]	Loss: 0.186665
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 76 [0/20036 (0%)]	Loss: 0.231633
Train epoch: 76 [333660/20036 (50%)]	Loss: 0.242482
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 77 [0/20036 (0%)]	Loss: 0.188520
Train epoch: 77 [328760/20036 (50%)]	Loss: 0.197154
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 78 [0/20036 (0%)]	Loss: 0.187191
Train epoch: 78 [326540/20036 (50%)]	Loss: 0.206979
predicting for valid data
Make prediction for 5010 samples...
0.31357118 No improvement since epoch  64 ; best_test_mse,best_test_ci: 0.31357118 0.8621206466166358 GINConvNet davis
Training on 20036 samples...
Train epoch: 79 [0/20036 (0%)]	Loss: 0.180661
Train epoch: 79 [330040/20036 (50%)]	Loss: 0.197206
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  79 ; best_test_mse,best_test_ci: 0.30464017 0.8575633596362808 GINConvNet davis
Training on 20036 samples...
Train epoch: 80 [0/20036 (0%)]	Loss: 0.221810
Train epoch: 80 [329420/20036 (50%)]	Loss: 0.218435
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  80 ; best_test_mse,best_test_ci: 0.30069175 0.8581736729667032 GINConvNet davis
Training on 20036 samples...
Train epoch: 81 [0/20036 (0%)]	Loss: 0.280802
Train epoch: 81 [330260/20036 (50%)]	Loss: 0.215707
predicting for valid data
Make prediction for 5010 samples...
0.30069175 No improvement since epoch  80 ; best_test_mse,best_test_ci: 0.30069175 0.8581736729667032 GINConvNet davis
Training on 20036 samples...
Train epoch: 82 [0/20036 (0%)]	Loss: 0.227364
Train epoch: 82 [320680/20036 (50%)]	Loss: 0.185550
predicting for valid data
Make prediction for 5010 samples...
0.30069175 No improvement since epoch  80 ; best_test_mse,best_test_ci: 0.30069175 0.8581736729667032 GINConvNet davis
Training on 20036 samples...
Train epoch: 83 [0/20036 (0%)]	Loss: 0.257447
Train epoch: 83 [328280/20036 (50%)]	Loss: 0.207171
predicting for valid data
Make prediction for 5010 samples...
0.30069175 No improvement since epoch  80 ; best_test_mse,best_test_ci: 0.30069175 0.8581736729667032 GINConvNet davis
Training on 20036 samples...
Train epoch: 84 [0/20036 (0%)]	Loss: 0.200688
Train epoch: 84 [327360/20036 (50%)]	Loss: 0.194185
predicting for valid data
Make prediction for 5010 samples...
0.30069175 No improvement since epoch  80 ; best_test_mse,best_test_ci: 0.30069175 0.8581736729667032 GINConvNet davis
Training on 20036 samples...
Train epoch: 85 [0/20036 (0%)]	Loss: 0.235371
Train epoch: 85 [325120/20036 (50%)]	Loss: 0.206736
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 86 [0/20036 (0%)]	Loss: 0.263504
Train epoch: 86 [330660/20036 (50%)]	Loss: 0.184638
predicting for valid data
Make prediction for 5010 samples...
0.3045546 No improvement since epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 87 [0/20036 (0%)]	Loss: 0.153306
Train epoch: 87 [328600/20036 (50%)]	Loss: 0.352200
predicting for valid data
Make prediction for 5010 samples...
0.3045546 No improvement since epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 88 [0/20036 (0%)]	Loss: 0.186960
Train epoch: 88 [330660/20036 (50%)]	Loss: 0.240253
predicting for valid data
Make prediction for 5010 samples...
0.3045546 No improvement since epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 89 [0/20036 (0%)]	Loss: 0.200436
Train epoch: 89 [328680/20036 (50%)]	Loss: 0.224942
predicting for valid data
Make prediction for 5010 samples...
0.3045546 No improvement since epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 90 [0/20036 (0%)]	Loss: 0.304930
Train epoch: 90 [328160/20036 (50%)]	Loss: 0.216105
predicting for valid data
Make prediction for 5010 samples...
0.3045546 No improvement since epoch  85 ; best_test_mse,best_test_ci: 0.3045546 0.8573433558472842 GINConvNet davis
Training on 20036 samples...
Train epoch: 91 [0/20036 (0%)]	Loss: 0.197442
Train epoch: 91 [328800/20036 (50%)]	Loss: 0.164233
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 92 [0/20036 (0%)]	Loss: 0.214404
Train epoch: 92 [333200/20036 (50%)]	Loss: 0.206139
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 93 [0/20036 (0%)]	Loss: 0.185746
Train epoch: 93 [333760/20036 (50%)]	Loss: 0.204049
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 94 [0/20036 (0%)]	Loss: 0.170759
Train epoch: 94 [328080/20036 (50%)]	Loss: 0.188815
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 95 [0/20036 (0%)]	Loss: 0.176755
Train epoch: 95 [331740/20036 (50%)]	Loss: 0.173297
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 96 [0/20036 (0%)]	Loss: 0.247409
Train epoch: 96 [330120/20036 (50%)]	Loss: 0.210313
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 97 [0/20036 (0%)]	Loss: 0.206220
Train epoch: 97 [324960/20036 (50%)]	Loss: 0.180742
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 98 [0/20036 (0%)]	Loss: 0.190830
Train epoch: 98 [332040/20036 (50%)]	Loss: 0.150438
predicting for valid data
Make prediction for 5010 samples...
0.28909826 No improvement since epoch  91 ; best_test_mse,best_test_ci: 0.28909826 0.8701195800615459 GINConvNet davis
Training on 20036 samples...
Train epoch: 99 [0/20036 (0%)]	Loss: 0.206229
Train epoch: 99 [325300/20036 (50%)]	Loss: 0.170570
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 100 [0/20036 (0%)]	Loss: 0.190179
Train epoch: 100 [330500/20036 (50%)]	Loss: 0.136739
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 101 [0/20036 (0%)]	Loss: 0.194657
Train epoch: 101 [327820/20036 (50%)]	Loss: 0.205444
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 102 [0/20036 (0%)]	Loss: 0.328473
Train epoch: 102 [325780/20036 (50%)]	Loss: 0.160927
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 103 [0/20036 (0%)]	Loss: 0.176506
Train epoch: 103 [331600/20036 (50%)]	Loss: 0.236289
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 104 [0/20036 (0%)]	Loss: 0.187636
Train epoch: 104 [330420/20036 (50%)]	Loss: 0.286431
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 105 [0/20036 (0%)]	Loss: 0.244795
Train epoch: 105 [330360/20036 (50%)]	Loss: 0.193062
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 106 [0/20036 (0%)]	Loss: 0.192949
Train epoch: 106 [328340/20036 (50%)]	Loss: 0.269048
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 107 [0/20036 (0%)]	Loss: 0.179444
Train epoch: 107 [331840/20036 (50%)]	Loss: 0.169433
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 108 [0/20036 (0%)]	Loss: 0.162385
Train epoch: 108 [328720/20036 (50%)]	Loss: 0.212093
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 109 [0/20036 (0%)]	Loss: 0.188904
Train epoch: 109 [324600/20036 (50%)]	Loss: 0.175473
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 110 [0/20036 (0%)]	Loss: 0.177492
Train epoch: 110 [329980/20036 (50%)]	Loss: 0.234757
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 111 [0/20036 (0%)]	Loss: 0.206152
Train epoch: 111 [326460/20036 (50%)]	Loss: 0.183322
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 112 [0/20036 (0%)]	Loss: 0.198251
Train epoch: 112 [326020/20036 (50%)]	Loss: 0.226342
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 113 [0/20036 (0%)]	Loss: 0.326868
Train epoch: 113 [326660/20036 (50%)]	Loss: 0.188351
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 114 [0/20036 (0%)]	Loss: 0.189627
Train epoch: 114 [333880/20036 (50%)]	Loss: 0.178842
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 115 [0/20036 (0%)]	Loss: 0.176023
Train epoch: 115 [323980/20036 (50%)]	Loss: 0.168624
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 116 [0/20036 (0%)]	Loss: 0.195495
Train epoch: 116 [326140/20036 (50%)]	Loss: 0.178992
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 117 [0/20036 (0%)]	Loss: 0.139320
Train epoch: 117 [332840/20036 (50%)]	Loss: 0.173567
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 118 [0/20036 (0%)]	Loss: 0.185245
Train epoch: 118 [328040/20036 (50%)]	Loss: 0.205719
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 119 [0/20036 (0%)]	Loss: 0.160151
Train epoch: 119 [328480/20036 (50%)]	Loss: 0.168369
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 120 [0/20036 (0%)]	Loss: 0.283119
Train epoch: 120 [328180/20036 (50%)]	Loss: 0.202460
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 121 [0/20036 (0%)]	Loss: 0.168877
Train epoch: 121 [328120/20036 (50%)]	Loss: 0.169583
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 122 [0/20036 (0%)]	Loss: 0.161767
Train epoch: 122 [333400/20036 (50%)]	Loss: 0.170025
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 123 [0/20036 (0%)]	Loss: 0.164733
Train epoch: 123 [330520/20036 (50%)]	Loss: 0.215251
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 124 [0/20036 (0%)]	Loss: 0.204123
Train epoch: 124 [332500/20036 (50%)]	Loss: 0.193128
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 125 [0/20036 (0%)]	Loss: 0.192452
Train epoch: 125 [327280/20036 (50%)]	Loss: 0.180083
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 126 [0/20036 (0%)]	Loss: 0.134008
Train epoch: 126 [327600/20036 (50%)]	Loss: 0.167862
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 127 [0/20036 (0%)]	Loss: 0.146633
Train epoch: 127 [332540/20036 (50%)]	Loss: 0.204744
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 128 [0/20036 (0%)]	Loss: 0.179114
Train epoch: 128 [330400/20036 (50%)]	Loss: 0.165164
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 129 [0/20036 (0%)]	Loss: 0.140886
Train epoch: 129 [329540/20036 (50%)]	Loss: 0.156823
predicting for valid data
Make prediction for 5010 samples...
0.29012153 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.29012153 0.8631990710372555 GINConvNet davis
Training on 20036 samples...
Train epoch: 130 [0/20036 (0%)]	Loss: 0.195511
Train epoch: 130 [329920/20036 (50%)]	Loss: 0.178279
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  130 ; best_test_mse,best_test_ci: 0.27935335 0.8728446252530656 GINConvNet davis
Training on 20036 samples...
Train epoch: 131 [0/20036 (0%)]	Loss: 0.198907
Train epoch: 131 [326440/20036 (50%)]	Loss: 0.180854
predicting for valid data
Make prediction for 5010 samples...
0.27935335 No improvement since epoch  130 ; best_test_mse,best_test_ci: 0.27935335 0.8728446252530656 GINConvNet davis
Training on 20036 samples...
Train epoch: 132 [0/20036 (0%)]	Loss: 0.164092
Train epoch: 132 [326280/20036 (50%)]	Loss: 0.165886
predicting for valid data
Make prediction for 5010 samples...
0.27935335 No improvement since epoch  130 ; best_test_mse,best_test_ci: 0.27935335 0.8728446252530656 GINConvNet davis
Training on 20036 samples...
Train epoch: 133 [0/20036 (0%)]	Loss: 0.161722
Train epoch: 133 [328660/20036 (50%)]	Loss: 0.174139
predicting for valid data
Make prediction for 5010 samples...
0.27935335 No improvement since epoch  130 ; best_test_mse,best_test_ci: 0.27935335 0.8728446252530656 GINConvNet davis
Training on 20036 samples...
Train epoch: 134 [0/20036 (0%)]	Loss: 0.151971
Train epoch: 134 [335000/20036 (50%)]	Loss: 0.212702
predicting for valid data
Make prediction for 5010 samples...
0.27935335 No improvement since epoch  130 ; best_test_mse,best_test_ci: 0.27935335 0.8728446252530656 GINConvNet davis
Training on 20036 samples...
Train epoch: 135 [0/20036 (0%)]	Loss: 0.203463
Train epoch: 135 [329420/20036 (50%)]	Loss: 0.222460
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 136 [0/20036 (0%)]	Loss: 0.161691
Train epoch: 136 [327920/20036 (50%)]	Loss: 0.170335
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 137 [0/20036 (0%)]	Loss: 0.169758
Train epoch: 137 [325900/20036 (50%)]	Loss: 0.150732
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 138 [0/20036 (0%)]	Loss: 0.270543
Train epoch: 138 [326640/20036 (50%)]	Loss: 0.201143
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 139 [0/20036 (0%)]	Loss: 0.142052
Train epoch: 139 [326460/20036 (50%)]	Loss: 0.142442
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 140 [0/20036 (0%)]	Loss: 0.141202
Train epoch: 140 [332480/20036 (50%)]	Loss: 0.148648
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 141 [0/20036 (0%)]	Loss: 0.171509
Train epoch: 141 [333780/20036 (50%)]	Loss: 0.216353
predicting for valid data
Make prediction for 5010 samples...
0.2865733 No improvement since epoch  135 ; best_test_mse,best_test_ci: 0.2865733 0.8676470835982236 GINConvNet davis
Training on 20036 samples...
Train epoch: 142 [0/20036 (0%)]	Loss: 0.133579
Train epoch: 142 [326100/20036 (50%)]	Loss: 0.127315
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 143 [0/20036 (0%)]	Loss: 0.159394
Train epoch: 143 [324280/20036 (50%)]	Loss: 0.168948
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 144 [0/20036 (0%)]	Loss: 0.148090
Train epoch: 144 [329680/20036 (50%)]	Loss: 0.161241
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 145 [0/20036 (0%)]	Loss: 0.193849
Train epoch: 145 [327320/20036 (50%)]	Loss: 0.172943
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 146 [0/20036 (0%)]	Loss: 0.173450
Train epoch: 146 [324840/20036 (50%)]	Loss: 0.156518
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 147 [0/20036 (0%)]	Loss: 0.197190
Train epoch: 147 [328760/20036 (50%)]	Loss: 0.158117
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 148 [0/20036 (0%)]	Loss: 0.171297
Train epoch: 148 [329200/20036 (50%)]	Loss: 0.158910
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 149 [0/20036 (0%)]	Loss: 0.268246
Train epoch: 149 [333040/20036 (50%)]	Loss: 0.171467
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 150 [0/20036 (0%)]	Loss: 0.157899
Train epoch: 150 [325720/20036 (50%)]	Loss: 0.187158
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 151 [0/20036 (0%)]	Loss: 0.228419
Train epoch: 151 [329420/20036 (50%)]	Loss: 0.169354
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 152 [0/20036 (0%)]	Loss: 0.176795
Train epoch: 152 [328540/20036 (50%)]	Loss: 0.144851
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 153 [0/20036 (0%)]	Loss: 0.134752
Train epoch: 153 [322700/20036 (50%)]	Loss: 0.145694
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 154 [0/20036 (0%)]	Loss: 0.166901
Train epoch: 154 [327620/20036 (50%)]	Loss: 0.157209
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 155 [0/20036 (0%)]	Loss: 0.135391
Train epoch: 155 [327580/20036 (50%)]	Loss: 0.238748
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 156 [0/20036 (0%)]	Loss: 0.138667
Train epoch: 156 [326080/20036 (50%)]	Loss: 0.170661
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 157 [0/20036 (0%)]	Loss: 0.148596
Train epoch: 157 [328500/20036 (50%)]	Loss: 0.176467
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 158 [0/20036 (0%)]	Loss: 0.154959
Train epoch: 158 [331020/20036 (50%)]	Loss: 0.182044
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 159 [0/20036 (0%)]	Loss: 0.210138
Train epoch: 159 [329160/20036 (50%)]	Loss: 0.176170
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 160 [0/20036 (0%)]	Loss: 0.182155
Train epoch: 160 [325740/20036 (50%)]	Loss: 0.148153
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 161 [0/20036 (0%)]	Loss: 0.119546
Train epoch: 161 [326680/20036 (50%)]	Loss: 0.161024
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 162 [0/20036 (0%)]	Loss: 0.225990
Train epoch: 162 [329940/20036 (50%)]	Loss: 0.150880
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 163 [0/20036 (0%)]	Loss: 0.164724
Train epoch: 163 [326260/20036 (50%)]	Loss: 0.147233
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 164 [0/20036 (0%)]	Loss: 0.177971
Train epoch: 164 [327780/20036 (50%)]	Loss: 0.148015
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 165 [0/20036 (0%)]	Loss: 0.160581
Train epoch: 165 [326720/20036 (50%)]	Loss: 0.182209
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 166 [0/20036 (0%)]	Loss: 0.164134
Train epoch: 166 [330540/20036 (50%)]	Loss: 0.169289
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 167 [0/20036 (0%)]	Loss: 0.152053
Train epoch: 167 [325820/20036 (50%)]	Loss: 0.184760
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 168 [0/20036 (0%)]	Loss: 0.126427
Train epoch: 168 [328280/20036 (50%)]	Loss: 0.154727
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 169 [0/20036 (0%)]	Loss: 0.178397
Train epoch: 169 [324720/20036 (50%)]	Loss: 0.163690
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 170 [0/20036 (0%)]	Loss: 0.162793
Train epoch: 170 [334320/20036 (50%)]	Loss: 0.133250
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 171 [0/20036 (0%)]	Loss: 0.167151
Train epoch: 171 [328680/20036 (50%)]	Loss: 0.156177
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 172 [0/20036 (0%)]	Loss: 0.134741
Train epoch: 172 [332460/20036 (50%)]	Loss: 0.132800
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 173 [0/20036 (0%)]	Loss: 0.115398
Train epoch: 173 [328360/20036 (50%)]	Loss: 0.158919
predicting for valid data
Make prediction for 5010 samples...
0.27937895 No improvement since epoch  142 ; best_test_mse,best_test_ci: 0.27937895 0.8693281637165126 GINConvNet davis
Training on 20036 samples...
Train epoch: 174 [0/20036 (0%)]	Loss: 0.187578
Train epoch: 174 [329400/20036 (50%)]	Loss: 0.169238
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 175 [0/20036 (0%)]	Loss: 0.147439
Train epoch: 175 [327380/20036 (50%)]	Loss: 0.184408
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 176 [0/20036 (0%)]	Loss: 0.140919
Train epoch: 176 [330060/20036 (50%)]	Loss: 0.163328
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 177 [0/20036 (0%)]	Loss: 0.144875
Train epoch: 177 [329680/20036 (50%)]	Loss: 0.141441
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 178 [0/20036 (0%)]	Loss: 0.143032
Train epoch: 178 [325980/20036 (50%)]	Loss: 0.148603
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 179 [0/20036 (0%)]	Loss: 0.157083
Train epoch: 179 [324820/20036 (50%)]	Loss: 0.163309
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 180 [0/20036 (0%)]	Loss: 0.178150
Train epoch: 180 [329960/20036 (50%)]	Loss: 0.183603
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 181 [0/20036 (0%)]	Loss: 0.214017
Train epoch: 181 [326320/20036 (50%)]	Loss: 0.169432
predicting for valid data
Make prediction for 5010 samples...
0.27457258 No improvement since epoch  174 ; best_test_mse,best_test_ci: 0.27457258 0.8759487232658639 GINConvNet davis
Training on 20036 samples...
Train epoch: 182 [0/20036 (0%)]	Loss: 0.132466
Train epoch: 182 [332740/20036 (50%)]	Loss: 0.164052
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 183 [0/20036 (0%)]	Loss: 0.165055
Train epoch: 183 [326900/20036 (50%)]	Loss: 0.182369
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 184 [0/20036 (0%)]	Loss: 0.222239
Train epoch: 184 [330180/20036 (50%)]	Loss: 0.173259
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 185 [0/20036 (0%)]	Loss: 0.183394
Train epoch: 185 [328300/20036 (50%)]	Loss: 0.137620
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 186 [0/20036 (0%)]	Loss: 0.224833
Train epoch: 186 [331540/20036 (50%)]	Loss: 0.153844
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 187 [0/20036 (0%)]	Loss: 0.142591
Train epoch: 187 [328440/20036 (50%)]	Loss: 0.181839
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 188 [0/20036 (0%)]	Loss: 0.165014
Train epoch: 188 [332820/20036 (50%)]	Loss: 0.163561
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 189 [0/20036 (0%)]	Loss: 0.173230
Train epoch: 189 [328960/20036 (50%)]	Loss: 0.168454
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 190 [0/20036 (0%)]	Loss: 0.165544
Train epoch: 190 [335500/20036 (50%)]	Loss: 0.202351
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 191 [0/20036 (0%)]	Loss: 0.174205
Train epoch: 191 [327600/20036 (50%)]	Loss: 0.114869
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 192 [0/20036 (0%)]	Loss: 0.137532
Train epoch: 192 [325940/20036 (50%)]	Loss: 0.160165
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 193 [0/20036 (0%)]	Loss: 0.178062
Train epoch: 193 [327220/20036 (50%)]	Loss: 0.163093
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 194 [0/20036 (0%)]	Loss: 0.161057
Train epoch: 194 [330280/20036 (50%)]	Loss: 0.128379
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 195 [0/20036 (0%)]	Loss: 0.118936
Train epoch: 195 [330700/20036 (50%)]	Loss: 0.151235
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 196 [0/20036 (0%)]	Loss: 0.152993
Train epoch: 196 [327560/20036 (50%)]	Loss: 0.193643
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 197 [0/20036 (0%)]	Loss: 0.128193
Train epoch: 197 [328500/20036 (50%)]	Loss: 0.138173
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 198 [0/20036 (0%)]	Loss: 0.115812
Train epoch: 198 [327120/20036 (50%)]	Loss: 0.111815
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 199 [0/20036 (0%)]	Loss: 0.170725
Train epoch: 199 [326420/20036 (50%)]	Loss: 0.143772
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 200 [0/20036 (0%)]	Loss: 0.145618
Train epoch: 200 [327140/20036 (50%)]	Loss: 0.145414
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 201 [0/20036 (0%)]	Loss: 0.114611
Train epoch: 201 [333540/20036 (50%)]	Loss: 0.153190
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 202 [0/20036 (0%)]	Loss: 0.151955
Train epoch: 202 [331440/20036 (50%)]	Loss: 0.142112
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 203 [0/20036 (0%)]	Loss: 0.122287
Train epoch: 203 [325300/20036 (50%)]	Loss: 0.147413
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 204 [0/20036 (0%)]	Loss: 0.188453
Train epoch: 204 [327920/20036 (50%)]	Loss: 0.141593
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 205 [0/20036 (0%)]	Loss: 0.243996
Train epoch: 205 [330600/20036 (50%)]	Loss: 0.140708
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 206 [0/20036 (0%)]	Loss: 0.138389
Train epoch: 206 [327520/20036 (50%)]	Loss: 0.166074
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 207 [0/20036 (0%)]	Loss: 0.158838
Train epoch: 207 [331000/20036 (50%)]	Loss: 0.161872
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 208 [0/20036 (0%)]	Loss: 0.154418
Train epoch: 208 [327360/20036 (50%)]	Loss: 0.162115
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 209 [0/20036 (0%)]	Loss: 0.127659
Train epoch: 209 [327320/20036 (50%)]	Loss: 0.157028
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 210 [0/20036 (0%)]	Loss: 0.184067
Train epoch: 210 [328640/20036 (50%)]	Loss: 0.152021
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 211 [0/20036 (0%)]	Loss: 0.140087
Train epoch: 211 [325700/20036 (50%)]	Loss: 0.170387
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 212 [0/20036 (0%)]	Loss: 0.188746
Train epoch: 212 [327080/20036 (50%)]	Loss: 0.136769
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 213 [0/20036 (0%)]	Loss: 0.162843
Train epoch: 213 [328140/20036 (50%)]	Loss: 0.196049
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 214 [0/20036 (0%)]	Loss: 0.150987
Train epoch: 214 [332000/20036 (50%)]	Loss: 0.119281
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 215 [0/20036 (0%)]	Loss: 0.125247
Train epoch: 215 [327060/20036 (50%)]	Loss: 0.127865
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 216 [0/20036 (0%)]	Loss: 0.134456
Train epoch: 216 [328060/20036 (50%)]	Loss: 0.160645
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 217 [0/20036 (0%)]	Loss: 0.136419
Train epoch: 217 [327360/20036 (50%)]	Loss: 0.135137
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 218 [0/20036 (0%)]	Loss: 0.155545
Train epoch: 218 [331820/20036 (50%)]	Loss: 0.138332
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 219 [0/20036 (0%)]	Loss: 0.165415
Train epoch: 219 [329140/20036 (50%)]	Loss: 0.154322
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 220 [0/20036 (0%)]	Loss: 0.116258
Train epoch: 220 [325140/20036 (50%)]	Loss: 0.142031
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 221 [0/20036 (0%)]	Loss: 0.130229
Train epoch: 221 [327980/20036 (50%)]	Loss: 0.157315
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 222 [0/20036 (0%)]	Loss: 0.139234
Train epoch: 222 [327220/20036 (50%)]	Loss: 0.174281
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 223 [0/20036 (0%)]	Loss: 0.123201
Train epoch: 223 [328840/20036 (50%)]	Loss: 0.145410
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 224 [0/20036 (0%)]	Loss: 0.146208
Train epoch: 224 [331300/20036 (50%)]	Loss: 0.134861
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 225 [0/20036 (0%)]	Loss: 0.150285
Train epoch: 225 [328260/20036 (50%)]	Loss: 0.110533
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 226 [0/20036 (0%)]	Loss: 0.158495
Train epoch: 226 [326320/20036 (50%)]	Loss: 0.157790
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 227 [0/20036 (0%)]	Loss: 0.189123
Train epoch: 227 [328060/20036 (50%)]	Loss: 0.138143
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 228 [0/20036 (0%)]	Loss: 0.181071
Train epoch: 228 [327020/20036 (50%)]	Loss: 0.151302
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 229 [0/20036 (0%)]	Loss: 0.119147
Train epoch: 229 [328560/20036 (50%)]	Loss: 0.133530
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 230 [0/20036 (0%)]	Loss: 0.140073
Train epoch: 230 [326900/20036 (50%)]	Loss: 0.130950
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 231 [0/20036 (0%)]	Loss: 0.134284
Train epoch: 231 [331180/20036 (50%)]	Loss: 0.119824
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 232 [0/20036 (0%)]	Loss: 0.155400
Train epoch: 232 [330340/20036 (50%)]	Loss: 0.140259
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 233 [0/20036 (0%)]	Loss: 0.121337
Train epoch: 233 [333600/20036 (50%)]	Loss: 0.146875
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 234 [0/20036 (0%)]	Loss: 0.132452
Train epoch: 234 [328700/20036 (50%)]	Loss: 0.147784
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 235 [0/20036 (0%)]	Loss: 0.260524
Train epoch: 235 [331560/20036 (50%)]	Loss: 0.156514
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 236 [0/20036 (0%)]	Loss: 0.140034
Train epoch: 236 [324580/20036 (50%)]	Loss: 0.146586
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 237 [0/20036 (0%)]	Loss: 0.164126
Train epoch: 237 [326740/20036 (50%)]	Loss: 0.133870
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 238 [0/20036 (0%)]	Loss: 0.111455
Train epoch: 238 [327380/20036 (50%)]	Loss: 0.161509
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 239 [0/20036 (0%)]	Loss: 0.105461
Train epoch: 239 [327460/20036 (50%)]	Loss: 0.142246
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 240 [0/20036 (0%)]	Loss: 0.125952
Train epoch: 240 [322260/20036 (50%)]	Loss: 0.126556
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 241 [0/20036 (0%)]	Loss: 0.175836
Train epoch: 241 [326720/20036 (50%)]	Loss: 0.141491
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 242 [0/20036 (0%)]	Loss: 0.114695
Train epoch: 242 [330420/20036 (50%)]	Loss: 0.157016
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 243 [0/20036 (0%)]	Loss: 0.183010
Train epoch: 243 [321780/20036 (50%)]	Loss: 0.131881
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 244 [0/20036 (0%)]	Loss: 0.130360
Train epoch: 244 [328920/20036 (50%)]	Loss: 0.137365
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 245 [0/20036 (0%)]	Loss: 0.147963
Train epoch: 245 [325100/20036 (50%)]	Loss: 0.130117
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 246 [0/20036 (0%)]	Loss: 0.108108
Train epoch: 246 [332560/20036 (50%)]	Loss: 0.117732
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 247 [0/20036 (0%)]	Loss: 0.130029
Train epoch: 247 [324920/20036 (50%)]	Loss: 0.186345
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 248 [0/20036 (0%)]	Loss: 0.135832
Train epoch: 248 [334120/20036 (50%)]	Loss: 0.137735
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 249 [0/20036 (0%)]	Loss: 0.117150
Train epoch: 249 [326900/20036 (50%)]	Loss: 0.146705
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 250 [0/20036 (0%)]	Loss: 0.143864
Train epoch: 250 [334600/20036 (50%)]	Loss: 0.122897
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 251 [0/20036 (0%)]	Loss: 0.183305
Train epoch: 251 [330680/20036 (50%)]	Loss: 0.155055
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 252 [0/20036 (0%)]	Loss: 0.124559
Train epoch: 252 [327720/20036 (50%)]	Loss: 0.119166
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 253 [0/20036 (0%)]	Loss: 0.107164
Train epoch: 253 [326220/20036 (50%)]	Loss: 0.134002
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 254 [0/20036 (0%)]	Loss: 0.140894
Train epoch: 254 [327180/20036 (50%)]	Loss: 0.104360
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 255 [0/20036 (0%)]	Loss: 0.114592
Train epoch: 255 [326300/20036 (50%)]	Loss: 0.114077
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 256 [0/20036 (0%)]	Loss: 0.135804
Train epoch: 256 [329900/20036 (50%)]	Loss: 0.096947
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 257 [0/20036 (0%)]	Loss: 0.141335
Train epoch: 257 [328040/20036 (50%)]	Loss: 0.127027
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 258 [0/20036 (0%)]	Loss: 0.135005
Train epoch: 258 [332040/20036 (50%)]	Loss: 0.116131
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 259 [0/20036 (0%)]	Loss: 0.175502
Train epoch: 259 [326400/20036 (50%)]	Loss: 0.138510
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 260 [0/20036 (0%)]	Loss: 0.123160
Train epoch: 260 [328580/20036 (50%)]	Loss: 0.141674
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 261 [0/20036 (0%)]	Loss: 0.110107
Train epoch: 261 [330140/20036 (50%)]	Loss: 0.155708
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 262 [0/20036 (0%)]	Loss: 0.126337
Train epoch: 262 [330500/20036 (50%)]	Loss: 0.154451
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 263 [0/20036 (0%)]	Loss: 0.165497
Train epoch: 263 [329400/20036 (50%)]	Loss: 0.126427
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 264 [0/20036 (0%)]	Loss: 0.122766
Train epoch: 264 [330200/20036 (50%)]	Loss: 0.121571
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 265 [0/20036 (0%)]	Loss: 0.156597
Train epoch: 265 [327520/20036 (50%)]	Loss: 0.146464
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 266 [0/20036 (0%)]	Loss: 0.135917
Train epoch: 266 [330240/20036 (50%)]	Loss: 0.149214
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 267 [0/20036 (0%)]	Loss: 0.141428
Train epoch: 267 [330640/20036 (50%)]	Loss: 0.147261
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 268 [0/20036 (0%)]	Loss: 0.167910
Train epoch: 268 [331520/20036 (50%)]	Loss: 0.148446
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 269 [0/20036 (0%)]	Loss: 0.140421
Train epoch: 269 [323220/20036 (50%)]	Loss: 0.122169
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 270 [0/20036 (0%)]	Loss: 0.128008
Train epoch: 270 [326940/20036 (50%)]	Loss: 0.140508
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 271 [0/20036 (0%)]	Loss: 0.136370
Train epoch: 271 [334480/20036 (50%)]	Loss: 0.141870
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 272 [0/20036 (0%)]	Loss: 0.156302
Train epoch: 272 [326980/20036 (50%)]	Loss: 0.110885
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 273 [0/20036 (0%)]	Loss: 0.143613
Train epoch: 273 [332900/20036 (50%)]	Loss: 0.160101
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 274 [0/20036 (0%)]	Loss: 0.105221
Train epoch: 274 [335720/20036 (50%)]	Loss: 0.120011
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 275 [0/20036 (0%)]	Loss: 0.116646
Train epoch: 275 [327560/20036 (50%)]	Loss: 0.120207
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 276 [0/20036 (0%)]	Loss: 0.104264
Train epoch: 276 [334320/20036 (50%)]	Loss: 0.142212
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 277 [0/20036 (0%)]	Loss: 0.124597
Train epoch: 277 [337120/20036 (50%)]	Loss: 0.126019
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 278 [0/20036 (0%)]	Loss: 0.112833
Train epoch: 278 [327180/20036 (50%)]	Loss: 0.129829
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 279 [0/20036 (0%)]	Loss: 0.118379
Train epoch: 279 [328140/20036 (50%)]	Loss: 0.141475
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 280 [0/20036 (0%)]	Loss: 0.150400
Train epoch: 280 [332080/20036 (50%)]	Loss: 0.127865
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 281 [0/20036 (0%)]	Loss: 0.189695
Train epoch: 281 [328840/20036 (50%)]	Loss: 0.113450
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 282 [0/20036 (0%)]	Loss: 0.189749
Train epoch: 282 [329600/20036 (50%)]	Loss: 0.148119
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 283 [0/20036 (0%)]	Loss: 0.158455
Train epoch: 283 [329300/20036 (50%)]	Loss: 0.112278
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 284 [0/20036 (0%)]	Loss: 0.130534
Train epoch: 284 [327760/20036 (50%)]	Loss: 0.149065
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 285 [0/20036 (0%)]	Loss: 0.133901
Train epoch: 285 [328000/20036 (50%)]	Loss: 0.131854
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 286 [0/20036 (0%)]	Loss: 0.115467
Train epoch: 286 [330320/20036 (50%)]	Loss: 0.144335
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 287 [0/20036 (0%)]	Loss: 0.109047
Train epoch: 287 [325720/20036 (50%)]	Loss: 0.126735
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 288 [0/20036 (0%)]	Loss: 0.158603
Train epoch: 288 [330940/20036 (50%)]	Loss: 0.142115
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 289 [0/20036 (0%)]	Loss: 0.135577
Train epoch: 289 [327040/20036 (50%)]	Loss: 0.153350
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 290 [0/20036 (0%)]	Loss: 0.199430
Train epoch: 290 [325220/20036 (50%)]	Loss: 0.147947
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 291 [0/20036 (0%)]	Loss: 0.145136
Train epoch: 291 [328600/20036 (50%)]	Loss: 0.130672
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 292 [0/20036 (0%)]	Loss: 0.178861
Train epoch: 292 [329280/20036 (50%)]	Loss: 0.148197
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 293 [0/20036 (0%)]	Loss: 0.088051
Train epoch: 293 [333640/20036 (50%)]	Loss: 0.170044
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 294 [0/20036 (0%)]	Loss: 0.127929
Train epoch: 294 [322380/20036 (50%)]	Loss: 0.129478
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 295 [0/20036 (0%)]	Loss: 0.145597
Train epoch: 295 [332220/20036 (50%)]	Loss: 0.119657
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 296 [0/20036 (0%)]	Loss: 0.138279
Train epoch: 296 [330060/20036 (50%)]	Loss: 0.131212
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 297 [0/20036 (0%)]	Loss: 0.134764
Train epoch: 297 [332300/20036 (50%)]	Loss: 0.128048
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 298 [0/20036 (0%)]	Loss: 0.110071
Train epoch: 298 [324340/20036 (50%)]	Loss: 0.132467
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 299 [0/20036 (0%)]	Loss: 0.233640
Train epoch: 299 [325700/20036 (50%)]	Loss: 0.177926
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 300 [0/20036 (0%)]	Loss: 0.117342
Train epoch: 300 [323160/20036 (50%)]	Loss: 0.145441
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 301 [0/20036 (0%)]	Loss: 0.117748
Train epoch: 301 [328540/20036 (50%)]	Loss: 0.132673
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 302 [0/20036 (0%)]	Loss: 0.229365
Train epoch: 302 [325760/20036 (50%)]	Loss: 0.148747
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 303 [0/20036 (0%)]	Loss: 0.129618
Train epoch: 303 [326060/20036 (50%)]	Loss: 0.171183
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 304 [0/20036 (0%)]	Loss: 0.153529
Train epoch: 304 [328960/20036 (50%)]	Loss: 0.112715
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 305 [0/20036 (0%)]	Loss: 0.114439
Train epoch: 305 [326900/20036 (50%)]	Loss: 0.131346
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 306 [0/20036 (0%)]	Loss: 0.150288
Train epoch: 306 [331760/20036 (50%)]	Loss: 0.123875
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 307 [0/20036 (0%)]	Loss: 0.135310
Train epoch: 307 [326420/20036 (50%)]	Loss: 0.102580
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 308 [0/20036 (0%)]	Loss: 0.133007
Train epoch: 308 [333720/20036 (50%)]	Loss: 0.122798
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 309 [0/20036 (0%)]	Loss: 0.085619
Train epoch: 309 [329560/20036 (50%)]	Loss: 0.128816
predicting for valid data
Make prediction for 5010 samples...
0.2730887 No improvement since epoch  182 ; best_test_mse,best_test_ci: 0.2730887 0.8764790909103439 GINConvNet davis
Training on 20036 samples...
Train epoch: 310 [0/20036 (0%)]	Loss: 0.140757
Train epoch: 310 [325800/20036 (50%)]	Loss: 0.138145
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 311 [0/20036 (0%)]	Loss: 0.100415
Train epoch: 311 [328480/20036 (50%)]	Loss: 0.158474
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 312 [0/20036 (0%)]	Loss: 0.284807
Train epoch: 312 [327760/20036 (50%)]	Loss: 0.129420
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 313 [0/20036 (0%)]	Loss: 0.117597
Train epoch: 313 [329860/20036 (50%)]	Loss: 0.115405
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 314 [0/20036 (0%)]	Loss: 0.121201
Train epoch: 314 [328960/20036 (50%)]	Loss: 0.131533
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 315 [0/20036 (0%)]	Loss: 0.113655
Train epoch: 315 [324580/20036 (50%)]	Loss: 0.112299
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 316 [0/20036 (0%)]	Loss: 0.097041
Train epoch: 316 [326120/20036 (50%)]	Loss: 0.131909
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 317 [0/20036 (0%)]	Loss: 0.100861
Train epoch: 317 [332300/20036 (50%)]	Loss: 0.106080
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 318 [0/20036 (0%)]	Loss: 0.106372
Train epoch: 318 [327600/20036 (50%)]	Loss: 0.155503
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 319 [0/20036 (0%)]	Loss: 0.104777
Train epoch: 319 [327820/20036 (50%)]	Loss: 0.173012
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 320 [0/20036 (0%)]	Loss: 0.111538
Train epoch: 320 [330860/20036 (50%)]	Loss: 0.122669
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 321 [0/20036 (0%)]	Loss: 0.133974
Train epoch: 321 [323360/20036 (50%)]	Loss: 0.140175
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 322 [0/20036 (0%)]	Loss: 0.150313
Train epoch: 322 [326220/20036 (50%)]	Loss: 0.121098
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 323 [0/20036 (0%)]	Loss: 0.179529
Train epoch: 323 [327140/20036 (50%)]	Loss: 0.131677
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 324 [0/20036 (0%)]	Loss: 0.153166
Train epoch: 324 [328660/20036 (50%)]	Loss: 0.135915
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 325 [0/20036 (0%)]	Loss: 0.154906
Train epoch: 325 [331640/20036 (50%)]	Loss: 0.146383
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 326 [0/20036 (0%)]	Loss: 0.100017
Train epoch: 326 [328940/20036 (50%)]	Loss: 0.157105
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 327 [0/20036 (0%)]	Loss: 0.098289
Train epoch: 327 [324960/20036 (50%)]	Loss: 0.101855
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 328 [0/20036 (0%)]	Loss: 0.146927
Train epoch: 328 [332860/20036 (50%)]	Loss: 0.124971
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 329 [0/20036 (0%)]	Loss: 0.102113
Train epoch: 329 [325980/20036 (50%)]	Loss: 0.149561
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 330 [0/20036 (0%)]	Loss: 0.158731
Train epoch: 330 [330520/20036 (50%)]	Loss: 0.110064
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 331 [0/20036 (0%)]	Loss: 0.133406
Train epoch: 331 [326520/20036 (50%)]	Loss: 0.122037
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 332 [0/20036 (0%)]	Loss: 0.130568
Train epoch: 332 [326560/20036 (50%)]	Loss: 0.133819
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 333 [0/20036 (0%)]	Loss: 0.160986
Train epoch: 333 [328440/20036 (50%)]	Loss: 0.144918
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 334 [0/20036 (0%)]	Loss: 0.168400
Train epoch: 334 [325980/20036 (50%)]	Loss: 0.131602
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 335 [0/20036 (0%)]	Loss: 0.161192
Train epoch: 335 [327120/20036 (50%)]	Loss: 0.116316
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 336 [0/20036 (0%)]	Loss: 0.160423
Train epoch: 336 [330080/20036 (50%)]	Loss: 0.148034
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 337 [0/20036 (0%)]	Loss: 0.124882
Train epoch: 337 [329460/20036 (50%)]	Loss: 0.143269
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 338 [0/20036 (0%)]	Loss: 0.111804
Train epoch: 338 [323960/20036 (50%)]	Loss: 0.108830
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 339 [0/20036 (0%)]	Loss: 0.113043
Train epoch: 339 [327360/20036 (50%)]	Loss: 0.119005
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 340 [0/20036 (0%)]	Loss: 0.109555
Train epoch: 340 [329460/20036 (50%)]	Loss: 0.113294
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 341 [0/20036 (0%)]	Loss: 0.093656
Train epoch: 341 [324100/20036 (50%)]	Loss: 0.111259
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 342 [0/20036 (0%)]	Loss: 0.133678
Train epoch: 342 [329140/20036 (50%)]	Loss: 0.154730
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 343 [0/20036 (0%)]	Loss: 0.099125
Train epoch: 343 [329360/20036 (50%)]	Loss: 0.132239
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 344 [0/20036 (0%)]	Loss: 0.113877
Train epoch: 344 [329180/20036 (50%)]	Loss: 0.136247
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 345 [0/20036 (0%)]	Loss: 0.124498
Train epoch: 345 [330060/20036 (50%)]	Loss: 0.134181
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 346 [0/20036 (0%)]	Loss: 0.130246
Train epoch: 346 [326420/20036 (50%)]	Loss: 0.112363
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 347 [0/20036 (0%)]	Loss: 0.107758
Train epoch: 347 [326420/20036 (50%)]	Loss: 0.136353
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 348 [0/20036 (0%)]	Loss: 0.105844
Train epoch: 348 [325540/20036 (50%)]	Loss: 0.127374
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 349 [0/20036 (0%)]	Loss: 0.091491
Train epoch: 349 [329320/20036 (50%)]	Loss: 0.095400
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 350 [0/20036 (0%)]	Loss: 0.144457
Train epoch: 350 [326080/20036 (50%)]	Loss: 0.103953
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 351 [0/20036 (0%)]	Loss: 0.118473
Train epoch: 351 [329420/20036 (50%)]	Loss: 0.119384
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 352 [0/20036 (0%)]	Loss: 0.172681
Train epoch: 352 [329660/20036 (50%)]	Loss: 0.106020
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 353 [0/20036 (0%)]	Loss: 0.112732
Train epoch: 353 [328420/20036 (50%)]	Loss: 0.118959
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 354 [0/20036 (0%)]	Loss: 0.128100
Train epoch: 354 [330380/20036 (50%)]	Loss: 0.128772
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 355 [0/20036 (0%)]	Loss: 0.140722
Train epoch: 355 [326880/20036 (50%)]	Loss: 0.133079
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 356 [0/20036 (0%)]	Loss: 0.138315
Train epoch: 356 [327900/20036 (50%)]	Loss: 0.105353
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 357 [0/20036 (0%)]	Loss: 0.124287
Train epoch: 357 [329560/20036 (50%)]	Loss: 0.130417
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 358 [0/20036 (0%)]	Loss: 0.180696
Train epoch: 358 [329180/20036 (50%)]	Loss: 0.111790
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 359 [0/20036 (0%)]	Loss: 0.134873
Train epoch: 359 [327620/20036 (50%)]	Loss: 0.095282
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 360 [0/20036 (0%)]	Loss: 0.131526
Train epoch: 360 [328140/20036 (50%)]	Loss: 0.143483
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 361 [0/20036 (0%)]	Loss: 0.108021
Train epoch: 361 [324780/20036 (50%)]	Loss: 0.117355
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 362 [0/20036 (0%)]	Loss: 0.124921
Train epoch: 362 [330660/20036 (50%)]	Loss: 0.122013
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 363 [0/20036 (0%)]	Loss: 0.103313
Train epoch: 363 [329440/20036 (50%)]	Loss: 0.117471
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 364 [0/20036 (0%)]	Loss: 0.194181
Train epoch: 364 [326560/20036 (50%)]	Loss: 0.136105
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 365 [0/20036 (0%)]	Loss: 0.114325
Train epoch: 365 [328160/20036 (50%)]	Loss: 0.119238
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 366 [0/20036 (0%)]	Loss: 0.131905
Train epoch: 366 [326700/20036 (50%)]	Loss: 0.111239
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 367 [0/20036 (0%)]	Loss: 0.129215
Train epoch: 367 [329200/20036 (50%)]	Loss: 0.134200
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 368 [0/20036 (0%)]	Loss: 0.104424
Train epoch: 368 [328580/20036 (50%)]	Loss: 0.099044
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 369 [0/20036 (0%)]	Loss: 0.117522
Train epoch: 369 [325520/20036 (50%)]	Loss: 0.116536
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 370 [0/20036 (0%)]	Loss: 0.130182
Train epoch: 370 [325940/20036 (50%)]	Loss: 0.104607
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 371 [0/20036 (0%)]	Loss: 0.116702
Train epoch: 371 [329180/20036 (50%)]	Loss: 0.124543
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 372 [0/20036 (0%)]	Loss: 0.107949
Train epoch: 372 [331620/20036 (50%)]	Loss: 0.115318
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 373 [0/20036 (0%)]	Loss: 0.114913
Train epoch: 373 [327180/20036 (50%)]	Loss: 0.138896
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 374 [0/20036 (0%)]	Loss: 0.230300
Train epoch: 374 [329780/20036 (50%)]	Loss: 0.129834
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 375 [0/20036 (0%)]	Loss: 0.109437
Train epoch: 375 [327200/20036 (50%)]	Loss: 0.119840
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 376 [0/20036 (0%)]	Loss: 0.117459
Train epoch: 376 [326100/20036 (50%)]	Loss: 0.121641
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 377 [0/20036 (0%)]	Loss: 0.172049
Train epoch: 377 [327560/20036 (50%)]	Loss: 0.108831
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 378 [0/20036 (0%)]	Loss: 0.146645
Train epoch: 378 [332880/20036 (50%)]	Loss: 0.127261
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 379 [0/20036 (0%)]	Loss: 0.165762
Train epoch: 379 [328740/20036 (50%)]	Loss: 0.156609
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 380 [0/20036 (0%)]	Loss: 0.106790
Train epoch: 380 [328200/20036 (50%)]	Loss: 0.144995
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 381 [0/20036 (0%)]	Loss: 0.105372
Train epoch: 381 [326260/20036 (50%)]	Loss: 0.121163
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 382 [0/20036 (0%)]	Loss: 0.110069
Train epoch: 382 [328780/20036 (50%)]	Loss: 0.129388
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 383 [0/20036 (0%)]	Loss: 0.108127
Train epoch: 383 [327360/20036 (50%)]	Loss: 0.126352
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 384 [0/20036 (0%)]	Loss: 0.134107
Train epoch: 384 [330240/20036 (50%)]	Loss: 0.110180
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 385 [0/20036 (0%)]	Loss: 0.173220
Train epoch: 385 [326500/20036 (50%)]	Loss: 0.172118
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 386 [0/20036 (0%)]	Loss: 0.120715
Train epoch: 386 [327200/20036 (50%)]	Loss: 0.133810
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 387 [0/20036 (0%)]	Loss: 0.136011
Train epoch: 387 [331320/20036 (50%)]	Loss: 0.097522
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 388 [0/20036 (0%)]	Loss: 0.120358
Train epoch: 388 [326440/20036 (50%)]	Loss: 0.141918
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 389 [0/20036 (0%)]	Loss: 0.148367
Train epoch: 389 [326280/20036 (50%)]	Loss: 0.138686
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 390 [0/20036 (0%)]	Loss: 0.100669
Train epoch: 390 [327800/20036 (50%)]	Loss: 0.197746
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 391 [0/20036 (0%)]	Loss: 0.132047
Train epoch: 391 [321700/20036 (50%)]	Loss: 0.107420
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 392 [0/20036 (0%)]	Loss: 0.107602
Train epoch: 392 [328020/20036 (50%)]	Loss: 0.150802
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 393 [0/20036 (0%)]	Loss: 0.188655
Train epoch: 393 [329280/20036 (50%)]	Loss: 0.111788
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 394 [0/20036 (0%)]	Loss: 0.131094
Train epoch: 394 [328080/20036 (50%)]	Loss: 0.136269
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 395 [0/20036 (0%)]	Loss: 0.134801
Train epoch: 395 [327400/20036 (50%)]	Loss: 0.093078
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 396 [0/20036 (0%)]	Loss: 0.126296
Train epoch: 396 [329220/20036 (50%)]	Loss: 0.153066
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 397 [0/20036 (0%)]	Loss: 0.099506
Train epoch: 397 [329200/20036 (50%)]	Loss: 0.099345
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 398 [0/20036 (0%)]	Loss: 0.106940
Train epoch: 398 [323720/20036 (50%)]	Loss: 0.120825
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 399 [0/20036 (0%)]	Loss: 0.106824
Train epoch: 399 [324400/20036 (50%)]	Loss: 0.118906
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 400 [0/20036 (0%)]	Loss: 0.138312
Train epoch: 400 [327400/20036 (50%)]	Loss: 0.142213
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 401 [0/20036 (0%)]	Loss: 0.130003
Train epoch: 401 [326640/20036 (50%)]	Loss: 0.109938
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 402 [0/20036 (0%)]	Loss: 0.097122
Train epoch: 402 [325840/20036 (50%)]	Loss: 0.105486
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 403 [0/20036 (0%)]	Loss: 0.105250
Train epoch: 403 [324560/20036 (50%)]	Loss: 0.124519
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 404 [0/20036 (0%)]	Loss: 0.122738
Train epoch: 404 [336320/20036 (50%)]	Loss: 0.120026
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 405 [0/20036 (0%)]	Loss: 0.129063
Train epoch: 405 [331440/20036 (50%)]	Loss: 0.121844
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 406 [0/20036 (0%)]	Loss: 0.123847
Train epoch: 406 [325540/20036 (50%)]	Loss: 0.106999
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 407 [0/20036 (0%)]	Loss: 0.131704
Train epoch: 407 [334080/20036 (50%)]	Loss: 0.086527
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 408 [0/20036 (0%)]	Loss: 0.109225
Train epoch: 408 [332660/20036 (50%)]	Loss: 0.123638
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 409 [0/20036 (0%)]	Loss: 0.130735
Train epoch: 409 [325540/20036 (50%)]	Loss: 0.123047
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 410 [0/20036 (0%)]	Loss: 0.093910
Train epoch: 410 [335540/20036 (50%)]	Loss: 0.131103
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 411 [0/20036 (0%)]	Loss: 0.108863
Train epoch: 411 [327900/20036 (50%)]	Loss: 0.123899
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 412 [0/20036 (0%)]	Loss: 0.124944
Train epoch: 412 [328240/20036 (50%)]	Loss: 0.115073
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 413 [0/20036 (0%)]	Loss: 0.118640
Train epoch: 413 [329860/20036 (50%)]	Loss: 0.177751
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 414 [0/20036 (0%)]	Loss: 0.123034
Train epoch: 414 [327300/20036 (50%)]	Loss: 0.102601
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 415 [0/20036 (0%)]	Loss: 0.076356
Train epoch: 415 [323660/20036 (50%)]	Loss: 0.132916
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 416 [0/20036 (0%)]	Loss: 0.102183
Train epoch: 416 [325080/20036 (50%)]	Loss: 0.130125
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 417 [0/20036 (0%)]	Loss: 0.135472
Train epoch: 417 [325300/20036 (50%)]	Loss: 0.117819
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 418 [0/20036 (0%)]	Loss: 0.097352
Train epoch: 418 [333860/20036 (50%)]	Loss: 0.140274
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 419 [0/20036 (0%)]	Loss: 0.099818
Train epoch: 419 [326960/20036 (50%)]	Loss: 0.101324
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 420 [0/20036 (0%)]	Loss: 0.087721
Train epoch: 420 [328200/20036 (50%)]	Loss: 0.098841
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 421 [0/20036 (0%)]	Loss: 0.105457
Train epoch: 421 [325900/20036 (50%)]	Loss: 0.117559
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 422 [0/20036 (0%)]	Loss: 0.106743
Train epoch: 422 [324720/20036 (50%)]	Loss: 0.091899
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 423 [0/20036 (0%)]	Loss: 0.139987
Train epoch: 423 [331340/20036 (50%)]	Loss: 0.160630
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 424 [0/20036 (0%)]	Loss: 0.114947
Train epoch: 424 [330280/20036 (50%)]	Loss: 0.113902
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 425 [0/20036 (0%)]	Loss: 0.108637
Train epoch: 425 [327960/20036 (50%)]	Loss: 0.098924
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 426 [0/20036 (0%)]	Loss: 0.188075
Train epoch: 426 [320840/20036 (50%)]	Loss: 0.105888
predicting for valid data
Make prediction for 5010 samples...
0.26918426 No improvement since epoch  310 ; best_test_mse,best_test_ci: 0.26918426 0.8740840131141555 GINConvNet davis
Training on 20036 samples...
Train epoch: 427 [0/20036 (0%)]	Loss: 0.121656
Train epoch: 427 [330460/20036 (50%)]	Loss: 0.133672
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 428 [0/20036 (0%)]	Loss: 0.097794
Train epoch: 428 [328820/20036 (50%)]	Loss: 0.136492
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 429 [0/20036 (0%)]	Loss: 0.116603
Train epoch: 429 [330100/20036 (50%)]	Loss: 0.119981
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 430 [0/20036 (0%)]	Loss: 0.149632
Train epoch: 430 [327000/20036 (50%)]	Loss: 0.128115
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 431 [0/20036 (0%)]	Loss: 0.099285
Train epoch: 431 [327120/20036 (50%)]	Loss: 0.103013
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 432 [0/20036 (0%)]	Loss: 0.112964
Train epoch: 432 [327240/20036 (50%)]	Loss: 0.124765
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 433 [0/20036 (0%)]	Loss: 0.091428
Train epoch: 433 [330980/20036 (50%)]	Loss: 0.126456
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 434 [0/20036 (0%)]	Loss: 0.121846
Train epoch: 434 [328860/20036 (50%)]	Loss: 0.153244
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 435 [0/20036 (0%)]	Loss: 0.125907
Train epoch: 435 [327840/20036 (50%)]	Loss: 0.106366
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 436 [0/20036 (0%)]	Loss: 0.121468
Train epoch: 436 [330400/20036 (50%)]	Loss: 0.122249
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 437 [0/20036 (0%)]	Loss: 0.116493
Train epoch: 437 [324780/20036 (50%)]	Loss: 0.086223
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 438 [0/20036 (0%)]	Loss: 0.226761
Train epoch: 438 [328240/20036 (50%)]	Loss: 0.102137
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 439 [0/20036 (0%)]	Loss: 0.156919
Train epoch: 439 [324760/20036 (50%)]	Loss: 0.104863
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 440 [0/20036 (0%)]	Loss: 0.121270
Train epoch: 440 [328720/20036 (50%)]	Loss: 0.103666
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 441 [0/20036 (0%)]	Loss: 0.113915
Train epoch: 441 [327280/20036 (50%)]	Loss: 0.105516
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 442 [0/20036 (0%)]	Loss: 0.138522
Train epoch: 442 [330020/20036 (50%)]	Loss: 0.099869
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 443 [0/20036 (0%)]	Loss: 0.122518
Train epoch: 443 [330820/20036 (50%)]	Loss: 0.101881
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 444 [0/20036 (0%)]	Loss: 0.142115
Train epoch: 444 [323940/20036 (50%)]	Loss: 0.112338
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 445 [0/20036 (0%)]	Loss: 0.098020
Train epoch: 445 [332140/20036 (50%)]	Loss: 0.131854
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 446 [0/20036 (0%)]	Loss: 0.129956
Train epoch: 446 [328760/20036 (50%)]	Loss: 0.124623
predicting for valid data
Make prediction for 5010 samples...
0.26999575 No improvement since epoch  427 ; best_test_mse,best_test_ci: 0.26999575 0.8789263937619086 GINConvNet davis
Training on 20036 samples...
Train epoch: 447 [0/20036 (0%)]	Loss: 0.133820
Train epoch: 447 [334100/20036 (50%)]	Loss: 0.108400
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 448 [0/20036 (0%)]	Loss: 0.106731
Train epoch: 448 [325320/20036 (50%)]	Loss: 0.125991
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 449 [0/20036 (0%)]	Loss: 0.087320
Train epoch: 449 [329360/20036 (50%)]	Loss: 0.142051
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 450 [0/20036 (0%)]	Loss: 0.104626
Train epoch: 450 [328200/20036 (50%)]	Loss: 0.126991
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 451 [0/20036 (0%)]	Loss: 0.097344
Train epoch: 451 [328600/20036 (50%)]	Loss: 0.120062
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 452 [0/20036 (0%)]	Loss: 0.086498
Train epoch: 452 [328060/20036 (50%)]	Loss: 0.082227
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 453 [0/20036 (0%)]	Loss: 0.126421
Train epoch: 453 [334520/20036 (50%)]	Loss: 0.109639
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 454 [0/20036 (0%)]	Loss: 0.097506
Train epoch: 454 [332200/20036 (50%)]	Loss: 0.120036
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 455 [0/20036 (0%)]	Loss: 0.098816
Train epoch: 455 [327480/20036 (50%)]	Loss: 0.092615
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 456 [0/20036 (0%)]	Loss: 0.103812
Train epoch: 456 [333000/20036 (50%)]	Loss: 0.107768
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 457 [0/20036 (0%)]	Loss: 0.104078
Train epoch: 457 [328420/20036 (50%)]	Loss: 0.096855
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 458 [0/20036 (0%)]	Loss: 0.091972
Train epoch: 458 [323640/20036 (50%)]	Loss: 0.084662
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 459 [0/20036 (0%)]	Loss: 0.111586
Train epoch: 459 [323000/20036 (50%)]	Loss: 0.109372
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 460 [0/20036 (0%)]	Loss: 0.125366
Train epoch: 460 [330860/20036 (50%)]	Loss: 0.136569
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 461 [0/20036 (0%)]	Loss: 0.094242
Train epoch: 461 [330600/20036 (50%)]	Loss: 0.084744
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 462 [0/20036 (0%)]	Loss: 0.108045
Train epoch: 462 [324300/20036 (50%)]	Loss: 0.116478
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 463 [0/20036 (0%)]	Loss: 0.158575
Train epoch: 463 [325620/20036 (50%)]	Loss: 0.144688
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 464 [0/20036 (0%)]	Loss: 0.112083
Train epoch: 464 [324740/20036 (50%)]	Loss: 0.132414
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 465 [0/20036 (0%)]	Loss: 0.110954
Train epoch: 465 [325300/20036 (50%)]	Loss: 0.129521
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 466 [0/20036 (0%)]	Loss: 0.102434
Train epoch: 466 [331140/20036 (50%)]	Loss: 0.122411
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 467 [0/20036 (0%)]	Loss: 0.076614
Train epoch: 467 [325940/20036 (50%)]	Loss: 0.128604
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 468 [0/20036 (0%)]	Loss: 0.209665
Train epoch: 468 [331220/20036 (50%)]	Loss: 0.149095
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 469 [0/20036 (0%)]	Loss: 0.105153
Train epoch: 469 [330760/20036 (50%)]	Loss: 0.100318
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 470 [0/20036 (0%)]	Loss: 0.097889
Train epoch: 470 [325160/20036 (50%)]	Loss: 0.111292
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 471 [0/20036 (0%)]	Loss: 0.118696
Train epoch: 471 [325840/20036 (50%)]	Loss: 0.136030
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 472 [0/20036 (0%)]	Loss: 0.122398
Train epoch: 472 [328600/20036 (50%)]	Loss: 0.079587
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 473 [0/20036 (0%)]	Loss: 0.101474
Train epoch: 473 [325420/20036 (50%)]	Loss: 0.142660
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 474 [0/20036 (0%)]	Loss: 0.185158
Train epoch: 474 [326020/20036 (50%)]	Loss: 0.107634
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 475 [0/20036 (0%)]	Loss: 0.172296
Train epoch: 475 [324920/20036 (50%)]	Loss: 0.124724
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 476 [0/20036 (0%)]	Loss: 0.104238
Train epoch: 476 [325580/20036 (50%)]	Loss: 0.118079
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 477 [0/20036 (0%)]	Loss: 0.091102
Train epoch: 477 [327660/20036 (50%)]	Loss: 0.090695
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 478 [0/20036 (0%)]	Loss: 0.098211
Train epoch: 478 [327680/20036 (50%)]	Loss: 0.093592
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 479 [0/20036 (0%)]	Loss: 0.125260
Train epoch: 479 [332920/20036 (50%)]	Loss: 0.121603
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 480 [0/20036 (0%)]	Loss: 0.113764
Train epoch: 480 [329440/20036 (50%)]	Loss: 0.113111
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 481 [0/20036 (0%)]	Loss: 0.091682
Train epoch: 481 [326080/20036 (50%)]	Loss: 0.107742
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 482 [0/20036 (0%)]	Loss: 0.089789
Train epoch: 482 [328540/20036 (50%)]	Loss: 0.108368
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 483 [0/20036 (0%)]	Loss: 0.136592
Train epoch: 483 [333800/20036 (50%)]	Loss: 0.100335
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 484 [0/20036 (0%)]	Loss: 0.110674
Train epoch: 484 [333000/20036 (50%)]	Loss: 0.104985
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 485 [0/20036 (0%)]	Loss: 0.099314
Train epoch: 485 [333820/20036 (50%)]	Loss: 0.116344
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 486 [0/20036 (0%)]	Loss: 0.119226
Train epoch: 486 [329280/20036 (50%)]	Loss: 0.120426
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 487 [0/20036 (0%)]	Loss: 0.159192
Train epoch: 487 [327060/20036 (50%)]	Loss: 0.142686
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 488 [0/20036 (0%)]	Loss: 0.141850
Train epoch: 488 [323520/20036 (50%)]	Loss: 0.131537
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 489 [0/20036 (0%)]	Loss: 0.090237
Train epoch: 489 [323960/20036 (50%)]	Loss: 0.088667
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 490 [0/20036 (0%)]	Loss: 0.098256
Train epoch: 490 [329580/20036 (50%)]	Loss: 0.127647
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 491 [0/20036 (0%)]	Loss: 0.101917
Train epoch: 491 [327960/20036 (50%)]	Loss: 0.089837
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 492 [0/20036 (0%)]	Loss: 0.095577
Train epoch: 492 [330380/20036 (50%)]	Loss: 0.117966
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 493 [0/20036 (0%)]	Loss: 0.144955
Train epoch: 493 [327280/20036 (50%)]	Loss: 0.112267
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 494 [0/20036 (0%)]	Loss: 0.082099
Train epoch: 494 [330660/20036 (50%)]	Loss: 0.104961
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 495 [0/20036 (0%)]	Loss: 0.094119
Train epoch: 495 [332780/20036 (50%)]	Loss: 0.094675
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 496 [0/20036 (0%)]	Loss: 0.129037
Train epoch: 496 [327660/20036 (50%)]	Loss: 0.089128
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 497 [0/20036 (0%)]	Loss: 0.091879
Train epoch: 497 [330780/20036 (50%)]	Loss: 0.131471
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 498 [0/20036 (0%)]	Loss: 0.160968
Train epoch: 498 [326800/20036 (50%)]	Loss: 0.134268
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 499 [0/20036 (0%)]	Loss: 0.091353
Train epoch: 499 [326240/20036 (50%)]	Loss: 0.128616
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 500 [0/20036 (0%)]	Loss: 0.088342
Train epoch: 500 [330460/20036 (50%)]	Loss: 0.124664
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 501 [0/20036 (0%)]	Loss: 0.143784
Train epoch: 501 [330400/20036 (50%)]	Loss: 0.105224
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 502 [0/20036 (0%)]	Loss: 0.097637
Train epoch: 502 [325320/20036 (50%)]	Loss: 0.089976
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 503 [0/20036 (0%)]	Loss: 0.092579
Train epoch: 503 [329580/20036 (50%)]	Loss: 0.122538
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 504 [0/20036 (0%)]	Loss: 0.106622
Train epoch: 504 [330100/20036 (50%)]	Loss: 0.087990
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 505 [0/20036 (0%)]	Loss: 0.106537
Train epoch: 505 [324160/20036 (50%)]	Loss: 0.130860
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 506 [0/20036 (0%)]	Loss: 0.103290
Train epoch: 506 [330500/20036 (50%)]	Loss: 0.096604
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 507 [0/20036 (0%)]	Loss: 0.129624
Train epoch: 507 [328380/20036 (50%)]	Loss: 0.090129
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 508 [0/20036 (0%)]	Loss: 0.089024
Train epoch: 508 [326720/20036 (50%)]	Loss: 0.098847
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 509 [0/20036 (0%)]	Loss: 0.083900
Train epoch: 509 [332120/20036 (50%)]	Loss: 0.094937
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 510 [0/20036 (0%)]	Loss: 0.088293
Train epoch: 510 [333380/20036 (50%)]	Loss: 0.117998
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 511 [0/20036 (0%)]	Loss: 0.102871
Train epoch: 511 [331180/20036 (50%)]	Loss: 0.093994
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 512 [0/20036 (0%)]	Loss: 0.085137
Train epoch: 512 [329240/20036 (50%)]	Loss: 0.080670
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 513 [0/20036 (0%)]	Loss: 0.134080
Train epoch: 513 [329460/20036 (50%)]	Loss: 0.133090
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 514 [0/20036 (0%)]	Loss: 0.109827
Train epoch: 514 [330360/20036 (50%)]	Loss: 0.099443
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 515 [0/20036 (0%)]	Loss: 0.088020
Train epoch: 515 [328440/20036 (50%)]	Loss: 0.093622
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 516 [0/20036 (0%)]	Loss: 0.119920
Train epoch: 516 [328380/20036 (50%)]	Loss: 0.137741
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 517 [0/20036 (0%)]	Loss: 0.110318
Train epoch: 517 [325400/20036 (50%)]	Loss: 0.115193
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 518 [0/20036 (0%)]	Loss: 0.078907
Train epoch: 518 [329600/20036 (50%)]	Loss: 0.105820
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 519 [0/20036 (0%)]	Loss: 0.124863
Train epoch: 519 [331520/20036 (50%)]	Loss: 0.097637
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 520 [0/20036 (0%)]	Loss: 0.103099
Train epoch: 520 [328080/20036 (50%)]	Loss: 0.134617
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 521 [0/20036 (0%)]	Loss: 0.080594
Train epoch: 521 [330200/20036 (50%)]	Loss: 0.099480
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 522 [0/20036 (0%)]	Loss: 0.087703
Train epoch: 522 [326100/20036 (50%)]	Loss: 0.100603
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 523 [0/20036 (0%)]	Loss: 0.124150
Train epoch: 523 [329160/20036 (50%)]	Loss: 0.102468
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 524 [0/20036 (0%)]	Loss: 0.090803
Train epoch: 524 [331040/20036 (50%)]	Loss: 0.137807
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 525 [0/20036 (0%)]	Loss: 0.100465
Train epoch: 525 [328100/20036 (50%)]	Loss: 0.094334
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 526 [0/20036 (0%)]	Loss: 0.116096
Train epoch: 526 [328380/20036 (50%)]	Loss: 0.120857
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 527 [0/20036 (0%)]	Loss: 0.129190
Train epoch: 527 [328360/20036 (50%)]	Loss: 0.106932
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 528 [0/20036 (0%)]	Loss: 0.097942
Train epoch: 528 [330120/20036 (50%)]	Loss: 0.101211
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 529 [0/20036 (0%)]	Loss: 0.105263
Train epoch: 529 [326400/20036 (50%)]	Loss: 0.088823
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 530 [0/20036 (0%)]	Loss: 0.110132
Train epoch: 530 [336240/20036 (50%)]	Loss: 0.128532
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 531 [0/20036 (0%)]	Loss: 0.173299
Train epoch: 531 [331860/20036 (50%)]	Loss: 0.091577
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 532 [0/20036 (0%)]	Loss: 0.090218
Train epoch: 532 [329140/20036 (50%)]	Loss: 0.077383
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 533 [0/20036 (0%)]	Loss: 0.112801
Train epoch: 533 [330840/20036 (50%)]	Loss: 0.103374
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 534 [0/20036 (0%)]	Loss: 0.086336
Train epoch: 534 [321700/20036 (50%)]	Loss: 0.108742
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 535 [0/20036 (0%)]	Loss: 0.115868
Train epoch: 535 [329660/20036 (50%)]	Loss: 0.104333
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 536 [0/20036 (0%)]	Loss: 0.108756
Train epoch: 536 [330700/20036 (50%)]	Loss: 0.099035
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 537 [0/20036 (0%)]	Loss: 0.112601
Train epoch: 537 [323700/20036 (50%)]	Loss: 0.100895
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 538 [0/20036 (0%)]	Loss: 0.137980
Train epoch: 538 [329540/20036 (50%)]	Loss: 0.091726
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 539 [0/20036 (0%)]	Loss: 0.112074
Train epoch: 539 [327600/20036 (50%)]	Loss: 0.094873
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 540 [0/20036 (0%)]	Loss: 0.110919
Train epoch: 540 [327000/20036 (50%)]	Loss: 0.097616
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 541 [0/20036 (0%)]	Loss: 0.090761
Train epoch: 541 [329220/20036 (50%)]	Loss: 0.085087
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 542 [0/20036 (0%)]	Loss: 0.089664
Train epoch: 542 [328060/20036 (50%)]	Loss: 0.123498
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 543 [0/20036 (0%)]	Loss: 0.121034
Train epoch: 543 [326160/20036 (50%)]	Loss: 0.127290
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 544 [0/20036 (0%)]	Loss: 0.169129
Train epoch: 544 [327640/20036 (50%)]	Loss: 0.088831
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 545 [0/20036 (0%)]	Loss: 0.087396
Train epoch: 545 [328660/20036 (50%)]	Loss: 0.099744
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 546 [0/20036 (0%)]	Loss: 0.126098
Train epoch: 546 [324560/20036 (50%)]	Loss: 0.094103
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 547 [0/20036 (0%)]	Loss: 0.083336
Train epoch: 547 [332000/20036 (50%)]	Loss: 0.110912
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 548 [0/20036 (0%)]	Loss: 0.110672
Train epoch: 548 [331020/20036 (50%)]	Loss: 0.100861
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 549 [0/20036 (0%)]	Loss: 0.122939
Train epoch: 549 [328100/20036 (50%)]	Loss: 0.095552
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 550 [0/20036 (0%)]	Loss: 0.107951
Train epoch: 550 [328940/20036 (50%)]	Loss: 0.129666
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 551 [0/20036 (0%)]	Loss: 0.084254
Train epoch: 551 [327360/20036 (50%)]	Loss: 0.121296
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 552 [0/20036 (0%)]	Loss: 0.078424
Train epoch: 552 [331440/20036 (50%)]	Loss: 0.094231
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 553 [0/20036 (0%)]	Loss: 0.096583
Train epoch: 553 [328900/20036 (50%)]	Loss: 0.083486
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 554 [0/20036 (0%)]	Loss: 0.119721
Train epoch: 554 [328240/20036 (50%)]	Loss: 0.107425
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 555 [0/20036 (0%)]	Loss: 0.092826
Train epoch: 555 [329920/20036 (50%)]	Loss: 0.097510
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 556 [0/20036 (0%)]	Loss: 0.093270
Train epoch: 556 [329380/20036 (50%)]	Loss: 0.104728
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 557 [0/20036 (0%)]	Loss: 0.114076
Train epoch: 557 [321360/20036 (50%)]	Loss: 0.092200
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 558 [0/20036 (0%)]	Loss: 0.120582
Train epoch: 558 [329780/20036 (50%)]	Loss: 0.085841
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 559 [0/20036 (0%)]	Loss: 0.090031
Train epoch: 559 [328620/20036 (50%)]	Loss: 0.100737
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 560 [0/20036 (0%)]	Loss: 0.086497
Train epoch: 560 [325400/20036 (50%)]	Loss: 0.095939
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 561 [0/20036 (0%)]	Loss: 0.071179
Train epoch: 561 [327920/20036 (50%)]	Loss: 0.091130
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 562 [0/20036 (0%)]	Loss: 0.093189
Train epoch: 562 [322640/20036 (50%)]	Loss: 0.114422
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 563 [0/20036 (0%)]	Loss: 0.080628
Train epoch: 563 [327240/20036 (50%)]	Loss: 0.117554
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 564 [0/20036 (0%)]	Loss: 0.106622
Train epoch: 564 [330500/20036 (50%)]	Loss: 0.110711
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 565 [0/20036 (0%)]	Loss: 0.097892
Train epoch: 565 [328700/20036 (50%)]	Loss: 0.070504
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 566 [0/20036 (0%)]	Loss: 0.094821
Train epoch: 566 [330940/20036 (50%)]	Loss: 0.106435
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 567 [0/20036 (0%)]	Loss: 0.115081
Train epoch: 567 [327460/20036 (50%)]	Loss: 0.091461
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 568 [0/20036 (0%)]	Loss: 0.125888
Train epoch: 568 [327640/20036 (50%)]	Loss: 0.083030
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 569 [0/20036 (0%)]	Loss: 0.116867
Train epoch: 569 [330080/20036 (50%)]	Loss: 0.105204
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 570 [0/20036 (0%)]	Loss: 0.084225
Train epoch: 570 [331880/20036 (50%)]	Loss: 0.093864
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 571 [0/20036 (0%)]	Loss: 0.128953
Train epoch: 571 [325760/20036 (50%)]	Loss: 0.081377
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 572 [0/20036 (0%)]	Loss: 0.087028
Train epoch: 572 [329380/20036 (50%)]	Loss: 0.095186
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 573 [0/20036 (0%)]	Loss: 0.096766
Train epoch: 573 [331460/20036 (50%)]	Loss: 0.105784
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 574 [0/20036 (0%)]	Loss: 0.098094
Train epoch: 574 [330640/20036 (50%)]	Loss: 0.104056
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 575 [0/20036 (0%)]	Loss: 0.110247
Train epoch: 575 [327260/20036 (50%)]	Loss: 0.156232
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 576 [0/20036 (0%)]	Loss: 0.095309
Train epoch: 576 [324400/20036 (50%)]	Loss: 0.084838
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 577 [0/20036 (0%)]	Loss: 0.160519
Train epoch: 577 [327520/20036 (50%)]	Loss: 0.089431
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 578 [0/20036 (0%)]	Loss: 0.141694
Train epoch: 578 [326260/20036 (50%)]	Loss: 0.111317
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 579 [0/20036 (0%)]	Loss: 0.080650
Train epoch: 579 [332160/20036 (50%)]	Loss: 0.138918
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 580 [0/20036 (0%)]	Loss: 0.078942
Train epoch: 580 [331760/20036 (50%)]	Loss: 0.089147
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 581 [0/20036 (0%)]	Loss: 0.088101
Train epoch: 581 [325240/20036 (50%)]	Loss: 0.080741
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 582 [0/20036 (0%)]	Loss: 0.087156
Train epoch: 582 [328340/20036 (50%)]	Loss: 0.130472
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 583 [0/20036 (0%)]	Loss: 0.090112
Train epoch: 583 [326260/20036 (50%)]	Loss: 0.078792
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 584 [0/20036 (0%)]	Loss: 0.085093
Train epoch: 584 [325980/20036 (50%)]	Loss: 0.118467
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 585 [0/20036 (0%)]	Loss: 0.080609
Train epoch: 585 [331020/20036 (50%)]	Loss: 0.141241
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 586 [0/20036 (0%)]	Loss: 0.220322
Train epoch: 586 [327140/20036 (50%)]	Loss: 0.152473
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 587 [0/20036 (0%)]	Loss: 0.096943
Train epoch: 587 [326840/20036 (50%)]	Loss: 0.110384
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 588 [0/20036 (0%)]	Loss: 0.122308
Train epoch: 588 [328620/20036 (50%)]	Loss: 0.145416
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 589 [0/20036 (0%)]	Loss: 0.098225
Train epoch: 589 [332000/20036 (50%)]	Loss: 0.097472
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 590 [0/20036 (0%)]	Loss: 0.112016
Train epoch: 590 [322820/20036 (50%)]	Loss: 0.100945
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 591 [0/20036 (0%)]	Loss: 0.112330
Train epoch: 591 [326980/20036 (50%)]	Loss: 0.097621
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 592 [0/20036 (0%)]	Loss: 0.089591
Train epoch: 592 [326780/20036 (50%)]	Loss: 0.093939
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 593 [0/20036 (0%)]	Loss: 0.108260
Train epoch: 593 [326880/20036 (50%)]	Loss: 0.093423
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 594 [0/20036 (0%)]	Loss: 0.135774
Train epoch: 594 [330400/20036 (50%)]	Loss: 0.083147
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 595 [0/20036 (0%)]	Loss: 0.111354
Train epoch: 595 [330920/20036 (50%)]	Loss: 0.114719
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 596 [0/20036 (0%)]	Loss: 0.118532
Train epoch: 596 [328580/20036 (50%)]	Loss: 0.081349
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 597 [0/20036 (0%)]	Loss: 0.133164
Train epoch: 597 [331000/20036 (50%)]	Loss: 0.093559
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 598 [0/20036 (0%)]	Loss: 0.108611
Train epoch: 598 [329480/20036 (50%)]	Loss: 0.083324
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 599 [0/20036 (0%)]	Loss: 0.095794
Train epoch: 599 [326740/20036 (50%)]	Loss: 0.075077
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 600 [0/20036 (0%)]	Loss: 0.119779
Train epoch: 600 [326240/20036 (50%)]	Loss: 0.105212
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 601 [0/20036 (0%)]	Loss: 0.092042
Train epoch: 601 [336160/20036 (50%)]	Loss: 0.105695
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 602 [0/20036 (0%)]	Loss: 0.112880
Train epoch: 602 [325880/20036 (50%)]	Loss: 0.094528
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 603 [0/20036 (0%)]	Loss: 0.086057
Train epoch: 603 [329480/20036 (50%)]	Loss: 0.073015
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 604 [0/20036 (0%)]	Loss: 0.100585
Train epoch: 604 [326100/20036 (50%)]	Loss: 0.070436
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 605 [0/20036 (0%)]	Loss: 0.098491
Train epoch: 605 [327540/20036 (50%)]	Loss: 0.093999
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 606 [0/20036 (0%)]	Loss: 0.122346
Train epoch: 606 [326060/20036 (50%)]	Loss: 0.084438
predicting for valid data
Make prediction for 5010 samples...
0.27265882 No improvement since epoch  447 ; best_test_mse,best_test_ci: 0.27265882 0.8792189153330772 GINConvNet davis
Training on 20036 samples...
Train epoch: 607 [0/20036 (0%)]	Loss: 0.114567
Train epoch: 607 [330900/20036 (50%)]	Loss: 0.069900
predicting for valid data
Make prediction for 5010 samples...
predicting for test data
Make prediction for 5010 samples...
rmse improved at epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 608 [0/20036 (0%)]	Loss: 0.108811
Train epoch: 608 [329620/20036 (50%)]	Loss: 0.091909
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 609 [0/20036 (0%)]	Loss: 0.134405
Train epoch: 609 [326240/20036 (50%)]	Loss: 0.085741
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 610 [0/20036 (0%)]	Loss: 0.192508
Train epoch: 610 [329640/20036 (50%)]	Loss: 0.107678
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 611 [0/20036 (0%)]	Loss: 0.088409
Train epoch: 611 [331120/20036 (50%)]	Loss: 0.138155
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 612 [0/20036 (0%)]	Loss: 0.111522
Train epoch: 612 [328380/20036 (50%)]	Loss: 0.108435
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 613 [0/20036 (0%)]	Loss: 0.092129
Train epoch: 613 [332940/20036 (50%)]	Loss: 0.077295
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 614 [0/20036 (0%)]	Loss: 0.070210
Train epoch: 614 [324700/20036 (50%)]	Loss: 0.098271
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 615 [0/20036 (0%)]	Loss: 0.066946
Train epoch: 615 [327480/20036 (50%)]	Loss: 0.115342
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 616 [0/20036 (0%)]	Loss: 0.126942
Train epoch: 616 [329560/20036 (50%)]	Loss: 0.098984
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 617 [0/20036 (0%)]	Loss: 0.110303
Train epoch: 617 [328800/20036 (50%)]	Loss: 0.082253
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 618 [0/20036 (0%)]	Loss: 0.086138
Train epoch: 618 [328020/20036 (50%)]	Loss: 0.088877
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 619 [0/20036 (0%)]	Loss: 0.084960
Train epoch: 619 [329120/20036 (50%)]	Loss: 0.110070
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 620 [0/20036 (0%)]	Loss: 0.096852
Train epoch: 620 [325680/20036 (50%)]	Loss: 0.076137
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 621 [0/20036 (0%)]	Loss: 0.146610
Train epoch: 621 [324900/20036 (50%)]	Loss: 0.092726
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 622 [0/20036 (0%)]	Loss: 0.110272
Train epoch: 622 [328380/20036 (50%)]	Loss: 0.093160
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 623 [0/20036 (0%)]	Loss: 0.089226
Train epoch: 623 [328800/20036 (50%)]	Loss: 0.091309
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 624 [0/20036 (0%)]	Loss: 0.073936
Train epoch: 624 [324060/20036 (50%)]	Loss: 0.107893
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 625 [0/20036 (0%)]	Loss: 0.106270
Train epoch: 625 [329600/20036 (50%)]	Loss: 0.100239
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 626 [0/20036 (0%)]	Loss: 0.104301
Train epoch: 626 [331140/20036 (50%)]	Loss: 0.081048
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 627 [0/20036 (0%)]	Loss: 0.088401
Train epoch: 627 [324380/20036 (50%)]	Loss: 0.116949
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 628 [0/20036 (0%)]	Loss: 0.208444
Train epoch: 628 [330040/20036 (50%)]	Loss: 0.099186
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 629 [0/20036 (0%)]	Loss: 0.130786
Train epoch: 629 [331360/20036 (50%)]	Loss: 0.096208
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 630 [0/20036 (0%)]	Loss: 0.098501
Train epoch: 630 [326800/20036 (50%)]	Loss: 0.067875
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 631 [0/20036 (0%)]	Loss: 0.084167
Train epoch: 631 [328680/20036 (50%)]	Loss: 0.110821
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 632 [0/20036 (0%)]	Loss: 0.202123
Train epoch: 632 [327280/20036 (50%)]	Loss: 0.107629
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 633 [0/20036 (0%)]	Loss: 0.119237
Train epoch: 633 [331740/20036 (50%)]	Loss: 0.104050
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 634 [0/20036 (0%)]	Loss: 0.089791
Train epoch: 634 [327700/20036 (50%)]	Loss: 0.115471
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 635 [0/20036 (0%)]	Loss: 0.087169
Train epoch: 635 [328660/20036 (50%)]	Loss: 0.113194
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 636 [0/20036 (0%)]	Loss: 0.079865
Train epoch: 636 [326200/20036 (50%)]	Loss: 0.097590
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 637 [0/20036 (0%)]	Loss: 0.069805
Train epoch: 637 [325520/20036 (50%)]	Loss: 0.089916
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 638 [0/20036 (0%)]	Loss: 0.096134
Train epoch: 638 [326860/20036 (50%)]	Loss: 0.109534
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 639 [0/20036 (0%)]	Loss: 0.088827
Train epoch: 639 [331760/20036 (50%)]	Loss: 0.083013
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 640 [0/20036 (0%)]	Loss: 0.101731
Train epoch: 640 [325800/20036 (50%)]	Loss: 0.093151
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 641 [0/20036 (0%)]	Loss: 0.087468
Train epoch: 641 [336500/20036 (50%)]	Loss: 0.086504
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 642 [0/20036 (0%)]	Loss: 0.111263
Train epoch: 642 [328100/20036 (50%)]	Loss: 0.127840
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 643 [0/20036 (0%)]	Loss: 0.080618
Train epoch: 643 [325600/20036 (50%)]	Loss: 0.105612
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 644 [0/20036 (0%)]	Loss: 0.113376
Train epoch: 644 [327580/20036 (50%)]	Loss: 0.100687
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 645 [0/20036 (0%)]	Loss: 0.111507
Train epoch: 645 [330480/20036 (50%)]	Loss: 0.084993
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 646 [0/20036 (0%)]	Loss: 0.097530
Train epoch: 646 [334080/20036 (50%)]	Loss: 0.102045
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 647 [0/20036 (0%)]	Loss: 0.081118
Train epoch: 647 [327940/20036 (50%)]	Loss: 0.081333
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 648 [0/20036 (0%)]	Loss: 0.102656
Train epoch: 648 [327260/20036 (50%)]	Loss: 0.091791
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 649 [0/20036 (0%)]	Loss: 0.104623
Train epoch: 649 [329720/20036 (50%)]	Loss: 0.096432
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 650 [0/20036 (0%)]	Loss: 0.090816
Train epoch: 650 [330180/20036 (50%)]	Loss: 0.116384
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 651 [0/20036 (0%)]	Loss: 0.072812
Train epoch: 651 [324780/20036 (50%)]	Loss: 0.081018
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 652 [0/20036 (0%)]	Loss: 0.084528
Train epoch: 652 [329280/20036 (50%)]	Loss: 0.072998
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 653 [0/20036 (0%)]	Loss: 0.109273
Train epoch: 653 [323580/20036 (50%)]	Loss: 0.082827
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 654 [0/20036 (0%)]	Loss: 0.113122
Train epoch: 654 [326900/20036 (50%)]	Loss: 0.098996
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 655 [0/20036 (0%)]	Loss: 0.099369
Train epoch: 655 [329840/20036 (50%)]	Loss: 0.106214
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 656 [0/20036 (0%)]	Loss: 0.081839
Train epoch: 656 [327460/20036 (50%)]	Loss: 0.084608
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 657 [0/20036 (0%)]	Loss: 0.096992
Train epoch: 657 [329340/20036 (50%)]	Loss: 0.088156
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 658 [0/20036 (0%)]	Loss: 0.088272
Train epoch: 658 [332960/20036 (50%)]	Loss: 0.081621
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 659 [0/20036 (0%)]	Loss: 0.090237
Train epoch: 659 [331420/20036 (50%)]	Loss: 0.103647
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 660 [0/20036 (0%)]	Loss: 0.077208
Train epoch: 660 [329040/20036 (50%)]	Loss: 0.086049
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 661 [0/20036 (0%)]	Loss: 0.160366
Train epoch: 661 [328940/20036 (50%)]	Loss: 0.110435
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 662 [0/20036 (0%)]	Loss: 0.096020
Train epoch: 662 [330300/20036 (50%)]	Loss: 0.088657
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 663 [0/20036 (0%)]	Loss: 0.092425
Train epoch: 663 [323860/20036 (50%)]	Loss: 0.118113
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 664 [0/20036 (0%)]	Loss: 0.110875
Train epoch: 664 [328780/20036 (50%)]	Loss: 0.087485
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 665 [0/20036 (0%)]	Loss: 0.112508
Train epoch: 665 [325980/20036 (50%)]	Loss: 0.102721
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 666 [0/20036 (0%)]	Loss: 0.085171
Train epoch: 666 [329080/20036 (50%)]	Loss: 0.085491
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 667 [0/20036 (0%)]	Loss: 0.071607
Train epoch: 667 [325080/20036 (50%)]	Loss: 0.115297
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 668 [0/20036 (0%)]	Loss: 0.113967
Train epoch: 668 [328580/20036 (50%)]	Loss: 0.089779
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 669 [0/20036 (0%)]	Loss: 0.092922
Train epoch: 669 [325740/20036 (50%)]	Loss: 0.078521
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 670 [0/20036 (0%)]	Loss: 0.074234
Train epoch: 670 [328040/20036 (50%)]	Loss: 0.128485
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 671 [0/20036 (0%)]	Loss: 0.076422
Train epoch: 671 [319080/20036 (50%)]	Loss: 0.103629
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 672 [0/20036 (0%)]	Loss: 0.142548
Train epoch: 672 [324560/20036 (50%)]	Loss: 0.084571
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 673 [0/20036 (0%)]	Loss: 0.101061
Train epoch: 673 [327720/20036 (50%)]	Loss: 0.095834
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 674 [0/20036 (0%)]	Loss: 0.087147
Train epoch: 674 [330920/20036 (50%)]	Loss: 0.093592
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 675 [0/20036 (0%)]	Loss: 0.086204
Train epoch: 675 [324960/20036 (50%)]	Loss: 0.101317
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 676 [0/20036 (0%)]	Loss: 0.099425
Train epoch: 676 [328560/20036 (50%)]	Loss: 0.082733
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 677 [0/20036 (0%)]	Loss: 0.106674
Train epoch: 677 [328840/20036 (50%)]	Loss: 0.090134
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 678 [0/20036 (0%)]	Loss: 0.084190
Train epoch: 678 [333500/20036 (50%)]	Loss: 0.070169
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 679 [0/20036 (0%)]	Loss: 0.084487
Train epoch: 679 [326240/20036 (50%)]	Loss: 0.072896
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 680 [0/20036 (0%)]	Loss: 0.071274
Train epoch: 680 [329240/20036 (50%)]	Loss: 0.117991
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 681 [0/20036 (0%)]	Loss: 0.110224
Train epoch: 681 [327740/20036 (50%)]	Loss: 0.074375
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 682 [0/20036 (0%)]	Loss: 0.094437
Train epoch: 682 [325280/20036 (50%)]	Loss: 0.105333
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 683 [0/20036 (0%)]	Loss: 0.095747
Train epoch: 683 [331840/20036 (50%)]	Loss: 0.078934
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 684 [0/20036 (0%)]	Loss: 0.140084
Train epoch: 684 [325900/20036 (50%)]	Loss: 0.092749
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 685 [0/20036 (0%)]	Loss: 0.120205
Train epoch: 685 [329500/20036 (50%)]	Loss: 0.105047
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 686 [0/20036 (0%)]	Loss: 0.092453
Train epoch: 686 [331180/20036 (50%)]	Loss: 0.091170
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 687 [0/20036 (0%)]	Loss: 0.079319
Train epoch: 687 [327320/20036 (50%)]	Loss: 0.103135
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 688 [0/20036 (0%)]	Loss: 0.118702
Train epoch: 688 [329140/20036 (50%)]	Loss: 0.076050
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 689 [0/20036 (0%)]	Loss: 0.094379
Train epoch: 689 [328600/20036 (50%)]	Loss: 0.071744
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 690 [0/20036 (0%)]	Loss: 0.081800
Train epoch: 690 [324840/20036 (50%)]	Loss: 0.070952
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 691 [0/20036 (0%)]	Loss: 0.079132
Train epoch: 691 [328540/20036 (50%)]	Loss: 0.107422
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 692 [0/20036 (0%)]	Loss: 0.122536
Train epoch: 692 [329200/20036 (50%)]	Loss: 0.098124
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 693 [0/20036 (0%)]	Loss: 0.078763
Train epoch: 693 [328120/20036 (50%)]	Loss: 0.092909
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 694 [0/20036 (0%)]	Loss: 0.070794
Train epoch: 694 [329500/20036 (50%)]	Loss: 0.103936
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 695 [0/20036 (0%)]	Loss: 0.072622
Train epoch: 695 [330940/20036 (50%)]	Loss: 0.101562
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 696 [0/20036 (0%)]	Loss: 0.077031
Train epoch: 696 [332120/20036 (50%)]	Loss: 0.082947
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 697 [0/20036 (0%)]	Loss: 0.100155
Train epoch: 697 [325040/20036 (50%)]	Loss: 0.096224
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 698 [0/20036 (0%)]	Loss: 0.082551
Train epoch: 698 [329420/20036 (50%)]	Loss: 0.102137
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 699 [0/20036 (0%)]	Loss: 0.085596
Train epoch: 699 [325840/20036 (50%)]	Loss: 0.082417
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 700 [0/20036 (0%)]	Loss: 0.086029
Train epoch: 700 [330840/20036 (50%)]	Loss: 0.088564
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 701 [0/20036 (0%)]	Loss: 0.110768
Train epoch: 701 [328240/20036 (50%)]	Loss: 0.073607
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 702 [0/20036 (0%)]	Loss: 0.084693
Train epoch: 702 [329900/20036 (50%)]	Loss: 0.127989
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 703 [0/20036 (0%)]	Loss: 0.100430
Train epoch: 703 [332240/20036 (50%)]	Loss: 0.105279
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 704 [0/20036 (0%)]	Loss: 0.093911
Train epoch: 704 [330340/20036 (50%)]	Loss: 0.075614
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 705 [0/20036 (0%)]	Loss: 0.206792
Train epoch: 705 [333880/20036 (50%)]	Loss: 0.106572
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 706 [0/20036 (0%)]	Loss: 0.249354
Train epoch: 706 [327000/20036 (50%)]	Loss: 0.095113
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 707 [0/20036 (0%)]	Loss: 0.084731
Train epoch: 707 [328260/20036 (50%)]	Loss: 0.102420
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 708 [0/20036 (0%)]	Loss: 0.116650
Train epoch: 708 [325400/20036 (50%)]	Loss: 0.080632
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 709 [0/20036 (0%)]	Loss: 0.066216
Train epoch: 709 [333080/20036 (50%)]	Loss: 0.083963
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 710 [0/20036 (0%)]	Loss: 0.078625
Train epoch: 710 [327300/20036 (50%)]	Loss: 0.079038
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 711 [0/20036 (0%)]	Loss: 0.086640
Train epoch: 711 [325160/20036 (50%)]	Loss: 0.090984
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 712 [0/20036 (0%)]	Loss: 0.073607
Train epoch: 712 [326960/20036 (50%)]	Loss: 0.087490
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 713 [0/20036 (0%)]	Loss: 0.075139
Train epoch: 713 [326080/20036 (50%)]	Loss: 0.079451
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 714 [0/20036 (0%)]	Loss: 0.112554
Train epoch: 714 [326080/20036 (50%)]	Loss: 0.096646
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 715 [0/20036 (0%)]	Loss: 0.082290
Train epoch: 715 [324440/20036 (50%)]	Loss: 0.119717
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 716 [0/20036 (0%)]	Loss: 0.140719
Train epoch: 716 [332880/20036 (50%)]	Loss: 0.086252
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 717 [0/20036 (0%)]	Loss: 0.079233
Train epoch: 717 [331980/20036 (50%)]	Loss: 0.103623
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 718 [0/20036 (0%)]	Loss: 0.094609
Train epoch: 718 [329280/20036 (50%)]	Loss: 0.081467
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 719 [0/20036 (0%)]	Loss: 0.083471
Train epoch: 719 [325580/20036 (50%)]	Loss: 0.097277
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 720 [0/20036 (0%)]	Loss: 0.080316
Train epoch: 720 [325720/20036 (50%)]	Loss: 0.114395
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 721 [0/20036 (0%)]	Loss: 0.075980
Train epoch: 721 [327760/20036 (50%)]	Loss: 0.126876
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 722 [0/20036 (0%)]	Loss: 0.089650
Train epoch: 722 [328000/20036 (50%)]	Loss: 0.095107
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 723 [0/20036 (0%)]	Loss: 0.101349
Train epoch: 723 [325100/20036 (50%)]	Loss: 0.114301
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 724 [0/20036 (0%)]	Loss: 0.091703
Train epoch: 724 [330280/20036 (50%)]	Loss: 0.070590
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 725 [0/20036 (0%)]	Loss: 0.077855
Train epoch: 725 [322820/20036 (50%)]	Loss: 0.095307
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 726 [0/20036 (0%)]	Loss: 0.108838
Train epoch: 726 [325240/20036 (50%)]	Loss: 0.102972
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 727 [0/20036 (0%)]	Loss: 0.072149
Train epoch: 727 [322580/20036 (50%)]	Loss: 0.096421
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 728 [0/20036 (0%)]	Loss: 0.114799
Train epoch: 728 [331000/20036 (50%)]	Loss: 0.083150
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 729 [0/20036 (0%)]	Loss: 0.107779
Train epoch: 729 [330480/20036 (50%)]	Loss: 0.110531
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 730 [0/20036 (0%)]	Loss: 0.068545
Train epoch: 730 [330660/20036 (50%)]	Loss: 0.131948
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 731 [0/20036 (0%)]	Loss: 0.083446
Train epoch: 731 [330320/20036 (50%)]	Loss: 0.086742
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 732 [0/20036 (0%)]	Loss: 0.082740
Train epoch: 732 [327240/20036 (50%)]	Loss: 0.099732
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 733 [0/20036 (0%)]	Loss: 0.094023
Train epoch: 733 [322980/20036 (50%)]	Loss: 0.078155
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 734 [0/20036 (0%)]	Loss: 0.104644
Train epoch: 734 [328820/20036 (50%)]	Loss: 0.078342
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 735 [0/20036 (0%)]	Loss: 0.144445
Train epoch: 735 [328820/20036 (50%)]	Loss: 0.078847
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 736 [0/20036 (0%)]	Loss: 0.090506
Train epoch: 736 [322180/20036 (50%)]	Loss: 0.093406
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 737 [0/20036 (0%)]	Loss: 0.167260
Train epoch: 737 [326840/20036 (50%)]	Loss: 0.148403
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 738 [0/20036 (0%)]	Loss: 0.079165
Train epoch: 738 [325800/20036 (50%)]	Loss: 0.078252
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 739 [0/20036 (0%)]	Loss: 0.098969
Train epoch: 739 [328660/20036 (50%)]	Loss: 0.076122
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 740 [0/20036 (0%)]	Loss: 0.082463
Train epoch: 740 [327880/20036 (50%)]	Loss: 0.133454
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 741 [0/20036 (0%)]	Loss: 0.095054
Train epoch: 741 [328100/20036 (50%)]	Loss: 0.064452
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 742 [0/20036 (0%)]	Loss: 0.103349
Train epoch: 742 [327100/20036 (50%)]	Loss: 0.113406
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 743 [0/20036 (0%)]	Loss: 0.079774
Train epoch: 743 [327080/20036 (50%)]	Loss: 0.069362
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 744 [0/20036 (0%)]	Loss: 0.067690
Train epoch: 744 [331060/20036 (50%)]	Loss: 0.079369
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 745 [0/20036 (0%)]	Loss: 0.114147
Train epoch: 745 [328480/20036 (50%)]	Loss: 0.072357
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 746 [0/20036 (0%)]	Loss: 0.079199
Train epoch: 746 [327440/20036 (50%)]	Loss: 0.085316
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 747 [0/20036 (0%)]	Loss: 0.079704
Train epoch: 747 [327720/20036 (50%)]	Loss: 0.077644
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 748 [0/20036 (0%)]	Loss: 0.073040
Train epoch: 748 [327460/20036 (50%)]	Loss: 0.105530
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 749 [0/20036 (0%)]	Loss: 0.061300
Train epoch: 749 [324620/20036 (50%)]	Loss: 0.063836
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 750 [0/20036 (0%)]	Loss: 0.089035
Train epoch: 750 [326600/20036 (50%)]	Loss: 0.103323
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 751 [0/20036 (0%)]	Loss: 0.081282
Train epoch: 751 [328660/20036 (50%)]	Loss: 0.088236
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 752 [0/20036 (0%)]	Loss: 0.089053
Train epoch: 752 [326500/20036 (50%)]	Loss: 0.089412
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 753 [0/20036 (0%)]	Loss: 0.086602
Train epoch: 753 [327400/20036 (50%)]	Loss: 0.101006
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 754 [0/20036 (0%)]	Loss: 0.084650
Train epoch: 754 [325040/20036 (50%)]	Loss: 0.096948
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 755 [0/20036 (0%)]	Loss: 0.109901
Train epoch: 755 [332920/20036 (50%)]	Loss: 0.090913
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 756 [0/20036 (0%)]	Loss: 0.111971
Train epoch: 756 [327440/20036 (50%)]	Loss: 0.076458
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 757 [0/20036 (0%)]	Loss: 0.062898
Train epoch: 757 [333280/20036 (50%)]	Loss: 0.102303
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 758 [0/20036 (0%)]	Loss: 0.073050
Train epoch: 758 [327020/20036 (50%)]	Loss: 0.069220
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 759 [0/20036 (0%)]	Loss: 0.139660
Train epoch: 759 [330720/20036 (50%)]	Loss: 0.078858
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 760 [0/20036 (0%)]	Loss: 0.068961
Train epoch: 760 [323260/20036 (50%)]	Loss: 0.069037
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 761 [0/20036 (0%)]	Loss: 0.085098
Train epoch: 761 [328320/20036 (50%)]	Loss: 0.125968
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 762 [0/20036 (0%)]	Loss: 0.095437
Train epoch: 762 [328680/20036 (50%)]	Loss: 0.083529
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 763 [0/20036 (0%)]	Loss: 0.095410
Train epoch: 763 [324900/20036 (50%)]	Loss: 0.096701
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 764 [0/20036 (0%)]	Loss: 0.077561
Train epoch: 764 [330980/20036 (50%)]	Loss: 0.091123
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 765 [0/20036 (0%)]	Loss: 0.093254
Train epoch: 765 [329600/20036 (50%)]	Loss: 0.086117
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 766 [0/20036 (0%)]	Loss: 0.101379
Train epoch: 766 [330340/20036 (50%)]	Loss: 0.073356
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 767 [0/20036 (0%)]	Loss: 0.110502
Train epoch: 767 [326720/20036 (50%)]	Loss: 0.067195
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 768 [0/20036 (0%)]	Loss: 0.139228
Train epoch: 768 [326740/20036 (50%)]	Loss: 0.090897
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 769 [0/20036 (0%)]	Loss: 0.076660
Train epoch: 769 [327740/20036 (50%)]	Loss: 0.081534
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 770 [0/20036 (0%)]	Loss: 0.065815
Train epoch: 770 [325280/20036 (50%)]	Loss: 0.078902
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 771 [0/20036 (0%)]	Loss: 0.070076
Train epoch: 771 [327780/20036 (50%)]	Loss: 0.079580
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 772 [0/20036 (0%)]	Loss: 0.077412
Train epoch: 772 [326680/20036 (50%)]	Loss: 0.068106
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 773 [0/20036 (0%)]	Loss: 0.079118
Train epoch: 773 [325540/20036 (50%)]	Loss: 0.086429
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 774 [0/20036 (0%)]	Loss: 0.146967
Train epoch: 774 [325440/20036 (50%)]	Loss: 0.099621
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 775 [0/20036 (0%)]	Loss: 0.058646
Train epoch: 775 [329400/20036 (50%)]	Loss: 0.057192
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 776 [0/20036 (0%)]	Loss: 0.127649
Train epoch: 776 [324760/20036 (50%)]	Loss: 0.071480
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 777 [0/20036 (0%)]	Loss: 0.067086
Train epoch: 777 [323100/20036 (50%)]	Loss: 0.066671
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 778 [0/20036 (0%)]	Loss: 0.089331
Train epoch: 778 [331780/20036 (50%)]	Loss: 0.082334
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 779 [0/20036 (0%)]	Loss: 0.067457
Train epoch: 779 [331520/20036 (50%)]	Loss: 0.113795
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 780 [0/20036 (0%)]	Loss: 0.179893
Train epoch: 780 [333500/20036 (50%)]	Loss: 0.079882
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 781 [0/20036 (0%)]	Loss: 0.117737
Train epoch: 781 [326420/20036 (50%)]	Loss: 0.070419
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 782 [0/20036 (0%)]	Loss: 0.078272
Train epoch: 782 [323400/20036 (50%)]	Loss: 0.070285
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 783 [0/20036 (0%)]	Loss: 0.083266
Train epoch: 783 [327580/20036 (50%)]	Loss: 0.100019
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 784 [0/20036 (0%)]	Loss: 0.103034
Train epoch: 784 [331620/20036 (50%)]	Loss: 0.103190
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 785 [0/20036 (0%)]	Loss: 0.117947
Train epoch: 785 [326500/20036 (50%)]	Loss: 0.122605
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 786 [0/20036 (0%)]	Loss: 0.088936
Train epoch: 786 [329320/20036 (50%)]	Loss: 0.083679
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 787 [0/20036 (0%)]	Loss: 0.081520
Train epoch: 787 [329040/20036 (50%)]	Loss: 0.082630
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 788 [0/20036 (0%)]	Loss: 0.064018
Train epoch: 788 [327340/20036 (50%)]	Loss: 0.070494
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 789 [0/20036 (0%)]	Loss: 0.102394
Train epoch: 789 [326920/20036 (50%)]	Loss: 0.079624
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 790 [0/20036 (0%)]	Loss: 0.068997
Train epoch: 790 [325960/20036 (50%)]	Loss: 0.089613
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 791 [0/20036 (0%)]	Loss: 0.136725
Train epoch: 791 [333940/20036 (50%)]	Loss: 0.085314
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 792 [0/20036 (0%)]	Loss: 0.083358
Train epoch: 792 [330440/20036 (50%)]	Loss: 0.111205
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 793 [0/20036 (0%)]	Loss: 0.065990
Train epoch: 793 [326820/20036 (50%)]	Loss: 0.080170
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 794 [0/20036 (0%)]	Loss: 0.117822
Train epoch: 794 [329900/20036 (50%)]	Loss: 0.105228
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 795 [0/20036 (0%)]	Loss: 0.104491
Train epoch: 795 [324520/20036 (50%)]	Loss: 0.083875
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 796 [0/20036 (0%)]	Loss: 0.075816
Train epoch: 796 [326120/20036 (50%)]	Loss: 0.067343
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 797 [0/20036 (0%)]	Loss: 0.087965
Train epoch: 797 [326980/20036 (50%)]	Loss: 0.082620
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 798 [0/20036 (0%)]	Loss: 0.102200
Train epoch: 798 [328460/20036 (50%)]	Loss: 0.077884
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 799 [0/20036 (0%)]	Loss: 0.064536
Train epoch: 799 [327220/20036 (50%)]	Loss: 0.068539
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 800 [0/20036 (0%)]	Loss: 0.082028
Train epoch: 800 [324620/20036 (50%)]	Loss: 0.093898
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 801 [0/20036 (0%)]	Loss: 0.071384
Train epoch: 801 [331220/20036 (50%)]	Loss: 0.066804
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 802 [0/20036 (0%)]	Loss: 0.077703
Train epoch: 802 [329840/20036 (50%)]	Loss: 0.064109
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 803 [0/20036 (0%)]	Loss: 0.080579
Train epoch: 803 [328180/20036 (50%)]	Loss: 0.067923
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 804 [0/20036 (0%)]	Loss: 0.080947
Train epoch: 804 [329980/20036 (50%)]	Loss: 0.078812
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 805 [0/20036 (0%)]	Loss: 0.100273
Train epoch: 805 [331760/20036 (50%)]	Loss: 0.082693
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 806 [0/20036 (0%)]	Loss: 0.084814
Train epoch: 806 [324620/20036 (50%)]	Loss: 0.064538
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 807 [0/20036 (0%)]	Loss: 0.086979
Train epoch: 807 [330740/20036 (50%)]	Loss: 0.062093
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 808 [0/20036 (0%)]	Loss: 0.093661
Train epoch: 808 [320940/20036 (50%)]	Loss: 0.080045
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 809 [0/20036 (0%)]	Loss: 0.093393
Train epoch: 809 [326240/20036 (50%)]	Loss: 0.068312
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 810 [0/20036 (0%)]	Loss: 0.096633
Train epoch: 810 [326300/20036 (50%)]	Loss: 0.085081
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 811 [0/20036 (0%)]	Loss: 0.073703
Train epoch: 811 [328680/20036 (50%)]	Loss: 0.090339
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 812 [0/20036 (0%)]	Loss: 0.079623
Train epoch: 812 [325920/20036 (50%)]	Loss: 0.082573
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 813 [0/20036 (0%)]	Loss: 0.071097
Train epoch: 813 [327560/20036 (50%)]	Loss: 0.096655
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 814 [0/20036 (0%)]	Loss: 0.096051
Train epoch: 814 [331920/20036 (50%)]	Loss: 0.080917
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 815 [0/20036 (0%)]	Loss: 0.114866
Train epoch: 815 [330640/20036 (50%)]	Loss: 0.094758
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 816 [0/20036 (0%)]	Loss: 0.067975
Train epoch: 816 [327400/20036 (50%)]	Loss: 0.065890
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 817 [0/20036 (0%)]	Loss: 0.078297
Train epoch: 817 [329240/20036 (50%)]	Loss: 0.097999
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 818 [0/20036 (0%)]	Loss: 0.085337
Train epoch: 818 [323380/20036 (50%)]	Loss: 0.080067
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 819 [0/20036 (0%)]	Loss: 0.075165
Train epoch: 819 [327540/20036 (50%)]	Loss: 0.109776
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 820 [0/20036 (0%)]	Loss: 0.080333
Train epoch: 820 [323540/20036 (50%)]	Loss: 0.063253
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 821 [0/20036 (0%)]	Loss: 0.066244
Train epoch: 821 [329260/20036 (50%)]	Loss: 0.072064
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 822 [0/20036 (0%)]	Loss: 0.091750
Train epoch: 822 [328300/20036 (50%)]	Loss: 0.085150
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 823 [0/20036 (0%)]	Loss: 0.074846
Train epoch: 823 [328260/20036 (50%)]	Loss: 0.083953
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 824 [0/20036 (0%)]	Loss: 0.090312
Train epoch: 824 [331400/20036 (50%)]	Loss: 0.085982
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 825 [0/20036 (0%)]	Loss: 0.050867
Train epoch: 825 [328580/20036 (50%)]	Loss: 0.097816
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 826 [0/20036 (0%)]	Loss: 0.089698
Train epoch: 826 [329080/20036 (50%)]	Loss: 0.090570
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 827 [0/20036 (0%)]	Loss: 0.064584
Train epoch: 827 [326620/20036 (50%)]	Loss: 0.099871
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 828 [0/20036 (0%)]	Loss: 0.073641
Train epoch: 828 [330820/20036 (50%)]	Loss: 0.090293
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 829 [0/20036 (0%)]	Loss: 0.106252
Train epoch: 829 [327320/20036 (50%)]	Loss: 0.086027
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 830 [0/20036 (0%)]	Loss: 0.087280
Train epoch: 830 [330260/20036 (50%)]	Loss: 0.087090
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 831 [0/20036 (0%)]	Loss: 0.082972
Train epoch: 831 [329620/20036 (50%)]	Loss: 0.077545
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 832 [0/20036 (0%)]	Loss: 0.086689
Train epoch: 832 [329600/20036 (50%)]	Loss: 0.083271
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 833 [0/20036 (0%)]	Loss: 0.081102
Train epoch: 833 [337060/20036 (50%)]	Loss: 0.074454
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 834 [0/20036 (0%)]	Loss: 0.118926
Train epoch: 834 [328820/20036 (50%)]	Loss: 0.068935
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 835 [0/20036 (0%)]	Loss: 0.133932
Train epoch: 835 [325020/20036 (50%)]	Loss: 0.100985
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 836 [0/20036 (0%)]	Loss: 0.081675
Train epoch: 836 [330780/20036 (50%)]	Loss: 0.084910
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 837 [0/20036 (0%)]	Loss: 0.065755
Train epoch: 837 [325640/20036 (50%)]	Loss: 0.078386
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 838 [0/20036 (0%)]	Loss: 0.113134
Train epoch: 838 [331540/20036 (50%)]	Loss: 0.074389
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 839 [0/20036 (0%)]	Loss: 0.119185
Train epoch: 839 [328520/20036 (50%)]	Loss: 0.079523
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 840 [0/20036 (0%)]	Loss: 0.085086
Train epoch: 840 [330760/20036 (50%)]	Loss: 0.094260
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 841 [0/20036 (0%)]	Loss: 0.084806
Train epoch: 841 [330980/20036 (50%)]	Loss: 0.078677
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 842 [0/20036 (0%)]	Loss: 0.075582
Train epoch: 842 [326940/20036 (50%)]	Loss: 0.083947
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 843 [0/20036 (0%)]	Loss: 0.093045
Train epoch: 843 [330520/20036 (50%)]	Loss: 0.070591
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 844 [0/20036 (0%)]	Loss: 0.092591
Train epoch: 844 [329240/20036 (50%)]	Loss: 0.078767
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 845 [0/20036 (0%)]	Loss: 0.056728
Train epoch: 845 [330940/20036 (50%)]	Loss: 0.056537
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 846 [0/20036 (0%)]	Loss: 0.073232
Train epoch: 846 [328920/20036 (50%)]	Loss: 0.082337
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 847 [0/20036 (0%)]	Loss: 0.107268
Train epoch: 847 [325840/20036 (50%)]	Loss: 0.103265
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 848 [0/20036 (0%)]	Loss: 0.139037
Train epoch: 848 [327740/20036 (50%)]	Loss: 0.077565
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 849 [0/20036 (0%)]	Loss: 0.094869
Train epoch: 849 [327340/20036 (50%)]	Loss: 0.072718
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 850 [0/20036 (0%)]	Loss: 0.091593
Train epoch: 850 [327860/20036 (50%)]	Loss: 0.133475
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 851 [0/20036 (0%)]	Loss: 0.072189
Train epoch: 851 [331180/20036 (50%)]	Loss: 0.093173
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 852 [0/20036 (0%)]	Loss: 0.088205
Train epoch: 852 [333900/20036 (50%)]	Loss: 0.098780
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 853 [0/20036 (0%)]	Loss: 0.082007
Train epoch: 853 [331880/20036 (50%)]	Loss: 0.069354
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 854 [0/20036 (0%)]	Loss: 0.092158
Train epoch: 854 [329820/20036 (50%)]	Loss: 0.085640
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 855 [0/20036 (0%)]	Loss: 0.078871
Train epoch: 855 [329200/20036 (50%)]	Loss: 0.069800
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 856 [0/20036 (0%)]	Loss: 0.059396
Train epoch: 856 [329320/20036 (50%)]	Loss: 0.095321
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 857 [0/20036 (0%)]	Loss: 0.112490
Train epoch: 857 [327440/20036 (50%)]	Loss: 0.111527
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 858 [0/20036 (0%)]	Loss: 0.135950
Train epoch: 858 [328900/20036 (50%)]	Loss: 0.061529
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 859 [0/20036 (0%)]	Loss: 0.076629
Train epoch: 859 [327960/20036 (50%)]	Loss: 0.078589
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 860 [0/20036 (0%)]	Loss: 0.082581
Train epoch: 860 [330240/20036 (50%)]	Loss: 0.094528
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 861 [0/20036 (0%)]	Loss: 0.083745
Train epoch: 861 [332160/20036 (50%)]	Loss: 0.074387
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 862 [0/20036 (0%)]	Loss: 0.054169
Train epoch: 862 [328520/20036 (50%)]	Loss: 0.063402
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 863 [0/20036 (0%)]	Loss: 0.094316
Train epoch: 863 [330260/20036 (50%)]	Loss: 0.087553
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 864 [0/20036 (0%)]	Loss: 0.090980
Train epoch: 864 [327680/20036 (50%)]	Loss: 0.067567
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 865 [0/20036 (0%)]	Loss: 0.141845
Train epoch: 865 [329420/20036 (50%)]	Loss: 0.093867
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 866 [0/20036 (0%)]	Loss: 0.084337
Train epoch: 866 [334400/20036 (50%)]	Loss: 0.086312
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 867 [0/20036 (0%)]	Loss: 0.064806
Train epoch: 867 [323440/20036 (50%)]	Loss: 0.061436
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 868 [0/20036 (0%)]	Loss: 0.077419
Train epoch: 868 [325840/20036 (50%)]	Loss: 0.098209
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 869 [0/20036 (0%)]	Loss: 0.063463
Train epoch: 869 [331300/20036 (50%)]	Loss: 0.085767
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 870 [0/20036 (0%)]	Loss: 0.081842
Train epoch: 870 [332440/20036 (50%)]	Loss: 0.097812
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 871 [0/20036 (0%)]	Loss: 0.084288
Train epoch: 871 [322320/20036 (50%)]	Loss: 0.080139
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 872 [0/20036 (0%)]	Loss: 0.142496
Train epoch: 872 [329680/20036 (50%)]	Loss: 0.059426
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 873 [0/20036 (0%)]	Loss: 0.123388
Train epoch: 873 [329920/20036 (50%)]	Loss: 0.072200
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 874 [0/20036 (0%)]	Loss: 0.062026
Train epoch: 874 [327500/20036 (50%)]	Loss: 0.077664
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 875 [0/20036 (0%)]	Loss: 0.080473
Train epoch: 875 [329140/20036 (50%)]	Loss: 0.079152
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 876 [0/20036 (0%)]	Loss: 0.071249
Train epoch: 876 [326820/20036 (50%)]	Loss: 0.069686
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 877 [0/20036 (0%)]	Loss: 0.067155
Train epoch: 877 [329680/20036 (50%)]	Loss: 0.048004
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 878 [0/20036 (0%)]	Loss: 0.068532
Train epoch: 878 [325920/20036 (50%)]	Loss: 0.071503
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 879 [0/20036 (0%)]	Loss: 0.073565
Train epoch: 879 [329520/20036 (50%)]	Loss: 0.071289
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 880 [0/20036 (0%)]	Loss: 0.083526
Train epoch: 880 [327200/20036 (50%)]	Loss: 0.067709
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 881 [0/20036 (0%)]	Loss: 0.079646
Train epoch: 881 [331800/20036 (50%)]	Loss: 0.092619
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 882 [0/20036 (0%)]	Loss: 0.057894
Train epoch: 882 [325060/20036 (50%)]	Loss: 0.076865
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 883 [0/20036 (0%)]	Loss: 0.090350
Train epoch: 883 [325000/20036 (50%)]	Loss: 0.095455
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 884 [0/20036 (0%)]	Loss: 0.094717
Train epoch: 884 [323280/20036 (50%)]	Loss: 0.084982
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 885 [0/20036 (0%)]	Loss: 0.088119
Train epoch: 885 [327900/20036 (50%)]	Loss: 0.070403
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 886 [0/20036 (0%)]	Loss: 0.082627
Train epoch: 886 [328160/20036 (50%)]	Loss: 0.077792
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 887 [0/20036 (0%)]	Loss: 0.052232
Train epoch: 887 [334080/20036 (50%)]	Loss: 0.068996
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 888 [0/20036 (0%)]	Loss: 0.069992
Train epoch: 888 [328260/20036 (50%)]	Loss: 0.123105
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 889 [0/20036 (0%)]	Loss: 0.123782
Train epoch: 889 [331740/20036 (50%)]	Loss: 0.085338
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 890 [0/20036 (0%)]	Loss: 0.106003
Train epoch: 890 [326060/20036 (50%)]	Loss: 0.048477
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 891 [0/20036 (0%)]	Loss: 0.068677
Train epoch: 891 [327580/20036 (50%)]	Loss: 0.090197
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 892 [0/20036 (0%)]	Loss: 0.053904
Train epoch: 892 [330660/20036 (50%)]	Loss: 0.061577
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 893 [0/20036 (0%)]	Loss: 0.133346
Train epoch: 893 [324240/20036 (50%)]	Loss: 0.086345
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 894 [0/20036 (0%)]	Loss: 0.076911
Train epoch: 894 [328160/20036 (50%)]	Loss: 0.091713
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 895 [0/20036 (0%)]	Loss: 0.055441
Train epoch: 895 [330700/20036 (50%)]	Loss: 0.060721
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 896 [0/20036 (0%)]	Loss: 0.100779
Train epoch: 896 [328200/20036 (50%)]	Loss: 0.070520
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 897 [0/20036 (0%)]	Loss: 0.091824
Train epoch: 897 [332440/20036 (50%)]	Loss: 0.072861
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 898 [0/20036 (0%)]	Loss: 0.078104
Train epoch: 898 [328360/20036 (50%)]	Loss: 0.099595
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 899 [0/20036 (0%)]	Loss: 0.102338
Train epoch: 899 [327320/20036 (50%)]	Loss: 0.081159
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 900 [0/20036 (0%)]	Loss: 0.065689
Train epoch: 900 [331620/20036 (50%)]	Loss: 0.057388
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 901 [0/20036 (0%)]	Loss: 0.077899
Train epoch: 901 [327240/20036 (50%)]	Loss: 0.092295
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 902 [0/20036 (0%)]	Loss: 0.087449
Train epoch: 902 [328980/20036 (50%)]	Loss: 0.077831
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 903 [0/20036 (0%)]	Loss: 0.066826
Train epoch: 903 [326840/20036 (50%)]	Loss: 0.088439
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 904 [0/20036 (0%)]	Loss: 0.098751
Train epoch: 904 [326760/20036 (50%)]	Loss: 0.062336
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 905 [0/20036 (0%)]	Loss: 0.055111
Train epoch: 905 [327300/20036 (50%)]	Loss: 0.072870
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 906 [0/20036 (0%)]	Loss: 0.099438
Train epoch: 906 [328020/20036 (50%)]	Loss: 0.067309
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 907 [0/20036 (0%)]	Loss: 0.091402
Train epoch: 907 [325800/20036 (50%)]	Loss: 0.079890
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 908 [0/20036 (0%)]	Loss: 0.069447
Train epoch: 908 [326040/20036 (50%)]	Loss: 0.069399
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 909 [0/20036 (0%)]	Loss: 0.091940
Train epoch: 909 [327440/20036 (50%)]	Loss: 0.069774
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 910 [0/20036 (0%)]	Loss: 0.067184
Train epoch: 910 [326800/20036 (50%)]	Loss: 0.070263
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 911 [0/20036 (0%)]	Loss: 0.060604
Train epoch: 911 [330440/20036 (50%)]	Loss: 0.067148
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 912 [0/20036 (0%)]	Loss: 0.051530
Train epoch: 912 [332400/20036 (50%)]	Loss: 0.112951
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 913 [0/20036 (0%)]	Loss: 0.094247
Train epoch: 913 [328020/20036 (50%)]	Loss: 0.066986
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 914 [0/20036 (0%)]	Loss: 0.067422
Train epoch: 914 [325340/20036 (50%)]	Loss: 0.065178
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 915 [0/20036 (0%)]	Loss: 0.072825
Train epoch: 915 [334680/20036 (50%)]	Loss: 0.063518
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 916 [0/20036 (0%)]	Loss: 0.155284
Train epoch: 916 [328680/20036 (50%)]	Loss: 0.067196
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 917 [0/20036 (0%)]	Loss: 0.075671
Train epoch: 917 [328540/20036 (50%)]	Loss: 0.080340
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 918 [0/20036 (0%)]	Loss: 0.060712
Train epoch: 918 [326760/20036 (50%)]	Loss: 0.077684
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 919 [0/20036 (0%)]	Loss: 0.069130
Train epoch: 919 [329720/20036 (50%)]	Loss: 0.068655
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 920 [0/20036 (0%)]	Loss: 0.093380
Train epoch: 920 [325820/20036 (50%)]	Loss: 0.092731
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 921 [0/20036 (0%)]	Loss: 0.100910
Train epoch: 921 [329720/20036 (50%)]	Loss: 0.070559
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 922 [0/20036 (0%)]	Loss: 0.070762
Train epoch: 922 [323560/20036 (50%)]	Loss: 0.076156
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 923 [0/20036 (0%)]	Loss: 0.070461
Train epoch: 923 [327920/20036 (50%)]	Loss: 0.061774
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 924 [0/20036 (0%)]	Loss: 0.082406
Train epoch: 924 [325800/20036 (50%)]	Loss: 0.051357
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 925 [0/20036 (0%)]	Loss: 0.058883
Train epoch: 925 [327120/20036 (50%)]	Loss: 0.065646
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 926 [0/20036 (0%)]	Loss: 0.092547
Train epoch: 926 [324880/20036 (50%)]	Loss: 0.086400
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 927 [0/20036 (0%)]	Loss: 0.074164
Train epoch: 927 [325720/20036 (50%)]	Loss: 0.079599
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 928 [0/20036 (0%)]	Loss: 0.063345
Train epoch: 928 [331120/20036 (50%)]	Loss: 0.070063
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 929 [0/20036 (0%)]	Loss: 0.063304
Train epoch: 929 [326920/20036 (50%)]	Loss: 0.065445
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 930 [0/20036 (0%)]	Loss: 0.068621
Train epoch: 930 [329420/20036 (50%)]	Loss: 0.075448
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 931 [0/20036 (0%)]	Loss: 0.054493
Train epoch: 931 [327720/20036 (50%)]	Loss: 0.055430
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 932 [0/20036 (0%)]	Loss: 0.062422
Train epoch: 932 [329360/20036 (50%)]	Loss: 0.070444
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 933 [0/20036 (0%)]	Loss: 0.080345
Train epoch: 933 [330380/20036 (50%)]	Loss: 0.063223
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 934 [0/20036 (0%)]	Loss: 0.056484
Train epoch: 934 [327340/20036 (50%)]	Loss: 0.076918
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 935 [0/20036 (0%)]	Loss: 0.100211
Train epoch: 935 [329320/20036 (50%)]	Loss: 0.077642
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 936 [0/20036 (0%)]	Loss: 0.089853
Train epoch: 936 [332380/20036 (50%)]	Loss: 0.070293
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 937 [0/20036 (0%)]	Loss: 0.097924
Train epoch: 937 [327580/20036 (50%)]	Loss: 0.061177
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 938 [0/20036 (0%)]	Loss: 0.056431
Train epoch: 938 [332300/20036 (50%)]	Loss: 0.092223
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 939 [0/20036 (0%)]	Loss: 0.094233
Train epoch: 939 [324560/20036 (50%)]	Loss: 0.060982
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 940 [0/20036 (0%)]	Loss: 0.075269
Train epoch: 940 [325680/20036 (50%)]	Loss: 0.087002
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 941 [0/20036 (0%)]	Loss: 0.072999
Train epoch: 941 [322740/20036 (50%)]	Loss: 0.088389
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 942 [0/20036 (0%)]	Loss: 0.073854
Train epoch: 942 [332920/20036 (50%)]	Loss: 0.070704
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 943 [0/20036 (0%)]	Loss: 0.083013
Train epoch: 943 [330720/20036 (50%)]	Loss: 0.054751
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 944 [0/20036 (0%)]	Loss: 0.051842
Train epoch: 944 [331260/20036 (50%)]	Loss: 0.076324
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 945 [0/20036 (0%)]	Loss: 0.073445
Train epoch: 945 [330700/20036 (50%)]	Loss: 0.084429
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 946 [0/20036 (0%)]	Loss: 0.092442
Train epoch: 946 [326580/20036 (50%)]	Loss: 0.070321
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 947 [0/20036 (0%)]	Loss: 0.066184
Train epoch: 947 [328940/20036 (50%)]	Loss: 0.062351
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 948 [0/20036 (0%)]	Loss: 0.079792
Train epoch: 948 [331940/20036 (50%)]	Loss: 0.074230
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 949 [0/20036 (0%)]	Loss: 0.062033
Train epoch: 949 [328540/20036 (50%)]	Loss: 0.072416
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 950 [0/20036 (0%)]	Loss: 0.071583
Train epoch: 950 [328700/20036 (50%)]	Loss: 0.087571
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 951 [0/20036 (0%)]	Loss: 0.073661
Train epoch: 951 [326360/20036 (50%)]	Loss: 0.056082
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 952 [0/20036 (0%)]	Loss: 0.052616
Train epoch: 952 [332420/20036 (50%)]	Loss: 0.066291
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 953 [0/20036 (0%)]	Loss: 0.051931
Train epoch: 953 [327700/20036 (50%)]	Loss: 0.110066
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 954 [0/20036 (0%)]	Loss: 0.055304
Train epoch: 954 [324400/20036 (50%)]	Loss: 0.065223
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 955 [0/20036 (0%)]	Loss: 0.078507
Train epoch: 955 [325960/20036 (50%)]	Loss: 0.085054
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 956 [0/20036 (0%)]	Loss: 0.085330
Train epoch: 956 [331040/20036 (50%)]	Loss: 0.092673
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 957 [0/20036 (0%)]	Loss: 0.072039
Train epoch: 957 [327700/20036 (50%)]	Loss: 0.055130
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 958 [0/20036 (0%)]	Loss: 0.100649
Train epoch: 958 [329780/20036 (50%)]	Loss: 0.083441
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 959 [0/20036 (0%)]	Loss: 0.072489
Train epoch: 959 [324980/20036 (50%)]	Loss: 0.085433
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 960 [0/20036 (0%)]	Loss: 0.079433
Train epoch: 960 [329020/20036 (50%)]	Loss: 0.072981
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 961 [0/20036 (0%)]	Loss: 0.071656
Train epoch: 961 [333280/20036 (50%)]	Loss: 0.065934
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 962 [0/20036 (0%)]	Loss: 0.086154
Train epoch: 962 [329540/20036 (50%)]	Loss: 0.081592
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 963 [0/20036 (0%)]	Loss: 0.072114
Train epoch: 963 [331780/20036 (50%)]	Loss: 0.078316
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 964 [0/20036 (0%)]	Loss: 0.076310
Train epoch: 964 [326440/20036 (50%)]	Loss: 0.061344
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 965 [0/20036 (0%)]	Loss: 0.059505
Train epoch: 965 [328520/20036 (50%)]	Loss: 0.093712
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 966 [0/20036 (0%)]	Loss: 0.104408
Train epoch: 966 [329420/20036 (50%)]	Loss: 0.065305
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 967 [0/20036 (0%)]	Loss: 0.077064
Train epoch: 967 [331680/20036 (50%)]	Loss: 0.109910
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 968 [0/20036 (0%)]	Loss: 0.074625
Train epoch: 968 [327620/20036 (50%)]	Loss: 0.117675
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 969 [0/20036 (0%)]	Loss: 0.077788
Train epoch: 969 [329720/20036 (50%)]	Loss: 0.097556
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 970 [0/20036 (0%)]	Loss: 0.072086
Train epoch: 970 [330660/20036 (50%)]	Loss: 0.050674
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 971 [0/20036 (0%)]	Loss: 0.072493
Train epoch: 971 [325760/20036 (50%)]	Loss: 0.061723
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 972 [0/20036 (0%)]	Loss: 0.090771
Train epoch: 972 [327760/20036 (50%)]	Loss: 0.090178
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 973 [0/20036 (0%)]	Loss: 0.088787
Train epoch: 973 [324860/20036 (50%)]	Loss: 0.079891
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 974 [0/20036 (0%)]	Loss: 0.081792
Train epoch: 974 [327280/20036 (50%)]	Loss: 0.064011
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 975 [0/20036 (0%)]	Loss: 0.068909
Train epoch: 975 [329500/20036 (50%)]	Loss: 0.068204
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 976 [0/20036 (0%)]	Loss: 0.101974
Train epoch: 976 [325360/20036 (50%)]	Loss: 0.064183
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 977 [0/20036 (0%)]	Loss: 0.080969
Train epoch: 977 [321940/20036 (50%)]	Loss: 0.067875
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 978 [0/20036 (0%)]	Loss: 0.054344
Train epoch: 978 [326540/20036 (50%)]	Loss: 0.054015
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 979 [0/20036 (0%)]	Loss: 0.052564
Train epoch: 979 [328060/20036 (50%)]	Loss: 0.057126
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 980 [0/20036 (0%)]	Loss: 0.093048
Train epoch: 980 [328280/20036 (50%)]	Loss: 0.081621
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 981 [0/20036 (0%)]	Loss: 0.065350
Train epoch: 981 [326600/20036 (50%)]	Loss: 0.071370
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 982 [0/20036 (0%)]	Loss: 0.050926
Train epoch: 982 [326880/20036 (50%)]	Loss: 0.054375
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 983 [0/20036 (0%)]	Loss: 0.059032
Train epoch: 983 [326840/20036 (50%)]	Loss: 0.059494
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 984 [0/20036 (0%)]	Loss: 0.087707
Train epoch: 984 [334200/20036 (50%)]	Loss: 0.060556
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 985 [0/20036 (0%)]	Loss: 0.070825
Train epoch: 985 [324860/20036 (50%)]	Loss: 0.082548
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 986 [0/20036 (0%)]	Loss: 0.062705
Train epoch: 986 [326540/20036 (50%)]	Loss: 0.061385
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 987 [0/20036 (0%)]	Loss: 0.080105
Train epoch: 987 [326680/20036 (50%)]	Loss: 0.073303
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 988 [0/20036 (0%)]	Loss: 0.099864
Train epoch: 988 [330420/20036 (50%)]	Loss: 0.080393
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 989 [0/20036 (0%)]	Loss: 0.066963
Train epoch: 989 [327540/20036 (50%)]	Loss: 0.059475
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 990 [0/20036 (0%)]	Loss: 0.074740
Train epoch: 990 [331360/20036 (50%)]	Loss: 0.048699
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 991 [0/20036 (0%)]	Loss: 0.114374
Train epoch: 991 [327700/20036 (50%)]	Loss: 0.064468
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 992 [0/20036 (0%)]	Loss: 0.060101
Train epoch: 992 [330840/20036 (50%)]	Loss: 0.053820
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 993 [0/20036 (0%)]	Loss: 0.066019
Train epoch: 993 [327080/20036 (50%)]	Loss: 0.083530
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 994 [0/20036 (0%)]	Loss: 0.090891
Train epoch: 994 [330280/20036 (50%)]	Loss: 0.058685
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 995 [0/20036 (0%)]	Loss: 0.063053
Train epoch: 995 [325140/20036 (50%)]	Loss: 0.106204
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 996 [0/20036 (0%)]	Loss: 0.097439
Train epoch: 996 [324560/20036 (50%)]	Loss: 0.055310
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 997 [0/20036 (0%)]	Loss: 0.091105
Train epoch: 997 [331460/20036 (50%)]	Loss: 0.080189
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 998 [0/20036 (0%)]	Loss: 0.082005
Train epoch: 998 [332680/20036 (50%)]	Loss: 0.080766
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 999 [0/20036 (0%)]	Loss: 0.059254
Train epoch: 999 [329020/20036 (50%)]	Loss: 0.063635
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Training on 20036 samples...
Train epoch: 1000 [0/20036 (0%)]	Loss: 0.109747
Train epoch: 1000 [326240/20036 (50%)]	Loss: 0.082264
predicting for valid data
Make prediction for 5010 samples...
0.26735047 No improvement since epoch  607 ; best_test_mse,best_test_ci: 0.26735047 0.8780001265040931 GINConvNet davis
Elapsed time: 2421 seconds
