Date
Mon Feb  5 11:33:11 AM EST 2024
cuda_name: cuda:0
Learning rate:  0.0005
Epochs:  1000

running on  GINConvNet_kiba
Pre-processed data found: data/processed/kiba_train.pt, loading ...
Pre-processed data found: data/processed/kiba_test.pt, loading ...
Training on 78836 samples...
Train epoch: 1 [0/78836 (0%)]	Loss: 136.541183
Train epoch: 1 [284920/78836 (13%)]	Loss: 4.802539
Train epoch: 1 [552280/78836 (26%)]	Loss: 1.994862
Train epoch: 1 [839580/78836 (39%)]	Loss: 1.327811
Train epoch: 1 [1106320/78836 (52%)]	Loss: 1.496143
Train epoch: 1 [1412100/78836 (65%)]	Loss: 1.434649
Train epoch: 1 [1668480/78836 (78%)]	Loss: 1.094045
Train epoch: 1 [1947680/78836 (91%)]	Loss: 1.245608
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  1 ; best_test_mse,best_test_ci: 0.565756 0.6888755287700637 GINConvNet kiba
Training on 78836 samples...
Train epoch: 2 [0/78836 (0%)]	Loss: 1.342075
Train epoch: 2 [276740/78836 (13%)]	Loss: 1.209629
Train epoch: 2 [553760/78836 (26%)]	Loss: 0.951258
Train epoch: 2 [830220/78836 (39%)]	Loss: 0.970499
Train epoch: 2 [1090880/78836 (52%)]	Loss: 1.342498
Train epoch: 2 [1381100/78836 (65%)]	Loss: 1.088511
Train epoch: 2 [1683120/78836 (78%)]	Loss: 1.118153
Train epoch: 2 [1967560/78836 (91%)]	Loss: 1.507493
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  2 ; best_test_mse,best_test_ci: 0.53010267 0.7012905856591538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 3 [0/78836 (0%)]	Loss: 0.935617
Train epoch: 3 [276740/78836 (13%)]	Loss: 0.946632
Train epoch: 3 [569480/78836 (26%)]	Loss: 1.066216
Train epoch: 3 [842760/78836 (39%)]	Loss: 0.992497
Train epoch: 3 [1118880/78836 (52%)]	Loss: 1.120673
Train epoch: 3 [1391600/78836 (65%)]	Loss: 0.888399
Train epoch: 3 [1697400/78836 (78%)]	Loss: 1.067514
Train epoch: 3 [1990660/78836 (91%)]	Loss: 0.997394
predicting for valid data
Make prediction for 19709 samples...
0.53010267 No improvement since epoch  2 ; best_test_mse,best_test_ci: 0.53010267 0.7012905856591538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 4 [0/78836 (0%)]	Loss: 0.887722
Train epoch: 4 [282220/78836 (13%)]	Loss: 1.330228
Train epoch: 4 [548120/78836 (26%)]	Loss: 1.105044
Train epoch: 4 [849300/78836 (39%)]	Loss: 1.161198
Train epoch: 4 [1087360/78836 (52%)]	Loss: 0.922973
Train epoch: 4 [1399400/78836 (65%)]	Loss: 1.075877
Train epoch: 4 [1679160/78836 (78%)]	Loss: 1.101622
Train epoch: 4 [1941240/78836 (91%)]	Loss: 0.853789
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  4 ; best_test_mse,best_test_ci: 0.4916988 0.7158882226355915 GINConvNet kiba
Training on 78836 samples...
Train epoch: 5 [0/78836 (0%)]	Loss: 0.859368
Train epoch: 5 [276900/78836 (13%)]	Loss: 0.985932
Train epoch: 5 [556400/78836 (26%)]	Loss: 0.872912
Train epoch: 5 [838380/78836 (39%)]	Loss: 0.870092
Train epoch: 5 [1125360/78836 (52%)]	Loss: 1.226800
Train epoch: 5 [1419300/78836 (65%)]	Loss: 1.142905
Train epoch: 5 [1651560/78836 (78%)]	Loss: 0.869998
Train epoch: 5 [1971900/78836 (91%)]	Loss: 0.852584
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 6 [0/78836 (0%)]	Loss: 1.033125
Train epoch: 6 [278000/78836 (13%)]	Loss: 0.982636
Train epoch: 6 [569120/78836 (26%)]	Loss: 0.907731
Train epoch: 6 [823320/78836 (39%)]	Loss: 0.764316
Train epoch: 6 [1122640/78836 (52%)]	Loss: 0.903071
Train epoch: 6 [1398300/78836 (65%)]	Loss: 1.042747
Train epoch: 6 [1671720/78836 (78%)]	Loss: 0.955523
Train epoch: 6 [2003540/78836 (91%)]	Loss: 0.987319
predicting for valid data
Make prediction for 19709 samples...
0.45598716 No improvement since epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 7 [0/78836 (0%)]	Loss: 1.655327
Train epoch: 7 [280560/78836 (13%)]	Loss: 0.891131
Train epoch: 7 [561120/78836 (26%)]	Loss: 0.699905
Train epoch: 7 [825660/78836 (39%)]	Loss: 1.015363
Train epoch: 7 [1136640/78836 (52%)]	Loss: 0.809977
Train epoch: 7 [1380300/78836 (65%)]	Loss: 1.143555
Train epoch: 7 [1674000/78836 (78%)]	Loss: 1.084116
Train epoch: 7 [1979460/78836 (91%)]	Loss: 0.852781
predicting for valid data
Make prediction for 19709 samples...
0.45598716 No improvement since epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 8 [0/78836 (0%)]	Loss: 0.777287
Train epoch: 8 [280920/78836 (13%)]	Loss: 0.905400
Train epoch: 8 [565920/78836 (26%)]	Loss: 1.200151
Train epoch: 8 [841740/78836 (39%)]	Loss: 0.743753
Train epoch: 8 [1125760/78836 (52%)]	Loss: 0.778979
Train epoch: 8 [1413300/78836 (65%)]	Loss: 0.830449
Train epoch: 8 [1660080/78836 (78%)]	Loss: 0.867570
Train epoch: 8 [1986600/78836 (91%)]	Loss: 0.986789
predicting for valid data
Make prediction for 19709 samples...
0.45598716 No improvement since epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 9 [0/78836 (0%)]	Loss: 1.394274
Train epoch: 9 [280780/78836 (13%)]	Loss: 0.804882
Train epoch: 9 [574080/78836 (26%)]	Loss: 0.790419
Train epoch: 9 [831780/78836 (39%)]	Loss: 0.845689
Train epoch: 9 [1124080/78836 (52%)]	Loss: 0.857629
Train epoch: 9 [1355600/78836 (65%)]	Loss: 0.772057
Train epoch: 9 [1671960/78836 (78%)]	Loss: 0.909047
Train epoch: 9 [1934380/78836 (91%)]	Loss: 1.051035
predicting for valid data
Make prediction for 19709 samples...
0.45598716 No improvement since epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 10 [0/78836 (0%)]	Loss: 0.917287
Train epoch: 10 [282860/78836 (13%)]	Loss: 0.803965
Train epoch: 10 [560720/78836 (26%)]	Loss: 1.000167
Train epoch: 10 [827820/78836 (39%)]	Loss: 0.830606
Train epoch: 10 [1104800/78836 (52%)]	Loss: 0.800311
Train epoch: 10 [1369400/78836 (65%)]	Loss: 0.859654
Train epoch: 10 [1692120/78836 (78%)]	Loss: 0.888111
Train epoch: 10 [1912680/78836 (91%)]	Loss: 0.777337
predicting for valid data
Make prediction for 19709 samples...
0.45598716 No improvement since epoch  5 ; best_test_mse,best_test_ci: 0.45598716 0.7281580814743225 GINConvNet kiba
Training on 78836 samples...
Train epoch: 11 [0/78836 (0%)]	Loss: 0.835682
Train epoch: 11 [279060/78836 (13%)]	Loss: 0.988287
Train epoch: 11 [550600/78836 (26%)]	Loss: 0.804126
Train epoch: 11 [833340/78836 (39%)]	Loss: 1.147924
Train epoch: 11 [1098400/78836 (52%)]	Loss: 0.838952
Train epoch: 11 [1440500/78836 (65%)]	Loss: 0.900798
Train epoch: 11 [1676280/78836 (78%)]	Loss: 0.857005
Train epoch: 11 [1972880/78836 (91%)]	Loss: 0.838939
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  11 ; best_test_mse,best_test_ci: 0.40870827 0.7464084980471333 GINConvNet kiba
Training on 78836 samples...
Train epoch: 12 [0/78836 (0%)]	Loss: 0.777493
Train epoch: 12 [282120/78836 (13%)]	Loss: 0.818102
Train epoch: 12 [557880/78836 (26%)]	Loss: 0.754621
Train epoch: 12 [822660/78836 (39%)]	Loss: 0.728954
Train epoch: 12 [1135680/78836 (52%)]	Loss: 0.895000
Train epoch: 12 [1374700/78836 (65%)]	Loss: 0.862788
Train epoch: 12 [1715520/78836 (78%)]	Loss: 0.856543
Train epoch: 12 [1971760/78836 (91%)]	Loss: 0.785320
predicting for valid data
Make prediction for 19709 samples...
0.40870827 No improvement since epoch  11 ; best_test_mse,best_test_ci: 0.40870827 0.7464084980471333 GINConvNet kiba
Training on 78836 samples...
Train epoch: 13 [0/78836 (0%)]	Loss: 0.936965
Train epoch: 13 [280940/78836 (13%)]	Loss: 0.678650
Train epoch: 13 [568440/78836 (26%)]	Loss: 1.062006
Train epoch: 13 [841980/78836 (39%)]	Loss: 1.048156
Train epoch: 13 [1103200/78836 (52%)]	Loss: 0.885057
Train epoch: 13 [1396700/78836 (65%)]	Loss: 0.788705
Train epoch: 13 [1690560/78836 (78%)]	Loss: 0.732263
Train epoch: 13 [1994580/78836 (91%)]	Loss: 0.788796
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  13 ; best_test_mse,best_test_ci: 0.38804302 0.7508909382935167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 14 [0/78836 (0%)]	Loss: 0.857082
Train epoch: 14 [280080/78836 (13%)]	Loss: 0.809118
Train epoch: 14 [556840/78836 (26%)]	Loss: 0.789721
Train epoch: 14 [830880/78836 (39%)]	Loss: 0.957029
Train epoch: 14 [1128080/78836 (52%)]	Loss: 0.799333
Train epoch: 14 [1383500/78836 (65%)]	Loss: 0.718044
Train epoch: 14 [1657200/78836 (78%)]	Loss: 0.826444
Train epoch: 14 [1987020/78836 (91%)]	Loss: 0.675374
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  14 ; best_test_mse,best_test_ci: 0.3775635 0.7514425326011309 GINConvNet kiba
Training on 78836 samples...
Train epoch: 15 [0/78836 (0%)]	Loss: 0.774960
Train epoch: 15 [278860/78836 (13%)]	Loss: 0.800727
Train epoch: 15 [551440/78836 (26%)]	Loss: 1.227331
Train epoch: 15 [841260/78836 (39%)]	Loss: 0.758542
Train epoch: 15 [1108320/78836 (52%)]	Loss: 0.743162
Train epoch: 15 [1406600/78836 (65%)]	Loss: 0.810487
Train epoch: 15 [1660920/78836 (78%)]	Loss: 1.062695
Train epoch: 15 [1954400/78836 (91%)]	Loss: 0.774477
predicting for valid data
Make prediction for 19709 samples...
0.3775635 No improvement since epoch  14 ; best_test_mse,best_test_ci: 0.3775635 0.7514425326011309 GINConvNet kiba
Training on 78836 samples...
Train epoch: 16 [0/78836 (0%)]	Loss: 0.698292
Train epoch: 16 [280100/78836 (13%)]	Loss: 0.762493
Train epoch: 16 [561360/78836 (26%)]	Loss: 0.771696
Train epoch: 16 [847140/78836 (39%)]	Loss: 0.776259
Train epoch: 16 [1121600/78836 (52%)]	Loss: 0.735005
Train epoch: 16 [1387400/78836 (65%)]	Loss: 1.130027
Train epoch: 16 [1672200/78836 (78%)]	Loss: 0.900254
Train epoch: 16 [1947260/78836 (91%)]	Loss: 0.842391
predicting for valid data
Make prediction for 19709 samples...
0.3775635 No improvement since epoch  14 ; best_test_mse,best_test_ci: 0.3775635 0.7514425326011309 GINConvNet kiba
Training on 78836 samples...
Train epoch: 17 [0/78836 (0%)]	Loss: 0.790656
Train epoch: 17 [282460/78836 (13%)]	Loss: 0.641492
Train epoch: 17 [555840/78836 (26%)]	Loss: 0.743555
Train epoch: 17 [823620/78836 (39%)]	Loss: 0.736034
Train epoch: 17 [1132960/78836 (52%)]	Loss: 0.778791
Train epoch: 17 [1399400/78836 (65%)]	Loss: 0.784671
Train epoch: 17 [1683000/78836 (78%)]	Loss: 0.768700
Train epoch: 17 [1962520/78836 (91%)]	Loss: 0.831821
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  17 ; best_test_mse,best_test_ci: 0.36054173 0.7649805881354759 GINConvNet kiba
Training on 78836 samples...
Train epoch: 18 [0/78836 (0%)]	Loss: 0.757183
Train epoch: 18 [286080/78836 (13%)]	Loss: 0.771458
Train epoch: 18 [555640/78836 (26%)]	Loss: 0.716979
Train epoch: 18 [840600/78836 (39%)]	Loss: 0.709671
Train epoch: 18 [1119280/78836 (52%)]	Loss: 0.712917
Train epoch: 18 [1423900/78836 (65%)]	Loss: 0.739648
Train epoch: 18 [1695360/78836 (78%)]	Loss: 1.002969
Train epoch: 18 [1978060/78836 (91%)]	Loss: 0.806738
predicting for valid data
Make prediction for 19709 samples...
0.36054173 No improvement since epoch  17 ; best_test_mse,best_test_ci: 0.36054173 0.7649805881354759 GINConvNet kiba
Training on 78836 samples...
Train epoch: 19 [0/78836 (0%)]	Loss: 0.660773
Train epoch: 19 [282160/78836 (13%)]	Loss: 0.731511
Train epoch: 19 [557440/78836 (26%)]	Loss: 0.753742
Train epoch: 19 [846300/78836 (39%)]	Loss: 0.688766
Train epoch: 19 [1127120/78836 (52%)]	Loss: 0.709852
Train epoch: 19 [1420600/78836 (65%)]	Loss: 0.846385
Train epoch: 19 [1707120/78836 (78%)]	Loss: 0.750382
Train epoch: 19 [1961820/78836 (91%)]	Loss: 0.813221
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  19 ; best_test_mse,best_test_ci: 0.3637398 0.7617900898762423 GINConvNet kiba
Training on 78836 samples...
Train epoch: 20 [0/78836 (0%)]	Loss: 0.772980
Train epoch: 20 [275760/78836 (13%)]	Loss: 0.678013
Train epoch: 20 [563520/78836 (26%)]	Loss: 0.834942
Train epoch: 20 [839340/78836 (39%)]	Loss: 0.683533
Train epoch: 20 [1133760/78836 (52%)]	Loss: 0.691420
Train epoch: 20 [1423600/78836 (65%)]	Loss: 0.811191
Train epoch: 20 [1695120/78836 (78%)]	Loss: 0.651211
Train epoch: 20 [1943340/78836 (91%)]	Loss: 0.617063
predicting for valid data
Make prediction for 19709 samples...
0.3637398 No improvement since epoch  19 ; best_test_mse,best_test_ci: 0.3637398 0.7617900898762423 GINConvNet kiba
Training on 78836 samples...
Train epoch: 21 [0/78836 (0%)]	Loss: 0.775517
Train epoch: 21 [279740/78836 (13%)]	Loss: 0.650803
Train epoch: 21 [552760/78836 (26%)]	Loss: 0.985516
Train epoch: 21 [844860/78836 (39%)]	Loss: 0.679508
Train epoch: 21 [1111520/78836 (52%)]	Loss: 0.646037
Train epoch: 21 [1373600/78836 (65%)]	Loss: 0.689387
Train epoch: 21 [1671360/78836 (78%)]	Loss: 0.702553
Train epoch: 21 [1979040/78836 (91%)]	Loss: 0.897998
predicting for valid data
Make prediction for 19709 samples...
0.3637398 No improvement since epoch  19 ; best_test_mse,best_test_ci: 0.3637398 0.7617900898762423 GINConvNet kiba
Training on 78836 samples...
Train epoch: 22 [0/78836 (0%)]	Loss: 0.753606
Train epoch: 22 [280200/78836 (13%)]	Loss: 0.730271
Train epoch: 22 [572000/78836 (26%)]	Loss: 0.690816
Train epoch: 22 [829980/78836 (39%)]	Loss: 0.741784
Train epoch: 22 [1127120/78836 (52%)]	Loss: 0.683575
Train epoch: 22 [1374700/78836 (65%)]	Loss: 0.797922
Train epoch: 22 [1696920/78836 (78%)]	Loss: 0.797142
Train epoch: 22 [1976660/78836 (91%)]	Loss: 0.769561
predicting for valid data
Make prediction for 19709 samples...
0.3637398 No improvement since epoch  19 ; best_test_mse,best_test_ci: 0.3637398 0.7617900898762423 GINConvNet kiba
Training on 78836 samples...
Train epoch: 23 [0/78836 (0%)]	Loss: 0.669215
Train epoch: 23 [280120/78836 (13%)]	Loss: 0.780776
Train epoch: 23 [573720/78836 (26%)]	Loss: 0.987350
Train epoch: 23 [836880/78836 (39%)]	Loss: 0.795952
Train epoch: 23 [1117920/78836 (52%)]	Loss: 0.766442
Train epoch: 23 [1411800/78836 (65%)]	Loss: 0.742764
Train epoch: 23 [1682760/78836 (78%)]	Loss: 0.652354
Train epoch: 23 [1921360/78836 (91%)]	Loss: 0.773067
predicting for valid data
Make prediction for 19709 samples...
0.3637398 No improvement since epoch  19 ; best_test_mse,best_test_ci: 0.3637398 0.7617900898762423 GINConvNet kiba
Training on 78836 samples...
Train epoch: 24 [0/78836 (0%)]	Loss: 0.747865
Train epoch: 24 [289640/78836 (13%)]	Loss: 0.631430
Train epoch: 24 [563560/78836 (26%)]	Loss: 0.639871
Train epoch: 24 [837840/78836 (39%)]	Loss: 0.678833
Train epoch: 24 [1120560/78836 (52%)]	Loss: 0.748470
Train epoch: 24 [1399700/78836 (65%)]	Loss: 0.713041
Train epoch: 24 [1689240/78836 (78%)]	Loss: 0.696083
Train epoch: 24 [1931020/78836 (91%)]	Loss: 0.688011
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 25 [0/78836 (0%)]	Loss: 0.701305
Train epoch: 25 [277360/78836 (13%)]	Loss: 0.856861
Train epoch: 25 [553920/78836 (26%)]	Loss: 0.649088
Train epoch: 25 [844620/78836 (39%)]	Loss: 0.673322
Train epoch: 25 [1125200/78836 (52%)]	Loss: 0.698164
Train epoch: 25 [1388000/78836 (65%)]	Loss: 0.791691
Train epoch: 25 [1684320/78836 (78%)]	Loss: 0.711755
Train epoch: 25 [1916740/78836 (91%)]	Loss: 0.770485
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 26 [0/78836 (0%)]	Loss: 0.854907
Train epoch: 26 [285540/78836 (13%)]	Loss: 0.637537
Train epoch: 26 [563200/78836 (26%)]	Loss: 0.715851
Train epoch: 26 [844440/78836 (39%)]	Loss: 0.782788
Train epoch: 26 [1109600/78836 (52%)]	Loss: 0.601654
Train epoch: 26 [1404300/78836 (65%)]	Loss: 0.690132
Train epoch: 26 [1680600/78836 (78%)]	Loss: 0.629549
Train epoch: 26 [1932980/78836 (91%)]	Loss: 0.789920
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 27 [0/78836 (0%)]	Loss: 0.646678
Train epoch: 27 [276400/78836 (13%)]	Loss: 0.724141
Train epoch: 27 [558480/78836 (26%)]	Loss: 0.692739
Train epoch: 27 [837600/78836 (39%)]	Loss: 0.792437
Train epoch: 27 [1135360/78836 (52%)]	Loss: 0.737505
Train epoch: 27 [1395700/78836 (65%)]	Loss: 0.979774
Train epoch: 27 [1674960/78836 (78%)]	Loss: 0.835820
Train epoch: 27 [1942780/78836 (91%)]	Loss: 0.772594
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 28 [0/78836 (0%)]	Loss: 0.779307
Train epoch: 28 [278980/78836 (13%)]	Loss: 0.686947
Train epoch: 28 [552720/78836 (26%)]	Loss: 0.698036
Train epoch: 28 [833460/78836 (39%)]	Loss: 0.686345
Train epoch: 28 [1112000/78836 (52%)]	Loss: 0.791062
Train epoch: 28 [1374100/78836 (65%)]	Loss: 0.869862
Train epoch: 28 [1673040/78836 (78%)]	Loss: 0.713313
Train epoch: 28 [1987440/78836 (91%)]	Loss: 0.589228
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 29 [0/78836 (0%)]	Loss: 0.777620
Train epoch: 29 [277620/78836 (13%)]	Loss: 0.712313
Train epoch: 29 [561360/78836 (26%)]	Loss: 0.633300
Train epoch: 29 [843600/78836 (39%)]	Loss: 0.976050
Train epoch: 29 [1157520/78836 (52%)]	Loss: 0.769222
Train epoch: 29 [1404500/78836 (65%)]	Loss: 0.690426
Train epoch: 29 [1664520/78836 (78%)]	Loss: 0.596671
Train epoch: 29 [1940260/78836 (91%)]	Loss: 0.621244
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 30 [0/78836 (0%)]	Loss: 0.606405
Train epoch: 30 [278140/78836 (13%)]	Loss: 0.718375
Train epoch: 30 [555120/78836 (26%)]	Loss: 0.703019
Train epoch: 30 [843780/78836 (39%)]	Loss: 0.687036
Train epoch: 30 [1112640/78836 (52%)]	Loss: 0.696036
Train epoch: 30 [1390800/78836 (65%)]	Loss: 0.629397
Train epoch: 30 [1680480/78836 (78%)]	Loss: 0.767214
Train epoch: 30 [1968680/78836 (91%)]	Loss: 0.930644
predicting for valid data
Make prediction for 19709 samples...
0.3453047 No improvement since epoch  24 ; best_test_mse,best_test_ci: 0.3453047 0.769496246137126 GINConvNet kiba
Training on 78836 samples...
Train epoch: 31 [0/78836 (0%)]	Loss: 0.836921
Train epoch: 31 [281680/78836 (13%)]	Loss: 0.887433
Train epoch: 31 [564760/78836 (26%)]	Loss: 0.655018
Train epoch: 31 [831420/78836 (39%)]	Loss: 0.694686
Train epoch: 31 [1120320/78836 (52%)]	Loss: 0.727382
Train epoch: 31 [1391200/78836 (65%)]	Loss: 0.751534
Train epoch: 31 [1699560/78836 (78%)]	Loss: 0.731284
Train epoch: 31 [1962240/78836 (91%)]	Loss: 0.767893
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  31 ; best_test_mse,best_test_ci: 0.342112 0.7810029453331047 GINConvNet kiba
Training on 78836 samples...
Train epoch: 32 [0/78836 (0%)]	Loss: 0.674043
Train epoch: 32 [274260/78836 (13%)]	Loss: 0.675970
Train epoch: 32 [565400/78836 (26%)]	Loss: 0.795012
Train epoch: 32 [829980/78836 (39%)]	Loss: 0.620217
Train epoch: 32 [1105840/78836 (52%)]	Loss: 0.702007
Train epoch: 32 [1422900/78836 (65%)]	Loss: 0.758524
Train epoch: 32 [1715760/78836 (78%)]	Loss: 0.728135
Train epoch: 32 [1950620/78836 (91%)]	Loss: 0.740669
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  32 ; best_test_mse,best_test_ci: 0.31810158 0.7788975504061425 GINConvNet kiba
Training on 78836 samples...
Train epoch: 33 [0/78836 (0%)]	Loss: 0.608797
Train epoch: 33 [280460/78836 (13%)]	Loss: 0.653504
Train epoch: 33 [558520/78836 (26%)]	Loss: 0.687257
Train epoch: 33 [842820/78836 (39%)]	Loss: 0.662992
Train epoch: 33 [1130560/78836 (52%)]	Loss: 0.714100
Train epoch: 33 [1423700/78836 (65%)]	Loss: 0.605381
Train epoch: 33 [1694400/78836 (78%)]	Loss: 0.722181
Train epoch: 33 [1997380/78836 (91%)]	Loss: 0.595198
predicting for valid data
Make prediction for 19709 samples...
0.31810158 No improvement since epoch  32 ; best_test_mse,best_test_ci: 0.31810158 0.7788975504061425 GINConvNet kiba
Training on 78836 samples...
Train epoch: 34 [0/78836 (0%)]	Loss: 0.686392
Train epoch: 34 [281100/78836 (13%)]	Loss: 0.647979
Train epoch: 34 [559760/78836 (26%)]	Loss: 0.663467
Train epoch: 34 [835980/78836 (39%)]	Loss: 0.731864
Train epoch: 34 [1109360/78836 (52%)]	Loss: 0.589730
Train epoch: 34 [1401400/78836 (65%)]	Loss: 0.714339
Train epoch: 34 [1683240/78836 (78%)]	Loss: 0.689459
Train epoch: 34 [1969660/78836 (91%)]	Loss: 0.665880
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 35 [0/78836 (0%)]	Loss: 0.638690
Train epoch: 35 [282160/78836 (13%)]	Loss: 0.700741
Train epoch: 35 [560480/78836 (26%)]	Loss: 0.777011
Train epoch: 35 [835800/78836 (39%)]	Loss: 0.934330
Train epoch: 35 [1117440/78836 (52%)]	Loss: 0.828674
Train epoch: 35 [1384700/78836 (65%)]	Loss: 0.728315
Train epoch: 35 [1657440/78836 (78%)]	Loss: 0.594896
Train epoch: 35 [1949360/78836 (91%)]	Loss: 0.691005
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 36 [0/78836 (0%)]	Loss: 0.604185
Train epoch: 36 [278120/78836 (13%)]	Loss: 0.758317
Train epoch: 36 [557200/78836 (26%)]	Loss: 0.681375
Train epoch: 36 [831000/78836 (39%)]	Loss: 0.696760
Train epoch: 36 [1107280/78836 (52%)]	Loss: 0.576106
Train epoch: 36 [1414000/78836 (65%)]	Loss: 0.694812
Train epoch: 36 [1698120/78836 (78%)]	Loss: 0.618553
Train epoch: 36 [1999060/78836 (91%)]	Loss: 0.710747
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 37 [0/78836 (0%)]	Loss: 0.697553
Train epoch: 37 [272640/78836 (13%)]	Loss: 0.724453
Train epoch: 37 [553640/78836 (26%)]	Loss: 0.714363
Train epoch: 37 [831360/78836 (39%)]	Loss: 0.606206
Train epoch: 37 [1107280/78836 (52%)]	Loss: 0.686243
Train epoch: 37 [1372300/78836 (65%)]	Loss: 0.804000
Train epoch: 37 [1698720/78836 (78%)]	Loss: 0.910971
Train epoch: 37 [1969520/78836 (91%)]	Loss: 0.666762
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 38 [0/78836 (0%)]	Loss: 0.725651
Train epoch: 38 [278740/78836 (13%)]	Loss: 0.699169
Train epoch: 38 [559000/78836 (26%)]	Loss: 0.827307
Train epoch: 38 [835980/78836 (39%)]	Loss: 0.661009
Train epoch: 38 [1090560/78836 (52%)]	Loss: 0.576013
Train epoch: 38 [1374300/78836 (65%)]	Loss: 0.728702
Train epoch: 38 [1719480/78836 (78%)]	Loss: 0.640422
Train epoch: 38 [1990240/78836 (91%)]	Loss: 0.576310
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 39 [0/78836 (0%)]	Loss: 0.658538
Train epoch: 39 [281500/78836 (13%)]	Loss: 0.581636
Train epoch: 39 [560920/78836 (26%)]	Loss: 0.647225
Train epoch: 39 [839400/78836 (39%)]	Loss: 0.711133
Train epoch: 39 [1105200/78836 (52%)]	Loss: 0.635888
Train epoch: 39 [1406900/78836 (65%)]	Loss: 0.610174
Train epoch: 39 [1671840/78836 (78%)]	Loss: 0.691970
Train epoch: 39 [2002700/78836 (91%)]	Loss: 0.700202
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 40 [0/78836 (0%)]	Loss: 0.728018
Train epoch: 40 [286940/78836 (13%)]	Loss: 0.684311
Train epoch: 40 [559440/78836 (26%)]	Loss: 0.733494
Train epoch: 40 [840240/78836 (39%)]	Loss: 0.712401
Train epoch: 40 [1102880/78836 (52%)]	Loss: 0.663039
Train epoch: 40 [1389700/78836 (65%)]	Loss: 0.702152
Train epoch: 40 [1684800/78836 (78%)]	Loss: 0.615018
Train epoch: 40 [1931300/78836 (91%)]	Loss: 0.798637
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 41 [0/78836 (0%)]	Loss: 0.915575
Train epoch: 41 [277440/78836 (13%)]	Loss: 0.636329
Train epoch: 41 [560000/78836 (26%)]	Loss: 0.750134
Train epoch: 41 [830400/78836 (39%)]	Loss: 0.692352
Train epoch: 41 [1108640/78836 (52%)]	Loss: 0.627134
Train epoch: 41 [1390800/78836 (65%)]	Loss: 0.586664
Train epoch: 41 [1690320/78836 (78%)]	Loss: 0.725138
Train epoch: 41 [1985200/78836 (91%)]	Loss: 0.632999
predicting for valid data
Make prediction for 19709 samples...
0.31723917 No improvement since epoch  34 ; best_test_mse,best_test_ci: 0.31723917 0.7797921019356083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 42 [0/78836 (0%)]	Loss: 0.602682
Train epoch: 42 [281120/78836 (13%)]	Loss: 0.778476
Train epoch: 42 [571520/78836 (26%)]	Loss: 0.719361
Train epoch: 42 [837300/78836 (39%)]	Loss: 0.710308
Train epoch: 42 [1101840/78836 (52%)]	Loss: 0.661292
Train epoch: 42 [1422600/78836 (65%)]	Loss: 0.521159
Train epoch: 42 [1719720/78836 (78%)]	Loss: 0.684966
Train epoch: 42 [1962100/78836 (91%)]	Loss: 0.696214
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  42 ; best_test_mse,best_test_ci: 0.30767035 0.7869136207915421 GINConvNet kiba
Training on 78836 samples...
Train epoch: 43 [0/78836 (0%)]	Loss: 0.707233
Train epoch: 43 [282440/78836 (13%)]	Loss: 0.889547
Train epoch: 43 [554160/78836 (26%)]	Loss: 0.764147
Train epoch: 43 [836880/78836 (39%)]	Loss: 0.610243
Train epoch: 43 [1132400/78836 (52%)]	Loss: 0.760994
Train epoch: 43 [1385200/78836 (65%)]	Loss: 0.683971
Train epoch: 43 [1703880/78836 (78%)]	Loss: 0.698263
Train epoch: 43 [1995280/78836 (91%)]	Loss: 0.566718
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  43 ; best_test_mse,best_test_ci: 0.31459242 0.7810649188793052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 44 [0/78836 (0%)]	Loss: 0.705624
Train epoch: 44 [285260/78836 (13%)]	Loss: 0.607153
Train epoch: 44 [555360/78836 (26%)]	Loss: 0.583449
Train epoch: 44 [824280/78836 (39%)]	Loss: 0.619398
Train epoch: 44 [1105200/78836 (52%)]	Loss: 0.777306
Train epoch: 44 [1380200/78836 (65%)]	Loss: 0.673243
Train epoch: 44 [1674360/78836 (78%)]	Loss: 0.721318
Train epoch: 44 [1984920/78836 (91%)]	Loss: 0.589645
predicting for valid data
Make prediction for 19709 samples...
0.31459242 No improvement since epoch  43 ; best_test_mse,best_test_ci: 0.31459242 0.7810649188793052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 45 [0/78836 (0%)]	Loss: 0.647139
Train epoch: 45 [279380/78836 (13%)]	Loss: 0.661977
Train epoch: 45 [563880/78836 (26%)]	Loss: 0.657317
Train epoch: 45 [846480/78836 (39%)]	Loss: 0.591182
Train epoch: 45 [1111040/78836 (52%)]	Loss: 0.718250
Train epoch: 45 [1417200/78836 (65%)]	Loss: 0.722295
Train epoch: 45 [1662120/78836 (78%)]	Loss: 0.496314
Train epoch: 45 [1918420/78836 (91%)]	Loss: 0.660945
predicting for valid data
Make prediction for 19709 samples...
0.31459242 No improvement since epoch  43 ; best_test_mse,best_test_ci: 0.31459242 0.7810649188793052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 46 [0/78836 (0%)]	Loss: 0.687629
Train epoch: 46 [272280/78836 (13%)]	Loss: 0.687653
Train epoch: 46 [563920/78836 (26%)]	Loss: 0.692811
Train epoch: 46 [830160/78836 (39%)]	Loss: 0.705139
Train epoch: 46 [1118560/78836 (52%)]	Loss: 0.614170
Train epoch: 46 [1393700/78836 (65%)]	Loss: 0.675421
Train epoch: 46 [1674600/78836 (78%)]	Loss: 0.617198
Train epoch: 46 [1906940/78836 (91%)]	Loss: 0.618652
predicting for valid data
Make prediction for 19709 samples...
0.31459242 No improvement since epoch  43 ; best_test_mse,best_test_ci: 0.31459242 0.7810649188793052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 47 [0/78836 (0%)]	Loss: 0.652644
Train epoch: 47 [273480/78836 (13%)]	Loss: 0.729599
Train epoch: 47 [553320/78836 (26%)]	Loss: 0.678986
Train epoch: 47 [852840/78836 (39%)]	Loss: 0.614396
Train epoch: 47 [1114240/78836 (52%)]	Loss: 0.667822
Train epoch: 47 [1373100/78836 (65%)]	Loss: 0.637310
Train epoch: 47 [1668600/78836 (78%)]	Loss: 0.590627
Train epoch: 47 [1986600/78836 (91%)]	Loss: 0.568269
predicting for valid data
Make prediction for 19709 samples...
0.31459242 No improvement since epoch  43 ; best_test_mse,best_test_ci: 0.31459242 0.7810649188793052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 48 [0/78836 (0%)]	Loss: 0.720525
Train epoch: 48 [285840/78836 (13%)]	Loss: 0.642525
Train epoch: 48 [556720/78836 (26%)]	Loss: 0.586578
Train epoch: 48 [834600/78836 (39%)]	Loss: 0.647961
Train epoch: 48 [1150080/78836 (52%)]	Loss: 0.672319
Train epoch: 48 [1427500/78836 (65%)]	Loss: 0.574840
Train epoch: 48 [1685880/78836 (78%)]	Loss: 0.881821
Train epoch: 48 [1979180/78836 (91%)]	Loss: 0.597858
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  48 ; best_test_mse,best_test_ci: 0.2983605 0.7890730013933882 GINConvNet kiba
Training on 78836 samples...
Train epoch: 49 [0/78836 (0%)]	Loss: 0.616000
Train epoch: 49 [286640/78836 (13%)]	Loss: 0.607023
Train epoch: 49 [565120/78836 (26%)]	Loss: 0.769786
Train epoch: 49 [849180/78836 (39%)]	Loss: 0.677203
Train epoch: 49 [1111520/78836 (52%)]	Loss: 0.643896
Train epoch: 49 [1408400/78836 (65%)]	Loss: 0.656045
Train epoch: 49 [1673160/78836 (78%)]	Loss: 0.645648
Train epoch: 49 [1960000/78836 (91%)]	Loss: 0.653540
predicting for valid data
Make prediction for 19709 samples...
0.2983605 No improvement since epoch  48 ; best_test_mse,best_test_ci: 0.2983605 0.7890730013933882 GINConvNet kiba
Training on 78836 samples...
Train epoch: 50 [0/78836 (0%)]	Loss: 0.635062
Train epoch: 50 [277040/78836 (13%)]	Loss: 0.645683
Train epoch: 50 [548320/78836 (26%)]	Loss: 0.612688
Train epoch: 50 [831660/78836 (39%)]	Loss: 0.685854
Train epoch: 50 [1137600/78836 (52%)]	Loss: 0.651851
Train epoch: 50 [1410300/78836 (65%)]	Loss: 0.624112
Train epoch: 50 [1680480/78836 (78%)]	Loss: 0.628890
Train epoch: 50 [1942640/78836 (91%)]	Loss: 0.732330
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  50 ; best_test_mse,best_test_ci: 0.29875877 0.7884512710103257 GINConvNet kiba
Training on 78836 samples...
Train epoch: 51 [0/78836 (0%)]	Loss: 0.615395
Train epoch: 51 [276600/78836 (13%)]	Loss: 0.567468
Train epoch: 51 [560080/78836 (26%)]	Loss: 0.543697
Train epoch: 51 [844680/78836 (39%)]	Loss: 0.646727
Train epoch: 51 [1145440/78836 (52%)]	Loss: 0.749554
Train epoch: 51 [1388800/78836 (65%)]	Loss: 0.761846
Train epoch: 51 [1689600/78836 (78%)]	Loss: 0.590711
Train epoch: 51 [1948240/78836 (91%)]	Loss: 0.665415
predicting for valid data
Make prediction for 19709 samples...
0.29875877 No improvement since epoch  50 ; best_test_mse,best_test_ci: 0.29875877 0.7884512710103257 GINConvNet kiba
Training on 78836 samples...
Train epoch: 52 [0/78836 (0%)]	Loss: 0.620665
Train epoch: 52 [278800/78836 (13%)]	Loss: 0.762441
Train epoch: 52 [559400/78836 (26%)]	Loss: 0.581399
Train epoch: 52 [863820/78836 (39%)]	Loss: 0.722986
Train epoch: 52 [1092880/78836 (52%)]	Loss: 0.652969
Train epoch: 52 [1408300/78836 (65%)]	Loss: 0.648529
Train epoch: 52 [1698360/78836 (78%)]	Loss: 0.604762
Train epoch: 52 [1973440/78836 (91%)]	Loss: 0.686282
predicting for valid data
Make prediction for 19709 samples...
0.29875877 No improvement since epoch  50 ; best_test_mse,best_test_ci: 0.29875877 0.7884512710103257 GINConvNet kiba
Training on 78836 samples...
Train epoch: 53 [0/78836 (0%)]	Loss: 0.696355
Train epoch: 53 [277880/78836 (13%)]	Loss: 0.594620
Train epoch: 53 [562720/78836 (26%)]	Loss: 0.528874
Train epoch: 53 [822900/78836 (39%)]	Loss: 0.580382
Train epoch: 53 [1108960/78836 (52%)]	Loss: 0.744657
Train epoch: 53 [1395700/78836 (65%)]	Loss: 0.561180
Train epoch: 53 [1744560/78836 (78%)]	Loss: 0.737853
Train epoch: 53 [1990940/78836 (91%)]	Loss: 0.599841
predicting for valid data
Make prediction for 19709 samples...
0.29875877 No improvement since epoch  50 ; best_test_mse,best_test_ci: 0.29875877 0.7884512710103257 GINConvNet kiba
Training on 78836 samples...
Train epoch: 54 [0/78836 (0%)]	Loss: 0.679563
Train epoch: 54 [283300/78836 (13%)]	Loss: 0.645565
Train epoch: 54 [545760/78836 (26%)]	Loss: 0.724385
Train epoch: 54 [820920/78836 (39%)]	Loss: 0.571754
Train epoch: 54 [1112800/78836 (52%)]	Loss: 0.608123
Train epoch: 54 [1391200/78836 (65%)]	Loss: 0.507738
Train epoch: 54 [1706760/78836 (78%)]	Loss: 0.643719
Train epoch: 54 [1962520/78836 (91%)]	Loss: 0.567461
predicting for valid data
Make prediction for 19709 samples...
0.29875877 No improvement since epoch  50 ; best_test_mse,best_test_ci: 0.29875877 0.7884512710103257 GINConvNet kiba
Training on 78836 samples...
Train epoch: 55 [0/78836 (0%)]	Loss: 0.603600
Train epoch: 55 [278360/78836 (13%)]	Loss: 0.623883
Train epoch: 55 [563160/78836 (26%)]	Loss: 0.713567
Train epoch: 55 [844560/78836 (39%)]	Loss: 0.577643
Train epoch: 55 [1106880/78836 (52%)]	Loss: 0.552743
Train epoch: 55 [1391300/78836 (65%)]	Loss: 0.555870
Train epoch: 55 [1671960/78836 (78%)]	Loss: 0.581050
Train epoch: 55 [1948800/78836 (91%)]	Loss: 0.618008
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  55 ; best_test_mse,best_test_ci: 0.30270997 0.7864093424090689 GINConvNet kiba
Training on 78836 samples...
Train epoch: 56 [0/78836 (0%)]	Loss: 0.570228
Train epoch: 56 [275640/78836 (13%)]	Loss: 0.535738
Train epoch: 56 [559200/78836 (26%)]	Loss: 0.593909
Train epoch: 56 [847080/78836 (39%)]	Loss: 0.602154
Train epoch: 56 [1151600/78836 (52%)]	Loss: 0.657129
Train epoch: 56 [1445300/78836 (65%)]	Loss: 0.716948
Train epoch: 56 [1679520/78836 (78%)]	Loss: 0.603393
Train epoch: 56 [1948100/78836 (91%)]	Loss: 0.708501
predicting for valid data
Make prediction for 19709 samples...
0.30270997 No improvement since epoch  55 ; best_test_mse,best_test_ci: 0.30270997 0.7864093424090689 GINConvNet kiba
Training on 78836 samples...
Train epoch: 57 [0/78836 (0%)]	Loss: 0.666918
Train epoch: 57 [281560/78836 (13%)]	Loss: 0.661475
Train epoch: 57 [554640/78836 (26%)]	Loss: 0.892145
Train epoch: 57 [837660/78836 (39%)]	Loss: 0.609580
Train epoch: 57 [1121920/78836 (52%)]	Loss: 0.583675
Train epoch: 57 [1418600/78836 (65%)]	Loss: 0.636641
Train epoch: 57 [1680000/78836 (78%)]	Loss: 0.625064
Train epoch: 57 [1974980/78836 (91%)]	Loss: 0.744378
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  57 ; best_test_mse,best_test_ci: 0.2815489 0.7964491442225312 GINConvNet kiba
Training on 78836 samples...
Train epoch: 58 [0/78836 (0%)]	Loss: 0.587023
Train epoch: 58 [277000/78836 (13%)]	Loss: 0.602947
Train epoch: 58 [553000/78836 (26%)]	Loss: 0.686682
Train epoch: 58 [838740/78836 (39%)]	Loss: 0.637756
Train epoch: 58 [1137200/78836 (52%)]	Loss: 0.610825
Train epoch: 58 [1411300/78836 (65%)]	Loss: 0.637407
Train epoch: 58 [1666080/78836 (78%)]	Loss: 0.581473
Train epoch: 58 [1960980/78836 (91%)]	Loss: 0.704657
predicting for valid data
Make prediction for 19709 samples...
0.2815489 No improvement since epoch  57 ; best_test_mse,best_test_ci: 0.2815489 0.7964491442225312 GINConvNet kiba
Training on 78836 samples...
Train epoch: 59 [0/78836 (0%)]	Loss: 0.550103
Train epoch: 59 [278340/78836 (13%)]	Loss: 0.678622
Train epoch: 59 [565760/78836 (26%)]	Loss: 0.703908
Train epoch: 59 [828300/78836 (39%)]	Loss: 0.574990
Train epoch: 59 [1104320/78836 (52%)]	Loss: 0.561603
Train epoch: 59 [1401500/78836 (65%)]	Loss: 0.584750
Train epoch: 59 [1658760/78836 (78%)]	Loss: 0.592447
Train epoch: 59 [1938160/78836 (91%)]	Loss: 0.580578
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 60 [0/78836 (0%)]	Loss: 0.593980
Train epoch: 60 [281740/78836 (13%)]	Loss: 0.620038
Train epoch: 60 [556320/78836 (26%)]	Loss: 0.641051
Train epoch: 60 [841260/78836 (39%)]	Loss: 0.538166
Train epoch: 60 [1110880/78836 (52%)]	Loss: 0.538131
Train epoch: 60 [1424300/78836 (65%)]	Loss: 0.545238
Train epoch: 60 [1671960/78836 (78%)]	Loss: 0.641786
Train epoch: 60 [1980860/78836 (91%)]	Loss: 0.642638
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 61 [0/78836 (0%)]	Loss: 0.725279
Train epoch: 61 [279000/78836 (13%)]	Loss: 0.537532
Train epoch: 61 [557760/78836 (26%)]	Loss: 0.607864
Train epoch: 61 [853980/78836 (39%)]	Loss: 0.625333
Train epoch: 61 [1126000/78836 (52%)]	Loss: 0.581250
Train epoch: 61 [1364500/78836 (65%)]	Loss: 0.626282
Train epoch: 61 [1685520/78836 (78%)]	Loss: 0.602244
Train epoch: 61 [1967000/78836 (91%)]	Loss: 0.708542
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 62 [0/78836 (0%)]	Loss: 0.642693
Train epoch: 62 [273720/78836 (13%)]	Loss: 0.657160
Train epoch: 62 [564480/78836 (26%)]	Loss: 0.564579
Train epoch: 62 [826560/78836 (39%)]	Loss: 0.592831
Train epoch: 62 [1106640/78836 (52%)]	Loss: 0.617520
Train epoch: 62 [1413100/78836 (65%)]	Loss: 0.668502
Train epoch: 62 [1675680/78836 (78%)]	Loss: 0.661257
Train epoch: 62 [1935640/78836 (91%)]	Loss: 0.578451
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 63 [0/78836 (0%)]	Loss: 0.611038
Train epoch: 63 [277860/78836 (13%)]	Loss: 0.608567
Train epoch: 63 [553160/78836 (26%)]	Loss: 0.706233
Train epoch: 63 [834120/78836 (39%)]	Loss: 0.595666
Train epoch: 63 [1109920/78836 (52%)]	Loss: 0.682463
Train epoch: 63 [1378600/78836 (65%)]	Loss: 0.719432
Train epoch: 63 [1631280/78836 (78%)]	Loss: 0.654539
Train epoch: 63 [1971620/78836 (91%)]	Loss: 0.590561
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 64 [0/78836 (0%)]	Loss: 0.671411
Train epoch: 64 [275620/78836 (13%)]	Loss: 0.652664
Train epoch: 64 [563600/78836 (26%)]	Loss: 0.633530
Train epoch: 64 [853560/78836 (39%)]	Loss: 0.612271
Train epoch: 64 [1115360/78836 (52%)]	Loss: 0.652575
Train epoch: 64 [1414500/78836 (65%)]	Loss: 0.796761
Train epoch: 64 [1662960/78836 (78%)]	Loss: 0.674192
Train epoch: 64 [1966720/78836 (91%)]	Loss: 0.657161
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 65 [0/78836 (0%)]	Loss: 0.564564
Train epoch: 65 [282460/78836 (13%)]	Loss: 0.621241
Train epoch: 65 [564360/78836 (26%)]	Loss: 0.618641
Train epoch: 65 [835380/78836 (39%)]	Loss: 0.634802
Train epoch: 65 [1096880/78836 (52%)]	Loss: 0.599719
Train epoch: 65 [1374700/78836 (65%)]	Loss: 0.648335
Train epoch: 65 [1660800/78836 (78%)]	Loss: 0.740714
Train epoch: 65 [1980440/78836 (91%)]	Loss: 0.681298
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 66 [0/78836 (0%)]	Loss: 0.537065
Train epoch: 66 [279660/78836 (13%)]	Loss: 0.546189
Train epoch: 66 [564840/78836 (26%)]	Loss: 0.722883
Train epoch: 66 [849420/78836 (39%)]	Loss: 0.613709
Train epoch: 66 [1094960/78836 (52%)]	Loss: 0.551637
Train epoch: 66 [1403300/78836 (65%)]	Loss: 0.588696
Train epoch: 66 [1669920/78836 (78%)]	Loss: 0.625188
Train epoch: 66 [2025240/78836 (91%)]	Loss: 0.476141
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 67 [0/78836 (0%)]	Loss: 0.661648
Train epoch: 67 [277620/78836 (13%)]	Loss: 0.768259
Train epoch: 67 [557400/78836 (26%)]	Loss: 0.673678
Train epoch: 67 [841140/78836 (39%)]	Loss: 0.615696
Train epoch: 67 [1120640/78836 (52%)]	Loss: 0.624158
Train epoch: 67 [1364900/78836 (65%)]	Loss: 0.660360
Train epoch: 67 [1632240/78836 (78%)]	Loss: 0.664323
Train epoch: 67 [1978620/78836 (91%)]	Loss: 0.681947
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 68 [0/78836 (0%)]	Loss: 0.673055
Train epoch: 68 [274840/78836 (13%)]	Loss: 0.487227
Train epoch: 68 [561800/78836 (26%)]	Loss: 0.605203
Train epoch: 68 [850620/78836 (39%)]	Loss: 0.551201
Train epoch: 68 [1132640/78836 (52%)]	Loss: 0.709419
Train epoch: 68 [1390100/78836 (65%)]	Loss: 0.635457
Train epoch: 68 [1661640/78836 (78%)]	Loss: 0.660055
Train epoch: 68 [1932280/78836 (91%)]	Loss: 0.774309
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 69 [0/78836 (0%)]	Loss: 0.509841
Train epoch: 69 [280180/78836 (13%)]	Loss: 0.519080
Train epoch: 69 [545960/78836 (26%)]	Loss: 0.576030
Train epoch: 69 [834660/78836 (39%)]	Loss: 0.645939
Train epoch: 69 [1135360/78836 (52%)]	Loss: 0.588618
Train epoch: 69 [1373300/78836 (65%)]	Loss: 0.651740
Train epoch: 69 [1681800/78836 (78%)]	Loss: 0.654618
Train epoch: 69 [1952300/78836 (91%)]	Loss: 0.605465
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 70 [0/78836 (0%)]	Loss: 0.691740
Train epoch: 70 [275160/78836 (13%)]	Loss: 0.581368
Train epoch: 70 [554600/78836 (26%)]	Loss: 0.623388
Train epoch: 70 [837000/78836 (39%)]	Loss: 0.612192
Train epoch: 70 [1110640/78836 (52%)]	Loss: 0.575490
Train epoch: 70 [1381800/78836 (65%)]	Loss: 0.673167
Train epoch: 70 [1665600/78836 (78%)]	Loss: 0.571668
Train epoch: 70 [1976940/78836 (91%)]	Loss: 0.515316
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 71 [0/78836 (0%)]	Loss: 0.642485
Train epoch: 71 [278520/78836 (13%)]	Loss: 0.579857
Train epoch: 71 [565560/78836 (26%)]	Loss: 0.587634
Train epoch: 71 [833760/78836 (39%)]	Loss: 0.711638
Train epoch: 71 [1098080/78836 (52%)]	Loss: 0.632336
Train epoch: 71 [1383100/78836 (65%)]	Loss: 0.521302
Train epoch: 71 [1645440/78836 (78%)]	Loss: 0.558767
Train epoch: 71 [1998500/78836 (91%)]	Loss: 0.656088
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 72 [0/78836 (0%)]	Loss: 0.603014
Train epoch: 72 [277620/78836 (13%)]	Loss: 0.521423
Train epoch: 72 [557160/78836 (26%)]	Loss: 0.538212
Train epoch: 72 [861960/78836 (39%)]	Loss: 0.543165
Train epoch: 72 [1134080/78836 (52%)]	Loss: 0.562193
Train epoch: 72 [1390500/78836 (65%)]	Loss: 0.673606
Train epoch: 72 [1638840/78836 (78%)]	Loss: 0.581065
Train epoch: 72 [1923880/78836 (91%)]	Loss: 0.559356
predicting for valid data
Make prediction for 19709 samples...
0.27828255 No improvement since epoch  59 ; best_test_mse,best_test_ci: 0.27828255 0.8039970522107682 GINConvNet kiba
Training on 78836 samples...
Train epoch: 73 [0/78836 (0%)]	Loss: 0.636436
Train epoch: 73 [275720/78836 (13%)]	Loss: 0.583387
Train epoch: 73 [552080/78836 (26%)]	Loss: 0.484248
Train epoch: 73 [847740/78836 (39%)]	Loss: 0.586387
Train epoch: 73 [1126320/78836 (52%)]	Loss: 0.635207
Train epoch: 73 [1446100/78836 (65%)]	Loss: 0.675206
Train epoch: 73 [1652280/78836 (78%)]	Loss: 0.606656
Train epoch: 73 [2000320/78836 (91%)]	Loss: 0.635669
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  73 ; best_test_mse,best_test_ci: 0.27711618 0.7914038278577981 GINConvNet kiba
Training on 78836 samples...
Train epoch: 74 [0/78836 (0%)]	Loss: 0.563342
Train epoch: 74 [272460/78836 (13%)]	Loss: 0.537679
Train epoch: 74 [566320/78836 (26%)]	Loss: 0.565925
Train epoch: 74 [831480/78836 (39%)]	Loss: 0.768630
Train epoch: 74 [1116800/78836 (52%)]	Loss: 0.780334
Train epoch: 74 [1393800/78836 (65%)]	Loss: 0.579310
Train epoch: 74 [1672920/78836 (78%)]	Loss: 0.602871
Train epoch: 74 [1956080/78836 (91%)]	Loss: 0.548179
predicting for valid data
Make prediction for 19709 samples...
0.27711618 No improvement since epoch  73 ; best_test_mse,best_test_ci: 0.27711618 0.7914038278577981 GINConvNet kiba
Training on 78836 samples...
Train epoch: 75 [0/78836 (0%)]	Loss: 0.570536
Train epoch: 75 [283700/78836 (13%)]	Loss: 0.526780
Train epoch: 75 [557760/78836 (26%)]	Loss: 0.567013
Train epoch: 75 [828300/78836 (39%)]	Loss: 0.628950
Train epoch: 75 [1120320/78836 (52%)]	Loss: 0.539318
Train epoch: 75 [1414100/78836 (65%)]	Loss: 0.517300
Train epoch: 75 [1671960/78836 (78%)]	Loss: 0.601260
Train epoch: 75 [1946700/78836 (91%)]	Loss: 0.535881
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 76 [0/78836 (0%)]	Loss: 0.492596
Train epoch: 76 [280800/78836 (13%)]	Loss: 0.540720
Train epoch: 76 [575640/78836 (26%)]	Loss: 0.562777
Train epoch: 76 [850620/78836 (39%)]	Loss: 0.582237
Train epoch: 76 [1125040/78836 (52%)]	Loss: 0.557768
Train epoch: 76 [1385200/78836 (65%)]	Loss: 0.562974
Train epoch: 76 [1710000/78836 (78%)]	Loss: 0.597770
Train epoch: 76 [2001860/78836 (91%)]	Loss: 0.542540
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 77 [0/78836 (0%)]	Loss: 0.509946
Train epoch: 77 [279440/78836 (13%)]	Loss: 0.609596
Train epoch: 77 [551600/78836 (26%)]	Loss: 0.558327
Train epoch: 77 [846360/78836 (39%)]	Loss: 0.559385
Train epoch: 77 [1109040/78836 (52%)]	Loss: 0.642009
Train epoch: 77 [1379600/78836 (65%)]	Loss: 0.643977
Train epoch: 77 [1666320/78836 (78%)]	Loss: 0.511612
Train epoch: 77 [1885660/78836 (91%)]	Loss: 0.561838
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 78 [0/78836 (0%)]	Loss: 0.628198
Train epoch: 78 [282300/78836 (13%)]	Loss: 0.568719
Train epoch: 78 [567200/78836 (26%)]	Loss: 0.570503
Train epoch: 78 [824100/78836 (39%)]	Loss: 0.519604
Train epoch: 78 [1128720/78836 (52%)]	Loss: 0.486954
Train epoch: 78 [1439500/78836 (65%)]	Loss: 0.607176
Train epoch: 78 [1681200/78836 (78%)]	Loss: 0.619724
Train epoch: 78 [1976520/78836 (91%)]	Loss: 0.679291
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 79 [0/78836 (0%)]	Loss: 0.470076
Train epoch: 79 [285280/78836 (13%)]	Loss: 0.580179
Train epoch: 79 [555960/78836 (26%)]	Loss: 0.574439
Train epoch: 79 [831960/78836 (39%)]	Loss: 0.634765
Train epoch: 79 [1128240/78836 (52%)]	Loss: 0.613828
Train epoch: 79 [1392400/78836 (65%)]	Loss: 0.739599
Train epoch: 79 [1674480/78836 (78%)]	Loss: 0.689482
Train epoch: 79 [1999900/78836 (91%)]	Loss: 0.612212
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 80 [0/78836 (0%)]	Loss: 0.464775
Train epoch: 80 [282660/78836 (13%)]	Loss: 0.557732
Train epoch: 80 [555400/78836 (26%)]	Loss: 0.517491
Train epoch: 80 [862620/78836 (39%)]	Loss: 0.599658
Train epoch: 80 [1128320/78836 (52%)]	Loss: 0.450476
Train epoch: 80 [1386800/78836 (65%)]	Loss: 0.592939
Train epoch: 80 [1707000/78836 (78%)]	Loss: 0.614330
Train epoch: 80 [1990380/78836 (91%)]	Loss: 0.594313
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 81 [0/78836 (0%)]	Loss: 0.488725
Train epoch: 81 [281700/78836 (13%)]	Loss: 0.584329
Train epoch: 81 [582040/78836 (26%)]	Loss: 0.579286
Train epoch: 81 [831360/78836 (39%)]	Loss: 0.549263
Train epoch: 81 [1110640/78836 (52%)]	Loss: 0.505774
Train epoch: 81 [1380500/78836 (65%)]	Loss: 0.582288
Train epoch: 81 [1705920/78836 (78%)]	Loss: 0.632367
Train epoch: 81 [1946280/78836 (91%)]	Loss: 0.590386
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 82 [0/78836 (0%)]	Loss: 0.642576
Train epoch: 82 [283080/78836 (13%)]	Loss: 0.605708
Train epoch: 82 [567320/78836 (26%)]	Loss: 0.587087
Train epoch: 82 [823440/78836 (39%)]	Loss: 0.566213
Train epoch: 82 [1089920/78836 (52%)]	Loss: 0.602618
Train epoch: 82 [1393600/78836 (65%)]	Loss: 0.535192
Train epoch: 82 [1672440/78836 (78%)]	Loss: 0.557550
Train epoch: 82 [1981280/78836 (91%)]	Loss: 0.575697
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 83 [0/78836 (0%)]	Loss: 0.642206
Train epoch: 83 [280360/78836 (13%)]	Loss: 0.518494
Train epoch: 83 [567640/78836 (26%)]	Loss: 0.596112
Train epoch: 83 [836520/78836 (39%)]	Loss: 0.474372
Train epoch: 83 [1089760/78836 (52%)]	Loss: 0.569417
Train epoch: 83 [1402100/78836 (65%)]	Loss: 0.610500
Train epoch: 83 [1677480/78836 (78%)]	Loss: 0.668057
Train epoch: 83 [1924440/78836 (91%)]	Loss: 0.645338
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 84 [0/78836 (0%)]	Loss: 0.744536
Train epoch: 84 [277980/78836 (13%)]	Loss: 0.595099
Train epoch: 84 [547640/78836 (26%)]	Loss: 0.472509
Train epoch: 84 [840000/78836 (39%)]	Loss: 0.471233
Train epoch: 84 [1138960/78836 (52%)]	Loss: 0.579755
Train epoch: 84 [1406400/78836 (65%)]	Loss: 0.559742
Train epoch: 84 [1642440/78836 (78%)]	Loss: 0.577447
Train epoch: 84 [1923880/78836 (91%)]	Loss: 0.580065
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 85 [0/78836 (0%)]	Loss: 0.637829
Train epoch: 85 [272280/78836 (13%)]	Loss: 0.624599
Train epoch: 85 [551200/78836 (26%)]	Loss: 0.581702
Train epoch: 85 [859920/78836 (39%)]	Loss: 0.522786
Train epoch: 85 [1114400/78836 (52%)]	Loss: 0.492174
Train epoch: 85 [1406300/78836 (65%)]	Loss: 0.545294
Train epoch: 85 [1657320/78836 (78%)]	Loss: 0.693724
Train epoch: 85 [1953560/78836 (91%)]	Loss: 0.604783
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 86 [0/78836 (0%)]	Loss: 0.593103
Train epoch: 86 [279020/78836 (13%)]	Loss: 0.501843
Train epoch: 86 [563200/78836 (26%)]	Loss: 0.534312
Train epoch: 86 [837240/78836 (39%)]	Loss: 0.539991
Train epoch: 86 [1125600/78836 (52%)]	Loss: 0.633872
Train epoch: 86 [1387600/78836 (65%)]	Loss: 0.577377
Train epoch: 86 [1687560/78836 (78%)]	Loss: 0.614056
Train epoch: 86 [1934380/78836 (91%)]	Loss: 0.650947
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 87 [0/78836 (0%)]	Loss: 0.670527
Train epoch: 87 [285860/78836 (13%)]	Loss: 0.556085
Train epoch: 87 [554480/78836 (26%)]	Loss: 0.564026
Train epoch: 87 [831240/78836 (39%)]	Loss: 0.598902
Train epoch: 87 [1131440/78836 (52%)]	Loss: 0.556331
Train epoch: 87 [1394000/78836 (65%)]	Loss: 0.545203
Train epoch: 87 [1659960/78836 (78%)]	Loss: 0.559823
Train epoch: 87 [1987860/78836 (91%)]	Loss: 0.501284
predicting for valid data
Make prediction for 19709 samples...
0.26289722 No improvement since epoch  75 ; best_test_mse,best_test_ci: 0.26289722 0.8082760487158085 GINConvNet kiba
Training on 78836 samples...
Train epoch: 88 [0/78836 (0%)]	Loss: 0.605623
Train epoch: 88 [285120/78836 (13%)]	Loss: 0.646762
Train epoch: 88 [567520/78836 (26%)]	Loss: 0.526459
Train epoch: 88 [829800/78836 (39%)]	Loss: 0.703834
Train epoch: 88 [1141280/78836 (52%)]	Loss: 0.502319
Train epoch: 88 [1431800/78836 (65%)]	Loss: 0.693942
Train epoch: 88 [1701360/78836 (78%)]	Loss: 0.662599
Train epoch: 88 [1959440/78836 (91%)]	Loss: 0.481394
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 89 [0/78836 (0%)]	Loss: 0.570423
Train epoch: 89 [286780/78836 (13%)]	Loss: 0.513551
Train epoch: 89 [563440/78836 (26%)]	Loss: 0.533233
Train epoch: 89 [841380/78836 (39%)]	Loss: 0.672969
Train epoch: 89 [1121040/78836 (52%)]	Loss: 0.483487
Train epoch: 89 [1380300/78836 (65%)]	Loss: 0.561399
Train epoch: 89 [1692960/78836 (78%)]	Loss: 0.551179
Train epoch: 89 [1970780/78836 (91%)]	Loss: 0.709692
predicting for valid data
Make prediction for 19709 samples...
0.26581764 No improvement since epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 90 [0/78836 (0%)]	Loss: 0.538657
Train epoch: 90 [277320/78836 (13%)]	Loss: 0.636648
Train epoch: 90 [538960/78836 (26%)]	Loss: 0.584332
Train epoch: 90 [830880/78836 (39%)]	Loss: 0.594136
Train epoch: 90 [1100960/78836 (52%)]	Loss: 0.508672
Train epoch: 90 [1393000/78836 (65%)]	Loss: 0.530156
Train epoch: 90 [1689600/78836 (78%)]	Loss: 0.531866
Train epoch: 90 [1980300/78836 (91%)]	Loss: 0.568646
predicting for valid data
Make prediction for 19709 samples...
0.26581764 No improvement since epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 91 [0/78836 (0%)]	Loss: 0.560805
Train epoch: 91 [282660/78836 (13%)]	Loss: 0.517110
Train epoch: 91 [563720/78836 (26%)]	Loss: 0.619827
Train epoch: 91 [825240/78836 (39%)]	Loss: 0.551480
Train epoch: 91 [1140160/78836 (52%)]	Loss: 0.530795
Train epoch: 91 [1390500/78836 (65%)]	Loss: 0.585063
Train epoch: 91 [1619280/78836 (78%)]	Loss: 0.667083
Train epoch: 91 [1961260/78836 (91%)]	Loss: 0.691218
predicting for valid data
Make prediction for 19709 samples...
0.26581764 No improvement since epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 92 [0/78836 (0%)]	Loss: 0.581965
Train epoch: 92 [278380/78836 (13%)]	Loss: 0.649758
Train epoch: 92 [577280/78836 (26%)]	Loss: 0.490243
Train epoch: 92 [831900/78836 (39%)]	Loss: 0.556151
Train epoch: 92 [1124560/78836 (52%)]	Loss: 0.497349
Train epoch: 92 [1381500/78836 (65%)]	Loss: 0.614633
Train epoch: 92 [1686840/78836 (78%)]	Loss: 0.580143
Train epoch: 92 [1974420/78836 (91%)]	Loss: 0.549223
predicting for valid data
Make prediction for 19709 samples...
0.26581764 No improvement since epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 93 [0/78836 (0%)]	Loss: 0.567726
Train epoch: 93 [279380/78836 (13%)]	Loss: 0.522932
Train epoch: 93 [561040/78836 (26%)]	Loss: 0.508735
Train epoch: 93 [843120/78836 (39%)]	Loss: 0.551894
Train epoch: 93 [1116160/78836 (52%)]	Loss: 0.526096
Train epoch: 93 [1393300/78836 (65%)]	Loss: 0.565813
Train epoch: 93 [1659120/78836 (78%)]	Loss: 0.584155
Train epoch: 93 [1940400/78836 (91%)]	Loss: 0.568296
predicting for valid data
Make prediction for 19709 samples...
0.26581764 No improvement since epoch  88 ; best_test_mse,best_test_ci: 0.26581764 0.8009783791492925 GINConvNet kiba
Training on 78836 samples...
Train epoch: 94 [0/78836 (0%)]	Loss: 0.495045
Train epoch: 94 [286860/78836 (13%)]	Loss: 0.590762
Train epoch: 94 [560120/78836 (26%)]	Loss: 0.489448
Train epoch: 94 [832440/78836 (39%)]	Loss: 0.550661
Train epoch: 94 [1133520/78836 (52%)]	Loss: 0.646636
Train epoch: 94 [1392200/78836 (65%)]	Loss: 0.498877
Train epoch: 94 [1690440/78836 (78%)]	Loss: 0.508166
Train epoch: 94 [1932000/78836 (91%)]	Loss: 0.523878
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  94 ; best_test_mse,best_test_ci: 0.2615694 0.8068161240053845 GINConvNet kiba
Training on 78836 samples...
Train epoch: 95 [0/78836 (0%)]	Loss: 0.502789
Train epoch: 95 [276560/78836 (13%)]	Loss: 0.541008
Train epoch: 95 [559280/78836 (26%)]	Loss: 0.507155
Train epoch: 95 [845460/78836 (39%)]	Loss: 0.502134
Train epoch: 95 [1094560/78836 (52%)]	Loss: 0.549058
Train epoch: 95 [1367700/78836 (65%)]	Loss: 0.493890
Train epoch: 95 [1666200/78836 (78%)]	Loss: 0.501133
Train epoch: 95 [1923180/78836 (91%)]	Loss: 0.521138
predicting for valid data
Make prediction for 19709 samples...
0.2615694 No improvement since epoch  94 ; best_test_mse,best_test_ci: 0.2615694 0.8068161240053845 GINConvNet kiba
Training on 78836 samples...
Train epoch: 96 [0/78836 (0%)]	Loss: 0.562509
Train epoch: 96 [279620/78836 (13%)]	Loss: 0.490215
Train epoch: 96 [554960/78836 (26%)]	Loss: 0.501547
Train epoch: 96 [841380/78836 (39%)]	Loss: 0.552129
Train epoch: 96 [1119920/78836 (52%)]	Loss: 0.534821
Train epoch: 96 [1395400/78836 (65%)]	Loss: 0.507083
Train epoch: 96 [1683240/78836 (78%)]	Loss: 0.469463
Train epoch: 96 [1948380/78836 (91%)]	Loss: 0.536817
predicting for valid data
Make prediction for 19709 samples...
0.2615694 No improvement since epoch  94 ; best_test_mse,best_test_ci: 0.2615694 0.8068161240053845 GINConvNet kiba
Training on 78836 samples...
Train epoch: 97 [0/78836 (0%)]	Loss: 0.489713
Train epoch: 97 [275820/78836 (13%)]	Loss: 0.459220
Train epoch: 97 [563640/78836 (26%)]	Loss: 0.558666
Train epoch: 97 [852420/78836 (39%)]	Loss: 0.543924
Train epoch: 97 [1098400/78836 (52%)]	Loss: 0.521401
Train epoch: 97 [1383100/78836 (65%)]	Loss: 0.614165
Train epoch: 97 [1688040/78836 (78%)]	Loss: 0.532924
Train epoch: 97 [1924580/78836 (91%)]	Loss: 0.637025
predicting for valid data
Make prediction for 19709 samples...
0.2615694 No improvement since epoch  94 ; best_test_mse,best_test_ci: 0.2615694 0.8068161240053845 GINConvNet kiba
Training on 78836 samples...
Train epoch: 98 [0/78836 (0%)]	Loss: 0.533924
Train epoch: 98 [277360/78836 (13%)]	Loss: 0.554807
Train epoch: 98 [555400/78836 (26%)]	Loss: 0.583954
Train epoch: 98 [835500/78836 (39%)]	Loss: 0.624987
Train epoch: 98 [1122160/78836 (52%)]	Loss: 0.530681
Train epoch: 98 [1393500/78836 (65%)]	Loss: 0.642152
Train epoch: 98 [1685160/78836 (78%)]	Loss: 0.503262
Train epoch: 98 [1954400/78836 (91%)]	Loss: 0.584262
predicting for valid data
Make prediction for 19709 samples...
0.2615694 No improvement since epoch  94 ; best_test_mse,best_test_ci: 0.2615694 0.8068161240053845 GINConvNet kiba
Training on 78836 samples...
Train epoch: 99 [0/78836 (0%)]	Loss: 0.505392
Train epoch: 99 [276420/78836 (13%)]	Loss: 0.611869
Train epoch: 99 [558280/78836 (26%)]	Loss: 0.486217
Train epoch: 99 [820980/78836 (39%)]	Loss: 0.588263
Train epoch: 99 [1104000/78836 (52%)]	Loss: 0.513032
Train epoch: 99 [1400600/78836 (65%)]	Loss: 0.533727
Train epoch: 99 [1681200/78836 (78%)]	Loss: 0.527123
Train epoch: 99 [1912400/78836 (91%)]	Loss: 0.508627
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  99 ; best_test_mse,best_test_ci: 0.24554868 0.8161404696235199 GINConvNet kiba
Training on 78836 samples...
Train epoch: 100 [0/78836 (0%)]	Loss: 0.553457
Train epoch: 100 [278140/78836 (13%)]	Loss: 0.464040
Train epoch: 100 [550120/78836 (26%)]	Loss: 0.509849
Train epoch: 100 [833460/78836 (39%)]	Loss: 0.604393
Train epoch: 100 [1121040/78836 (52%)]	Loss: 0.554147
Train epoch: 100 [1373100/78836 (65%)]	Loss: 0.535498
Train epoch: 100 [1671960/78836 (78%)]	Loss: 0.579454
Train epoch: 100 [1927380/78836 (91%)]	Loss: 0.595009
predicting for valid data
Make prediction for 19709 samples...
0.24554868 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.24554868 0.8161404696235199 GINConvNet kiba
Training on 78836 samples...
Train epoch: 101 [0/78836 (0%)]	Loss: 0.569475
Train epoch: 101 [276800/78836 (13%)]	Loss: 0.535629
Train epoch: 101 [553880/78836 (26%)]	Loss: 0.583228
Train epoch: 101 [832260/78836 (39%)]	Loss: 0.502322
Train epoch: 101 [1133120/78836 (52%)]	Loss: 0.576388
Train epoch: 101 [1384500/78836 (65%)]	Loss: 0.473429
Train epoch: 101 [1687080/78836 (78%)]	Loss: 0.632352
Train epoch: 101 [1959440/78836 (91%)]	Loss: 0.695749
predicting for valid data
Make prediction for 19709 samples...
0.24554868 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.24554868 0.8161404696235199 GINConvNet kiba
Training on 78836 samples...
Train epoch: 102 [0/78836 (0%)]	Loss: 0.571821
Train epoch: 102 [280260/78836 (13%)]	Loss: 0.483663
Train epoch: 102 [565000/78836 (26%)]	Loss: 0.542844
Train epoch: 102 [832020/78836 (39%)]	Loss: 0.548687
Train epoch: 102 [1114400/78836 (52%)]	Loss: 0.647405
Train epoch: 102 [1398900/78836 (65%)]	Loss: 0.591661
Train epoch: 102 [1702320/78836 (78%)]	Loss: 0.610892
Train epoch: 102 [1970220/78836 (91%)]	Loss: 0.703538
predicting for valid data
Make prediction for 19709 samples...
0.24554868 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.24554868 0.8161404696235199 GINConvNet kiba
Training on 78836 samples...
Train epoch: 103 [0/78836 (0%)]	Loss: 0.509592
Train epoch: 103 [282020/78836 (13%)]	Loss: 0.491526
Train epoch: 103 [567240/78836 (26%)]	Loss: 0.488331
Train epoch: 103 [835860/78836 (39%)]	Loss: 0.547624
Train epoch: 103 [1116240/78836 (52%)]	Loss: 0.553441
Train epoch: 103 [1377500/78836 (65%)]	Loss: 0.493861
Train epoch: 103 [1674360/78836 (78%)]	Loss: 0.524896
Train epoch: 103 [1941520/78836 (91%)]	Loss: 0.519177
predicting for valid data
Make prediction for 19709 samples...
0.24554868 No improvement since epoch  99 ; best_test_mse,best_test_ci: 0.24554868 0.8161404696235199 GINConvNet kiba
Training on 78836 samples...
Train epoch: 104 [0/78836 (0%)]	Loss: 0.513891
Train epoch: 104 [278480/78836 (13%)]	Loss: 0.531487
Train epoch: 104 [563080/78836 (26%)]	Loss: 0.463425
Train epoch: 104 [834120/78836 (39%)]	Loss: 0.503230
Train epoch: 104 [1116000/78836 (52%)]	Loss: 0.534850
Train epoch: 104 [1406200/78836 (65%)]	Loss: 0.621633
Train epoch: 104 [1686000/78836 (78%)]	Loss: 0.556684
Train epoch: 104 [1924720/78836 (91%)]	Loss: 0.515251
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  104 ; best_test_mse,best_test_ci: 0.25486642 0.8086208671362382 GINConvNet kiba
Training on 78836 samples...
Train epoch: 105 [0/78836 (0%)]	Loss: 0.453913
Train epoch: 105 [281840/78836 (13%)]	Loss: 0.568519
Train epoch: 105 [559120/78836 (26%)]	Loss: 0.561937
Train epoch: 105 [854220/78836 (39%)]	Loss: 0.527443
Train epoch: 105 [1107280/78836 (52%)]	Loss: 0.558163
Train epoch: 105 [1388200/78836 (65%)]	Loss: 0.586779
Train epoch: 105 [1626360/78836 (78%)]	Loss: 0.596532
Train epoch: 105 [1956780/78836 (91%)]	Loss: 0.514023
predicting for valid data
Make prediction for 19709 samples...
0.25486642 No improvement since epoch  104 ; best_test_mse,best_test_ci: 0.25486642 0.8086208671362382 GINConvNet kiba
Training on 78836 samples...
Train epoch: 106 [0/78836 (0%)]	Loss: 0.533150
Train epoch: 106 [278760/78836 (13%)]	Loss: 0.509397
Train epoch: 106 [556920/78836 (26%)]	Loss: 0.691355
Train epoch: 106 [826980/78836 (39%)]	Loss: 0.553879
Train epoch: 106 [1161280/78836 (52%)]	Loss: 0.612334
Train epoch: 106 [1404700/78836 (65%)]	Loss: 0.496415
Train epoch: 106 [1698480/78836 (78%)]	Loss: 0.592462
Train epoch: 106 [1962940/78836 (91%)]	Loss: 0.528423
predicting for valid data
Make prediction for 19709 samples...
0.25486642 No improvement since epoch  104 ; best_test_mse,best_test_ci: 0.25486642 0.8086208671362382 GINConvNet kiba
Training on 78836 samples...
Train epoch: 107 [0/78836 (0%)]	Loss: 0.482547
Train epoch: 107 [274380/78836 (13%)]	Loss: 0.511653
Train epoch: 107 [561240/78836 (26%)]	Loss: 0.550255
Train epoch: 107 [836160/78836 (39%)]	Loss: 0.467647
Train epoch: 107 [1106640/78836 (52%)]	Loss: 0.513210
Train epoch: 107 [1384700/78836 (65%)]	Loss: 0.592506
Train epoch: 107 [1704120/78836 (78%)]	Loss: 0.468978
Train epoch: 107 [1941520/78836 (91%)]	Loss: 0.469517
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 108 [0/78836 (0%)]	Loss: 0.501786
Train epoch: 108 [280580/78836 (13%)]	Loss: 0.511502
Train epoch: 108 [577600/78836 (26%)]	Loss: 0.556281
Train epoch: 108 [837720/78836 (39%)]	Loss: 0.568618
Train epoch: 108 [1136640/78836 (52%)]	Loss: 0.623542
Train epoch: 108 [1356600/78836 (65%)]	Loss: 0.561728
Train epoch: 108 [1637280/78836 (78%)]	Loss: 0.597862
Train epoch: 108 [1923460/78836 (91%)]	Loss: 0.497218
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 109 [0/78836 (0%)]	Loss: 0.682216
Train epoch: 109 [276260/78836 (13%)]	Loss: 0.548419
Train epoch: 109 [560280/78836 (26%)]	Loss: 0.543525
Train epoch: 109 [836700/78836 (39%)]	Loss: 0.577829
Train epoch: 109 [1113920/78836 (52%)]	Loss: 0.567109
Train epoch: 109 [1405600/78836 (65%)]	Loss: 0.495320
Train epoch: 109 [1677840/78836 (78%)]	Loss: 0.519784
Train epoch: 109 [2003960/78836 (91%)]	Loss: 0.462604
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 110 [0/78836 (0%)]	Loss: 0.560493
Train epoch: 110 [279320/78836 (13%)]	Loss: 0.504633
Train epoch: 110 [550920/78836 (26%)]	Loss: 0.514841
Train epoch: 110 [846060/78836 (39%)]	Loss: 0.606439
Train epoch: 110 [1100960/78836 (52%)]	Loss: 0.492237
Train epoch: 110 [1417300/78836 (65%)]	Loss: 0.559016
Train epoch: 110 [1645800/78836 (78%)]	Loss: 0.506041
Train epoch: 110 [1969380/78836 (91%)]	Loss: 0.504279
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 111 [0/78836 (0%)]	Loss: 0.458455
Train epoch: 111 [279020/78836 (13%)]	Loss: 0.563108
Train epoch: 111 [548280/78836 (26%)]	Loss: 0.596441
Train epoch: 111 [835680/78836 (39%)]	Loss: 0.508295
Train epoch: 111 [1131040/78836 (52%)]	Loss: 0.405629
Train epoch: 111 [1393800/78836 (65%)]	Loss: 0.429675
Train epoch: 111 [1659000/78836 (78%)]	Loss: 0.570982
Train epoch: 111 [1980580/78836 (91%)]	Loss: 0.518017
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 112 [0/78836 (0%)]	Loss: 0.408433
Train epoch: 112 [278260/78836 (13%)]	Loss: 0.503831
Train epoch: 112 [560080/78836 (26%)]	Loss: 0.605673
Train epoch: 112 [839940/78836 (39%)]	Loss: 0.463993
Train epoch: 112 [1131440/78836 (52%)]	Loss: 0.578400
Train epoch: 112 [1410500/78836 (65%)]	Loss: 0.538457
Train epoch: 112 [1706640/78836 (78%)]	Loss: 0.447597
Train epoch: 112 [1905820/78836 (91%)]	Loss: 0.437516
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 113 [0/78836 (0%)]	Loss: 0.469933
Train epoch: 113 [278560/78836 (13%)]	Loss: 0.519808
Train epoch: 113 [554000/78836 (26%)]	Loss: 0.667130
Train epoch: 113 [862020/78836 (39%)]	Loss: 0.585931
Train epoch: 113 [1078800/78836 (52%)]	Loss: 0.635766
Train epoch: 113 [1412900/78836 (65%)]	Loss: 0.553582
Train epoch: 113 [1694160/78836 (78%)]	Loss: 0.451537
Train epoch: 113 [2018940/78836 (91%)]	Loss: 0.509518
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 114 [0/78836 (0%)]	Loss: 0.484813
Train epoch: 114 [275960/78836 (13%)]	Loss: 0.488144
Train epoch: 114 [566600/78836 (26%)]	Loss: 0.534835
Train epoch: 114 [822840/78836 (39%)]	Loss: 0.564259
Train epoch: 114 [1127280/78836 (52%)]	Loss: 0.586581
Train epoch: 114 [1389400/78836 (65%)]	Loss: 0.503655
Train epoch: 114 [1654200/78836 (78%)]	Loss: 0.466226
Train epoch: 114 [1958320/78836 (91%)]	Loss: 0.491173
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 115 [0/78836 (0%)]	Loss: 0.549599
Train epoch: 115 [274720/78836 (13%)]	Loss: 0.487350
Train epoch: 115 [549880/78836 (26%)]	Loss: 0.476630
Train epoch: 115 [837960/78836 (39%)]	Loss: 0.410749
Train epoch: 115 [1133920/78836 (52%)]	Loss: 0.512534
Train epoch: 115 [1376900/78836 (65%)]	Loss: 0.587687
Train epoch: 115 [1666200/78836 (78%)]	Loss: 0.514815
Train epoch: 115 [1925840/78836 (91%)]	Loss: 0.516458
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 116 [0/78836 (0%)]	Loss: 0.536639
Train epoch: 116 [277100/78836 (13%)]	Loss: 0.537835
Train epoch: 116 [570480/78836 (26%)]	Loss: 0.650811
Train epoch: 116 [859920/78836 (39%)]	Loss: 0.576825
Train epoch: 116 [1126080/78836 (52%)]	Loss: 0.720272
Train epoch: 116 [1397600/78836 (65%)]	Loss: 0.490450
Train epoch: 116 [1706880/78836 (78%)]	Loss: 0.497087
Train epoch: 116 [1966720/78836 (91%)]	Loss: 0.621107
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 117 [0/78836 (0%)]	Loss: 0.470661
Train epoch: 117 [275020/78836 (13%)]	Loss: 0.567365
Train epoch: 117 [569240/78836 (26%)]	Loss: 0.643266
Train epoch: 117 [865200/78836 (39%)]	Loss: 0.577220
Train epoch: 117 [1119040/78836 (52%)]	Loss: 0.485364
Train epoch: 117 [1377100/78836 (65%)]	Loss: 0.567561
Train epoch: 117 [1655040/78836 (78%)]	Loss: 0.582222
Train epoch: 117 [1943620/78836 (91%)]	Loss: 0.545252
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 118 [0/78836 (0%)]	Loss: 0.541562
Train epoch: 118 [286820/78836 (13%)]	Loss: 0.550474
Train epoch: 118 [562120/78836 (26%)]	Loss: 0.428614
Train epoch: 118 [835980/78836 (39%)]	Loss: 0.446640
Train epoch: 118 [1125680/78836 (52%)]	Loss: 0.539979
Train epoch: 118 [1396100/78836 (65%)]	Loss: 0.467651
Train epoch: 118 [1678800/78836 (78%)]	Loss: 0.582538
Train epoch: 118 [1923600/78836 (91%)]	Loss: 0.469324
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 119 [0/78836 (0%)]	Loss: 0.479935
Train epoch: 119 [283320/78836 (13%)]	Loss: 0.489594
Train epoch: 119 [563520/78836 (26%)]	Loss: 0.584310
Train epoch: 119 [828420/78836 (39%)]	Loss: 0.469026
Train epoch: 119 [1131520/78836 (52%)]	Loss: 0.532833
Train epoch: 119 [1395200/78836 (65%)]	Loss: 0.519347
Train epoch: 119 [1693920/78836 (78%)]	Loss: 0.451775
Train epoch: 119 [1934240/78836 (91%)]	Loss: 0.521785
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 120 [0/78836 (0%)]	Loss: 0.452341
Train epoch: 120 [279840/78836 (13%)]	Loss: 0.552608
Train epoch: 120 [560600/78836 (26%)]	Loss: 0.540904
Train epoch: 120 [846420/78836 (39%)]	Loss: 0.564128
Train epoch: 120 [1115360/78836 (52%)]	Loss: 0.535452
Train epoch: 120 [1414400/78836 (65%)]	Loss: 0.438153
Train epoch: 120 [1692360/78836 (78%)]	Loss: 0.518660
Train epoch: 120 [2007880/78836 (91%)]	Loss: 0.561188
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 121 [0/78836 (0%)]	Loss: 0.564627
Train epoch: 121 [279100/78836 (13%)]	Loss: 0.674077
Train epoch: 121 [554840/78836 (26%)]	Loss: 0.510480
Train epoch: 121 [842940/78836 (39%)]	Loss: 0.436144
Train epoch: 121 [1087920/78836 (52%)]	Loss: 0.536197
Train epoch: 121 [1397100/78836 (65%)]	Loss: 0.473677
Train epoch: 121 [1677600/78836 (78%)]	Loss: 0.549574
Train epoch: 121 [1981980/78836 (91%)]	Loss: 0.434214
predicting for valid data
Make prediction for 19709 samples...
0.24530776 No improvement since epoch  107 ; best_test_mse,best_test_ci: 0.24530776 0.8146259779547851 GINConvNet kiba
Training on 78836 samples...
Train epoch: 122 [0/78836 (0%)]	Loss: 0.430864
Train epoch: 122 [274640/78836 (13%)]	Loss: 0.546315
Train epoch: 122 [562360/78836 (26%)]	Loss: 0.518589
Train epoch: 122 [835140/78836 (39%)]	Loss: 0.490662
Train epoch: 122 [1087600/78836 (52%)]	Loss: 0.506633
Train epoch: 122 [1409100/78836 (65%)]	Loss: 0.461850
Train epoch: 122 [1687800/78836 (78%)]	Loss: 0.475944
Train epoch: 122 [1953000/78836 (91%)]	Loss: 0.573169
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 123 [0/78836 (0%)]	Loss: 0.491540
Train epoch: 123 [274780/78836 (13%)]	Loss: 0.465613
Train epoch: 123 [554160/78836 (26%)]	Loss: 0.479109
Train epoch: 123 [836460/78836 (39%)]	Loss: 0.465339
Train epoch: 123 [1120240/78836 (52%)]	Loss: 0.499298
Train epoch: 123 [1423800/78836 (65%)]	Loss: 0.564303
Train epoch: 123 [1654680/78836 (78%)]	Loss: 0.594994
Train epoch: 123 [1951600/78836 (91%)]	Loss: 0.480550
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 124 [0/78836 (0%)]	Loss: 0.482949
Train epoch: 124 [280400/78836 (13%)]	Loss: 0.484413
Train epoch: 124 [544840/78836 (26%)]	Loss: 0.560461
Train epoch: 124 [839040/78836 (39%)]	Loss: 0.567572
Train epoch: 124 [1138560/78836 (52%)]	Loss: 0.508466
Train epoch: 124 [1414200/78836 (65%)]	Loss: 0.507803
Train epoch: 124 [1718040/78836 (78%)]	Loss: 0.468142
Train epoch: 124 [1960560/78836 (91%)]	Loss: 0.450859
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 125 [0/78836 (0%)]	Loss: 0.517274
Train epoch: 125 [280240/78836 (13%)]	Loss: 0.444261
Train epoch: 125 [539880/78836 (26%)]	Loss: 0.469126
Train epoch: 125 [847020/78836 (39%)]	Loss: 0.465131
Train epoch: 125 [1107200/78836 (52%)]	Loss: 0.500527
Train epoch: 125 [1384000/78836 (65%)]	Loss: 0.477297
Train epoch: 125 [1681680/78836 (78%)]	Loss: 0.423491
Train epoch: 125 [1936900/78836 (91%)]	Loss: 0.501045
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 126 [0/78836 (0%)]	Loss: 0.494537
Train epoch: 126 [279980/78836 (13%)]	Loss: 0.447604
Train epoch: 126 [562480/78836 (26%)]	Loss: 0.446732
Train epoch: 126 [825720/78836 (39%)]	Loss: 0.507659
Train epoch: 126 [1130400/78836 (52%)]	Loss: 0.434163
Train epoch: 126 [1400000/78836 (65%)]	Loss: 0.437212
Train epoch: 126 [1657680/78836 (78%)]	Loss: 0.494992
Train epoch: 126 [1987020/78836 (91%)]	Loss: 0.542050
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 127 [0/78836 (0%)]	Loss: 0.566966
Train epoch: 127 [281520/78836 (13%)]	Loss: 0.483236
Train epoch: 127 [555240/78836 (26%)]	Loss: 0.456461
Train epoch: 127 [840660/78836 (39%)]	Loss: 0.578628
Train epoch: 127 [1104480/78836 (52%)]	Loss: 0.429566
Train epoch: 127 [1398100/78836 (65%)]	Loss: 0.454441
Train epoch: 127 [1636080/78836 (78%)]	Loss: 0.444998
Train epoch: 127 [1963080/78836 (91%)]	Loss: 0.493237
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 128 [0/78836 (0%)]	Loss: 0.464970
Train epoch: 128 [287120/78836 (13%)]	Loss: 0.453119
Train epoch: 128 [552160/78836 (26%)]	Loss: 0.465086
Train epoch: 128 [837720/78836 (39%)]	Loss: 0.481669
Train epoch: 128 [1115520/78836 (52%)]	Loss: 0.473471
Train epoch: 128 [1411900/78836 (65%)]	Loss: 0.487319
Train epoch: 128 [1656360/78836 (78%)]	Loss: 0.532166
Train epoch: 128 [2004380/78836 (91%)]	Loss: 0.522824
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 129 [0/78836 (0%)]	Loss: 0.612723
Train epoch: 129 [282900/78836 (13%)]	Loss: 0.494638
Train epoch: 129 [560640/78836 (26%)]	Loss: 0.435273
Train epoch: 129 [838080/78836 (39%)]	Loss: 0.506174
Train epoch: 129 [1085040/78836 (52%)]	Loss: 0.518624
Train epoch: 129 [1401100/78836 (65%)]	Loss: 0.494496
Train epoch: 129 [1690320/78836 (78%)]	Loss: 0.521884
Train epoch: 129 [1937320/78836 (91%)]	Loss: 0.631750
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 130 [0/78836 (0%)]	Loss: 0.463410
Train epoch: 130 [282160/78836 (13%)]	Loss: 0.496210
Train epoch: 130 [549600/78836 (26%)]	Loss: 0.459593
Train epoch: 130 [837900/78836 (39%)]	Loss: 0.439762
Train epoch: 130 [1103200/78836 (52%)]	Loss: 0.518437
Train epoch: 130 [1396100/78836 (65%)]	Loss: 0.485795
Train epoch: 130 [1646760/78836 (78%)]	Loss: 0.453147
Train epoch: 130 [1979320/78836 (91%)]	Loss: 0.442140
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 131 [0/78836 (0%)]	Loss: 0.521591
Train epoch: 131 [278680/78836 (13%)]	Loss: 0.554608
Train epoch: 131 [553040/78836 (26%)]	Loss: 0.542845
Train epoch: 131 [841620/78836 (39%)]	Loss: 0.518513
Train epoch: 131 [1144880/78836 (52%)]	Loss: 0.512764
Train epoch: 131 [1398200/78836 (65%)]	Loss: 0.425639
Train epoch: 131 [1689720/78836 (78%)]	Loss: 0.509177
Train epoch: 131 [1926960/78836 (91%)]	Loss: 0.554232
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 132 [0/78836 (0%)]	Loss: 0.564614
Train epoch: 132 [288080/78836 (13%)]	Loss: 0.432675
Train epoch: 132 [554880/78836 (26%)]	Loss: 0.450880
Train epoch: 132 [844740/78836 (39%)]	Loss: 0.484524
Train epoch: 132 [1126800/78836 (52%)]	Loss: 0.428552
Train epoch: 132 [1401300/78836 (65%)]	Loss: 0.455711
Train epoch: 132 [1677960/78836 (78%)]	Loss: 0.428202
Train epoch: 132 [1977920/78836 (91%)]	Loss: 0.472570
predicting for valid data
Make prediction for 19709 samples...
0.2426825 No improvement since epoch  122 ; best_test_mse,best_test_ci: 0.2426825 0.8181021565505976 GINConvNet kiba
Training on 78836 samples...
Train epoch: 133 [0/78836 (0%)]	Loss: 0.626925
Train epoch: 133 [276760/78836 (13%)]	Loss: 0.432559
Train epoch: 133 [561760/78836 (26%)]	Loss: 0.539238
Train epoch: 133 [846300/78836 (39%)]	Loss: 0.510483
Train epoch: 133 [1101920/78836 (52%)]	Loss: 0.745090
Train epoch: 133 [1398000/78836 (65%)]	Loss: 0.468708
Train epoch: 133 [1689960/78836 (78%)]	Loss: 0.538503
Train epoch: 133 [1917720/78836 (91%)]	Loss: 0.455122
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 134 [0/78836 (0%)]	Loss: 0.467044
Train epoch: 134 [278280/78836 (13%)]	Loss: 0.523561
Train epoch: 134 [574600/78836 (26%)]	Loss: 0.487143
Train epoch: 134 [839940/78836 (39%)]	Loss: 0.557088
Train epoch: 134 [1122640/78836 (52%)]	Loss: 0.516812
Train epoch: 134 [1365300/78836 (65%)]	Loss: 0.481225
Train epoch: 134 [1679640/78836 (78%)]	Loss: 0.485126
Train epoch: 134 [1925420/78836 (91%)]	Loss: 0.479264
predicting for valid data
Make prediction for 19709 samples...
0.23624372 No improvement since epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 135 [0/78836 (0%)]	Loss: 0.428375
Train epoch: 135 [283840/78836 (13%)]	Loss: 0.492825
Train epoch: 135 [576080/78836 (26%)]	Loss: 0.546920
Train epoch: 135 [843660/78836 (39%)]	Loss: 0.575412
Train epoch: 135 [1125360/78836 (52%)]	Loss: 0.493077
Train epoch: 135 [1420500/78836 (65%)]	Loss: 0.541629
Train epoch: 135 [1637760/78836 (78%)]	Loss: 0.553157
Train epoch: 135 [1939700/78836 (91%)]	Loss: 0.510489
predicting for valid data
Make prediction for 19709 samples...
0.23624372 No improvement since epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 136 [0/78836 (0%)]	Loss: 0.557355
Train epoch: 136 [288600/78836 (13%)]	Loss: 0.485692
Train epoch: 136 [553680/78836 (26%)]	Loss: 0.520927
Train epoch: 136 [810660/78836 (39%)]	Loss: 0.481464
Train epoch: 136 [1119280/78836 (52%)]	Loss: 0.424827
Train epoch: 136 [1398500/78836 (65%)]	Loss: 0.484129
Train epoch: 136 [1659120/78836 (78%)]	Loss: 0.473152
Train epoch: 136 [1936620/78836 (91%)]	Loss: 0.502833
predicting for valid data
Make prediction for 19709 samples...
0.23624372 No improvement since epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 137 [0/78836 (0%)]	Loss: 0.557281
Train epoch: 137 [281180/78836 (13%)]	Loss: 0.529215
Train epoch: 137 [562160/78836 (26%)]	Loss: 0.544490
Train epoch: 137 [839040/78836 (39%)]	Loss: 0.569284
Train epoch: 137 [1086080/78836 (52%)]	Loss: 0.433154
Train epoch: 137 [1375400/78836 (65%)]	Loss: 0.507742
Train epoch: 137 [1692120/78836 (78%)]	Loss: 0.498737
Train epoch: 137 [1950620/78836 (91%)]	Loss: 0.463505
predicting for valid data
Make prediction for 19709 samples...
0.23624372 No improvement since epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 138 [0/78836 (0%)]	Loss: 0.557805
Train epoch: 138 [277000/78836 (13%)]	Loss: 0.484652
Train epoch: 138 [556200/78836 (26%)]	Loss: 0.500236
Train epoch: 138 [833700/78836 (39%)]	Loss: 0.521130
Train epoch: 138 [1117120/78836 (52%)]	Loss: 0.554604
Train epoch: 138 [1403000/78836 (65%)]	Loss: 0.517699
Train epoch: 138 [1702080/78836 (78%)]	Loss: 0.487736
Train epoch: 138 [1944740/78836 (91%)]	Loss: 0.512418
predicting for valid data
Make prediction for 19709 samples...
0.23624372 No improvement since epoch  133 ; best_test_mse,best_test_ci: 0.23624372 0.8202960621131634 GINConvNet kiba
Training on 78836 samples...
Train epoch: 139 [0/78836 (0%)]	Loss: 0.451296
Train epoch: 139 [276320/78836 (13%)]	Loss: 0.422384
Train epoch: 139 [559680/78836 (26%)]	Loss: 0.510174
Train epoch: 139 [838500/78836 (39%)]	Loss: 0.442551
Train epoch: 139 [1108480/78836 (52%)]	Loss: 0.453007
Train epoch: 139 [1394300/78836 (65%)]	Loss: 0.506417
Train epoch: 139 [1676520/78836 (78%)]	Loss: 0.517305
Train epoch: 139 [1916320/78836 (91%)]	Loss: 0.491746
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 140 [0/78836 (0%)]	Loss: 0.452228
Train epoch: 140 [285340/78836 (13%)]	Loss: 0.491299
Train epoch: 140 [554880/78836 (26%)]	Loss: 0.466168
Train epoch: 140 [843300/78836 (39%)]	Loss: 0.501827
Train epoch: 140 [1135840/78836 (52%)]	Loss: 0.486205
Train epoch: 140 [1402500/78836 (65%)]	Loss: 0.490743
Train epoch: 140 [1711800/78836 (78%)]	Loss: 0.509784
Train epoch: 140 [1965320/78836 (91%)]	Loss: 0.465357
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 141 [0/78836 (0%)]	Loss: 0.447327
Train epoch: 141 [277620/78836 (13%)]	Loss: 0.458668
Train epoch: 141 [548400/78836 (26%)]	Loss: 0.487649
Train epoch: 141 [837600/78836 (39%)]	Loss: 0.451057
Train epoch: 141 [1138480/78836 (52%)]	Loss: 0.586008
Train epoch: 141 [1404300/78836 (65%)]	Loss: 0.558903
Train epoch: 141 [1658280/78836 (78%)]	Loss: 0.562066
Train epoch: 141 [1995000/78836 (91%)]	Loss: 0.535679
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 142 [0/78836 (0%)]	Loss: 0.456754
Train epoch: 142 [283100/78836 (13%)]	Loss: 0.512387
Train epoch: 142 [546680/78836 (26%)]	Loss: 0.406496
Train epoch: 142 [835980/78836 (39%)]	Loss: 0.563357
Train epoch: 142 [1097680/78836 (52%)]	Loss: 0.493053
Train epoch: 142 [1390200/78836 (65%)]	Loss: 0.481040
Train epoch: 142 [1683840/78836 (78%)]	Loss: 0.593495
Train epoch: 142 [1953560/78836 (91%)]	Loss: 0.537752
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 143 [0/78836 (0%)]	Loss: 0.471056
Train epoch: 143 [279660/78836 (13%)]	Loss: 0.581916
Train epoch: 143 [557800/78836 (26%)]	Loss: 0.477200
Train epoch: 143 [829500/78836 (39%)]	Loss: 0.406056
Train epoch: 143 [1103920/78836 (52%)]	Loss: 0.489232
Train epoch: 143 [1451500/78836 (65%)]	Loss: 0.511936
Train epoch: 143 [1660680/78836 (78%)]	Loss: 0.483638
Train epoch: 143 [1969240/78836 (91%)]	Loss: 0.431539
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 144 [0/78836 (0%)]	Loss: 0.518332
Train epoch: 144 [277500/78836 (13%)]	Loss: 0.462377
Train epoch: 144 [556760/78836 (26%)]	Loss: 0.505531
Train epoch: 144 [835560/78836 (39%)]	Loss: 0.516025
Train epoch: 144 [1115840/78836 (52%)]	Loss: 0.530741
Train epoch: 144 [1382300/78836 (65%)]	Loss: 0.477059
Train epoch: 144 [1649040/78836 (78%)]	Loss: 0.398586
Train epoch: 144 [1933820/78836 (91%)]	Loss: 0.465492
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 145 [0/78836 (0%)]	Loss: 0.441006
Train epoch: 145 [278880/78836 (13%)]	Loss: 0.504095
Train epoch: 145 [557920/78836 (26%)]	Loss: 0.488483
Train epoch: 145 [836040/78836 (39%)]	Loss: 0.558513
Train epoch: 145 [1091040/78836 (52%)]	Loss: 0.435222
Train epoch: 145 [1344300/78836 (65%)]	Loss: 0.556675
Train epoch: 145 [1699680/78836 (78%)]	Loss: 0.435544
Train epoch: 145 [1997800/78836 (91%)]	Loss: 0.579555
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 146 [0/78836 (0%)]	Loss: 0.582920
Train epoch: 146 [278500/78836 (13%)]	Loss: 0.456686
Train epoch: 146 [559000/78836 (26%)]	Loss: 0.405786
Train epoch: 146 [848220/78836 (39%)]	Loss: 0.530114
Train epoch: 146 [1125120/78836 (52%)]	Loss: 0.448698
Train epoch: 146 [1434600/78836 (65%)]	Loss: 0.450606
Train epoch: 146 [1685760/78836 (78%)]	Loss: 0.509591
Train epoch: 146 [1923600/78836 (91%)]	Loss: 0.473014
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 147 [0/78836 (0%)]	Loss: 0.455159
Train epoch: 147 [276700/78836 (13%)]	Loss: 0.440959
Train epoch: 147 [549360/78836 (26%)]	Loss: 0.618375
Train epoch: 147 [840360/78836 (39%)]	Loss: 0.486643
Train epoch: 147 [1109040/78836 (52%)]	Loss: 0.477832
Train epoch: 147 [1400600/78836 (65%)]	Loss: 0.444593
Train epoch: 147 [1677960/78836 (78%)]	Loss: 0.512654
Train epoch: 147 [1989120/78836 (91%)]	Loss: 0.510991
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 148 [0/78836 (0%)]	Loss: 0.443882
Train epoch: 148 [283260/78836 (13%)]	Loss: 0.480382
Train epoch: 148 [558120/78836 (26%)]	Loss: 0.434801
Train epoch: 148 [841920/78836 (39%)]	Loss: 0.555057
Train epoch: 148 [1116560/78836 (52%)]	Loss: 0.574498
Train epoch: 148 [1425500/78836 (65%)]	Loss: 0.447048
Train epoch: 148 [1682040/78836 (78%)]	Loss: 0.686588
Train epoch: 148 [1936340/78836 (91%)]	Loss: 0.567875
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 149 [0/78836 (0%)]	Loss: 0.472090
Train epoch: 149 [280480/78836 (13%)]	Loss: 0.466900
Train epoch: 149 [555000/78836 (26%)]	Loss: 0.460970
Train epoch: 149 [836700/78836 (39%)]	Loss: 0.534617
Train epoch: 149 [1142000/78836 (52%)]	Loss: 0.484754
Train epoch: 149 [1396800/78836 (65%)]	Loss: 0.458492
Train epoch: 149 [1680240/78836 (78%)]	Loss: 0.449766
Train epoch: 149 [1969380/78836 (91%)]	Loss: 0.412600
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 150 [0/78836 (0%)]	Loss: 0.468640
Train epoch: 150 [284740/78836 (13%)]	Loss: 0.433442
Train epoch: 150 [567360/78836 (26%)]	Loss: 0.460601
Train epoch: 150 [839640/78836 (39%)]	Loss: 0.477117
Train epoch: 150 [1126880/78836 (52%)]	Loss: 0.468306
Train epoch: 150 [1391900/78836 (65%)]	Loss: 0.463646
Train epoch: 150 [1694640/78836 (78%)]	Loss: 0.454394
Train epoch: 150 [2018240/78836 (91%)]	Loss: 0.574330
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 151 [0/78836 (0%)]	Loss: 0.477337
Train epoch: 151 [283060/78836 (13%)]	Loss: 0.463905
Train epoch: 151 [569600/78836 (26%)]	Loss: 0.431618
Train epoch: 151 [823200/78836 (39%)]	Loss: 0.544800
Train epoch: 151 [1115280/78836 (52%)]	Loss: 0.479524
Train epoch: 151 [1432500/78836 (65%)]	Loss: 0.463250
Train epoch: 151 [1642200/78836 (78%)]	Loss: 0.498632
Train epoch: 151 [1934240/78836 (91%)]	Loss: 0.454916
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 152 [0/78836 (0%)]	Loss: 0.442705
Train epoch: 152 [281740/78836 (13%)]	Loss: 0.466857
Train epoch: 152 [562000/78836 (26%)]	Loss: 0.439651
Train epoch: 152 [812220/78836 (39%)]	Loss: 0.442000
Train epoch: 152 [1132960/78836 (52%)]	Loss: 0.472954
Train epoch: 152 [1395000/78836 (65%)]	Loss: 0.738065
Train epoch: 152 [1646760/78836 (78%)]	Loss: 0.745140
Train epoch: 152 [1911700/78836 (91%)]	Loss: 0.501342
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 153 [0/78836 (0%)]	Loss: 0.510675
Train epoch: 153 [276700/78836 (13%)]	Loss: 0.476066
Train epoch: 153 [562680/78836 (26%)]	Loss: 0.554409
Train epoch: 153 [833700/78836 (39%)]	Loss: 0.402349
Train epoch: 153 [1106000/78836 (52%)]	Loss: 0.445523
Train epoch: 153 [1401700/78836 (65%)]	Loss: 0.423061
Train epoch: 153 [1655160/78836 (78%)]	Loss: 0.414824
Train epoch: 153 [1938440/78836 (91%)]	Loss: 0.486597
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 154 [0/78836 (0%)]	Loss: 0.439900
Train epoch: 154 [278160/78836 (13%)]	Loss: 0.458475
Train epoch: 154 [561200/78836 (26%)]	Loss: 0.483928
Train epoch: 154 [839400/78836 (39%)]	Loss: 0.547632
Train epoch: 154 [1093520/78836 (52%)]	Loss: 0.445074
Train epoch: 154 [1401200/78836 (65%)]	Loss: 0.398660
Train epoch: 154 [1664640/78836 (78%)]	Loss: 0.495436
Train epoch: 154 [1951460/78836 (91%)]	Loss: 0.426015
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 155 [0/78836 (0%)]	Loss: 0.438318
Train epoch: 155 [273500/78836 (13%)]	Loss: 0.441445
Train epoch: 155 [555480/78836 (26%)]	Loss: 0.447563
Train epoch: 155 [844020/78836 (39%)]	Loss: 0.502402
Train epoch: 155 [1093520/78836 (52%)]	Loss: 0.430420
Train epoch: 155 [1396300/78836 (65%)]	Loss: 0.457128
Train epoch: 155 [1688640/78836 (78%)]	Loss: 0.462250
Train epoch: 155 [2009840/78836 (91%)]	Loss: 0.660425
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 156 [0/78836 (0%)]	Loss: 0.525735
Train epoch: 156 [274200/78836 (13%)]	Loss: 0.419954
Train epoch: 156 [558200/78836 (26%)]	Loss: 0.455047
Train epoch: 156 [839220/78836 (39%)]	Loss: 0.447214
Train epoch: 156 [1108800/78836 (52%)]	Loss: 0.491331
Train epoch: 156 [1397400/78836 (65%)]	Loss: 0.447663
Train epoch: 156 [1677120/78836 (78%)]	Loss: 0.465611
Train epoch: 156 [1979740/78836 (91%)]	Loss: 0.404842
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 157 [0/78836 (0%)]	Loss: 0.444180
Train epoch: 157 [277420/78836 (13%)]	Loss: 0.479250
Train epoch: 157 [565680/78836 (26%)]	Loss: 0.414233
Train epoch: 157 [828660/78836 (39%)]	Loss: 0.534905
Train epoch: 157 [1113040/78836 (52%)]	Loss: 0.444409
Train epoch: 157 [1365100/78836 (65%)]	Loss: 0.501929
Train epoch: 157 [1639080/78836 (78%)]	Loss: 0.496321
Train epoch: 157 [1962240/78836 (91%)]	Loss: 0.474395
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 158 [0/78836 (0%)]	Loss: 0.416770
Train epoch: 158 [280560/78836 (13%)]	Loss: 0.476440
Train epoch: 158 [559720/78836 (26%)]	Loss: 0.423066
Train epoch: 158 [828780/78836 (39%)]	Loss: 0.433783
Train epoch: 158 [1111440/78836 (52%)]	Loss: 0.510189
Train epoch: 158 [1374400/78836 (65%)]	Loss: 0.491029
Train epoch: 158 [1677960/78836 (78%)]	Loss: 0.506844
Train epoch: 158 [1999200/78836 (91%)]	Loss: 0.438178
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 159 [0/78836 (0%)]	Loss: 0.436104
Train epoch: 159 [277660/78836 (13%)]	Loss: 0.440205
Train epoch: 159 [549240/78836 (26%)]	Loss: 0.595953
Train epoch: 159 [839340/78836 (39%)]	Loss: 0.634395
Train epoch: 159 [1102960/78836 (52%)]	Loss: 0.428441
Train epoch: 159 [1399300/78836 (65%)]	Loss: 0.512127
Train epoch: 159 [1671120/78836 (78%)]	Loss: 0.433540
Train epoch: 159 [1980160/78836 (91%)]	Loss: 0.498658
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 160 [0/78836 (0%)]	Loss: 0.532542
Train epoch: 160 [275620/78836 (13%)]	Loss: 0.438525
Train epoch: 160 [561040/78836 (26%)]	Loss: 0.403820
Train epoch: 160 [838620/78836 (39%)]	Loss: 0.482473
Train epoch: 160 [1104640/78836 (52%)]	Loss: 0.501811
Train epoch: 160 [1379000/78836 (65%)]	Loss: 0.446696
Train epoch: 160 [1673760/78836 (78%)]	Loss: 0.434263
Train epoch: 160 [1995700/78836 (91%)]	Loss: 0.588922
predicting for valid data
Make prediction for 19709 samples...
0.2331109 No improvement since epoch  139 ; best_test_mse,best_test_ci: 0.2331109 0.8216798359656375 GINConvNet kiba
Training on 78836 samples...
Train epoch: 161 [0/78836 (0%)]	Loss: 0.417411
Train epoch: 161 [283540/78836 (13%)]	Loss: 0.452280
Train epoch: 161 [557320/78836 (26%)]	Loss: 0.413906
Train epoch: 161 [846180/78836 (39%)]	Loss: 0.518960
Train epoch: 161 [1112880/78836 (52%)]	Loss: 0.405423
Train epoch: 161 [1381300/78836 (65%)]	Loss: 0.497876
Train epoch: 161 [1714920/78836 (78%)]	Loss: 0.424662
Train epoch: 161 [1964060/78836 (91%)]	Loss: 0.567994
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  161 ; best_test_mse,best_test_ci: 0.23135176 0.8254171254393807 GINConvNet kiba
Training on 78836 samples...
Train epoch: 162 [0/78836 (0%)]	Loss: 0.441331
Train epoch: 162 [279700/78836 (13%)]	Loss: 0.429705
Train epoch: 162 [561560/78836 (26%)]	Loss: 0.454250
Train epoch: 162 [842400/78836 (39%)]	Loss: 0.414240
Train epoch: 162 [1110480/78836 (52%)]	Loss: 0.448601
Train epoch: 162 [1422200/78836 (65%)]	Loss: 0.479364
Train epoch: 162 [1677480/78836 (78%)]	Loss: 0.461227
Train epoch: 162 [1906940/78836 (91%)]	Loss: 0.401138
predicting for valid data
Make prediction for 19709 samples...
0.23135176 No improvement since epoch  161 ; best_test_mse,best_test_ci: 0.23135176 0.8254171254393807 GINConvNet kiba
Training on 78836 samples...
Train epoch: 163 [0/78836 (0%)]	Loss: 0.452925
Train epoch: 163 [277640/78836 (13%)]	Loss: 0.487128
Train epoch: 163 [562640/78836 (26%)]	Loss: 0.469603
Train epoch: 163 [822660/78836 (39%)]	Loss: 0.409914
Train epoch: 163 [1114080/78836 (52%)]	Loss: 0.415657
Train epoch: 163 [1387600/78836 (65%)]	Loss: 0.461530
Train epoch: 163 [1649400/78836 (78%)]	Loss: 0.451023
Train epoch: 163 [1957480/78836 (91%)]	Loss: 0.445246
predicting for valid data
Make prediction for 19709 samples...
0.23135176 No improvement since epoch  161 ; best_test_mse,best_test_ci: 0.23135176 0.8254171254393807 GINConvNet kiba
Training on 78836 samples...
Train epoch: 164 [0/78836 (0%)]	Loss: 0.546735
Train epoch: 164 [276460/78836 (13%)]	Loss: 0.452286
Train epoch: 164 [553120/78836 (26%)]	Loss: 0.428994
Train epoch: 164 [836220/78836 (39%)]	Loss: 0.468399
Train epoch: 164 [1142800/78836 (52%)]	Loss: 0.560104
Train epoch: 164 [1393600/78836 (65%)]	Loss: 0.449645
Train epoch: 164 [1684320/78836 (78%)]	Loss: 0.511646
Train epoch: 164 [1952020/78836 (91%)]	Loss: 0.454790
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  164 ; best_test_mse,best_test_ci: 0.22916041 0.8257309966576476 GINConvNet kiba
Training on 78836 samples...
Train epoch: 165 [0/78836 (0%)]	Loss: 0.464861
Train epoch: 165 [277920/78836 (13%)]	Loss: 0.451046
Train epoch: 165 [552920/78836 (26%)]	Loss: 0.488526
Train epoch: 165 [841500/78836 (39%)]	Loss: 0.587205
Train epoch: 165 [1104720/78836 (52%)]	Loss: 0.480943
Train epoch: 165 [1406600/78836 (65%)]	Loss: 0.455176
Train epoch: 165 [1652160/78836 (78%)]	Loss: 0.439502
Train epoch: 165 [1964620/78836 (91%)]	Loss: 0.484796
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 166 [0/78836 (0%)]	Loss: 0.461953
Train epoch: 166 [282660/78836 (13%)]	Loss: 0.521507
Train epoch: 166 [564640/78836 (26%)]	Loss: 0.562184
Train epoch: 166 [827400/78836 (39%)]	Loss: 0.542202
Train epoch: 166 [1121120/78836 (52%)]	Loss: 0.460565
Train epoch: 166 [1406100/78836 (65%)]	Loss: 0.463872
Train epoch: 166 [1678560/78836 (78%)]	Loss: 0.389832
Train epoch: 166 [1981980/78836 (91%)]	Loss: 0.428666
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 167 [0/78836 (0%)]	Loss: 0.367263
Train epoch: 167 [279980/78836 (13%)]	Loss: 0.387404
Train epoch: 167 [553800/78836 (26%)]	Loss: 0.445772
Train epoch: 167 [851820/78836 (39%)]	Loss: 0.417310
Train epoch: 167 [1107280/78836 (52%)]	Loss: 0.568721
Train epoch: 167 [1380000/78836 (65%)]	Loss: 0.504063
Train epoch: 167 [1663080/78836 (78%)]	Loss: 0.517674
Train epoch: 167 [1969800/78836 (91%)]	Loss: 0.486230
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 168 [0/78836 (0%)]	Loss: 0.435124
Train epoch: 168 [287920/78836 (13%)]	Loss: 0.440155
Train epoch: 168 [562600/78836 (26%)]	Loss: 0.510368
Train epoch: 168 [823080/78836 (39%)]	Loss: 0.395513
Train epoch: 168 [1105120/78836 (52%)]	Loss: 0.505800
Train epoch: 168 [1392600/78836 (65%)]	Loss: 0.498896
Train epoch: 168 [1685040/78836 (78%)]	Loss: 0.491716
Train epoch: 168 [1899380/78836 (91%)]	Loss: 0.395870
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 169 [0/78836 (0%)]	Loss: 0.414092
Train epoch: 169 [282840/78836 (13%)]	Loss: 0.412891
Train epoch: 169 [550400/78836 (26%)]	Loss: 0.505848
Train epoch: 169 [817200/78836 (39%)]	Loss: 0.451037
Train epoch: 169 [1090320/78836 (52%)]	Loss: 0.536028
Train epoch: 169 [1413500/78836 (65%)]	Loss: 0.421315
Train epoch: 169 [1670400/78836 (78%)]	Loss: 0.537727
Train epoch: 169 [1995980/78836 (91%)]	Loss: 0.495666
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 170 [0/78836 (0%)]	Loss: 0.422685
Train epoch: 170 [280600/78836 (13%)]	Loss: 0.402999
Train epoch: 170 [558240/78836 (26%)]	Loss: 0.535924
Train epoch: 170 [846060/78836 (39%)]	Loss: 0.502664
Train epoch: 170 [1137440/78836 (52%)]	Loss: 0.429972
Train epoch: 170 [1395000/78836 (65%)]	Loss: 0.646680
Train epoch: 170 [1697880/78836 (78%)]	Loss: 0.440305
Train epoch: 170 [1932000/78836 (91%)]	Loss: 0.472567
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 171 [0/78836 (0%)]	Loss: 0.443599
Train epoch: 171 [277780/78836 (13%)]	Loss: 0.443345
Train epoch: 171 [546240/78836 (26%)]	Loss: 0.546198
Train epoch: 171 [842700/78836 (39%)]	Loss: 0.421113
Train epoch: 171 [1102880/78836 (52%)]	Loss: 0.360912
Train epoch: 171 [1361500/78836 (65%)]	Loss: 0.409125
Train epoch: 171 [1703040/78836 (78%)]	Loss: 0.446015
Train epoch: 171 [1917300/78836 (91%)]	Loss: 0.508082
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 172 [0/78836 (0%)]	Loss: 0.491016
Train epoch: 172 [280660/78836 (13%)]	Loss: 0.467974
Train epoch: 172 [544160/78836 (26%)]	Loss: 0.415363
Train epoch: 172 [813360/78836 (39%)]	Loss: 0.431260
Train epoch: 172 [1141040/78836 (52%)]	Loss: 0.417403
Train epoch: 172 [1384500/78836 (65%)]	Loss: 0.468099
Train epoch: 172 [1668960/78836 (78%)]	Loss: 0.468260
Train epoch: 172 [1943620/78836 (91%)]	Loss: 0.473876
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 173 [0/78836 (0%)]	Loss: 0.460916
Train epoch: 173 [276520/78836 (13%)]	Loss: 0.405092
Train epoch: 173 [557280/78836 (26%)]	Loss: 0.425918
Train epoch: 173 [845220/78836 (39%)]	Loss: 0.435452
Train epoch: 173 [1130080/78836 (52%)]	Loss: 0.476349
Train epoch: 173 [1423400/78836 (65%)]	Loss: 0.410963
Train epoch: 173 [1661040/78836 (78%)]	Loss: 0.411610
Train epoch: 173 [1995000/78836 (91%)]	Loss: 0.474333
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 174 [0/78836 (0%)]	Loss: 0.386091
Train epoch: 174 [271120/78836 (13%)]	Loss: 0.532453
Train epoch: 174 [556920/78836 (26%)]	Loss: 0.422058
Train epoch: 174 [854760/78836 (39%)]	Loss: 0.462214
Train epoch: 174 [1117760/78836 (52%)]	Loss: 0.390610
Train epoch: 174 [1408100/78836 (65%)]	Loss: 0.421233
Train epoch: 174 [1670280/78836 (78%)]	Loss: 0.505632
Train epoch: 174 [1923880/78836 (91%)]	Loss: 0.533423
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 175 [0/78836 (0%)]	Loss: 0.398648
Train epoch: 175 [282400/78836 (13%)]	Loss: 0.553275
Train epoch: 175 [554360/78836 (26%)]	Loss: 0.445368
Train epoch: 175 [847440/78836 (39%)]	Loss: 0.424219
Train epoch: 175 [1100400/78836 (52%)]	Loss: 0.416000
Train epoch: 175 [1382600/78836 (65%)]	Loss: 0.432922
Train epoch: 175 [1627560/78836 (78%)]	Loss: 0.412399
Train epoch: 175 [1930600/78836 (91%)]	Loss: 0.442020
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 176 [0/78836 (0%)]	Loss: 0.472480
Train epoch: 176 [285280/78836 (13%)]	Loss: 0.407045
Train epoch: 176 [562280/78836 (26%)]	Loss: 0.477014
Train epoch: 176 [829200/78836 (39%)]	Loss: 0.463954
Train epoch: 176 [1138240/78836 (52%)]	Loss: 0.482576
Train epoch: 176 [1384700/78836 (65%)]	Loss: 0.448831
Train epoch: 176 [1662480/78836 (78%)]	Loss: 0.407485
Train epoch: 176 [1963640/78836 (91%)]	Loss: 0.473276
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 177 [0/78836 (0%)]	Loss: 0.451697
Train epoch: 177 [271880/78836 (13%)]	Loss: 0.430618
Train epoch: 177 [558480/78836 (26%)]	Loss: 0.417369
Train epoch: 177 [836220/78836 (39%)]	Loss: 0.478490
Train epoch: 177 [1135040/78836 (52%)]	Loss: 0.508770
Train epoch: 177 [1397700/78836 (65%)]	Loss: 0.508651
Train epoch: 177 [1709880/78836 (78%)]	Loss: 0.436061
Train epoch: 177 [1941800/78836 (91%)]	Loss: 0.418829
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 178 [0/78836 (0%)]	Loss: 0.427855
Train epoch: 178 [276340/78836 (13%)]	Loss: 0.490432
Train epoch: 178 [548680/78836 (26%)]	Loss: 0.400342
Train epoch: 178 [841860/78836 (39%)]	Loss: 0.551870
Train epoch: 178 [1155200/78836 (52%)]	Loss: 0.486828
Train epoch: 178 [1393200/78836 (65%)]	Loss: 0.422406
Train epoch: 178 [1707600/78836 (78%)]	Loss: 0.440210
Train epoch: 178 [1992900/78836 (91%)]	Loss: 0.417560
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 179 [0/78836 (0%)]	Loss: 0.425751
Train epoch: 179 [280040/78836 (13%)]	Loss: 0.431252
Train epoch: 179 [563080/78836 (26%)]	Loss: 0.486589
Train epoch: 179 [844020/78836 (39%)]	Loss: 0.371698
Train epoch: 179 [1128400/78836 (52%)]	Loss: 0.413643
Train epoch: 179 [1392200/78836 (65%)]	Loss: 0.457260
Train epoch: 179 [1656960/78836 (78%)]	Loss: 0.421611
Train epoch: 179 [1932560/78836 (91%)]	Loss: 0.402539
predicting for valid data
Make prediction for 19709 samples...
0.22443943 No improvement since epoch  165 ; best_test_mse,best_test_ci: 0.22443943 0.8269019907565565 GINConvNet kiba
Training on 78836 samples...
Train epoch: 180 [0/78836 (0%)]	Loss: 0.411480
Train epoch: 180 [284120/78836 (13%)]	Loss: 0.444415
Train epoch: 180 [556880/78836 (26%)]	Loss: 0.459433
Train epoch: 180 [845460/78836 (39%)]	Loss: 0.466604
Train epoch: 180 [1123840/78836 (52%)]	Loss: 0.420716
Train epoch: 180 [1363500/78836 (65%)]	Loss: 0.427452
Train epoch: 180 [1691880/78836 (78%)]	Loss: 0.425052
Train epoch: 180 [1967000/78836 (91%)]	Loss: 0.517161
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 181 [0/78836 (0%)]	Loss: 0.410681
Train epoch: 181 [271940/78836 (13%)]	Loss: 0.386254
Train epoch: 181 [555480/78836 (26%)]	Loss: 0.406713
Train epoch: 181 [857460/78836 (39%)]	Loss: 0.402630
Train epoch: 181 [1141680/78836 (52%)]	Loss: 0.507739
Train epoch: 181 [1433500/78836 (65%)]	Loss: 0.446421
Train epoch: 181 [1691040/78836 (78%)]	Loss: 0.408519
Train epoch: 181 [1893360/78836 (91%)]	Loss: 0.485700
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 182 [0/78836 (0%)]	Loss: 0.455903
Train epoch: 182 [274260/78836 (13%)]	Loss: 0.457262
Train epoch: 182 [557720/78836 (26%)]	Loss: 0.496398
Train epoch: 182 [832320/78836 (39%)]	Loss: 0.374628
Train epoch: 182 [1108320/78836 (52%)]	Loss: 0.456320
Train epoch: 182 [1452000/78836 (65%)]	Loss: 0.406286
Train epoch: 182 [1637520/78836 (78%)]	Loss: 0.462637
Train epoch: 182 [1939420/78836 (91%)]	Loss: 0.444292
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 183 [0/78836 (0%)]	Loss: 0.484926
Train epoch: 183 [281200/78836 (13%)]	Loss: 0.381022
Train epoch: 183 [550640/78836 (26%)]	Loss: 0.380823
Train epoch: 183 [842820/78836 (39%)]	Loss: 0.391895
Train epoch: 183 [1117360/78836 (52%)]	Loss: 0.460405
Train epoch: 183 [1387100/78836 (65%)]	Loss: 0.430461
Train epoch: 183 [1670760/78836 (78%)]	Loss: 0.349397
Train epoch: 183 [1978340/78836 (91%)]	Loss: 0.475370
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 184 [0/78836 (0%)]	Loss: 0.438415
Train epoch: 184 [275640/78836 (13%)]	Loss: 0.437670
Train epoch: 184 [547200/78836 (26%)]	Loss: 0.430909
Train epoch: 184 [843480/78836 (39%)]	Loss: 0.513068
Train epoch: 184 [1113200/78836 (52%)]	Loss: 0.352698
Train epoch: 184 [1440100/78836 (65%)]	Loss: 0.371610
Train epoch: 184 [1671000/78836 (78%)]	Loss: 0.568976
Train epoch: 184 [1977780/78836 (91%)]	Loss: 0.420891
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 185 [0/78836 (0%)]	Loss: 0.465725
Train epoch: 185 [289460/78836 (13%)]	Loss: 0.371355
Train epoch: 185 [558040/78836 (26%)]	Loss: 0.406374
Train epoch: 185 [837600/78836 (39%)]	Loss: 0.413060
Train epoch: 185 [1120160/78836 (52%)]	Loss: 0.415139
Train epoch: 185 [1392500/78836 (65%)]	Loss: 0.443827
Train epoch: 185 [1658760/78836 (78%)]	Loss: 0.412405
Train epoch: 185 [1942780/78836 (91%)]	Loss: 0.488274
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 186 [0/78836 (0%)]	Loss: 0.449403
Train epoch: 186 [287420/78836 (13%)]	Loss: 0.398536
Train epoch: 186 [552280/78836 (26%)]	Loss: 0.451161
Train epoch: 186 [843180/78836 (39%)]	Loss: 0.496209
Train epoch: 186 [1106560/78836 (52%)]	Loss: 0.454680
Train epoch: 186 [1391200/78836 (65%)]	Loss: 0.481478
Train epoch: 186 [1696920/78836 (78%)]	Loss: 0.426373
Train epoch: 186 [1957480/78836 (91%)]	Loss: 0.446230
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 187 [0/78836 (0%)]	Loss: 0.564985
Train epoch: 187 [274020/78836 (13%)]	Loss: 0.582377
Train epoch: 187 [560360/78836 (26%)]	Loss: 0.501393
Train epoch: 187 [859920/78836 (39%)]	Loss: 0.422166
Train epoch: 187 [1128400/78836 (52%)]	Loss: 0.403392
Train epoch: 187 [1408100/78836 (65%)]	Loss: 0.489954
Train epoch: 187 [1696560/78836 (78%)]	Loss: 0.521567
Train epoch: 187 [1946700/78836 (91%)]	Loss: 0.409753
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 188 [0/78836 (0%)]	Loss: 0.467983
Train epoch: 188 [287160/78836 (13%)]	Loss: 0.431524
Train epoch: 188 [568920/78836 (26%)]	Loss: 0.472314
Train epoch: 188 [842400/78836 (39%)]	Loss: 0.429502
Train epoch: 188 [1137280/78836 (52%)]	Loss: 0.494487
Train epoch: 188 [1412000/78836 (65%)]	Loss: 0.511024
Train epoch: 188 [1645320/78836 (78%)]	Loss: 0.534818
Train epoch: 188 [1928220/78836 (91%)]	Loss: 0.490556
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 189 [0/78836 (0%)]	Loss: 0.414511
Train epoch: 189 [278940/78836 (13%)]	Loss: 0.495134
Train epoch: 189 [541320/78836 (26%)]	Loss: 0.424535
Train epoch: 189 [848820/78836 (39%)]	Loss: 0.508227
Train epoch: 189 [1115440/78836 (52%)]	Loss: 0.470215
Train epoch: 189 [1402800/78836 (65%)]	Loss: 0.395215
Train epoch: 189 [1658400/78836 (78%)]	Loss: 0.424566
Train epoch: 189 [1937600/78836 (91%)]	Loss: 0.441937
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 190 [0/78836 (0%)]	Loss: 0.366779
Train epoch: 190 [276860/78836 (13%)]	Loss: 0.402029
Train epoch: 190 [555520/78836 (26%)]	Loss: 0.416840
Train epoch: 190 [841500/78836 (39%)]	Loss: 0.484225
Train epoch: 190 [1113200/78836 (52%)]	Loss: 0.376987
Train epoch: 190 [1418200/78836 (65%)]	Loss: 0.418497
Train epoch: 190 [1667760/78836 (78%)]	Loss: 0.394084
Train epoch: 190 [1971620/78836 (91%)]	Loss: 0.434118
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 191 [0/78836 (0%)]	Loss: 0.433099
Train epoch: 191 [275580/78836 (13%)]	Loss: 0.446811
Train epoch: 191 [566400/78836 (26%)]	Loss: 0.483668
Train epoch: 191 [848040/78836 (39%)]	Loss: 0.536441
Train epoch: 191 [1107280/78836 (52%)]	Loss: 0.374296
Train epoch: 191 [1399700/78836 (65%)]	Loss: 0.373376
Train epoch: 191 [1680120/78836 (78%)]	Loss: 0.375067
Train epoch: 191 [1922060/78836 (91%)]	Loss: 0.392962
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 192 [0/78836 (0%)]	Loss: 0.436316
Train epoch: 192 [279260/78836 (13%)]	Loss: 0.353596
Train epoch: 192 [554480/78836 (26%)]	Loss: 0.372293
Train epoch: 192 [831300/78836 (39%)]	Loss: 0.392387
Train epoch: 192 [1125680/78836 (52%)]	Loss: 0.427244
Train epoch: 192 [1434400/78836 (65%)]	Loss: 0.467906
Train epoch: 192 [1692960/78836 (78%)]	Loss: 0.404024
Train epoch: 192 [1983100/78836 (91%)]	Loss: 0.453083
predicting for valid data
Make prediction for 19709 samples...
0.22111094 No improvement since epoch  180 ; best_test_mse,best_test_ci: 0.22111094 0.8327681339006295 GINConvNet kiba
Training on 78836 samples...
Train epoch: 193 [0/78836 (0%)]	Loss: 0.497315
Train epoch: 193 [279740/78836 (13%)]	Loss: 0.385625
Train epoch: 193 [550120/78836 (26%)]	Loss: 0.359963
Train epoch: 193 [837660/78836 (39%)]	Loss: 0.382245
Train epoch: 193 [1121520/78836 (52%)]	Loss: 0.572942
Train epoch: 193 [1420800/78836 (65%)]	Loss: 0.370147
Train epoch: 193 [1663800/78836 (78%)]	Loss: 0.442600
Train epoch: 193 [1943060/78836 (91%)]	Loss: 0.417462
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  193 ; best_test_mse,best_test_ci: 0.21851172 0.8254597938261369 GINConvNet kiba
Training on 78836 samples...
Train epoch: 194 [0/78836 (0%)]	Loss: 0.409490
Train epoch: 194 [270780/78836 (13%)]	Loss: 0.434702
Train epoch: 194 [550560/78836 (26%)]	Loss: 0.406565
Train epoch: 194 [850920/78836 (39%)]	Loss: 0.424696
Train epoch: 194 [1098480/78836 (52%)]	Loss: 0.471274
Train epoch: 194 [1406000/78836 (65%)]	Loss: 0.435127
Train epoch: 194 [1698720/78836 (78%)]	Loss: 0.413882
Train epoch: 194 [1904980/78836 (91%)]	Loss: 0.446227
predicting for valid data
Make prediction for 19709 samples...
0.21851172 No improvement since epoch  193 ; best_test_mse,best_test_ci: 0.21851172 0.8254597938261369 GINConvNet kiba
Training on 78836 samples...
Train epoch: 195 [0/78836 (0%)]	Loss: 0.426986
Train epoch: 195 [285120/78836 (13%)]	Loss: 0.430028
Train epoch: 195 [564960/78836 (26%)]	Loss: 0.371881
Train epoch: 195 [837840/78836 (39%)]	Loss: 0.413065
Train epoch: 195 [1136880/78836 (52%)]	Loss: 0.578694
Train epoch: 195 [1405100/78836 (65%)]	Loss: 0.407979
Train epoch: 195 [1685160/78836 (78%)]	Loss: 0.409190
Train epoch: 195 [1919820/78836 (91%)]	Loss: 0.415682
predicting for valid data
Make prediction for 19709 samples...
0.21851172 No improvement since epoch  193 ; best_test_mse,best_test_ci: 0.21851172 0.8254597938261369 GINConvNet kiba
Training on 78836 samples...
Train epoch: 196 [0/78836 (0%)]	Loss: 0.379967
Train epoch: 196 [278740/78836 (13%)]	Loss: 0.411955
Train epoch: 196 [561200/78836 (26%)]	Loss: 0.463700
Train epoch: 196 [822360/78836 (39%)]	Loss: 0.420738
Train epoch: 196 [1097200/78836 (52%)]	Loss: 0.451427
Train epoch: 196 [1416800/78836 (65%)]	Loss: 0.422990
Train epoch: 196 [1722000/78836 (78%)]	Loss: 0.362321
Train epoch: 196 [1974420/78836 (91%)]	Loss: 0.418861
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  196 ; best_test_mse,best_test_ci: 0.21799985 0.8311740418798061 GINConvNet kiba
Training on 78836 samples...
Train epoch: 197 [0/78836 (0%)]	Loss: 0.419410
Train epoch: 197 [286600/78836 (13%)]	Loss: 0.382428
Train epoch: 197 [540880/78836 (26%)]	Loss: 0.573089
Train epoch: 197 [828060/78836 (39%)]	Loss: 0.417650
Train epoch: 197 [1138800/78836 (52%)]	Loss: 0.479804
Train epoch: 197 [1366600/78836 (65%)]	Loss: 0.423307
Train epoch: 197 [1668720/78836 (78%)]	Loss: 0.386945
Train epoch: 197 [1935220/78836 (91%)]	Loss: 0.360522
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 198 [0/78836 (0%)]	Loss: 0.376403
Train epoch: 198 [277860/78836 (13%)]	Loss: 0.410506
Train epoch: 198 [572440/78836 (26%)]	Loss: 0.373445
Train epoch: 198 [841020/78836 (39%)]	Loss: 0.365065
Train epoch: 198 [1120080/78836 (52%)]	Loss: 0.422886
Train epoch: 198 [1400900/78836 (65%)]	Loss: 0.459826
Train epoch: 198 [1677360/78836 (78%)]	Loss: 0.539026
Train epoch: 198 [1950340/78836 (91%)]	Loss: 0.434624
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 199 [0/78836 (0%)]	Loss: 0.533615
Train epoch: 199 [279200/78836 (13%)]	Loss: 0.400833
Train epoch: 199 [570400/78836 (26%)]	Loss: 0.494129
Train epoch: 199 [850320/78836 (39%)]	Loss: 0.439844
Train epoch: 199 [1114800/78836 (52%)]	Loss: 0.428051
Train epoch: 199 [1400700/78836 (65%)]	Loss: 0.420757
Train epoch: 199 [1695360/78836 (78%)]	Loss: 0.526607
Train epoch: 199 [1941940/78836 (91%)]	Loss: 0.442461
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 200 [0/78836 (0%)]	Loss: 0.487235
Train epoch: 200 [275080/78836 (13%)]	Loss: 0.388168
Train epoch: 200 [568880/78836 (26%)]	Loss: 0.396141
Train epoch: 200 [834300/78836 (39%)]	Loss: 0.398651
Train epoch: 200 [1143200/78836 (52%)]	Loss: 0.507360
Train epoch: 200 [1386800/78836 (65%)]	Loss: 0.386542
Train epoch: 200 [1662840/78836 (78%)]	Loss: 0.383920
Train epoch: 200 [1930600/78836 (91%)]	Loss: 0.369559
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 201 [0/78836 (0%)]	Loss: 0.391002
Train epoch: 201 [281920/78836 (13%)]	Loss: 0.415000
Train epoch: 201 [559520/78836 (26%)]	Loss: 0.454203
Train epoch: 201 [854280/78836 (39%)]	Loss: 0.447824
Train epoch: 201 [1098880/78836 (52%)]	Loss: 0.433240
Train epoch: 201 [1393000/78836 (65%)]	Loss: 0.481687
Train epoch: 201 [1685280/78836 (78%)]	Loss: 0.410850
Train epoch: 201 [1962380/78836 (91%)]	Loss: 0.398740
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 202 [0/78836 (0%)]	Loss: 0.461546
Train epoch: 202 [278280/78836 (13%)]	Loss: 0.537579
Train epoch: 202 [567280/78836 (26%)]	Loss: 0.431181
Train epoch: 202 [854220/78836 (39%)]	Loss: 0.360253
Train epoch: 202 [1117360/78836 (52%)]	Loss: 0.400010
Train epoch: 202 [1371600/78836 (65%)]	Loss: 0.436441
Train epoch: 202 [1709160/78836 (78%)]	Loss: 0.376002
Train epoch: 202 [1964480/78836 (91%)]	Loss: 0.374989
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 203 [0/78836 (0%)]	Loss: 0.485727
Train epoch: 203 [278840/78836 (13%)]	Loss: 0.483967
Train epoch: 203 [557160/78836 (26%)]	Loss: 0.444074
Train epoch: 203 [814620/78836 (39%)]	Loss: 0.435276
Train epoch: 203 [1107760/78836 (52%)]	Loss: 0.377406
Train epoch: 203 [1375800/78836 (65%)]	Loss: 0.547778
Train epoch: 203 [1711320/78836 (78%)]	Loss: 0.453120
Train epoch: 203 [1966300/78836 (91%)]	Loss: 0.445642
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 204 [0/78836 (0%)]	Loss: 0.412113
Train epoch: 204 [275520/78836 (13%)]	Loss: 0.430678
Train epoch: 204 [557120/78836 (26%)]	Loss: 0.436346
Train epoch: 204 [824940/78836 (39%)]	Loss: 0.386962
Train epoch: 204 [1097680/78836 (52%)]	Loss: 0.414690
Train epoch: 204 [1387800/78836 (65%)]	Loss: 0.455812
Train epoch: 204 [1675320/78836 (78%)]	Loss: 0.446240
Train epoch: 204 [1976240/78836 (91%)]	Loss: 0.383405
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 205 [0/78836 (0%)]	Loss: 0.383643
Train epoch: 205 [277980/78836 (13%)]	Loss: 0.405435
Train epoch: 205 [562200/78836 (26%)]	Loss: 0.424190
Train epoch: 205 [830760/78836 (39%)]	Loss: 0.374029
Train epoch: 205 [1119920/78836 (52%)]	Loss: 0.427587
Train epoch: 205 [1364600/78836 (65%)]	Loss: 0.347663
Train epoch: 205 [1666920/78836 (78%)]	Loss: 0.408217
Train epoch: 205 [1931020/78836 (91%)]	Loss: 0.395557
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 206 [0/78836 (0%)]	Loss: 0.337856
Train epoch: 206 [289620/78836 (13%)]	Loss: 0.413939
Train epoch: 206 [558640/78836 (26%)]	Loss: 0.355557
Train epoch: 206 [836160/78836 (39%)]	Loss: 0.455964
Train epoch: 206 [1114720/78836 (52%)]	Loss: 0.357461
Train epoch: 206 [1388600/78836 (65%)]	Loss: 0.363336
Train epoch: 206 [1721040/78836 (78%)]	Loss: 0.394562
Train epoch: 206 [1941100/78836 (91%)]	Loss: 0.430338
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 207 [0/78836 (0%)]	Loss: 0.449095
Train epoch: 207 [281780/78836 (13%)]	Loss: 0.485613
Train epoch: 207 [548400/78836 (26%)]	Loss: 0.417067
Train epoch: 207 [818100/78836 (39%)]	Loss: 0.463131
Train epoch: 207 [1110560/78836 (52%)]	Loss: 0.545785
Train epoch: 207 [1362500/78836 (65%)]	Loss: 0.381809
Train epoch: 207 [1695480/78836 (78%)]	Loss: 0.436668
Train epoch: 207 [1960140/78836 (91%)]	Loss: 0.434855
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 208 [0/78836 (0%)]	Loss: 0.422841
Train epoch: 208 [284780/78836 (13%)]	Loss: 0.410479
Train epoch: 208 [559800/78836 (26%)]	Loss: 0.387746
Train epoch: 208 [840540/78836 (39%)]	Loss: 0.355981
Train epoch: 208 [1108160/78836 (52%)]	Loss: 0.356276
Train epoch: 208 [1354800/78836 (65%)]	Loss: 0.442500
Train epoch: 208 [1662480/78836 (78%)]	Loss: 0.452002
Train epoch: 208 [1940680/78836 (91%)]	Loss: 0.412418
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 209 [0/78836 (0%)]	Loss: 0.414295
Train epoch: 209 [279820/78836 (13%)]	Loss: 0.499585
Train epoch: 209 [549800/78836 (26%)]	Loss: 0.366477
Train epoch: 209 [841260/78836 (39%)]	Loss: 0.411381
Train epoch: 209 [1122400/78836 (52%)]	Loss: 0.421884
Train epoch: 209 [1372500/78836 (65%)]	Loss: 0.419419
Train epoch: 209 [1670880/78836 (78%)]	Loss: 0.420647
Train epoch: 209 [1957620/78836 (91%)]	Loss: 0.383425
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 210 [0/78836 (0%)]	Loss: 0.441935
Train epoch: 210 [282040/78836 (13%)]	Loss: 0.376443
Train epoch: 210 [562000/78836 (26%)]	Loss: 0.413079
Train epoch: 210 [833940/78836 (39%)]	Loss: 0.464240
Train epoch: 210 [1142880/78836 (52%)]	Loss: 0.463226
Train epoch: 210 [1400400/78836 (65%)]	Loss: 0.390987
Train epoch: 210 [1662000/78836 (78%)]	Loss: 0.416666
Train epoch: 210 [1985760/78836 (91%)]	Loss: 0.406342
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 211 [0/78836 (0%)]	Loss: 0.466246
Train epoch: 211 [277120/78836 (13%)]	Loss: 0.346880
Train epoch: 211 [555080/78836 (26%)]	Loss: 0.478987
Train epoch: 211 [835980/78836 (39%)]	Loss: 0.373904
Train epoch: 211 [1116560/78836 (52%)]	Loss: 0.355530
Train epoch: 211 [1396100/78836 (65%)]	Loss: 0.400058
Train epoch: 211 [1676640/78836 (78%)]	Loss: 0.377869
Train epoch: 211 [1944040/78836 (91%)]	Loss: 0.499016
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 212 [0/78836 (0%)]	Loss: 0.451422
Train epoch: 212 [276720/78836 (13%)]	Loss: 0.429619
Train epoch: 212 [551320/78836 (26%)]	Loss: 0.371390
Train epoch: 212 [837300/78836 (39%)]	Loss: 0.381169
Train epoch: 212 [1124640/78836 (52%)]	Loss: 0.418412
Train epoch: 212 [1378100/78836 (65%)]	Loss: 0.433299
Train epoch: 212 [1652160/78836 (78%)]	Loss: 0.414775
Train epoch: 212 [1950620/78836 (91%)]	Loss: 0.432061
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 213 [0/78836 (0%)]	Loss: 0.393191
Train epoch: 213 [277960/78836 (13%)]	Loss: 0.435688
Train epoch: 213 [569280/78836 (26%)]	Loss: 0.362602
Train epoch: 213 [837960/78836 (39%)]	Loss: 0.408555
Train epoch: 213 [1139680/78836 (52%)]	Loss: 0.406629
Train epoch: 213 [1386400/78836 (65%)]	Loss: 0.365757
Train epoch: 213 [1687200/78836 (78%)]	Loss: 0.448049
Train epoch: 213 [1960280/78836 (91%)]	Loss: 0.417425
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 214 [0/78836 (0%)]	Loss: 0.393739
Train epoch: 214 [285320/78836 (13%)]	Loss: 0.370178
Train epoch: 214 [554040/78836 (26%)]	Loss: 0.433707
Train epoch: 214 [831420/78836 (39%)]	Loss: 0.403808
Train epoch: 214 [1099280/78836 (52%)]	Loss: 0.388285
Train epoch: 214 [1412000/78836 (65%)]	Loss: 0.369961
Train epoch: 214 [1663560/78836 (78%)]	Loss: 0.384591
Train epoch: 214 [1958320/78836 (91%)]	Loss: 0.435283
predicting for valid data
Make prediction for 19709 samples...
0.21770269 No improvement since epoch  197 ; best_test_mse,best_test_ci: 0.21770269 0.8297322188265203 GINConvNet kiba
Training on 78836 samples...
Train epoch: 215 [0/78836 (0%)]	Loss: 0.428887
Train epoch: 215 [283320/78836 (13%)]	Loss: 0.393161
Train epoch: 215 [559720/78836 (26%)]	Loss: 0.381003
Train epoch: 215 [846000/78836 (39%)]	Loss: 0.461837
Train epoch: 215 [1109600/78836 (52%)]	Loss: 0.494468
Train epoch: 215 [1385600/78836 (65%)]	Loss: 0.350412
Train epoch: 215 [1692960/78836 (78%)]	Loss: 0.392467
Train epoch: 215 [1923880/78836 (91%)]	Loss: 0.391280
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  215 ; best_test_mse,best_test_ci: 0.22079338 0.8282684352674315 GINConvNet kiba
Training on 78836 samples...
Train epoch: 216 [0/78836 (0%)]	Loss: 0.420910
Train epoch: 216 [283480/78836 (13%)]	Loss: 0.413250
Train epoch: 216 [559120/78836 (26%)]	Loss: 0.365539
Train epoch: 216 [839040/78836 (39%)]	Loss: 0.437599
Train epoch: 216 [1112240/78836 (52%)]	Loss: 0.410537
Train epoch: 216 [1424100/78836 (65%)]	Loss: 0.460097
Train epoch: 216 [1667280/78836 (78%)]	Loss: 0.431162
Train epoch: 216 [1953420/78836 (91%)]	Loss: 0.489802
predicting for valid data
Make prediction for 19709 samples...
0.22079338 No improvement since epoch  215 ; best_test_mse,best_test_ci: 0.22079338 0.8282684352674315 GINConvNet kiba
Training on 78836 samples...
Train epoch: 217 [0/78836 (0%)]	Loss: 0.360110
Train epoch: 217 [281740/78836 (13%)]	Loss: 0.410390
Train epoch: 217 [567240/78836 (26%)]	Loss: 0.379928
Train epoch: 217 [842700/78836 (39%)]	Loss: 0.471309
Train epoch: 217 [1105200/78836 (52%)]	Loss: 0.424084
Train epoch: 217 [1367300/78836 (65%)]	Loss: 0.412095
Train epoch: 217 [1680600/78836 (78%)]	Loss: 0.514749
Train epoch: 217 [1969800/78836 (91%)]	Loss: 0.493647
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 218 [0/78836 (0%)]	Loss: 0.370679
Train epoch: 218 [279020/78836 (13%)]	Loss: 0.415208
Train epoch: 218 [556800/78836 (26%)]	Loss: 0.364844
Train epoch: 218 [817020/78836 (39%)]	Loss: 0.374743
Train epoch: 218 [1113120/78836 (52%)]	Loss: 0.376322
Train epoch: 218 [1414600/78836 (65%)]	Loss: 0.384433
Train epoch: 218 [1673160/78836 (78%)]	Loss: 0.429816
Train epoch: 218 [1948100/78836 (91%)]	Loss: 0.380696
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 219 [0/78836 (0%)]	Loss: 0.343411
Train epoch: 219 [279380/78836 (13%)]	Loss: 0.402086
Train epoch: 219 [554000/78836 (26%)]	Loss: 0.352132
Train epoch: 219 [831660/78836 (39%)]	Loss: 0.366047
Train epoch: 219 [1129920/78836 (52%)]	Loss: 0.448299
Train epoch: 219 [1377200/78836 (65%)]	Loss: 0.363142
Train epoch: 219 [1668960/78836 (78%)]	Loss: 0.433097
Train epoch: 219 [1948940/78836 (91%)]	Loss: 0.399860
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 220 [0/78836 (0%)]	Loss: 0.447689
Train epoch: 220 [280180/78836 (13%)]	Loss: 0.405612
Train epoch: 220 [559000/78836 (26%)]	Loss: 0.391822
Train epoch: 220 [853740/78836 (39%)]	Loss: 0.429532
Train epoch: 220 [1107600/78836 (52%)]	Loss: 0.336716
Train epoch: 220 [1384100/78836 (65%)]	Loss: 0.429347
Train epoch: 220 [1675800/78836 (78%)]	Loss: 0.348173
Train epoch: 220 [1938580/78836 (91%)]	Loss: 0.411889
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 221 [0/78836 (0%)]	Loss: 0.376445
Train epoch: 221 [282440/78836 (13%)]	Loss: 0.497510
Train epoch: 221 [560640/78836 (26%)]	Loss: 0.369501
Train epoch: 221 [828120/78836 (39%)]	Loss: 0.395750
Train epoch: 221 [1103680/78836 (52%)]	Loss: 0.365026
Train epoch: 221 [1390000/78836 (65%)]	Loss: 0.367359
Train epoch: 221 [1678080/78836 (78%)]	Loss: 0.384913
Train epoch: 221 [1939420/78836 (91%)]	Loss: 0.407916
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 222 [0/78836 (0%)]	Loss: 0.398528
Train epoch: 222 [275560/78836 (13%)]	Loss: 0.351623
Train epoch: 222 [565720/78836 (26%)]	Loss: 0.363240
Train epoch: 222 [833760/78836 (39%)]	Loss: 0.370511
Train epoch: 222 [1129120/78836 (52%)]	Loss: 0.411902
Train epoch: 222 [1382300/78836 (65%)]	Loss: 0.416633
Train epoch: 222 [1645920/78836 (78%)]	Loss: 0.402989
Train epoch: 222 [1930460/78836 (91%)]	Loss: 0.394603
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 223 [0/78836 (0%)]	Loss: 0.330602
Train epoch: 223 [279520/78836 (13%)]	Loss: 0.391865
Train epoch: 223 [557240/78836 (26%)]	Loss: 0.366965
Train epoch: 223 [864420/78836 (39%)]	Loss: 0.374754
Train epoch: 223 [1126640/78836 (52%)]	Loss: 0.439800
Train epoch: 223 [1416600/78836 (65%)]	Loss: 0.514805
Train epoch: 223 [1719840/78836 (78%)]	Loss: 0.354821
Train epoch: 223 [1905820/78836 (91%)]	Loss: 0.334018
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 224 [0/78836 (0%)]	Loss: 0.350495
Train epoch: 224 [277720/78836 (13%)]	Loss: 0.428868
Train epoch: 224 [561480/78836 (26%)]	Loss: 0.330297
Train epoch: 224 [841380/78836 (39%)]	Loss: 0.468698
Train epoch: 224 [1131680/78836 (52%)]	Loss: 0.352744
Train epoch: 224 [1390500/78836 (65%)]	Loss: 0.379721
Train epoch: 224 [1687800/78836 (78%)]	Loss: 0.362732
Train epoch: 224 [1966020/78836 (91%)]	Loss: 0.438107
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 225 [0/78836 (0%)]	Loss: 0.382795
Train epoch: 225 [285320/78836 (13%)]	Loss: 0.367175
Train epoch: 225 [569320/78836 (26%)]	Loss: 0.443726
Train epoch: 225 [850260/78836 (39%)]	Loss: 0.386356
Train epoch: 225 [1132560/78836 (52%)]	Loss: 0.387979
Train epoch: 225 [1401300/78836 (65%)]	Loss: 0.383253
Train epoch: 225 [1654920/78836 (78%)]	Loss: 0.405324
Train epoch: 225 [1997800/78836 (91%)]	Loss: 0.469501
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 226 [0/78836 (0%)]	Loss: 0.455167
Train epoch: 226 [279980/78836 (13%)]	Loss: 0.355925
Train epoch: 226 [550880/78836 (26%)]	Loss: 0.329770
Train epoch: 226 [822780/78836 (39%)]	Loss: 0.398096
Train epoch: 226 [1101520/78836 (52%)]	Loss: 0.429380
Train epoch: 226 [1395300/78836 (65%)]	Loss: 0.455430
Train epoch: 226 [1655160/78836 (78%)]	Loss: 0.393059
Train epoch: 226 [1956780/78836 (91%)]	Loss: 0.464687
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 227 [0/78836 (0%)]	Loss: 0.412272
Train epoch: 227 [282580/78836 (13%)]	Loss: 0.351458
Train epoch: 227 [560480/78836 (26%)]	Loss: 0.387162
Train epoch: 227 [853320/78836 (39%)]	Loss: 0.365503
Train epoch: 227 [1132160/78836 (52%)]	Loss: 0.366489
Train epoch: 227 [1389800/78836 (65%)]	Loss: 0.370258
Train epoch: 227 [1641360/78836 (78%)]	Loss: 0.309910
Train epoch: 227 [1945440/78836 (91%)]	Loss: 0.352949
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 228 [0/78836 (0%)]	Loss: 0.429453
Train epoch: 228 [284680/78836 (13%)]	Loss: 0.357913
Train epoch: 228 [557800/78836 (26%)]	Loss: 0.395905
Train epoch: 228 [848400/78836 (39%)]	Loss: 0.420104
Train epoch: 228 [1131760/78836 (52%)]	Loss: 0.368970
Train epoch: 228 [1391500/78836 (65%)]	Loss: 0.392961
Train epoch: 228 [1662600/78836 (78%)]	Loss: 0.406655
Train epoch: 228 [1987860/78836 (91%)]	Loss: 0.385970
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 229 [0/78836 (0%)]	Loss: 0.387544
Train epoch: 229 [276640/78836 (13%)]	Loss: 0.513479
Train epoch: 229 [562440/78836 (26%)]	Loss: 0.425050
Train epoch: 229 [825900/78836 (39%)]	Loss: 0.365821
Train epoch: 229 [1103440/78836 (52%)]	Loss: 0.475811
Train epoch: 229 [1412100/78836 (65%)]	Loss: 0.425925
Train epoch: 229 [1662360/78836 (78%)]	Loss: 0.425157
Train epoch: 229 [1921080/78836 (91%)]	Loss: 0.404454
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 230 [0/78836 (0%)]	Loss: 0.329794
Train epoch: 230 [278000/78836 (13%)]	Loss: 0.411212
Train epoch: 230 [554520/78836 (26%)]	Loss: 0.430566
Train epoch: 230 [846960/78836 (39%)]	Loss: 0.432521
Train epoch: 230 [1128640/78836 (52%)]	Loss: 0.452874
Train epoch: 230 [1376600/78836 (65%)]	Loss: 0.385928
Train epoch: 230 [1677240/78836 (78%)]	Loss: 0.325851
Train epoch: 230 [1955380/78836 (91%)]	Loss: 0.366553
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 231 [0/78836 (0%)]	Loss: 0.393337
Train epoch: 231 [281540/78836 (13%)]	Loss: 0.345362
Train epoch: 231 [564120/78836 (26%)]	Loss: 0.430838
Train epoch: 231 [866280/78836 (39%)]	Loss: 0.464276
Train epoch: 231 [1131840/78836 (52%)]	Loss: 0.383137
Train epoch: 231 [1406100/78836 (65%)]	Loss: 0.349794
Train epoch: 231 [1674840/78836 (78%)]	Loss: 0.372920
Train epoch: 231 [1909880/78836 (91%)]	Loss: 0.348154
predicting for valid data
Make prediction for 19709 samples...
0.21101303 No improvement since epoch  217 ; best_test_mse,best_test_ci: 0.21101303 0.8367379776805721 GINConvNet kiba
Training on 78836 samples...
Train epoch: 232 [0/78836 (0%)]	Loss: 0.326278
Train epoch: 232 [275540/78836 (13%)]	Loss: 0.436239
Train epoch: 232 [554720/78836 (26%)]	Loss: 0.418134
Train epoch: 232 [836640/78836 (39%)]	Loss: 0.464904
Train epoch: 232 [1106240/78836 (52%)]	Loss: 0.384073
Train epoch: 232 [1377500/78836 (65%)]	Loss: 0.381536
Train epoch: 232 [1668360/78836 (78%)]	Loss: 0.376920
Train epoch: 232 [1939420/78836 (91%)]	Loss: 0.420121
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 233 [0/78836 (0%)]	Loss: 0.387232
Train epoch: 233 [281960/78836 (13%)]	Loss: 0.366647
Train epoch: 233 [570160/78836 (26%)]	Loss: 0.401055
Train epoch: 233 [840840/78836 (39%)]	Loss: 0.367106
Train epoch: 233 [1099680/78836 (52%)]	Loss: 0.358595
Train epoch: 233 [1396200/78836 (65%)]	Loss: 0.395705
Train epoch: 233 [1672680/78836 (78%)]	Loss: 0.386670
Train epoch: 233 [1978200/78836 (91%)]	Loss: 0.357877
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 234 [0/78836 (0%)]	Loss: 0.386636
Train epoch: 234 [275880/78836 (13%)]	Loss: 0.350852
Train epoch: 234 [565320/78836 (26%)]	Loss: 0.401985
Train epoch: 234 [842040/78836 (39%)]	Loss: 0.401777
Train epoch: 234 [1102560/78836 (52%)]	Loss: 0.381517
Train epoch: 234 [1380100/78836 (65%)]	Loss: 0.444932
Train epoch: 234 [1693440/78836 (78%)]	Loss: 0.361809
Train epoch: 234 [1969520/78836 (91%)]	Loss: 0.392804
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 235 [0/78836 (0%)]	Loss: 0.333961
Train epoch: 235 [280400/78836 (13%)]	Loss: 0.463945
Train epoch: 235 [557000/78836 (26%)]	Loss: 0.475876
Train epoch: 235 [831300/78836 (39%)]	Loss: 0.405755
Train epoch: 235 [1109920/78836 (52%)]	Loss: 0.359109
Train epoch: 235 [1383800/78836 (65%)]	Loss: 0.424068
Train epoch: 235 [1642560/78836 (78%)]	Loss: 0.401469
Train epoch: 235 [1953560/78836 (91%)]	Loss: 0.348435
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 236 [0/78836 (0%)]	Loss: 0.479333
Train epoch: 236 [280120/78836 (13%)]	Loss: 0.328173
Train epoch: 236 [542600/78836 (26%)]	Loss: 0.389535
Train epoch: 236 [829980/78836 (39%)]	Loss: 0.388173
Train epoch: 236 [1114320/78836 (52%)]	Loss: 0.421158
Train epoch: 236 [1378200/78836 (65%)]	Loss: 0.357917
Train epoch: 236 [1669080/78836 (78%)]	Loss: 0.364048
Train epoch: 236 [1988420/78836 (91%)]	Loss: 0.345197
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 237 [0/78836 (0%)]	Loss: 0.387291
Train epoch: 237 [284620/78836 (13%)]	Loss: 0.351940
Train epoch: 237 [551840/78836 (26%)]	Loss: 0.364813
Train epoch: 237 [828180/78836 (39%)]	Loss: 0.370323
Train epoch: 237 [1107440/78836 (52%)]	Loss: 0.441792
Train epoch: 237 [1388300/78836 (65%)]	Loss: 0.342501
Train epoch: 237 [1680960/78836 (78%)]	Loss: 0.417866
Train epoch: 237 [1967980/78836 (91%)]	Loss: 0.413861
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 238 [0/78836 (0%)]	Loss: 0.418213
Train epoch: 238 [275440/78836 (13%)]	Loss: 0.383079
Train epoch: 238 [552720/78836 (26%)]	Loss: 0.373603
Train epoch: 238 [847980/78836 (39%)]	Loss: 0.419318
Train epoch: 238 [1113280/78836 (52%)]	Loss: 0.449866
Train epoch: 238 [1436500/78836 (65%)]	Loss: 0.396995
Train epoch: 238 [1622880/78836 (78%)]	Loss: 0.370276
Train epoch: 238 [1922900/78836 (91%)]	Loss: 0.400193
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 239 [0/78836 (0%)]	Loss: 0.394809
Train epoch: 239 [281880/78836 (13%)]	Loss: 0.401493
Train epoch: 239 [570080/78836 (26%)]	Loss: 0.350519
Train epoch: 239 [845760/78836 (39%)]	Loss: 0.399470
Train epoch: 239 [1117680/78836 (52%)]	Loss: 0.460757
Train epoch: 239 [1421900/78836 (65%)]	Loss: 0.345720
Train epoch: 239 [1667880/78836 (78%)]	Loss: 0.414845
Train epoch: 239 [1967560/78836 (91%)]	Loss: 0.371806
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 240 [0/78836 (0%)]	Loss: 0.405641
Train epoch: 240 [282480/78836 (13%)]	Loss: 0.451325
Train epoch: 240 [573160/78836 (26%)]	Loss: 0.388473
Train epoch: 240 [835320/78836 (39%)]	Loss: 0.344738
Train epoch: 240 [1115680/78836 (52%)]	Loss: 0.406508
Train epoch: 240 [1384200/78836 (65%)]	Loss: 0.391109
Train epoch: 240 [1722840/78836 (78%)]	Loss: 0.361220
Train epoch: 240 [1945160/78836 (91%)]	Loss: 0.312978
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 241 [0/78836 (0%)]	Loss: 0.463627
Train epoch: 241 [284020/78836 (13%)]	Loss: 0.336439
Train epoch: 241 [554800/78836 (26%)]	Loss: 0.393575
Train epoch: 241 [856740/78836 (39%)]	Loss: 0.297863
Train epoch: 241 [1114560/78836 (52%)]	Loss: 0.388065
Train epoch: 241 [1398500/78836 (65%)]	Loss: 0.360811
Train epoch: 241 [1657200/78836 (78%)]	Loss: 0.479785
Train epoch: 241 [1952580/78836 (91%)]	Loss: 0.335558
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 242 [0/78836 (0%)]	Loss: 0.389464
Train epoch: 242 [283900/78836 (13%)]	Loss: 0.412616
Train epoch: 242 [557400/78836 (26%)]	Loss: 0.408283
Train epoch: 242 [852960/78836 (39%)]	Loss: 0.347027
Train epoch: 242 [1124480/78836 (52%)]	Loss: 0.400312
Train epoch: 242 [1407200/78836 (65%)]	Loss: 0.379813
Train epoch: 242 [1661160/78836 (78%)]	Loss: 0.300250
Train epoch: 242 [1993740/78836 (91%)]	Loss: 0.418455
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 243 [0/78836 (0%)]	Loss: 0.340531
Train epoch: 243 [281700/78836 (13%)]	Loss: 0.414340
Train epoch: 243 [558400/78836 (26%)]	Loss: 0.325780
Train epoch: 243 [830220/78836 (39%)]	Loss: 0.323044
Train epoch: 243 [1122320/78836 (52%)]	Loss: 0.378165
Train epoch: 243 [1390900/78836 (65%)]	Loss: 0.398167
Train epoch: 243 [1658760/78836 (78%)]	Loss: 0.367151
Train epoch: 243 [1956500/78836 (91%)]	Loss: 0.396229
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 244 [0/78836 (0%)]	Loss: 0.410813
Train epoch: 244 [279880/78836 (13%)]	Loss: 0.347337
Train epoch: 244 [564960/78836 (26%)]	Loss: 0.387364
Train epoch: 244 [845580/78836 (39%)]	Loss: 0.419082
Train epoch: 244 [1124800/78836 (52%)]	Loss: 0.320929
Train epoch: 244 [1387300/78836 (65%)]	Loss: 0.506655
Train epoch: 244 [1664160/78836 (78%)]	Loss: 0.466033
Train epoch: 244 [1914640/78836 (91%)]	Loss: 0.413333
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 245 [0/78836 (0%)]	Loss: 0.411176
Train epoch: 245 [281300/78836 (13%)]	Loss: 0.341653
Train epoch: 245 [554600/78836 (26%)]	Loss: 0.325779
Train epoch: 245 [843360/78836 (39%)]	Loss: 0.397798
Train epoch: 245 [1128160/78836 (52%)]	Loss: 0.383834
Train epoch: 245 [1435400/78836 (65%)]	Loss: 0.414513
Train epoch: 245 [1662360/78836 (78%)]	Loss: 0.405613
Train epoch: 245 [1925980/78836 (91%)]	Loss: 0.479203
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 246 [0/78836 (0%)]	Loss: 0.432532
Train epoch: 246 [276360/78836 (13%)]	Loss: 0.387871
Train epoch: 246 [558240/78836 (26%)]	Loss: 0.379439
Train epoch: 246 [839580/78836 (39%)]	Loss: 0.400422
Train epoch: 246 [1110720/78836 (52%)]	Loss: 0.322906
Train epoch: 246 [1398200/78836 (65%)]	Loss: 0.472225
Train epoch: 246 [1643640/78836 (78%)]	Loss: 0.351397
Train epoch: 246 [1950200/78836 (91%)]	Loss: 0.375816
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 247 [0/78836 (0%)]	Loss: 0.375867
Train epoch: 247 [279960/78836 (13%)]	Loss: 0.333099
Train epoch: 247 [563440/78836 (26%)]	Loss: 0.366239
Train epoch: 247 [830940/78836 (39%)]	Loss: 0.372983
Train epoch: 247 [1122320/78836 (52%)]	Loss: 0.425665
Train epoch: 247 [1438400/78836 (65%)]	Loss: 0.371145
Train epoch: 247 [1652280/78836 (78%)]	Loss: 0.338099
Train epoch: 247 [1935500/78836 (91%)]	Loss: 0.413558
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 248 [0/78836 (0%)]	Loss: 0.381501
Train epoch: 248 [276900/78836 (13%)]	Loss: 0.346971
Train epoch: 248 [565200/78836 (26%)]	Loss: 0.334535
Train epoch: 248 [848880/78836 (39%)]	Loss: 0.452884
Train epoch: 248 [1114320/78836 (52%)]	Loss: 0.350882
Train epoch: 248 [1396900/78836 (65%)]	Loss: 0.385475
Train epoch: 248 [1677720/78836 (78%)]	Loss: 0.479569
Train epoch: 248 [1960140/78836 (91%)]	Loss: 0.347771
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 249 [0/78836 (0%)]	Loss: 0.409393
Train epoch: 249 [277600/78836 (13%)]	Loss: 0.360656
Train epoch: 249 [570400/78836 (26%)]	Loss: 0.331818
Train epoch: 249 [839640/78836 (39%)]	Loss: 0.380292
Train epoch: 249 [1110800/78836 (52%)]	Loss: 0.386673
Train epoch: 249 [1387400/78836 (65%)]	Loss: 0.322700
Train epoch: 249 [1696080/78836 (78%)]	Loss: 0.378530
Train epoch: 249 [1963780/78836 (91%)]	Loss: 0.355801
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 250 [0/78836 (0%)]	Loss: 0.349665
Train epoch: 250 [277900/78836 (13%)]	Loss: 0.382058
Train epoch: 250 [559400/78836 (26%)]	Loss: 0.405309
Train epoch: 250 [838020/78836 (39%)]	Loss: 0.312663
Train epoch: 250 [1125840/78836 (52%)]	Loss: 0.403492
Train epoch: 250 [1392700/78836 (65%)]	Loss: 0.372170
Train epoch: 250 [1725000/78836 (78%)]	Loss: 0.362724
Train epoch: 250 [1950900/78836 (91%)]	Loss: 0.398836
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 251 [0/78836 (0%)]	Loss: 0.354904
Train epoch: 251 [277480/78836 (13%)]	Loss: 0.366909
Train epoch: 251 [571040/78836 (26%)]	Loss: 0.348391
Train epoch: 251 [848460/78836 (39%)]	Loss: 0.341160
Train epoch: 251 [1116640/78836 (52%)]	Loss: 0.389096
Train epoch: 251 [1358000/78836 (65%)]	Loss: 0.423024
Train epoch: 251 [1675920/78836 (78%)]	Loss: 0.424425
Train epoch: 251 [1941520/78836 (91%)]	Loss: 0.385734
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 252 [0/78836 (0%)]	Loss: 0.404158
Train epoch: 252 [276400/78836 (13%)]	Loss: 0.468263
Train epoch: 252 [567520/78836 (26%)]	Loss: 0.430663
Train epoch: 252 [819180/78836 (39%)]	Loss: 0.369184
Train epoch: 252 [1103120/78836 (52%)]	Loss: 0.321933
Train epoch: 252 [1421000/78836 (65%)]	Loss: 0.374323
Train epoch: 252 [1705440/78836 (78%)]	Loss: 0.406245
Train epoch: 252 [1956500/78836 (91%)]	Loss: 0.533513
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 253 [0/78836 (0%)]	Loss: 0.418933
Train epoch: 253 [282560/78836 (13%)]	Loss: 0.338576
Train epoch: 253 [552760/78836 (26%)]	Loss: 0.440210
Train epoch: 253 [840180/78836 (39%)]	Loss: 0.487385
Train epoch: 253 [1108400/78836 (52%)]	Loss: 0.334890
Train epoch: 253 [1441100/78836 (65%)]	Loss: 0.338542
Train epoch: 253 [1659840/78836 (78%)]	Loss: 0.380965
Train epoch: 253 [1963080/78836 (91%)]	Loss: 0.368888
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 254 [0/78836 (0%)]	Loss: 0.364180
Train epoch: 254 [275580/78836 (13%)]	Loss: 0.388096
Train epoch: 254 [542440/78836 (26%)]	Loss: 0.326595
Train epoch: 254 [833460/78836 (39%)]	Loss: 0.337120
Train epoch: 254 [1125440/78836 (52%)]	Loss: 0.317603
Train epoch: 254 [1429200/78836 (65%)]	Loss: 0.347547
Train epoch: 254 [1647240/78836 (78%)]	Loss: 0.393113
Train epoch: 254 [1945720/78836 (91%)]	Loss: 0.373057
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 255 [0/78836 (0%)]	Loss: 0.343961
Train epoch: 255 [277520/78836 (13%)]	Loss: 0.350175
Train epoch: 255 [555600/78836 (26%)]	Loss: 0.373445
Train epoch: 255 [840240/78836 (39%)]	Loss: 0.385599
Train epoch: 255 [1140400/78836 (52%)]	Loss: 0.387327
Train epoch: 255 [1382600/78836 (65%)]	Loss: 0.394458
Train epoch: 255 [1695480/78836 (78%)]	Loss: 0.511443
Train epoch: 255 [1913380/78836 (91%)]	Loss: 0.444158
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 256 [0/78836 (0%)]	Loss: 0.327597
Train epoch: 256 [276860/78836 (13%)]	Loss: 0.327597
Train epoch: 256 [563760/78836 (26%)]	Loss: 0.328293
Train epoch: 256 [843240/78836 (39%)]	Loss: 0.372625
Train epoch: 256 [1113680/78836 (52%)]	Loss: 0.353950
Train epoch: 256 [1402700/78836 (65%)]	Loss: 0.359597
Train epoch: 256 [1675440/78836 (78%)]	Loss: 0.421590
Train epoch: 256 [1970640/78836 (91%)]	Loss: 0.298205
predicting for valid data
Make prediction for 19709 samples...
0.20989476 No improvement since epoch  232 ; best_test_mse,best_test_ci: 0.20989476 0.8348999976912405 GINConvNet kiba
Training on 78836 samples...
Train epoch: 257 [0/78836 (0%)]	Loss: 0.360602
Train epoch: 257 [277520/78836 (13%)]	Loss: 0.371101
Train epoch: 257 [553680/78836 (26%)]	Loss: 0.368917
Train epoch: 257 [818160/78836 (39%)]	Loss: 0.385833
Train epoch: 257 [1127520/78836 (52%)]	Loss: 0.385601
Train epoch: 257 [1409300/78836 (65%)]	Loss: 0.369647
Train epoch: 257 [1693080/78836 (78%)]	Loss: 0.396745
Train epoch: 257 [1904980/78836 (91%)]	Loss: 0.410956
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 258 [0/78836 (0%)]	Loss: 0.308017
Train epoch: 258 [284860/78836 (13%)]	Loss: 0.314819
Train epoch: 258 [557440/78836 (26%)]	Loss: 0.325365
Train epoch: 258 [837120/78836 (39%)]	Loss: 0.327116
Train epoch: 258 [1112080/78836 (52%)]	Loss: 0.356930
Train epoch: 258 [1428900/78836 (65%)]	Loss: 0.424993
Train epoch: 258 [1713480/78836 (78%)]	Loss: 0.381984
Train epoch: 258 [1932420/78836 (91%)]	Loss: 0.344963
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 259 [0/78836 (0%)]	Loss: 0.419156
Train epoch: 259 [283880/78836 (13%)]	Loss: 0.359207
Train epoch: 259 [564560/78836 (26%)]	Loss: 0.431410
Train epoch: 259 [836580/78836 (39%)]	Loss: 0.345272
Train epoch: 259 [1129360/78836 (52%)]	Loss: 0.365381
Train epoch: 259 [1395700/78836 (65%)]	Loss: 0.343422
Train epoch: 259 [1700280/78836 (78%)]	Loss: 0.402372
Train epoch: 259 [1956640/78836 (91%)]	Loss: 0.402359
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 260 [0/78836 (0%)]	Loss: 0.327215
Train epoch: 260 [281300/78836 (13%)]	Loss: 0.406313
Train epoch: 260 [555760/78836 (26%)]	Loss: 0.353837
Train epoch: 260 [843000/78836 (39%)]	Loss: 0.353554
Train epoch: 260 [1124240/78836 (52%)]	Loss: 0.359274
Train epoch: 260 [1377800/78836 (65%)]	Loss: 0.353077
Train epoch: 260 [1653360/78836 (78%)]	Loss: 0.357040
Train epoch: 260 [1944460/78836 (91%)]	Loss: 0.336720
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 261 [0/78836 (0%)]	Loss: 0.381011
Train epoch: 261 [279280/78836 (13%)]	Loss: 0.365908
Train epoch: 261 [553720/78836 (26%)]	Loss: 0.367493
Train epoch: 261 [854400/78836 (39%)]	Loss: 0.328442
Train epoch: 261 [1111920/78836 (52%)]	Loss: 0.419745
Train epoch: 261 [1396700/78836 (65%)]	Loss: 0.342105
Train epoch: 261 [1699920/78836 (78%)]	Loss: 0.335108
Train epoch: 261 [1950760/78836 (91%)]	Loss: 0.404801
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 262 [0/78836 (0%)]	Loss: 0.367953
Train epoch: 262 [278160/78836 (13%)]	Loss: 0.482896
Train epoch: 262 [550040/78836 (26%)]	Loss: 0.328733
Train epoch: 262 [841740/78836 (39%)]	Loss: 0.389232
Train epoch: 262 [1116560/78836 (52%)]	Loss: 0.318277
Train epoch: 262 [1401500/78836 (65%)]	Loss: 0.298568
Train epoch: 262 [1672800/78836 (78%)]	Loss: 0.410599
Train epoch: 262 [1980020/78836 (91%)]	Loss: 0.366905
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 263 [0/78836 (0%)]	Loss: 0.351850
Train epoch: 263 [279100/78836 (13%)]	Loss: 0.296336
Train epoch: 263 [566160/78836 (26%)]	Loss: 0.324977
Train epoch: 263 [838080/78836 (39%)]	Loss: 0.412854
Train epoch: 263 [1129600/78836 (52%)]	Loss: 0.396756
Train epoch: 263 [1403800/78836 (65%)]	Loss: 0.286074
Train epoch: 263 [1702920/78836 (78%)]	Loss: 0.357580
Train epoch: 263 [1964060/78836 (91%)]	Loss: 0.419832
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 264 [0/78836 (0%)]	Loss: 0.383512
Train epoch: 264 [283140/78836 (13%)]	Loss: 0.348798
Train epoch: 264 [557960/78836 (26%)]	Loss: 0.359502
Train epoch: 264 [836520/78836 (39%)]	Loss: 0.449635
Train epoch: 264 [1143440/78836 (52%)]	Loss: 0.383519
Train epoch: 264 [1374600/78836 (65%)]	Loss: 0.365470
Train epoch: 264 [1708920/78836 (78%)]	Loss: 0.340996
Train epoch: 264 [1930880/78836 (91%)]	Loss: 0.358366
predicting for valid data
Make prediction for 19709 samples...
0.20616803 No improvement since epoch  257 ; best_test_mse,best_test_ci: 0.20616803 0.8395685960018507 GINConvNet kiba
Training on 78836 samples...
Train epoch: 265 [0/78836 (0%)]	Loss: 0.401601
Train epoch: 265 [277600/78836 (13%)]	Loss: 0.392508
Train epoch: 265 [554880/78836 (26%)]	Loss: 0.339342
Train epoch: 265 [844200/78836 (39%)]	Loss: 0.415755
Train epoch: 265 [1104960/78836 (52%)]	Loss: 0.399562
Train epoch: 265 [1413000/78836 (65%)]	Loss: 0.360512
Train epoch: 265 [1680720/78836 (78%)]	Loss: 0.428691
Train epoch: 265 [1939840/78836 (91%)]	Loss: 0.392594
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  265 ; best_test_mse,best_test_ci: 0.20274931 0.8380322775497916 GINConvNet kiba
Training on 78836 samples...
Train epoch: 266 [0/78836 (0%)]	Loss: 0.346579
Train epoch: 266 [275560/78836 (13%)]	Loss: 0.486876
Train epoch: 266 [554320/78836 (26%)]	Loss: 0.375540
Train epoch: 266 [844440/78836 (39%)]	Loss: 0.342475
Train epoch: 266 [1106160/78836 (52%)]	Loss: 0.383337
Train epoch: 266 [1419900/78836 (65%)]	Loss: 0.347524
Train epoch: 266 [1670400/78836 (78%)]	Loss: 0.371392
Train epoch: 266 [2008020/78836 (91%)]	Loss: 0.434437
predicting for valid data
Make prediction for 19709 samples...
0.20274931 No improvement since epoch  265 ; best_test_mse,best_test_ci: 0.20274931 0.8380322775497916 GINConvNet kiba
Training on 78836 samples...
Train epoch: 267 [0/78836 (0%)]	Loss: 0.435955
Train epoch: 267 [280140/78836 (13%)]	Loss: 0.356017
Train epoch: 267 [559200/78836 (26%)]	Loss: 0.355641
Train epoch: 267 [828540/78836 (39%)]	Loss: 0.330983
Train epoch: 267 [1098640/78836 (52%)]	Loss: 0.353783
Train epoch: 267 [1387600/78836 (65%)]	Loss: 0.412948
Train epoch: 267 [1692000/78836 (78%)]	Loss: 0.357386
Train epoch: 267 [1907080/78836 (91%)]	Loss: 0.301356
predicting for valid data
Make prediction for 19709 samples...
0.20274931 No improvement since epoch  265 ; best_test_mse,best_test_ci: 0.20274931 0.8380322775497916 GINConvNet kiba
Training on 78836 samples...
Train epoch: 268 [0/78836 (0%)]	Loss: 0.325776
Train epoch: 268 [279880/78836 (13%)]	Loss: 0.312024
Train epoch: 268 [575280/78836 (26%)]	Loss: 0.293625
Train epoch: 268 [836640/78836 (39%)]	Loss: 0.362484
Train epoch: 268 [1114880/78836 (52%)]	Loss: 0.369920
Train epoch: 268 [1423200/78836 (65%)]	Loss: 0.351194
Train epoch: 268 [1698720/78836 (78%)]	Loss: 0.410631
Train epoch: 268 [1962520/78836 (91%)]	Loss: 0.377244
predicting for valid data
Make prediction for 19709 samples...
0.20274931 No improvement since epoch  265 ; best_test_mse,best_test_ci: 0.20274931 0.8380322775497916 GINConvNet kiba
Training on 78836 samples...
Train epoch: 269 [0/78836 (0%)]	Loss: 0.338508
Train epoch: 269 [283880/78836 (13%)]	Loss: 0.404411
Train epoch: 269 [566800/78836 (26%)]	Loss: 0.363003
Train epoch: 269 [832920/78836 (39%)]	Loss: 0.416832
Train epoch: 269 [1117120/78836 (52%)]	Loss: 0.357416
Train epoch: 269 [1417700/78836 (65%)]	Loss: 0.356275
Train epoch: 269 [1678680/78836 (78%)]	Loss: 0.335611
Train epoch: 269 [1908900/78836 (91%)]	Loss: 0.310405
predicting for valid data
Make prediction for 19709 samples...
0.20274931 No improvement since epoch  265 ; best_test_mse,best_test_ci: 0.20274931 0.8380322775497916 GINConvNet kiba
Training on 78836 samples...
Train epoch: 270 [0/78836 (0%)]	Loss: 0.336497
Train epoch: 270 [277380/78836 (13%)]	Loss: 0.351144
Train epoch: 270 [565640/78836 (26%)]	Loss: 0.416073
Train epoch: 270 [824520/78836 (39%)]	Loss: 0.358290
Train epoch: 270 [1117600/78836 (52%)]	Loss: 0.396253
Train epoch: 270 [1413600/78836 (65%)]	Loss: 0.461401
Train epoch: 270 [1672320/78836 (78%)]	Loss: 0.384752
Train epoch: 270 [1939140/78836 (91%)]	Loss: 0.369258
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 271 [0/78836 (0%)]	Loss: 0.369107
Train epoch: 271 [281380/78836 (13%)]	Loss: 0.385583
Train epoch: 271 [565640/78836 (26%)]	Loss: 0.351430
Train epoch: 271 [839700/78836 (39%)]	Loss: 0.372889
Train epoch: 271 [1136480/78836 (52%)]	Loss: 0.361913
Train epoch: 271 [1419400/78836 (65%)]	Loss: 0.364123
Train epoch: 271 [1724280/78836 (78%)]	Loss: 0.347414
Train epoch: 271 [1922200/78836 (91%)]	Loss: 0.457141
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 272 [0/78836 (0%)]	Loss: 0.344949
Train epoch: 272 [279860/78836 (13%)]	Loss: 0.360846
Train epoch: 272 [557280/78836 (26%)]	Loss: 0.330052
Train epoch: 272 [831240/78836 (39%)]	Loss: 0.360473
Train epoch: 272 [1119520/78836 (52%)]	Loss: 0.390792
Train epoch: 272 [1374800/78836 (65%)]	Loss: 0.341389
Train epoch: 272 [1679520/78836 (78%)]	Loss: 0.366993
Train epoch: 272 [1984220/78836 (91%)]	Loss: 0.359677
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 273 [0/78836 (0%)]	Loss: 0.435241
Train epoch: 273 [281260/78836 (13%)]	Loss: 0.350456
Train epoch: 273 [554040/78836 (26%)]	Loss: 0.324235
Train epoch: 273 [864900/78836 (39%)]	Loss: 0.327384
Train epoch: 273 [1132480/78836 (52%)]	Loss: 0.344278
Train epoch: 273 [1391100/78836 (65%)]	Loss: 0.310776
Train epoch: 273 [1711680/78836 (78%)]	Loss: 0.362568
Train epoch: 273 [1986460/78836 (91%)]	Loss: 0.376527
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 274 [0/78836 (0%)]	Loss: 0.386433
Train epoch: 274 [280760/78836 (13%)]	Loss: 0.352287
Train epoch: 274 [556880/78836 (26%)]	Loss: 0.346249
Train epoch: 274 [842040/78836 (39%)]	Loss: 0.354026
Train epoch: 274 [1114080/78836 (52%)]	Loss: 0.335180
Train epoch: 274 [1387600/78836 (65%)]	Loss: 0.436224
Train epoch: 274 [1664280/78836 (78%)]	Loss: 0.414914
Train epoch: 274 [2005780/78836 (91%)]	Loss: 0.427457
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 275 [0/78836 (0%)]	Loss: 0.351842
Train epoch: 275 [275140/78836 (13%)]	Loss: 0.336360
Train epoch: 275 [558840/78836 (26%)]	Loss: 0.347019
Train epoch: 275 [833880/78836 (39%)]	Loss: 0.348387
Train epoch: 275 [1109760/78836 (52%)]	Loss: 0.315929
Train epoch: 275 [1394800/78836 (65%)]	Loss: 0.389257
Train epoch: 275 [1689720/78836 (78%)]	Loss: 0.320858
Train epoch: 275 [1961260/78836 (91%)]	Loss: 0.413071
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 276 [0/78836 (0%)]	Loss: 0.334642
Train epoch: 276 [281380/78836 (13%)]	Loss: 0.401961
Train epoch: 276 [559800/78836 (26%)]	Loss: 0.353456
Train epoch: 276 [822120/78836 (39%)]	Loss: 0.329949
Train epoch: 276 [1106240/78836 (52%)]	Loss: 0.401969
Train epoch: 276 [1405900/78836 (65%)]	Loss: 0.345631
Train epoch: 276 [1688520/78836 (78%)]	Loss: 0.335501
Train epoch: 276 [1941380/78836 (91%)]	Loss: 0.380211
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 277 [0/78836 (0%)]	Loss: 0.284959
Train epoch: 277 [276320/78836 (13%)]	Loss: 0.307551
Train epoch: 277 [553240/78836 (26%)]	Loss: 0.303290
Train epoch: 277 [849900/78836 (39%)]	Loss: 0.330433
Train epoch: 277 [1118080/78836 (52%)]	Loss: 0.351930
Train epoch: 277 [1400000/78836 (65%)]	Loss: 0.363846
Train epoch: 277 [1673040/78836 (78%)]	Loss: 0.321190
Train epoch: 277 [1934520/78836 (91%)]	Loss: 0.310858
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 278 [0/78836 (0%)]	Loss: 0.323624
Train epoch: 278 [279220/78836 (13%)]	Loss: 0.278156
Train epoch: 278 [563640/78836 (26%)]	Loss: 0.354394
Train epoch: 278 [843060/78836 (39%)]	Loss: 0.358127
Train epoch: 278 [1091040/78836 (52%)]	Loss: 0.353333
Train epoch: 278 [1395500/78836 (65%)]	Loss: 0.328555
Train epoch: 278 [1650120/78836 (78%)]	Loss: 0.338367
Train epoch: 278 [1941380/78836 (91%)]	Loss: 0.342384
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 279 [0/78836 (0%)]	Loss: 0.355220
Train epoch: 279 [282000/78836 (13%)]	Loss: 0.313581
Train epoch: 279 [571400/78836 (26%)]	Loss: 0.394434
Train epoch: 279 [837240/78836 (39%)]	Loss: 0.301499
Train epoch: 279 [1111120/78836 (52%)]	Loss: 0.345744
Train epoch: 279 [1425400/78836 (65%)]	Loss: 0.361148
Train epoch: 279 [1650840/78836 (78%)]	Loss: 0.383150
Train epoch: 279 [1963640/78836 (91%)]	Loss: 0.317428
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 280 [0/78836 (0%)]	Loss: 0.322695
Train epoch: 280 [282960/78836 (13%)]	Loss: 0.401409
Train epoch: 280 [563520/78836 (26%)]	Loss: 0.373676
Train epoch: 280 [833820/78836 (39%)]	Loss: 0.339085
Train epoch: 280 [1122320/78836 (52%)]	Loss: 0.395669
Train epoch: 280 [1415500/78836 (65%)]	Loss: 0.356991
Train epoch: 280 [1726680/78836 (78%)]	Loss: 0.282473
Train epoch: 280 [1953420/78836 (91%)]	Loss: 0.354279
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 281 [0/78836 (0%)]	Loss: 0.325687
Train epoch: 281 [276760/78836 (13%)]	Loss: 0.347565
Train epoch: 281 [553520/78836 (26%)]	Loss: 0.356132
Train epoch: 281 [821880/78836 (39%)]	Loss: 0.333969
Train epoch: 281 [1116560/78836 (52%)]	Loss: 0.330909
Train epoch: 281 [1392200/78836 (65%)]	Loss: 0.323110
Train epoch: 281 [1663320/78836 (78%)]	Loss: 0.357757
Train epoch: 281 [1969940/78836 (91%)]	Loss: 0.364247
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 282 [0/78836 (0%)]	Loss: 0.388006
Train epoch: 282 [283040/78836 (13%)]	Loss: 0.306484
Train epoch: 282 [569920/78836 (26%)]	Loss: 0.320072
Train epoch: 282 [832380/78836 (39%)]	Loss: 0.380321
Train epoch: 282 [1123120/78836 (52%)]	Loss: 0.329022
Train epoch: 282 [1391200/78836 (65%)]	Loss: 0.439885
Train epoch: 282 [1717080/78836 (78%)]	Loss: 0.314786
Train epoch: 282 [2005220/78836 (91%)]	Loss: 0.383834
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 283 [0/78836 (0%)]	Loss: 0.326157
Train epoch: 283 [279220/78836 (13%)]	Loss: 0.341149
Train epoch: 283 [558800/78836 (26%)]	Loss: 0.336231
Train epoch: 283 [818220/78836 (39%)]	Loss: 0.363577
Train epoch: 283 [1092000/78836 (52%)]	Loss: 0.355714
Train epoch: 283 [1399600/78836 (65%)]	Loss: 0.347459
Train epoch: 283 [1642440/78836 (78%)]	Loss: 0.297325
Train epoch: 283 [1970080/78836 (91%)]	Loss: 0.336494
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 284 [0/78836 (0%)]	Loss: 0.322031
Train epoch: 284 [275820/78836 (13%)]	Loss: 0.350757
Train epoch: 284 [559800/78836 (26%)]	Loss: 0.397658
Train epoch: 284 [845760/78836 (39%)]	Loss: 0.394153
Train epoch: 284 [1118080/78836 (52%)]	Loss: 0.304823
Train epoch: 284 [1384900/78836 (65%)]	Loss: 0.351891
Train epoch: 284 [1677600/78836 (78%)]	Loss: 0.334227
Train epoch: 284 [1914080/78836 (91%)]	Loss: 0.336267
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 285 [0/78836 (0%)]	Loss: 0.335038
Train epoch: 285 [283600/78836 (13%)]	Loss: 0.336574
Train epoch: 285 [552920/78836 (26%)]	Loss: 0.362251
Train epoch: 285 [843540/78836 (39%)]	Loss: 0.359261
Train epoch: 285 [1123200/78836 (52%)]	Loss: 0.283267
Train epoch: 285 [1407600/78836 (65%)]	Loss: 0.358934
Train epoch: 285 [1682880/78836 (78%)]	Loss: 0.321802
Train epoch: 285 [1966580/78836 (91%)]	Loss: 0.367836
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 286 [0/78836 (0%)]	Loss: 0.332899
Train epoch: 286 [281920/78836 (13%)]	Loss: 0.287834
Train epoch: 286 [563400/78836 (26%)]	Loss: 0.313231
Train epoch: 286 [828000/78836 (39%)]	Loss: 0.395648
Train epoch: 286 [1131840/78836 (52%)]	Loss: 0.345664
Train epoch: 286 [1377700/78836 (65%)]	Loss: 0.355547
Train epoch: 286 [1687800/78836 (78%)]	Loss: 0.331433
Train epoch: 286 [1924160/78836 (91%)]	Loss: 0.400692
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 287 [0/78836 (0%)]	Loss: 0.305462
Train epoch: 287 [281560/78836 (13%)]	Loss: 0.285585
Train epoch: 287 [560760/78836 (26%)]	Loss: 0.412180
Train epoch: 287 [832200/78836 (39%)]	Loss: 0.349449
Train epoch: 287 [1123680/78836 (52%)]	Loss: 0.357718
Train epoch: 287 [1434400/78836 (65%)]	Loss: 0.339630
Train epoch: 287 [1654320/78836 (78%)]	Loss: 0.348371
Train epoch: 287 [1955660/78836 (91%)]	Loss: 0.351819
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 288 [0/78836 (0%)]	Loss: 0.382732
Train epoch: 288 [279720/78836 (13%)]	Loss: 0.352617
Train epoch: 288 [558760/78836 (26%)]	Loss: 0.346333
Train epoch: 288 [848820/78836 (39%)]	Loss: 0.358610
Train epoch: 288 [1118080/78836 (52%)]	Loss: 0.346309
Train epoch: 288 [1401500/78836 (65%)]	Loss: 0.416841
Train epoch: 288 [1667400/78836 (78%)]	Loss: 0.345581
Train epoch: 288 [1976940/78836 (91%)]	Loss: 0.357566
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 289 [0/78836 (0%)]	Loss: 0.318079
Train epoch: 289 [280220/78836 (13%)]	Loss: 0.377923
Train epoch: 289 [559520/78836 (26%)]	Loss: 0.309953
Train epoch: 289 [826980/78836 (39%)]	Loss: 0.337107
Train epoch: 289 [1118640/78836 (52%)]	Loss: 0.362731
Train epoch: 289 [1380800/78836 (65%)]	Loss: 0.360778
Train epoch: 289 [1677960/78836 (78%)]	Loss: 0.379814
Train epoch: 289 [1946420/78836 (91%)]	Loss: 0.337051
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 290 [0/78836 (0%)]	Loss: 0.309888
Train epoch: 290 [274220/78836 (13%)]	Loss: 0.286466
Train epoch: 290 [563720/78836 (26%)]	Loss: 0.323335
Train epoch: 290 [843720/78836 (39%)]	Loss: 0.432159
Train epoch: 290 [1117760/78836 (52%)]	Loss: 0.423373
Train epoch: 290 [1411800/78836 (65%)]	Loss: 0.325182
Train epoch: 290 [1678440/78836 (78%)]	Loss: 0.345380
Train epoch: 290 [1954960/78836 (91%)]	Loss: 0.412720
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 291 [0/78836 (0%)]	Loss: 0.320049
Train epoch: 291 [283220/78836 (13%)]	Loss: 0.290523
Train epoch: 291 [550080/78836 (26%)]	Loss: 0.325721
Train epoch: 291 [846840/78836 (39%)]	Loss: 0.389478
Train epoch: 291 [1118240/78836 (52%)]	Loss: 0.347175
Train epoch: 291 [1401900/78836 (65%)]	Loss: 0.338245
Train epoch: 291 [1627200/78836 (78%)]	Loss: 0.274404
Train epoch: 291 [1931160/78836 (91%)]	Loss: 0.331551
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 292 [0/78836 (0%)]	Loss: 0.367636
Train epoch: 292 [280880/78836 (13%)]	Loss: 0.297473
Train epoch: 292 [558320/78836 (26%)]	Loss: 0.320501
Train epoch: 292 [847680/78836 (39%)]	Loss: 0.320157
Train epoch: 292 [1109920/78836 (52%)]	Loss: 0.395882
Train epoch: 292 [1389800/78836 (65%)]	Loss: 0.316181
Train epoch: 292 [1696560/78836 (78%)]	Loss: 0.419221
Train epoch: 292 [1996820/78836 (91%)]	Loss: 0.361045
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 293 [0/78836 (0%)]	Loss: 0.360710
Train epoch: 293 [278860/78836 (13%)]	Loss: 0.400880
Train epoch: 293 [553800/78836 (26%)]	Loss: 0.334170
Train epoch: 293 [858360/78836 (39%)]	Loss: 0.315540
Train epoch: 293 [1121680/78836 (52%)]	Loss: 0.366179
Train epoch: 293 [1388000/78836 (65%)]	Loss: 0.306543
Train epoch: 293 [1694640/78836 (78%)]	Loss: 0.344303
Train epoch: 293 [1964480/78836 (91%)]	Loss: 0.421716
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 294 [0/78836 (0%)]	Loss: 0.309811
Train epoch: 294 [278380/78836 (13%)]	Loss: 0.434643
Train epoch: 294 [557840/78836 (26%)]	Loss: 0.395114
Train epoch: 294 [830460/78836 (39%)]	Loss: 0.312136
Train epoch: 294 [1113200/78836 (52%)]	Loss: 0.334341
Train epoch: 294 [1403100/78836 (65%)]	Loss: 0.409161
Train epoch: 294 [1658040/78836 (78%)]	Loss: 0.338496
Train epoch: 294 [1952300/78836 (91%)]	Loss: 0.338955
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 295 [0/78836 (0%)]	Loss: 0.335040
Train epoch: 295 [275160/78836 (13%)]	Loss: 0.372176
Train epoch: 295 [538760/78836 (26%)]	Loss: 0.333441
Train epoch: 295 [850140/78836 (39%)]	Loss: 0.358903
Train epoch: 295 [1138320/78836 (52%)]	Loss: 0.281450
Train epoch: 295 [1388400/78836 (65%)]	Loss: 0.374102
Train epoch: 295 [1660920/78836 (78%)]	Loss: 0.289896
Train epoch: 295 [1988280/78836 (91%)]	Loss: 0.346868
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 296 [0/78836 (0%)]	Loss: 0.331442
Train epoch: 296 [283900/78836 (13%)]	Loss: 0.292641
Train epoch: 296 [573480/78836 (26%)]	Loss: 0.380530
Train epoch: 296 [834540/78836 (39%)]	Loss: 0.311333
Train epoch: 296 [1110720/78836 (52%)]	Loss: 0.336327
Train epoch: 296 [1373600/78836 (65%)]	Loss: 0.305857
Train epoch: 296 [1705200/78836 (78%)]	Loss: 0.402493
Train epoch: 296 [1939840/78836 (91%)]	Loss: 0.374309
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 297 [0/78836 (0%)]	Loss: 0.369903
Train epoch: 297 [283160/78836 (13%)]	Loss: 0.386554
Train epoch: 297 [568160/78836 (26%)]	Loss: 0.327277
Train epoch: 297 [852240/78836 (39%)]	Loss: 0.348357
Train epoch: 297 [1138160/78836 (52%)]	Loss: 0.373496
Train epoch: 297 [1389000/78836 (65%)]	Loss: 0.327162
Train epoch: 297 [1694160/78836 (78%)]	Loss: 0.342441
Train epoch: 297 [1910860/78836 (91%)]	Loss: 0.354505
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 298 [0/78836 (0%)]	Loss: 0.348323
Train epoch: 298 [281720/78836 (13%)]	Loss: 0.358714
Train epoch: 298 [554640/78836 (26%)]	Loss: 0.270237
Train epoch: 298 [824400/78836 (39%)]	Loss: 0.304754
Train epoch: 298 [1114560/78836 (52%)]	Loss: 0.295663
Train epoch: 298 [1378000/78836 (65%)]	Loss: 0.295138
Train epoch: 298 [1683000/78836 (78%)]	Loss: 0.427415
Train epoch: 298 [1952860/78836 (91%)]	Loss: 0.308099
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 299 [0/78836 (0%)]	Loss: 0.377704
Train epoch: 299 [285460/78836 (13%)]	Loss: 0.293439
Train epoch: 299 [553080/78836 (26%)]	Loss: 0.294998
Train epoch: 299 [845520/78836 (39%)]	Loss: 0.329437
Train epoch: 299 [1143200/78836 (52%)]	Loss: 0.335870
Train epoch: 299 [1406600/78836 (65%)]	Loss: 0.420924
Train epoch: 299 [1697400/78836 (78%)]	Loss: 0.349207
Train epoch: 299 [1955940/78836 (91%)]	Loss: 0.333471
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 300 [0/78836 (0%)]	Loss: 0.352268
Train epoch: 300 [276820/78836 (13%)]	Loss: 0.423635
Train epoch: 300 [556000/78836 (26%)]	Loss: 0.267071
Train epoch: 300 [834120/78836 (39%)]	Loss: 0.314955
Train epoch: 300 [1155520/78836 (52%)]	Loss: 0.337884
Train epoch: 300 [1381800/78836 (65%)]	Loss: 0.343472
Train epoch: 300 [1662720/78836 (78%)]	Loss: 0.348639
Train epoch: 300 [1959300/78836 (91%)]	Loss: 0.344474
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 301 [0/78836 (0%)]	Loss: 0.316603
Train epoch: 301 [287660/78836 (13%)]	Loss: 0.310290
Train epoch: 301 [555760/78836 (26%)]	Loss: 0.343820
Train epoch: 301 [836220/78836 (39%)]	Loss: 0.391872
Train epoch: 301 [1125200/78836 (52%)]	Loss: 0.328871
Train epoch: 301 [1379300/78836 (65%)]	Loss: 0.357496
Train epoch: 301 [1669920/78836 (78%)]	Loss: 0.365138
Train epoch: 301 [1909880/78836 (91%)]	Loss: 0.356456
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 302 [0/78836 (0%)]	Loss: 0.315895
Train epoch: 302 [279140/78836 (13%)]	Loss: 0.316424
Train epoch: 302 [550840/78836 (26%)]	Loss: 0.327303
Train epoch: 302 [822660/78836 (39%)]	Loss: 0.303219
Train epoch: 302 [1111440/78836 (52%)]	Loss: 0.356983
Train epoch: 302 [1417400/78836 (65%)]	Loss: 0.360503
Train epoch: 302 [1675920/78836 (78%)]	Loss: 0.383389
Train epoch: 302 [1920660/78836 (91%)]	Loss: 0.285258
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 303 [0/78836 (0%)]	Loss: 0.358974
Train epoch: 303 [277400/78836 (13%)]	Loss: 0.376458
Train epoch: 303 [564360/78836 (26%)]	Loss: 0.304125
Train epoch: 303 [852240/78836 (39%)]	Loss: 0.350699
Train epoch: 303 [1137120/78836 (52%)]	Loss: 0.369103
Train epoch: 303 [1379500/78836 (65%)]	Loss: 0.378618
Train epoch: 303 [1697640/78836 (78%)]	Loss: 0.362123
Train epoch: 303 [1947820/78836 (91%)]	Loss: 0.338874
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 304 [0/78836 (0%)]	Loss: 0.332425
Train epoch: 304 [277340/78836 (13%)]	Loss: 0.311689
Train epoch: 304 [558000/78836 (26%)]	Loss: 0.409659
Train epoch: 304 [848460/78836 (39%)]	Loss: 0.345541
Train epoch: 304 [1119680/78836 (52%)]	Loss: 0.338898
Train epoch: 304 [1398000/78836 (65%)]	Loss: 0.349919
Train epoch: 304 [1640040/78836 (78%)]	Loss: 0.468404
Train epoch: 304 [1962240/78836 (91%)]	Loss: 0.387345
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 305 [0/78836 (0%)]	Loss: 0.343610
Train epoch: 305 [274000/78836 (13%)]	Loss: 0.303760
Train epoch: 305 [556760/78836 (26%)]	Loss: 0.292725
Train epoch: 305 [835320/78836 (39%)]	Loss: 0.317950
Train epoch: 305 [1124240/78836 (52%)]	Loss: 0.317082
Train epoch: 305 [1375000/78836 (65%)]	Loss: 0.327997
Train epoch: 305 [1708320/78836 (78%)]	Loss: 0.288365
Train epoch: 305 [2006340/78836 (91%)]	Loss: 0.334709
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 306 [0/78836 (0%)]	Loss: 0.326935
Train epoch: 306 [279700/78836 (13%)]	Loss: 0.294847
Train epoch: 306 [559520/78836 (26%)]	Loss: 0.391042
Train epoch: 306 [846780/78836 (39%)]	Loss: 0.379246
Train epoch: 306 [1103120/78836 (52%)]	Loss: 0.424753
Train epoch: 306 [1420900/78836 (65%)]	Loss: 0.354857
Train epoch: 306 [1666680/78836 (78%)]	Loss: 0.360162
Train epoch: 306 [1965320/78836 (91%)]	Loss: 0.354583
predicting for valid data
Make prediction for 19709 samples...
0.20139045 No improvement since epoch  270 ; best_test_mse,best_test_ci: 0.20139045 0.8426890045791489 GINConvNet kiba
Training on 78836 samples...
Train epoch: 307 [0/78836 (0%)]	Loss: 0.336151
Train epoch: 307 [283760/78836 (13%)]	Loss: 0.326082
Train epoch: 307 [564280/78836 (26%)]	Loss: 0.309148
Train epoch: 307 [834420/78836 (39%)]	Loss: 0.277998
Train epoch: 307 [1118960/78836 (52%)]	Loss: 0.343791
Train epoch: 307 [1407000/78836 (65%)]	Loss: 0.341853
Train epoch: 307 [1697520/78836 (78%)]	Loss: 0.325599
Train epoch: 307 [1991640/78836 (91%)]	Loss: 0.303081
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 308 [0/78836 (0%)]	Loss: 0.274406
Train epoch: 308 [277860/78836 (13%)]	Loss: 0.304270
Train epoch: 308 [563800/78836 (26%)]	Loss: 0.311066
Train epoch: 308 [813480/78836 (39%)]	Loss: 0.300400
Train epoch: 308 [1118400/78836 (52%)]	Loss: 0.342717
Train epoch: 308 [1418200/78836 (65%)]	Loss: 0.312755
Train epoch: 308 [1655160/78836 (78%)]	Loss: 0.284094
Train epoch: 308 [1999900/78836 (91%)]	Loss: 0.326469
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 309 [0/78836 (0%)]	Loss: 0.291461
Train epoch: 309 [280320/78836 (13%)]	Loss: 0.358724
Train epoch: 309 [565960/78836 (26%)]	Loss: 0.339090
Train epoch: 309 [853380/78836 (39%)]	Loss: 0.357277
Train epoch: 309 [1100080/78836 (52%)]	Loss: 0.312051
Train epoch: 309 [1383500/78836 (65%)]	Loss: 0.345380
Train epoch: 309 [1676280/78836 (78%)]	Loss: 0.365073
Train epoch: 309 [1961540/78836 (91%)]	Loss: 0.323262
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 310 [0/78836 (0%)]	Loss: 0.315374
Train epoch: 310 [282360/78836 (13%)]	Loss: 0.342357
Train epoch: 310 [565560/78836 (26%)]	Loss: 0.294632
Train epoch: 310 [842580/78836 (39%)]	Loss: 0.371405
Train epoch: 310 [1114640/78836 (52%)]	Loss: 0.291206
Train epoch: 310 [1372700/78836 (65%)]	Loss: 0.317350
Train epoch: 310 [1690680/78836 (78%)]	Loss: 0.367172
Train epoch: 310 [1957060/78836 (91%)]	Loss: 0.368691
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 311 [0/78836 (0%)]	Loss: 0.315919
Train epoch: 311 [280260/78836 (13%)]	Loss: 0.340745
Train epoch: 311 [568960/78836 (26%)]	Loss: 0.308062
Train epoch: 311 [816960/78836 (39%)]	Loss: 0.315916
Train epoch: 311 [1122800/78836 (52%)]	Loss: 0.325486
Train epoch: 311 [1399800/78836 (65%)]	Loss: 0.311451
Train epoch: 311 [1633560/78836 (78%)]	Loss: 0.349984
Train epoch: 311 [1934520/78836 (91%)]	Loss: 0.305705
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 312 [0/78836 (0%)]	Loss: 0.312290
Train epoch: 312 [276900/78836 (13%)]	Loss: 0.323051
Train epoch: 312 [564720/78836 (26%)]	Loss: 0.401150
Train epoch: 312 [840960/78836 (39%)]	Loss: 0.319164
Train epoch: 312 [1127520/78836 (52%)]	Loss: 0.344675
Train epoch: 312 [1395700/78836 (65%)]	Loss: 0.344747
Train epoch: 312 [1667040/78836 (78%)]	Loss: 0.294936
Train epoch: 312 [1946000/78836 (91%)]	Loss: 0.355689
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 313 [0/78836 (0%)]	Loss: 0.329771
Train epoch: 313 [284440/78836 (13%)]	Loss: 0.329384
Train epoch: 313 [564480/78836 (26%)]	Loss: 0.327138
Train epoch: 313 [839820/78836 (39%)]	Loss: 0.319450
Train epoch: 313 [1121920/78836 (52%)]	Loss: 0.372786
Train epoch: 313 [1399800/78836 (65%)]	Loss: 0.333877
Train epoch: 313 [1664160/78836 (78%)]	Loss: 0.323340
Train epoch: 313 [1965740/78836 (91%)]	Loss: 0.330871
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 314 [0/78836 (0%)]	Loss: 0.324451
Train epoch: 314 [273820/78836 (13%)]	Loss: 0.337572
Train epoch: 314 [563800/78836 (26%)]	Loss: 0.330529
Train epoch: 314 [852480/78836 (39%)]	Loss: 0.346497
Train epoch: 314 [1135120/78836 (52%)]	Loss: 0.307176
Train epoch: 314 [1413400/78836 (65%)]	Loss: 0.325793
Train epoch: 314 [1676880/78836 (78%)]	Loss: 0.352184
Train epoch: 314 [2027200/78836 (91%)]	Loss: 0.434817
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 315 [0/78836 (0%)]	Loss: 0.282113
Train epoch: 315 [277060/78836 (13%)]	Loss: 0.374171
Train epoch: 315 [554480/78836 (26%)]	Loss: 0.367909
Train epoch: 315 [845520/78836 (39%)]	Loss: 0.335019
Train epoch: 315 [1124320/78836 (52%)]	Loss: 0.337998
Train epoch: 315 [1400300/78836 (65%)]	Loss: 0.324402
Train epoch: 315 [1707840/78836 (78%)]	Loss: 0.365376
Train epoch: 315 [1961680/78836 (91%)]	Loss: 0.331522
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 316 [0/78836 (0%)]	Loss: 0.264851
Train epoch: 316 [274640/78836 (13%)]	Loss: 0.333531
Train epoch: 316 [566240/78836 (26%)]	Loss: 0.358635
Train epoch: 316 [828180/78836 (39%)]	Loss: 0.321413
Train epoch: 316 [1129280/78836 (52%)]	Loss: 0.295640
Train epoch: 316 [1393500/78836 (65%)]	Loss: 0.322090
Train epoch: 316 [1677840/78836 (78%)]	Loss: 0.374821
Train epoch: 316 [1990660/78836 (91%)]	Loss: 0.350096
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 317 [0/78836 (0%)]	Loss: 0.306509
Train epoch: 317 [277360/78836 (13%)]	Loss: 0.350321
Train epoch: 317 [551840/78836 (26%)]	Loss: 0.358383
Train epoch: 317 [831960/78836 (39%)]	Loss: 0.306606
Train epoch: 317 [1147760/78836 (52%)]	Loss: 0.332810
Train epoch: 317 [1396800/78836 (65%)]	Loss: 0.330139
Train epoch: 317 [1681320/78836 (78%)]	Loss: 0.359908
Train epoch: 317 [1993320/78836 (91%)]	Loss: 0.268158
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 318 [0/78836 (0%)]	Loss: 0.307412
Train epoch: 318 [285440/78836 (13%)]	Loss: 0.447123
Train epoch: 318 [546320/78836 (26%)]	Loss: 0.343933
Train epoch: 318 [842460/78836 (39%)]	Loss: 0.295643
Train epoch: 318 [1092240/78836 (52%)]	Loss: 0.386504
Train epoch: 318 [1379600/78836 (65%)]	Loss: 0.343575
Train epoch: 318 [1644960/78836 (78%)]	Loss: 0.293542
Train epoch: 318 [1968120/78836 (91%)]	Loss: 0.375307
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 319 [0/78836 (0%)]	Loss: 0.414594
Train epoch: 319 [277440/78836 (13%)]	Loss: 0.281214
Train epoch: 319 [581480/78836 (26%)]	Loss: 0.269810
Train epoch: 319 [847920/78836 (39%)]	Loss: 0.280837
Train epoch: 319 [1120400/78836 (52%)]	Loss: 0.333563
Train epoch: 319 [1411600/78836 (65%)]	Loss: 0.286242
Train epoch: 319 [1714080/78836 (78%)]	Loss: 0.313842
Train epoch: 319 [1944040/78836 (91%)]	Loss: 0.292410
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 320 [0/78836 (0%)]	Loss: 0.310779
Train epoch: 320 [280620/78836 (13%)]	Loss: 0.317345
Train epoch: 320 [559520/78836 (26%)]	Loss: 0.319997
Train epoch: 320 [833700/78836 (39%)]	Loss: 0.307287
Train epoch: 320 [1140160/78836 (52%)]	Loss: 0.305324
Train epoch: 320 [1423400/78836 (65%)]	Loss: 0.350950
Train epoch: 320 [1670160/78836 (78%)]	Loss: 0.291933
Train epoch: 320 [1962800/78836 (91%)]	Loss: 0.318027
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 321 [0/78836 (0%)]	Loss: 0.314151
Train epoch: 321 [277520/78836 (13%)]	Loss: 0.387002
Train epoch: 321 [563520/78836 (26%)]	Loss: 0.319944
Train epoch: 321 [833880/78836 (39%)]	Loss: 0.323463
Train epoch: 321 [1112400/78836 (52%)]	Loss: 0.362462
Train epoch: 321 [1388000/78836 (65%)]	Loss: 0.265120
Train epoch: 321 [1664640/78836 (78%)]	Loss: 0.301547
Train epoch: 321 [1953560/78836 (91%)]	Loss: 0.333898
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 322 [0/78836 (0%)]	Loss: 0.336557
Train epoch: 322 [282980/78836 (13%)]	Loss: 0.299381
Train epoch: 322 [565400/78836 (26%)]	Loss: 0.296546
Train epoch: 322 [842940/78836 (39%)]	Loss: 0.356248
Train epoch: 322 [1123360/78836 (52%)]	Loss: 0.323068
Train epoch: 322 [1433400/78836 (65%)]	Loss: 0.346073
Train epoch: 322 [1681080/78836 (78%)]	Loss: 0.348623
Train epoch: 322 [1953980/78836 (91%)]	Loss: 0.316769
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 323 [0/78836 (0%)]	Loss: 0.314911
Train epoch: 323 [283960/78836 (13%)]	Loss: 0.352136
Train epoch: 323 [562560/78836 (26%)]	Loss: 0.252626
Train epoch: 323 [848460/78836 (39%)]	Loss: 0.361109
Train epoch: 323 [1127840/78836 (52%)]	Loss: 0.343129
Train epoch: 323 [1406500/78836 (65%)]	Loss: 0.308150
Train epoch: 323 [1680240/78836 (78%)]	Loss: 0.305298
Train epoch: 323 [1964900/78836 (91%)]	Loss: 0.327446
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 324 [0/78836 (0%)]	Loss: 0.276947
Train epoch: 324 [285080/78836 (13%)]	Loss: 0.418048
Train epoch: 324 [554160/78836 (26%)]	Loss: 0.303358
Train epoch: 324 [842400/78836 (39%)]	Loss: 0.309342
Train epoch: 324 [1127760/78836 (52%)]	Loss: 0.309094
Train epoch: 324 [1396500/78836 (65%)]	Loss: 0.327427
Train epoch: 324 [1704840/78836 (78%)]	Loss: 0.306468
Train epoch: 324 [1970500/78836 (91%)]	Loss: 0.290713
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 325 [0/78836 (0%)]	Loss: 0.284126
Train epoch: 325 [275000/78836 (13%)]	Loss: 0.349121
Train epoch: 325 [551160/78836 (26%)]	Loss: 0.313984
Train epoch: 325 [846540/78836 (39%)]	Loss: 0.289891
Train epoch: 325 [1127760/78836 (52%)]	Loss: 0.308545
Train epoch: 325 [1410700/78836 (65%)]	Loss: 0.304615
Train epoch: 325 [1680840/78836 (78%)]	Loss: 0.314214
Train epoch: 325 [1963640/78836 (91%)]	Loss: 0.345048
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 326 [0/78836 (0%)]	Loss: 0.320754
Train epoch: 326 [285000/78836 (13%)]	Loss: 0.356524
Train epoch: 326 [551360/78836 (26%)]	Loss: 0.336814
Train epoch: 326 [841320/78836 (39%)]	Loss: 0.337075
Train epoch: 326 [1118000/78836 (52%)]	Loss: 0.351029
Train epoch: 326 [1391600/78836 (65%)]	Loss: 0.339788
Train epoch: 326 [1661520/78836 (78%)]	Loss: 0.292198
Train epoch: 326 [1928360/78836 (91%)]	Loss: 0.300492
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 327 [0/78836 (0%)]	Loss: 0.296142
Train epoch: 327 [280400/78836 (13%)]	Loss: 0.309431
Train epoch: 327 [553520/78836 (26%)]	Loss: 0.347657
Train epoch: 327 [862080/78836 (39%)]	Loss: 0.347950
Train epoch: 327 [1114720/78836 (52%)]	Loss: 0.333128
Train epoch: 327 [1374800/78836 (65%)]	Loss: 0.371422
Train epoch: 327 [1709040/78836 (78%)]	Loss: 0.354099
Train epoch: 327 [1980580/78836 (91%)]	Loss: 0.301071
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 328 [0/78836 (0%)]	Loss: 0.293989
Train epoch: 328 [280420/78836 (13%)]	Loss: 0.335774
Train epoch: 328 [557000/78836 (26%)]	Loss: 0.288076
Train epoch: 328 [835980/78836 (39%)]	Loss: 0.362793
Train epoch: 328 [1122800/78836 (52%)]	Loss: 0.332382
Train epoch: 328 [1408700/78836 (65%)]	Loss: 0.319952
Train epoch: 328 [1671240/78836 (78%)]	Loss: 0.386162
Train epoch: 328 [1960000/78836 (91%)]	Loss: 0.317109
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 329 [0/78836 (0%)]	Loss: 0.303061
Train epoch: 329 [275600/78836 (13%)]	Loss: 0.298393
Train epoch: 329 [557800/78836 (26%)]	Loss: 0.322293
Train epoch: 329 [832440/78836 (39%)]	Loss: 0.279573
Train epoch: 329 [1110800/78836 (52%)]	Loss: 0.288842
Train epoch: 329 [1402900/78836 (65%)]	Loss: 0.335469
Train epoch: 329 [1712520/78836 (78%)]	Loss: 0.332815
Train epoch: 329 [1958460/78836 (91%)]	Loss: 0.347694
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 330 [0/78836 (0%)]	Loss: 0.335429
Train epoch: 330 [285400/78836 (13%)]	Loss: 0.376467
Train epoch: 330 [559640/78836 (26%)]	Loss: 0.319059
Train epoch: 330 [847920/78836 (39%)]	Loss: 0.283786
Train epoch: 330 [1108960/78836 (52%)]	Loss: 0.315608
Train epoch: 330 [1376000/78836 (65%)]	Loss: 0.328210
Train epoch: 330 [1712400/78836 (78%)]	Loss: 0.308644
Train epoch: 330 [1968960/78836 (91%)]	Loss: 0.302376
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 331 [0/78836 (0%)]	Loss: 0.297043
Train epoch: 331 [275640/78836 (13%)]	Loss: 0.260287
Train epoch: 331 [559880/78836 (26%)]	Loss: 0.300971
Train epoch: 331 [833580/78836 (39%)]	Loss: 0.329746
Train epoch: 331 [1113280/78836 (52%)]	Loss: 0.369510
Train epoch: 331 [1381600/78836 (65%)]	Loss: 0.297551
Train epoch: 331 [1680480/78836 (78%)]	Loss: 0.272515
Train epoch: 331 [1940120/78836 (91%)]	Loss: 0.312560
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 332 [0/78836 (0%)]	Loss: 0.265869
Train epoch: 332 [272760/78836 (13%)]	Loss: 0.344825
Train epoch: 332 [558160/78836 (26%)]	Loss: 0.345487
Train epoch: 332 [850560/78836 (39%)]	Loss: 0.317783
Train epoch: 332 [1097440/78836 (52%)]	Loss: 0.315831
Train epoch: 332 [1395400/78836 (65%)]	Loss: 0.287998
Train epoch: 332 [1717320/78836 (78%)]	Loss: 0.352626
Train epoch: 332 [1921920/78836 (91%)]	Loss: 0.289172
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 333 [0/78836 (0%)]	Loss: 0.318274
Train epoch: 333 [280320/78836 (13%)]	Loss: 0.328528
Train epoch: 333 [549560/78836 (26%)]	Loss: 0.319143
Train epoch: 333 [833340/78836 (39%)]	Loss: 0.349362
Train epoch: 333 [1137840/78836 (52%)]	Loss: 0.337949
Train epoch: 333 [1385300/78836 (65%)]	Loss: 0.300036
Train epoch: 333 [1652640/78836 (78%)]	Loss: 0.334906
Train epoch: 333 [1948380/78836 (91%)]	Loss: 0.282438
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 334 [0/78836 (0%)]	Loss: 0.289236
Train epoch: 334 [281860/78836 (13%)]	Loss: 0.360537
Train epoch: 334 [553000/78836 (26%)]	Loss: 0.347885
Train epoch: 334 [843120/78836 (39%)]	Loss: 0.335379
Train epoch: 334 [1120080/78836 (52%)]	Loss: 0.304223
Train epoch: 334 [1409000/78836 (65%)]	Loss: 0.297063
Train epoch: 334 [1681560/78836 (78%)]	Loss: 0.301820
Train epoch: 334 [1989680/78836 (91%)]	Loss: 0.306924
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 335 [0/78836 (0%)]	Loss: 0.253146
Train epoch: 335 [285140/78836 (13%)]	Loss: 0.320009
Train epoch: 335 [568280/78836 (26%)]	Loss: 0.315060
Train epoch: 335 [829080/78836 (39%)]	Loss: 0.290589
Train epoch: 335 [1102560/78836 (52%)]	Loss: 0.282890
Train epoch: 335 [1403000/78836 (65%)]	Loss: 0.298051
Train epoch: 335 [1667040/78836 (78%)]	Loss: 0.315218
Train epoch: 335 [1943620/78836 (91%)]	Loss: 0.356840
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 336 [0/78836 (0%)]	Loss: 0.336430
Train epoch: 336 [282480/78836 (13%)]	Loss: 0.363755
Train epoch: 336 [562640/78836 (26%)]	Loss: 0.331233
Train epoch: 336 [837120/78836 (39%)]	Loss: 0.290051
Train epoch: 336 [1112720/78836 (52%)]	Loss: 0.373633
Train epoch: 336 [1397600/78836 (65%)]	Loss: 0.356857
Train epoch: 336 [1679640/78836 (78%)]	Loss: 0.288767
Train epoch: 336 [1969800/78836 (91%)]	Loss: 0.352813
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 337 [0/78836 (0%)]	Loss: 0.275583
Train epoch: 337 [272360/78836 (13%)]	Loss: 0.306680
Train epoch: 337 [560320/78836 (26%)]	Loss: 0.277220
Train epoch: 337 [842940/78836 (39%)]	Loss: 0.326889
Train epoch: 337 [1104880/78836 (52%)]	Loss: 0.268311
Train epoch: 337 [1388800/78836 (65%)]	Loss: 0.296495
Train epoch: 337 [1662720/78836 (78%)]	Loss: 0.301104
Train epoch: 337 [1944460/78836 (91%)]	Loss: 0.304300
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 338 [0/78836 (0%)]	Loss: 0.332611
Train epoch: 338 [278820/78836 (13%)]	Loss: 0.323885
Train epoch: 338 [569320/78836 (26%)]	Loss: 0.293173
Train epoch: 338 [852540/78836 (39%)]	Loss: 0.376291
Train epoch: 338 [1103600/78836 (52%)]	Loss: 0.353810
Train epoch: 338 [1409200/78836 (65%)]	Loss: 0.307013
Train epoch: 338 [1683720/78836 (78%)]	Loss: 0.330870
Train epoch: 338 [1961960/78836 (91%)]	Loss: 0.355894
predicting for valid data
Make prediction for 19709 samples...
0.1980095 No improvement since epoch  307 ; best_test_mse,best_test_ci: 0.1980095 0.8412472879580397 GINConvNet kiba
Training on 78836 samples...
Train epoch: 339 [0/78836 (0%)]	Loss: 0.305664
Train epoch: 339 [280760/78836 (13%)]	Loss: 0.314846
Train epoch: 339 [564560/78836 (26%)]	Loss: 0.307195
Train epoch: 339 [845460/78836 (39%)]	Loss: 0.301762
Train epoch: 339 [1104560/78836 (52%)]	Loss: 0.285072
Train epoch: 339 [1386800/78836 (65%)]	Loss: 0.303520
Train epoch: 339 [1687080/78836 (78%)]	Loss: 0.369334
Train epoch: 339 [1976100/78836 (91%)]	Loss: 0.418475
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 340 [0/78836 (0%)]	Loss: 0.268562
Train epoch: 340 [282560/78836 (13%)]	Loss: 0.333697
Train epoch: 340 [556280/78836 (26%)]	Loss: 0.291290
Train epoch: 340 [834660/78836 (39%)]	Loss: 0.261360
Train epoch: 340 [1116160/78836 (52%)]	Loss: 0.279200
Train epoch: 340 [1420100/78836 (65%)]	Loss: 0.313669
Train epoch: 340 [1674960/78836 (78%)]	Loss: 0.310964
Train epoch: 340 [1939140/78836 (91%)]	Loss: 0.318605
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 341 [0/78836 (0%)]	Loss: 0.319510
Train epoch: 341 [282640/78836 (13%)]	Loss: 0.327082
Train epoch: 341 [553720/78836 (26%)]	Loss: 0.281170
Train epoch: 341 [835320/78836 (39%)]	Loss: 0.268556
Train epoch: 341 [1139680/78836 (52%)]	Loss: 0.325209
Train epoch: 341 [1425200/78836 (65%)]	Loss: 0.276817
Train epoch: 341 [1704360/78836 (78%)]	Loss: 0.324382
Train epoch: 341 [1967000/78836 (91%)]	Loss: 0.286615
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 342 [0/78836 (0%)]	Loss: 0.315833
Train epoch: 342 [275080/78836 (13%)]	Loss: 0.277970
Train epoch: 342 [558600/78836 (26%)]	Loss: 0.339133
Train epoch: 342 [838320/78836 (39%)]	Loss: 0.392362
Train epoch: 342 [1126800/78836 (52%)]	Loss: 0.270410
Train epoch: 342 [1389400/78836 (65%)]	Loss: 0.364030
Train epoch: 342 [1643160/78836 (78%)]	Loss: 0.285525
Train epoch: 342 [1999200/78836 (91%)]	Loss: 0.310403
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 343 [0/78836 (0%)]	Loss: 0.325857
Train epoch: 343 [277900/78836 (13%)]	Loss: 0.291300
Train epoch: 343 [561280/78836 (26%)]	Loss: 0.367437
Train epoch: 343 [840000/78836 (39%)]	Loss: 0.312535
Train epoch: 343 [1105120/78836 (52%)]	Loss: 0.280853
Train epoch: 343 [1390600/78836 (65%)]	Loss: 0.283038
Train epoch: 343 [1644840/78836 (78%)]	Loss: 0.313905
Train epoch: 343 [1954820/78836 (91%)]	Loss: 0.307068
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 344 [0/78836 (0%)]	Loss: 0.336762
Train epoch: 344 [274980/78836 (13%)]	Loss: 0.301173
Train epoch: 344 [552760/78836 (26%)]	Loss: 0.329165
Train epoch: 344 [848460/78836 (39%)]	Loss: 0.239190
Train epoch: 344 [1085280/78836 (52%)]	Loss: 0.310008
Train epoch: 344 [1425300/78836 (65%)]	Loss: 0.325120
Train epoch: 344 [1696320/78836 (78%)]	Loss: 0.321259
Train epoch: 344 [1956360/78836 (91%)]	Loss: 0.343522
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 345 [0/78836 (0%)]	Loss: 0.330412
Train epoch: 345 [276280/78836 (13%)]	Loss: 0.311034
Train epoch: 345 [571680/78836 (26%)]	Loss: 0.295728
Train epoch: 345 [827040/78836 (39%)]	Loss: 0.291314
Train epoch: 345 [1143440/78836 (52%)]	Loss: 0.350584
Train epoch: 345 [1421900/78836 (65%)]	Loss: 0.357285
Train epoch: 345 [1640280/78836 (78%)]	Loss: 0.258417
Train epoch: 345 [1943760/78836 (91%)]	Loss: 0.378743
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 346 [0/78836 (0%)]	Loss: 0.312778
Train epoch: 346 [276980/78836 (13%)]	Loss: 0.314500
Train epoch: 346 [559040/78836 (26%)]	Loss: 0.288668
Train epoch: 346 [834180/78836 (39%)]	Loss: 0.394406
Train epoch: 346 [1146560/78836 (52%)]	Loss: 0.354362
Train epoch: 346 [1387300/78836 (65%)]	Loss: 0.348193
Train epoch: 346 [1681200/78836 (78%)]	Loss: 0.316275
Train epoch: 346 [1985760/78836 (91%)]	Loss: 0.299853
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 347 [0/78836 (0%)]	Loss: 0.302072
Train epoch: 347 [276020/78836 (13%)]	Loss: 0.256675
Train epoch: 347 [567680/78836 (26%)]	Loss: 0.328236
Train epoch: 347 [838020/78836 (39%)]	Loss: 0.290880
Train epoch: 347 [1107360/78836 (52%)]	Loss: 0.306538
Train epoch: 347 [1362800/78836 (65%)]	Loss: 0.359863
Train epoch: 347 [1664160/78836 (78%)]	Loss: 0.404226
Train epoch: 347 [1937180/78836 (91%)]	Loss: 0.352019
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 348 [0/78836 (0%)]	Loss: 0.286105
Train epoch: 348 [275960/78836 (13%)]	Loss: 0.325812
Train epoch: 348 [574120/78836 (26%)]	Loss: 0.267853
Train epoch: 348 [838740/78836 (39%)]	Loss: 0.326392
Train epoch: 348 [1102000/78836 (52%)]	Loss: 0.321168
Train epoch: 348 [1414200/78836 (65%)]	Loss: 0.281311
Train epoch: 348 [1679400/78836 (78%)]	Loss: 0.319093
Train epoch: 348 [1943200/78836 (91%)]	Loss: 0.360294
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 349 [0/78836 (0%)]	Loss: 0.273095
Train epoch: 349 [282400/78836 (13%)]	Loss: 0.355151
Train epoch: 349 [559640/78836 (26%)]	Loss: 0.312158
Train epoch: 349 [832740/78836 (39%)]	Loss: 0.298600
Train epoch: 349 [1107840/78836 (52%)]	Loss: 0.358257
Train epoch: 349 [1380200/78836 (65%)]	Loss: 0.354959
Train epoch: 349 [1673760/78836 (78%)]	Loss: 0.296343
Train epoch: 349 [1950480/78836 (91%)]	Loss: 0.281655
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 350 [0/78836 (0%)]	Loss: 0.300087
Train epoch: 350 [286100/78836 (13%)]	Loss: 0.280780
Train epoch: 350 [563320/78836 (26%)]	Loss: 0.270057
Train epoch: 350 [829560/78836 (39%)]	Loss: 0.296761
Train epoch: 350 [1144880/78836 (52%)]	Loss: 0.298989
Train epoch: 350 [1410400/78836 (65%)]	Loss: 0.388422
Train epoch: 350 [1668240/78836 (78%)]	Loss: 0.287229
Train epoch: 350 [1957620/78836 (91%)]	Loss: 0.322261
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 351 [0/78836 (0%)]	Loss: 0.372624
Train epoch: 351 [281620/78836 (13%)]	Loss: 0.256990
Train epoch: 351 [562880/78836 (26%)]	Loss: 0.337799
Train epoch: 351 [862560/78836 (39%)]	Loss: 0.361388
Train epoch: 351 [1103840/78836 (52%)]	Loss: 0.297455
Train epoch: 351 [1378200/78836 (65%)]	Loss: 0.287534
Train epoch: 351 [1673160/78836 (78%)]	Loss: 0.319342
Train epoch: 351 [1971200/78836 (91%)]	Loss: 0.256254
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 352 [0/78836 (0%)]	Loss: 0.294396
Train epoch: 352 [287040/78836 (13%)]	Loss: 0.321328
Train epoch: 352 [554680/78836 (26%)]	Loss: 0.298380
Train epoch: 352 [834120/78836 (39%)]	Loss: 0.301459
Train epoch: 352 [1117280/78836 (52%)]	Loss: 0.292267
Train epoch: 352 [1399400/78836 (65%)]	Loss: 0.303816
Train epoch: 352 [1698600/78836 (78%)]	Loss: 0.311864
Train epoch: 352 [1953420/78836 (91%)]	Loss: 0.320259
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 353 [0/78836 (0%)]	Loss: 0.297871
Train epoch: 353 [279280/78836 (13%)]	Loss: 0.322885
Train epoch: 353 [556040/78836 (26%)]	Loss: 0.304929
Train epoch: 353 [830940/78836 (39%)]	Loss: 0.280194
Train epoch: 353 [1137440/78836 (52%)]	Loss: 0.282883
Train epoch: 353 [1384600/78836 (65%)]	Loss: 0.288434
Train epoch: 353 [1685040/78836 (78%)]	Loss: 0.316415
Train epoch: 353 [1938580/78836 (91%)]	Loss: 0.264938
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 354 [0/78836 (0%)]	Loss: 0.286694
Train epoch: 354 [275200/78836 (13%)]	Loss: 0.278302
Train epoch: 354 [550160/78836 (26%)]	Loss: 0.300660
Train epoch: 354 [826500/78836 (39%)]	Loss: 0.253542
Train epoch: 354 [1112880/78836 (52%)]	Loss: 0.300705
Train epoch: 354 [1395000/78836 (65%)]	Loss: 0.278546
Train epoch: 354 [1641960/78836 (78%)]	Loss: 0.320151
Train epoch: 354 [2007600/78836 (91%)]	Loss: 0.271211
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 355 [0/78836 (0%)]	Loss: 0.268684
Train epoch: 355 [280520/78836 (13%)]	Loss: 0.313627
Train epoch: 355 [558200/78836 (26%)]	Loss: 0.298477
Train epoch: 355 [839820/78836 (39%)]	Loss: 0.275449
Train epoch: 355 [1139760/78836 (52%)]	Loss: 0.324194
Train epoch: 355 [1399400/78836 (65%)]	Loss: 0.314734
Train epoch: 355 [1701120/78836 (78%)]	Loss: 0.290281
Train epoch: 355 [1928220/78836 (91%)]	Loss: 0.303714
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 356 [0/78836 (0%)]	Loss: 0.267742
Train epoch: 356 [278280/78836 (13%)]	Loss: 0.309950
Train epoch: 356 [560080/78836 (26%)]	Loss: 0.316579
Train epoch: 356 [821100/78836 (39%)]	Loss: 0.288151
Train epoch: 356 [1120480/78836 (52%)]	Loss: 0.325596
Train epoch: 356 [1409000/78836 (65%)]	Loss: 0.328768
Train epoch: 356 [1688040/78836 (78%)]	Loss: 0.307053
Train epoch: 356 [1970080/78836 (91%)]	Loss: 0.317130
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 357 [0/78836 (0%)]	Loss: 0.369678
Train epoch: 357 [277760/78836 (13%)]	Loss: 0.267008
Train epoch: 357 [561960/78836 (26%)]	Loss: 0.261773
Train epoch: 357 [845280/78836 (39%)]	Loss: 0.224775
Train epoch: 357 [1119840/78836 (52%)]	Loss: 0.316862
Train epoch: 357 [1384700/78836 (65%)]	Loss: 0.279200
Train epoch: 357 [1709640/78836 (78%)]	Loss: 0.277999
Train epoch: 357 [1922480/78836 (91%)]	Loss: 0.309677
predicting for valid data
Make prediction for 19709 samples...
0.19630767 No improvement since epoch  339 ; best_test_mse,best_test_ci: 0.19630767 0.842240862347336 GINConvNet kiba
Training on 78836 samples...
Train epoch: 358 [0/78836 (0%)]	Loss: 0.306128
Train epoch: 358 [287100/78836 (13%)]	Loss: 0.263699
Train epoch: 358 [560960/78836 (26%)]	Loss: 0.268900
Train epoch: 358 [840060/78836 (39%)]	Loss: 0.314470
Train epoch: 358 [1127760/78836 (52%)]	Loss: 0.298875
Train epoch: 358 [1409500/78836 (65%)]	Loss: 0.271483
Train epoch: 358 [1696440/78836 (78%)]	Loss: 0.270111
Train epoch: 358 [1940680/78836 (91%)]	Loss: 0.261469
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 359 [0/78836 (0%)]	Loss: 0.260042
Train epoch: 359 [278020/78836 (13%)]	Loss: 0.287312
Train epoch: 359 [552720/78836 (26%)]	Loss: 0.235806
Train epoch: 359 [845700/78836 (39%)]	Loss: 0.274054
Train epoch: 359 [1110400/78836 (52%)]	Loss: 0.289243
Train epoch: 359 [1401700/78836 (65%)]	Loss: 0.349882
Train epoch: 359 [1689960/78836 (78%)]	Loss: 0.306963
Train epoch: 359 [1926120/78836 (91%)]	Loss: 0.307027
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 360 [0/78836 (0%)]	Loss: 0.321158
Train epoch: 360 [279160/78836 (13%)]	Loss: 0.262698
Train epoch: 360 [565560/78836 (26%)]	Loss: 0.282572
Train epoch: 360 [843900/78836 (39%)]	Loss: 0.344180
Train epoch: 360 [1114000/78836 (52%)]	Loss: 0.293890
Train epoch: 360 [1386800/78836 (65%)]	Loss: 0.280490
Train epoch: 360 [1682520/78836 (78%)]	Loss: 0.297841
Train epoch: 360 [1940820/78836 (91%)]	Loss: 0.265097
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 361 [0/78836 (0%)]	Loss: 0.281386
Train epoch: 361 [273920/78836 (13%)]	Loss: 0.305399
Train epoch: 361 [551120/78836 (26%)]	Loss: 0.276652
Train epoch: 361 [842100/78836 (39%)]	Loss: 0.291848
Train epoch: 361 [1117040/78836 (52%)]	Loss: 0.282326
Train epoch: 361 [1412800/78836 (65%)]	Loss: 0.261664
Train epoch: 361 [1678200/78836 (78%)]	Loss: 0.272918
Train epoch: 361 [1944460/78836 (91%)]	Loss: 0.362469
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 362 [0/78836 (0%)]	Loss: 0.284574
Train epoch: 362 [283640/78836 (13%)]	Loss: 0.274304
Train epoch: 362 [561480/78836 (26%)]	Loss: 0.255986
Train epoch: 362 [837960/78836 (39%)]	Loss: 0.311850
Train epoch: 362 [1111760/78836 (52%)]	Loss: 0.294670
Train epoch: 362 [1400800/78836 (65%)]	Loss: 0.312874
Train epoch: 362 [1702680/78836 (78%)]	Loss: 0.301567
Train epoch: 362 [1949500/78836 (91%)]	Loss: 0.233974
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 363 [0/78836 (0%)]	Loss: 0.296000
Train epoch: 363 [281840/78836 (13%)]	Loss: 0.300307
Train epoch: 363 [559560/78836 (26%)]	Loss: 0.277893
Train epoch: 363 [841080/78836 (39%)]	Loss: 0.310871
Train epoch: 363 [1126080/78836 (52%)]	Loss: 0.265831
Train epoch: 363 [1392300/78836 (65%)]	Loss: 0.319615
Train epoch: 363 [1667640/78836 (78%)]	Loss: 0.274224
Train epoch: 363 [1974000/78836 (91%)]	Loss: 0.308722
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 364 [0/78836 (0%)]	Loss: 0.281332
Train epoch: 364 [273240/78836 (13%)]	Loss: 0.280313
Train epoch: 364 [551600/78836 (26%)]	Loss: 0.308145
Train epoch: 364 [853260/78836 (39%)]	Loss: 0.291584
Train epoch: 364 [1108480/78836 (52%)]	Loss: 0.340560
Train epoch: 364 [1383800/78836 (65%)]	Loss: 0.275280
Train epoch: 364 [1662240/78836 (78%)]	Loss: 0.365309
Train epoch: 364 [1972740/78836 (91%)]	Loss: 0.309387
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 365 [0/78836 (0%)]	Loss: 0.282330
Train epoch: 365 [278140/78836 (13%)]	Loss: 0.320780
Train epoch: 365 [558440/78836 (26%)]	Loss: 0.279661
Train epoch: 365 [818220/78836 (39%)]	Loss: 0.252695
Train epoch: 365 [1124400/78836 (52%)]	Loss: 0.319777
Train epoch: 365 [1415300/78836 (65%)]	Loss: 0.270810
Train epoch: 365 [1697520/78836 (78%)]	Loss: 0.306125
Train epoch: 365 [1903860/78836 (91%)]	Loss: 0.255574
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 366 [0/78836 (0%)]	Loss: 0.332590
Train epoch: 366 [282360/78836 (13%)]	Loss: 0.323682
Train epoch: 366 [557280/78836 (26%)]	Loss: 0.301238
Train epoch: 366 [840000/78836 (39%)]	Loss: 0.304876
Train epoch: 366 [1117680/78836 (52%)]	Loss: 0.325194
Train epoch: 366 [1384600/78836 (65%)]	Loss: 0.273043
Train epoch: 366 [1692480/78836 (78%)]	Loss: 0.235596
Train epoch: 366 [1981700/78836 (91%)]	Loss: 0.273769
predicting for valid data
Make prediction for 19709 samples...
0.1933892 No improvement since epoch  358 ; best_test_mse,best_test_ci: 0.1933892 0.8448041339567385 GINConvNet kiba
Training on 78836 samples...
Train epoch: 367 [0/78836 (0%)]	Loss: 0.357853
Train epoch: 367 [280240/78836 (13%)]	Loss: 0.334064
Train epoch: 367 [576240/78836 (26%)]	Loss: 0.272199
Train epoch: 367 [834000/78836 (39%)]	Loss: 0.312993
Train epoch: 367 [1105520/78836 (52%)]	Loss: 0.284272
Train epoch: 367 [1421400/78836 (65%)]	Loss: 0.294767
Train epoch: 367 [1698960/78836 (78%)]	Loss: 0.278314
Train epoch: 367 [1992620/78836 (91%)]	Loss: 0.272096
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 368 [0/78836 (0%)]	Loss: 0.301410
Train epoch: 368 [280520/78836 (13%)]	Loss: 0.342860
Train epoch: 368 [567400/78836 (26%)]	Loss: 0.291262
Train epoch: 368 [831600/78836 (39%)]	Loss: 0.310095
Train epoch: 368 [1136400/78836 (52%)]	Loss: 0.265390
Train epoch: 368 [1374600/78836 (65%)]	Loss: 0.282464
Train epoch: 368 [1690200/78836 (78%)]	Loss: 0.275775
Train epoch: 368 [1990380/78836 (91%)]	Loss: 0.291586
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 369 [0/78836 (0%)]	Loss: 0.274279
Train epoch: 369 [277040/78836 (13%)]	Loss: 0.268506
Train epoch: 369 [559400/78836 (26%)]	Loss: 0.287200
Train epoch: 369 [831060/78836 (39%)]	Loss: 0.290438
Train epoch: 369 [1126800/78836 (52%)]	Loss: 0.317139
Train epoch: 369 [1417000/78836 (65%)]	Loss: 0.242199
Train epoch: 369 [1673640/78836 (78%)]	Loss: 0.290510
Train epoch: 369 [1947960/78836 (91%)]	Loss: 0.268943
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 370 [0/78836 (0%)]	Loss: 0.300559
Train epoch: 370 [282140/78836 (13%)]	Loss: 0.279191
Train epoch: 370 [554360/78836 (26%)]	Loss: 0.294790
Train epoch: 370 [834300/78836 (39%)]	Loss: 0.282821
Train epoch: 370 [1115760/78836 (52%)]	Loss: 0.281211
Train epoch: 370 [1383600/78836 (65%)]	Loss: 0.283574
Train epoch: 370 [1652880/78836 (78%)]	Loss: 0.286824
Train epoch: 370 [1931720/78836 (91%)]	Loss: 0.254361
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 371 [0/78836 (0%)]	Loss: 0.272150
Train epoch: 371 [280520/78836 (13%)]	Loss: 0.252351
Train epoch: 371 [564280/78836 (26%)]	Loss: 0.266128
Train epoch: 371 [843780/78836 (39%)]	Loss: 0.263349
Train epoch: 371 [1135600/78836 (52%)]	Loss: 0.339014
Train epoch: 371 [1417100/78836 (65%)]	Loss: 0.289176
Train epoch: 371 [1697040/78836 (78%)]	Loss: 0.293803
Train epoch: 371 [1966720/78836 (91%)]	Loss: 0.284824
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 372 [0/78836 (0%)]	Loss: 0.299952
Train epoch: 372 [277600/78836 (13%)]	Loss: 0.304588
Train epoch: 372 [553440/78836 (26%)]	Loss: 0.306481
Train epoch: 372 [838140/78836 (39%)]	Loss: 0.289468
Train epoch: 372 [1099840/78836 (52%)]	Loss: 0.295236
Train epoch: 372 [1393000/78836 (65%)]	Loss: 0.276511
Train epoch: 372 [1712040/78836 (78%)]	Loss: 0.263173
Train epoch: 372 [1962660/78836 (91%)]	Loss: 0.292754
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 373 [0/78836 (0%)]	Loss: 0.324557
Train epoch: 373 [279680/78836 (13%)]	Loss: 0.242172
Train epoch: 373 [555120/78836 (26%)]	Loss: 0.251128
Train epoch: 373 [829860/78836 (39%)]	Loss: 0.269092
Train epoch: 373 [1113760/78836 (52%)]	Loss: 0.270724
Train epoch: 373 [1386400/78836 (65%)]	Loss: 0.284387
Train epoch: 373 [1694880/78836 (78%)]	Loss: 0.264006
Train epoch: 373 [1904980/78836 (91%)]	Loss: 0.283313
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 374 [0/78836 (0%)]	Loss: 0.280295
Train epoch: 374 [282380/78836 (13%)]	Loss: 0.284030
Train epoch: 374 [553560/78836 (26%)]	Loss: 0.325613
Train epoch: 374 [871740/78836 (39%)]	Loss: 0.311044
Train epoch: 374 [1130640/78836 (52%)]	Loss: 0.267410
Train epoch: 374 [1388200/78836 (65%)]	Loss: 0.264219
Train epoch: 374 [1665720/78836 (78%)]	Loss: 0.274447
Train epoch: 374 [1919400/78836 (91%)]	Loss: 0.354379
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 375 [0/78836 (0%)]	Loss: 0.250847
Train epoch: 375 [276580/78836 (13%)]	Loss: 0.254460
Train epoch: 375 [564200/78836 (26%)]	Loss: 0.298873
Train epoch: 375 [830160/78836 (39%)]	Loss: 0.291815
Train epoch: 375 [1102320/78836 (52%)]	Loss: 0.331653
Train epoch: 375 [1410000/78836 (65%)]	Loss: 0.342409
Train epoch: 375 [1661160/78836 (78%)]	Loss: 0.312424
Train epoch: 375 [2024260/78836 (91%)]	Loss: 0.285027
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 376 [0/78836 (0%)]	Loss: 0.280289
Train epoch: 376 [283940/78836 (13%)]	Loss: 0.275169
Train epoch: 376 [547520/78836 (26%)]	Loss: 0.291722
Train epoch: 376 [842220/78836 (39%)]	Loss: 0.281976
Train epoch: 376 [1116800/78836 (52%)]	Loss: 0.326369
Train epoch: 376 [1405600/78836 (65%)]	Loss: 0.296086
Train epoch: 376 [1695840/78836 (78%)]	Loss: 0.292489
Train epoch: 376 [1976240/78836 (91%)]	Loss: 0.224499
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 377 [0/78836 (0%)]	Loss: 0.314780
Train epoch: 377 [275960/78836 (13%)]	Loss: 0.271547
Train epoch: 377 [565360/78836 (26%)]	Loss: 0.280580
Train epoch: 377 [833100/78836 (39%)]	Loss: 0.270760
Train epoch: 377 [1117360/78836 (52%)]	Loss: 0.259589
Train epoch: 377 [1391000/78836 (65%)]	Loss: 0.326677
Train epoch: 377 [1676760/78836 (78%)]	Loss: 0.333389
Train epoch: 377 [1929200/78836 (91%)]	Loss: 0.280071
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 378 [0/78836 (0%)]	Loss: 0.298230
Train epoch: 378 [280120/78836 (13%)]	Loss: 0.247525
Train epoch: 378 [552040/78836 (26%)]	Loss: 0.393808
Train epoch: 378 [845460/78836 (39%)]	Loss: 0.275776
Train epoch: 378 [1118160/78836 (52%)]	Loss: 0.251369
Train epoch: 378 [1411700/78836 (65%)]	Loss: 0.311386
Train epoch: 378 [1676400/78836 (78%)]	Loss: 0.320876
Train epoch: 378 [1989120/78836 (91%)]	Loss: 0.305433
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 379 [0/78836 (0%)]	Loss: 0.288449
Train epoch: 379 [275700/78836 (13%)]	Loss: 0.289330
Train epoch: 379 [551440/78836 (26%)]	Loss: 0.216759
Train epoch: 379 [839160/78836 (39%)]	Loss: 0.344783
Train epoch: 379 [1095200/78836 (52%)]	Loss: 0.266970
Train epoch: 379 [1410400/78836 (65%)]	Loss: 0.294325
Train epoch: 379 [1677360/78836 (78%)]	Loss: 0.297759
Train epoch: 379 [1984500/78836 (91%)]	Loss: 0.279175
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 380 [0/78836 (0%)]	Loss: 0.280882
Train epoch: 380 [282420/78836 (13%)]	Loss: 0.285716
Train epoch: 380 [558920/78836 (26%)]	Loss: 0.274935
Train epoch: 380 [843840/78836 (39%)]	Loss: 0.269594
Train epoch: 380 [1107760/78836 (52%)]	Loss: 0.280684
Train epoch: 380 [1398100/78836 (65%)]	Loss: 0.296669
Train epoch: 380 [1677480/78836 (78%)]	Loss: 0.254209
Train epoch: 380 [1961540/78836 (91%)]	Loss: 0.333365
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 381 [0/78836 (0%)]	Loss: 0.271659
Train epoch: 381 [282300/78836 (13%)]	Loss: 0.253693
Train epoch: 381 [558400/78836 (26%)]	Loss: 0.284874
Train epoch: 381 [861060/78836 (39%)]	Loss: 0.304277
Train epoch: 381 [1160000/78836 (52%)]	Loss: 0.321222
Train epoch: 381 [1410000/78836 (65%)]	Loss: 0.290497
Train epoch: 381 [1677240/78836 (78%)]	Loss: 0.291941
Train epoch: 381 [1929900/78836 (91%)]	Loss: 0.260180
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 382 [0/78836 (0%)]	Loss: 0.263048
Train epoch: 382 [286160/78836 (13%)]	Loss: 0.262129
Train epoch: 382 [556760/78836 (26%)]	Loss: 0.326821
Train epoch: 382 [845100/78836 (39%)]	Loss: 0.326394
Train epoch: 382 [1125200/78836 (52%)]	Loss: 0.307469
Train epoch: 382 [1397100/78836 (65%)]	Loss: 0.295691
Train epoch: 382 [1703520/78836 (78%)]	Loss: 0.278054
Train epoch: 382 [1958320/78836 (91%)]	Loss: 0.315145
predicting for valid data
Make prediction for 19709 samples...
0.19529317 No improvement since epoch  367 ; best_test_mse,best_test_ci: 0.19529317 0.843604703363426 GINConvNet kiba
Training on 78836 samples...
Train epoch: 383 [0/78836 (0%)]	Loss: 0.319732
Train epoch: 383 [279140/78836 (13%)]	Loss: 0.353099
Train epoch: 383 [561040/78836 (26%)]	Loss: 0.255992
Train epoch: 383 [845580/78836 (39%)]	Loss: 0.307952
Train epoch: 383 [1132560/78836 (52%)]	Loss: 0.264942
Train epoch: 383 [1380400/78836 (65%)]	Loss: 0.276344
Train epoch: 383 [1668840/78836 (78%)]	Loss: 0.297522
Train epoch: 383 [1926400/78836 (91%)]	Loss: 0.253936
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 384 [0/78836 (0%)]	Loss: 0.205717
Train epoch: 384 [279280/78836 (13%)]	Loss: 0.249457
Train epoch: 384 [551560/78836 (26%)]	Loss: 0.304603
Train epoch: 384 [848040/78836 (39%)]	Loss: 0.290053
Train epoch: 384 [1112560/78836 (52%)]	Loss: 0.291307
Train epoch: 384 [1391400/78836 (65%)]	Loss: 0.342065
Train epoch: 384 [1670400/78836 (78%)]	Loss: 0.278809
Train epoch: 384 [1942920/78836 (91%)]	Loss: 0.293691
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 385 [0/78836 (0%)]	Loss: 0.262870
Train epoch: 385 [269600/78836 (13%)]	Loss: 0.262110
Train epoch: 385 [555200/78836 (26%)]	Loss: 0.248057
Train epoch: 385 [816120/78836 (39%)]	Loss: 0.273933
Train epoch: 385 [1098400/78836 (52%)]	Loss: 0.331527
Train epoch: 385 [1386500/78836 (65%)]	Loss: 0.407863
Train epoch: 385 [1714320/78836 (78%)]	Loss: 0.303647
Train epoch: 385 [1936760/78836 (91%)]	Loss: 0.287348
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 386 [0/78836 (0%)]	Loss: 0.323108
Train epoch: 386 [275940/78836 (13%)]	Loss: 0.296889
Train epoch: 386 [566240/78836 (26%)]	Loss: 0.282413
Train epoch: 386 [833220/78836 (39%)]	Loss: 0.263030
Train epoch: 386 [1116560/78836 (52%)]	Loss: 0.294398
Train epoch: 386 [1392400/78836 (65%)]	Loss: 0.304615
Train epoch: 386 [1664160/78836 (78%)]	Loss: 0.280973
Train epoch: 386 [1908060/78836 (91%)]	Loss: 0.254625
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 387 [0/78836 (0%)]	Loss: 0.222740
Train epoch: 387 [283140/78836 (13%)]	Loss: 0.223729
Train epoch: 387 [555160/78836 (26%)]	Loss: 0.295906
Train epoch: 387 [840480/78836 (39%)]	Loss: 0.302401
Train epoch: 387 [1118960/78836 (52%)]	Loss: 0.316790
Train epoch: 387 [1405700/78836 (65%)]	Loss: 0.284440
Train epoch: 387 [1705440/78836 (78%)]	Loss: 0.302081
Train epoch: 387 [1953700/78836 (91%)]	Loss: 0.262702
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 388 [0/78836 (0%)]	Loss: 0.256965
Train epoch: 388 [274480/78836 (13%)]	Loss: 0.316922
Train epoch: 388 [562160/78836 (26%)]	Loss: 0.236707
Train epoch: 388 [830100/78836 (39%)]	Loss: 0.298342
Train epoch: 388 [1119680/78836 (52%)]	Loss: 0.359884
Train epoch: 388 [1421200/78836 (65%)]	Loss: 0.280055
Train epoch: 388 [1707720/78836 (78%)]	Loss: 0.289112
Train epoch: 388 [1925700/78836 (91%)]	Loss: 0.255102
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 389 [0/78836 (0%)]	Loss: 0.316401
Train epoch: 389 [276680/78836 (13%)]	Loss: 0.297235
Train epoch: 389 [566840/78836 (26%)]	Loss: 0.265463
Train epoch: 389 [829140/78836 (39%)]	Loss: 0.278241
Train epoch: 389 [1122320/78836 (52%)]	Loss: 0.242153
Train epoch: 389 [1392500/78836 (65%)]	Loss: 0.336016
Train epoch: 389 [1670160/78836 (78%)]	Loss: 0.295889
Train epoch: 389 [1942780/78836 (91%)]	Loss: 0.271647
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 390 [0/78836 (0%)]	Loss: 0.295367
Train epoch: 390 [274620/78836 (13%)]	Loss: 0.276332
Train epoch: 390 [562560/78836 (26%)]	Loss: 0.209826
Train epoch: 390 [842400/78836 (39%)]	Loss: 0.283668
Train epoch: 390 [1100160/78836 (52%)]	Loss: 0.276995
Train epoch: 390 [1377000/78836 (65%)]	Loss: 0.297552
Train epoch: 390 [1649640/78836 (78%)]	Loss: 0.294986
Train epoch: 390 [1990800/78836 (91%)]	Loss: 0.230120
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 391 [0/78836 (0%)]	Loss: 0.256860
Train epoch: 391 [278380/78836 (13%)]	Loss: 0.314686
Train epoch: 391 [547960/78836 (26%)]	Loss: 0.265852
Train epoch: 391 [846240/78836 (39%)]	Loss: 0.230916
Train epoch: 391 [1130400/78836 (52%)]	Loss: 0.254926
Train epoch: 391 [1379600/78836 (65%)]	Loss: 0.244730
Train epoch: 391 [1663920/78836 (78%)]	Loss: 0.228498
Train epoch: 391 [1996540/78836 (91%)]	Loss: 0.269804
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 392 [0/78836 (0%)]	Loss: 0.275071
Train epoch: 392 [283360/78836 (13%)]	Loss: 0.257183
Train epoch: 392 [556560/78836 (26%)]	Loss: 0.302849
Train epoch: 392 [850920/78836 (39%)]	Loss: 0.235328
Train epoch: 392 [1098240/78836 (52%)]	Loss: 0.298440
Train epoch: 392 [1382600/78836 (65%)]	Loss: 0.279328
Train epoch: 392 [1665720/78836 (78%)]	Loss: 0.278037
Train epoch: 392 [1972320/78836 (91%)]	Loss: 0.296582
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 393 [0/78836 (0%)]	Loss: 0.235789
Train epoch: 393 [285900/78836 (13%)]	Loss: 0.299851
Train epoch: 393 [559160/78836 (26%)]	Loss: 0.276020
Train epoch: 393 [836580/78836 (39%)]	Loss: 0.346891
Train epoch: 393 [1117600/78836 (52%)]	Loss: 0.270318
Train epoch: 393 [1377100/78836 (65%)]	Loss: 0.274128
Train epoch: 393 [1689480/78836 (78%)]	Loss: 0.264169
Train epoch: 393 [1947260/78836 (91%)]	Loss: 0.291203
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 394 [0/78836 (0%)]	Loss: 0.277283
Train epoch: 394 [276520/78836 (13%)]	Loss: 0.260719
Train epoch: 394 [561760/78836 (26%)]	Loss: 0.336795
Train epoch: 394 [850080/78836 (39%)]	Loss: 0.291533
Train epoch: 394 [1102800/78836 (52%)]	Loss: 0.301725
Train epoch: 394 [1397900/78836 (65%)]	Loss: 0.300837
Train epoch: 394 [1705320/78836 (78%)]	Loss: 0.246317
Train epoch: 394 [1931440/78836 (91%)]	Loss: 0.243493
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 395 [0/78836 (0%)]	Loss: 0.240611
Train epoch: 395 [278480/78836 (13%)]	Loss: 0.246170
Train epoch: 395 [561880/78836 (26%)]	Loss: 0.288265
Train epoch: 395 [829800/78836 (39%)]	Loss: 0.303690
Train epoch: 395 [1109360/78836 (52%)]	Loss: 0.308427
Train epoch: 395 [1369700/78836 (65%)]	Loss: 0.255551
Train epoch: 395 [1701240/78836 (78%)]	Loss: 0.251236
Train epoch: 395 [1959020/78836 (91%)]	Loss: 0.277890
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 396 [0/78836 (0%)]	Loss: 0.313950
Train epoch: 396 [279540/78836 (13%)]	Loss: 0.366005
Train epoch: 396 [551760/78836 (26%)]	Loss: 0.266476
Train epoch: 396 [865140/78836 (39%)]	Loss: 0.273748
Train epoch: 396 [1089760/78836 (52%)]	Loss: 0.229893
Train epoch: 396 [1391600/78836 (65%)]	Loss: 0.231227
Train epoch: 396 [1665480/78836 (78%)]	Loss: 0.293989
Train epoch: 396 [2000600/78836 (91%)]	Loss: 0.252900
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 397 [0/78836 (0%)]	Loss: 0.251827
Train epoch: 397 [283020/78836 (13%)]	Loss: 0.263129
Train epoch: 397 [553640/78836 (26%)]	Loss: 0.266482
Train epoch: 397 [849300/78836 (39%)]	Loss: 0.248844
Train epoch: 397 [1137360/78836 (52%)]	Loss: 0.268764
Train epoch: 397 [1424400/78836 (65%)]	Loss: 0.272043
Train epoch: 397 [1639200/78836 (78%)]	Loss: 0.274432
Train epoch: 397 [1948380/78836 (91%)]	Loss: 0.301184
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 398 [0/78836 (0%)]	Loss: 0.266605
Train epoch: 398 [280780/78836 (13%)]	Loss: 0.266176
Train epoch: 398 [560200/78836 (26%)]	Loss: 0.274248
Train epoch: 398 [830160/78836 (39%)]	Loss: 0.276828
Train epoch: 398 [1118240/78836 (52%)]	Loss: 0.285016
Train epoch: 398 [1406200/78836 (65%)]	Loss: 0.259503
Train epoch: 398 [1695240/78836 (78%)]	Loss: 0.262830
Train epoch: 398 [1958460/78836 (91%)]	Loss: 0.293017
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 399 [0/78836 (0%)]	Loss: 0.235487
Train epoch: 399 [280040/78836 (13%)]	Loss: 0.275759
Train epoch: 399 [557760/78836 (26%)]	Loss: 0.245678
Train epoch: 399 [852480/78836 (39%)]	Loss: 0.273784
Train epoch: 399 [1118480/78836 (52%)]	Loss: 0.286128
Train epoch: 399 [1417900/78836 (65%)]	Loss: 0.315383
Train epoch: 399 [1689600/78836 (78%)]	Loss: 0.262260
Train epoch: 399 [1952160/78836 (91%)]	Loss: 0.261866
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 400 [0/78836 (0%)]	Loss: 0.247314
Train epoch: 400 [277200/78836 (13%)]	Loss: 0.296576
Train epoch: 400 [565320/78836 (26%)]	Loss: 0.264918
Train epoch: 400 [824700/78836 (39%)]	Loss: 0.264581
Train epoch: 400 [1114160/78836 (52%)]	Loss: 0.248759
Train epoch: 400 [1427800/78836 (65%)]	Loss: 0.254884
Train epoch: 400 [1644360/78836 (78%)]	Loss: 0.295547
Train epoch: 400 [2023420/78836 (91%)]	Loss: 0.274900
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 401 [0/78836 (0%)]	Loss: 0.298789
Train epoch: 401 [280820/78836 (13%)]	Loss: 0.283682
Train epoch: 401 [554120/78836 (26%)]	Loss: 0.332910
Train epoch: 401 [829560/78836 (39%)]	Loss: 0.269154
Train epoch: 401 [1125680/78836 (52%)]	Loss: 0.251189
Train epoch: 401 [1397900/78836 (65%)]	Loss: 0.289157
Train epoch: 401 [1675560/78836 (78%)]	Loss: 0.260620
Train epoch: 401 [1955520/78836 (91%)]	Loss: 0.282962
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 402 [0/78836 (0%)]	Loss: 0.269597
Train epoch: 402 [279420/78836 (13%)]	Loss: 0.249507
Train epoch: 402 [567560/78836 (26%)]	Loss: 0.309967
Train epoch: 402 [837300/78836 (39%)]	Loss: 0.232219
Train epoch: 402 [1105040/78836 (52%)]	Loss: 0.229599
Train epoch: 402 [1398600/78836 (65%)]	Loss: 0.253726
Train epoch: 402 [1677480/78836 (78%)]	Loss: 0.249868
Train epoch: 402 [1949220/78836 (91%)]	Loss: 0.220994
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 403 [0/78836 (0%)]	Loss: 0.253654
Train epoch: 403 [275660/78836 (13%)]	Loss: 0.270717
Train epoch: 403 [557680/78836 (26%)]	Loss: 0.237997
Train epoch: 403 [830100/78836 (39%)]	Loss: 0.270223
Train epoch: 403 [1109120/78836 (52%)]	Loss: 0.250453
Train epoch: 403 [1407500/78836 (65%)]	Loss: 0.260059
Train epoch: 403 [1653480/78836 (78%)]	Loss: 0.300056
Train epoch: 403 [1971620/78836 (91%)]	Loss: 0.290688
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 404 [0/78836 (0%)]	Loss: 0.252127
Train epoch: 404 [282380/78836 (13%)]	Loss: 0.290573
Train epoch: 404 [563960/78836 (26%)]	Loss: 0.250346
Train epoch: 404 [846120/78836 (39%)]	Loss: 0.256423
Train epoch: 404 [1079840/78836 (52%)]	Loss: 0.236998
Train epoch: 404 [1410000/78836 (65%)]	Loss: 0.278667
Train epoch: 404 [1708320/78836 (78%)]	Loss: 0.276205
Train epoch: 404 [1931860/78836 (91%)]	Loss: 0.234229
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 405 [0/78836 (0%)]	Loss: 0.299658
Train epoch: 405 [283740/78836 (13%)]	Loss: 0.252837
Train epoch: 405 [557960/78836 (26%)]	Loss: 0.266231
Train epoch: 405 [847620/78836 (39%)]	Loss: 0.269227
Train epoch: 405 [1135440/78836 (52%)]	Loss: 0.275613
Train epoch: 405 [1395600/78836 (65%)]	Loss: 0.251004
Train epoch: 405 [1670040/78836 (78%)]	Loss: 0.274988
Train epoch: 405 [1945440/78836 (91%)]	Loss: 0.250580
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 406 [0/78836 (0%)]	Loss: 0.272973
Train epoch: 406 [274700/78836 (13%)]	Loss: 0.231298
Train epoch: 406 [561600/78836 (26%)]	Loss: 0.365301
Train epoch: 406 [830940/78836 (39%)]	Loss: 0.310831
Train epoch: 406 [1140960/78836 (52%)]	Loss: 0.289825
Train epoch: 406 [1410400/78836 (65%)]	Loss: 0.342003
Train epoch: 406 [1654200/78836 (78%)]	Loss: 0.271549
Train epoch: 406 [1956500/78836 (91%)]	Loss: 0.248038
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 407 [0/78836 (0%)]	Loss: 0.213950
Train epoch: 407 [278440/78836 (13%)]	Loss: 0.286146
Train epoch: 407 [557520/78836 (26%)]	Loss: 0.260698
Train epoch: 407 [829500/78836 (39%)]	Loss: 0.258271
Train epoch: 407 [1118880/78836 (52%)]	Loss: 0.321880
Train epoch: 407 [1375200/78836 (65%)]	Loss: 0.262446
Train epoch: 407 [1679040/78836 (78%)]	Loss: 0.261874
Train epoch: 407 [1982820/78836 (91%)]	Loss: 0.255813
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 408 [0/78836 (0%)]	Loss: 0.280339
Train epoch: 408 [280180/78836 (13%)]	Loss: 0.234204
Train epoch: 408 [567520/78836 (26%)]	Loss: 0.261518
Train epoch: 408 [846720/78836 (39%)]	Loss: 0.253958
Train epoch: 408 [1112160/78836 (52%)]	Loss: 0.266752
Train epoch: 408 [1392900/78836 (65%)]	Loss: 0.288855
Train epoch: 408 [1714320/78836 (78%)]	Loss: 0.286708
Train epoch: 408 [1937180/78836 (91%)]	Loss: 0.272763
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 409 [0/78836 (0%)]	Loss: 0.306052
Train epoch: 409 [278260/78836 (13%)]	Loss: 0.237089
Train epoch: 409 [564760/78836 (26%)]	Loss: 0.342519
Train epoch: 409 [824700/78836 (39%)]	Loss: 0.219297
Train epoch: 409 [1091200/78836 (52%)]	Loss: 0.257579
Train epoch: 409 [1424300/78836 (65%)]	Loss: 0.280780
Train epoch: 409 [1654680/78836 (78%)]	Loss: 0.271000
Train epoch: 409 [1943060/78836 (91%)]	Loss: 0.271440
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 410 [0/78836 (0%)]	Loss: 0.332804
Train epoch: 410 [278780/78836 (13%)]	Loss: 0.269548
Train epoch: 410 [552760/78836 (26%)]	Loss: 0.266661
Train epoch: 410 [829560/78836 (39%)]	Loss: 0.284472
Train epoch: 410 [1131680/78836 (52%)]	Loss: 0.248368
Train epoch: 410 [1383800/78836 (65%)]	Loss: 0.267201
Train epoch: 410 [1687080/78836 (78%)]	Loss: 0.253308
Train epoch: 410 [1961960/78836 (91%)]	Loss: 0.292370
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 411 [0/78836 (0%)]	Loss: 0.301107
Train epoch: 411 [279620/78836 (13%)]	Loss: 0.263703
Train epoch: 411 [554640/78836 (26%)]	Loss: 0.287796
Train epoch: 411 [823140/78836 (39%)]	Loss: 0.252085
Train epoch: 411 [1123040/78836 (52%)]	Loss: 0.264707
Train epoch: 411 [1388700/78836 (65%)]	Loss: 0.242715
Train epoch: 411 [1686960/78836 (78%)]	Loss: 0.245610
Train epoch: 411 [1918420/78836 (91%)]	Loss: 0.249436
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 412 [0/78836 (0%)]	Loss: 0.274605
Train epoch: 412 [280940/78836 (13%)]	Loss: 0.222771
Train epoch: 412 [559920/78836 (26%)]	Loss: 0.229568
Train epoch: 412 [851400/78836 (39%)]	Loss: 0.251669
Train epoch: 412 [1120960/78836 (52%)]	Loss: 0.227311
Train epoch: 412 [1384900/78836 (65%)]	Loss: 0.255013
Train epoch: 412 [1662480/78836 (78%)]	Loss: 0.284447
Train epoch: 412 [1948800/78836 (91%)]	Loss: 0.261276
predicting for valid data
Make prediction for 19709 samples...
0.19352542 No improvement since epoch  383 ; best_test_mse,best_test_ci: 0.19352542 0.8466481860382052 GINConvNet kiba
Training on 78836 samples...
Train epoch: 413 [0/78836 (0%)]	Loss: 0.261381
Train epoch: 413 [273000/78836 (13%)]	Loss: 0.224803
Train epoch: 413 [561120/78836 (26%)]	Loss: 0.256908
Train epoch: 413 [833100/78836 (39%)]	Loss: 0.266806
Train epoch: 413 [1112720/78836 (52%)]	Loss: 0.318471
Train epoch: 413 [1400000/78836 (65%)]	Loss: 0.262477
Train epoch: 413 [1679040/78836 (78%)]	Loss: 0.258311
Train epoch: 413 [1924300/78836 (91%)]	Loss: 0.232043
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 414 [0/78836 (0%)]	Loss: 0.265576
Train epoch: 414 [274800/78836 (13%)]	Loss: 0.257579
Train epoch: 414 [550240/78836 (26%)]	Loss: 0.265466
Train epoch: 414 [855960/78836 (39%)]	Loss: 0.317193
Train epoch: 414 [1120080/78836 (52%)]	Loss: 0.244261
Train epoch: 414 [1422800/78836 (65%)]	Loss: 0.246427
Train epoch: 414 [1672560/78836 (78%)]	Loss: 0.279101
Train epoch: 414 [1963360/78836 (91%)]	Loss: 0.265095
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 415 [0/78836 (0%)]	Loss: 0.232371
Train epoch: 415 [274680/78836 (13%)]	Loss: 0.256256
Train epoch: 415 [560240/78836 (26%)]	Loss: 0.264703
Train epoch: 415 [827520/78836 (39%)]	Loss: 0.301513
Train epoch: 415 [1118560/78836 (52%)]	Loss: 0.262379
Train epoch: 415 [1415000/78836 (65%)]	Loss: 0.245133
Train epoch: 415 [1674960/78836 (78%)]	Loss: 0.246056
Train epoch: 415 [1914080/78836 (91%)]	Loss: 0.268696
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 416 [0/78836 (0%)]	Loss: 0.299298
Train epoch: 416 [277680/78836 (13%)]	Loss: 0.270316
Train epoch: 416 [553960/78836 (26%)]	Loss: 0.257376
Train epoch: 416 [840360/78836 (39%)]	Loss: 0.255918
Train epoch: 416 [1106880/78836 (52%)]	Loss: 0.262720
Train epoch: 416 [1384300/78836 (65%)]	Loss: 0.256225
Train epoch: 416 [1641720/78836 (78%)]	Loss: 0.299783
Train epoch: 416 [1960700/78836 (91%)]	Loss: 0.260015
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 417 [0/78836 (0%)]	Loss: 0.291858
Train epoch: 417 [284140/78836 (13%)]	Loss: 0.293735
Train epoch: 417 [555880/78836 (26%)]	Loss: 0.255119
Train epoch: 417 [844200/78836 (39%)]	Loss: 0.223753
Train epoch: 417 [1097680/78836 (52%)]	Loss: 0.272559
Train epoch: 417 [1412100/78836 (65%)]	Loss: 0.241096
Train epoch: 417 [1638840/78836 (78%)]	Loss: 0.261856
Train epoch: 417 [1925420/78836 (91%)]	Loss: 0.242360
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 418 [0/78836 (0%)]	Loss: 0.293025
Train epoch: 418 [279520/78836 (13%)]	Loss: 0.296725
Train epoch: 418 [559600/78836 (26%)]	Loss: 0.253577
Train epoch: 418 [835800/78836 (39%)]	Loss: 0.280102
Train epoch: 418 [1101600/78836 (52%)]	Loss: 0.214597
Train epoch: 418 [1424900/78836 (65%)]	Loss: 0.424121
Train epoch: 418 [1642440/78836 (78%)]	Loss: 0.290541
Train epoch: 418 [1950480/78836 (91%)]	Loss: 0.290274
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 419 [0/78836 (0%)]	Loss: 0.225915
Train epoch: 419 [284100/78836 (13%)]	Loss: 0.226964
Train epoch: 419 [555040/78836 (26%)]	Loss: 0.250900
Train epoch: 419 [836100/78836 (39%)]	Loss: 0.256566
Train epoch: 419 [1113200/78836 (52%)]	Loss: 0.269813
Train epoch: 419 [1394400/78836 (65%)]	Loss: 0.273122
Train epoch: 419 [1672800/78836 (78%)]	Loss: 0.252443
Train epoch: 419 [1906940/78836 (91%)]	Loss: 0.258056
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 420 [0/78836 (0%)]	Loss: 0.249464
Train epoch: 420 [282100/78836 (13%)]	Loss: 0.247889
Train epoch: 420 [560480/78836 (26%)]	Loss: 0.238005
Train epoch: 420 [847440/78836 (39%)]	Loss: 0.290485
Train epoch: 420 [1122000/78836 (52%)]	Loss: 0.250878
Train epoch: 420 [1381200/78836 (65%)]	Loss: 0.229463
Train epoch: 420 [1634760/78836 (78%)]	Loss: 0.240608
Train epoch: 420 [1922060/78836 (91%)]	Loss: 0.217232
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 421 [0/78836 (0%)]	Loss: 0.242564
Train epoch: 421 [281240/78836 (13%)]	Loss: 0.293462
Train epoch: 421 [566960/78836 (26%)]	Loss: 0.415624
Train epoch: 421 [844260/78836 (39%)]	Loss: 0.272856
Train epoch: 421 [1113360/78836 (52%)]	Loss: 0.281717
Train epoch: 421 [1376100/78836 (65%)]	Loss: 0.299786
Train epoch: 421 [1702080/78836 (78%)]	Loss: 0.282903
Train epoch: 421 [1925420/78836 (91%)]	Loss: 0.259089
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 422 [0/78836 (0%)]	Loss: 0.262063
Train epoch: 422 [280840/78836 (13%)]	Loss: 0.285843
Train epoch: 422 [563080/78836 (26%)]	Loss: 0.211544
Train epoch: 422 [830880/78836 (39%)]	Loss: 0.223797
Train epoch: 422 [1106960/78836 (52%)]	Loss: 0.268949
Train epoch: 422 [1417200/78836 (65%)]	Loss: 0.222192
Train epoch: 422 [1633080/78836 (78%)]	Loss: 0.278898
Train epoch: 422 [1992900/78836 (91%)]	Loss: 0.244970
predicting for valid data
Make prediction for 19709 samples...
0.19095132 No improvement since epoch  413 ; best_test_mse,best_test_ci: 0.19095132 0.8452764854152167 GINConvNet kiba
Training on 78836 samples...
Train epoch: 423 [0/78836 (0%)]	Loss: 0.282212
Train epoch: 423 [280320/78836 (13%)]	Loss: 0.272314
Train epoch: 423 [554080/78836 (26%)]	Loss: 0.264970
Train epoch: 423 [843540/78836 (39%)]	Loss: 0.243527
Train epoch: 423 [1088240/78836 (52%)]	Loss: 0.246188
Train epoch: 423 [1395600/78836 (65%)]	Loss: 0.260491
Train epoch: 423 [1658760/78836 (78%)]	Loss: 0.230189
Train epoch: 423 [1927240/78836 (91%)]	Loss: 0.219321
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  423 ; best_test_mse,best_test_ci: 0.19410801 0.8461982208142367 GINConvNet kiba
Training on 78836 samples...
Train epoch: 424 [0/78836 (0%)]	Loss: 0.198915
Train epoch: 424 [272300/78836 (13%)]	Loss: 0.226559
Train epoch: 424 [554960/78836 (26%)]	Loss: 0.225530
Train epoch: 424 [837720/78836 (39%)]	Loss: 0.281251
Train epoch: 424 [1107920/78836 (52%)]	Loss: 0.235708
Train epoch: 424 [1403200/78836 (65%)]	Loss: 0.206125
Train epoch: 424 [1660080/78836 (78%)]	Loss: 0.228061
Train epoch: 424 [1924580/78836 (91%)]	Loss: 0.217273
predicting for valid data
Make prediction for 19709 samples...
0.19410801 No improvement since epoch  423 ; best_test_mse,best_test_ci: 0.19410801 0.8461982208142367 GINConvNet kiba
Training on 78836 samples...
Train epoch: 425 [0/78836 (0%)]	Loss: 0.213014
Train epoch: 425 [281340/78836 (13%)]	Loss: 0.239279
Train epoch: 425 [561160/78836 (26%)]	Loss: 0.224263
Train epoch: 425 [831000/78836 (39%)]	Loss: 0.240405
Train epoch: 425 [1129680/78836 (52%)]	Loss: 0.281726
Train epoch: 425 [1380900/78836 (65%)]	Loss: 0.234236
Train epoch: 425 [1743960/78836 (78%)]	Loss: 0.308023
Train epoch: 425 [1925000/78836 (91%)]	Loss: 0.266313
predicting for valid data
Make prediction for 19709 samples...
0.19410801 No improvement since epoch  423 ; best_test_mse,best_test_ci: 0.19410801 0.8461982208142367 GINConvNet kiba
Training on 78836 samples...
Train epoch: 426 [0/78836 (0%)]	Loss: 0.265997
Train epoch: 426 [280000/78836 (13%)]	Loss: 0.201796
Train epoch: 426 [566880/78836 (26%)]	Loss: 0.281298
Train epoch: 426 [844080/78836 (39%)]	Loss: 0.235172
Train epoch: 426 [1130320/78836 (52%)]	Loss: 0.211792
Train epoch: 426 [1381500/78836 (65%)]	Loss: 0.310566
Train epoch: 426 [1680840/78836 (78%)]	Loss: 0.273753
Train epoch: 426 [1959580/78836 (91%)]	Loss: 0.269749
predicting for valid data
Make prediction for 19709 samples...
0.19410801 No improvement since epoch  423 ; best_test_mse,best_test_ci: 0.19410801 0.8461982208142367 GINConvNet kiba
Training on 78836 samples...
Train epoch: 427 [0/78836 (0%)]	Loss: 0.248209
Train epoch: 427 [275640/78836 (13%)]	Loss: 0.255605
Train epoch: 427 [564480/78836 (26%)]	Loss: 0.238628
Train epoch: 427 [822240/78836 (39%)]	Loss: 0.243093
Train epoch: 427 [1113680/78836 (52%)]	Loss: 0.274521
Train epoch: 427 [1413400/78836 (65%)]	Loss: 0.234799
Train epoch: 427 [1670640/78836 (78%)]	Loss: 0.252426
Train epoch: 427 [1995980/78836 (91%)]	Loss: 0.239153
predicting for valid data
Make prediction for 19709 samples...
0.19410801 No improvement since epoch  423 ; best_test_mse,best_test_ci: 0.19410801 0.8461982208142367 GINConvNet kiba
Training on 78836 samples...
Train epoch: 428 [0/78836 (0%)]	Loss: 0.241781
Train epoch: 428 [276760/78836 (13%)]	Loss: 0.264478
Train epoch: 428 [548400/78836 (26%)]	Loss: 0.241592
Train epoch: 428 [840660/78836 (39%)]	Loss: 0.246835
Train epoch: 428 [1125200/78836 (52%)]	Loss: 0.254078
Train epoch: 428 [1396600/78836 (65%)]	Loss: 0.221548
Train epoch: 428 [1668240/78836 (78%)]	Loss: 0.239111
Train epoch: 428 [1940120/78836 (91%)]	Loss: 0.228943
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  428 ; best_test_mse,best_test_ci: 0.19124676 0.850152953954111 GINConvNet kiba
Training on 78836 samples...
Train epoch: 429 [0/78836 (0%)]	Loss: 0.229460
Train epoch: 429 [284720/78836 (13%)]	Loss: 0.247365
Train epoch: 429 [559520/78836 (26%)]	Loss: 0.254706
Train epoch: 429 [812880/78836 (39%)]	Loss: 0.235141
Train epoch: 429 [1113520/78836 (52%)]	Loss: 0.274522
Train epoch: 429 [1420600/78836 (65%)]	Loss: 0.216247
Train epoch: 429 [1674360/78836 (78%)]	Loss: 0.241514
Train epoch: 429 [1953280/78836 (91%)]	Loss: 0.325015
predicting for valid data
Make prediction for 19709 samples...
0.19124676 No improvement since epoch  428 ; best_test_mse,best_test_ci: 0.19124676 0.850152953954111 GINConvNet kiba
Training on 78836 samples...
Train epoch: 430 [0/78836 (0%)]	Loss: 0.259766
Train epoch: 430 [280240/78836 (13%)]	Loss: 0.299516
Train epoch: 430 [556520/78836 (26%)]	Loss: 0.228423
Train epoch: 430 [848880/78836 (39%)]	Loss: 0.287729
Train epoch: 430 [1140000/78836 (52%)]	Loss: 0.296220
Train epoch: 430 [1418800/78836 (65%)]	Loss: 0.258780
Train epoch: 430 [1690440/78836 (78%)]	Loss: 0.258595
Train epoch: 430 [1950480/78836 (91%)]	Loss: 0.277817
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 431 [0/78836 (0%)]	Loss: 0.245835
Train epoch: 431 [276520/78836 (13%)]	Loss: 0.228602
Train epoch: 431 [549720/78836 (26%)]	Loss: 0.247088
Train epoch: 431 [842820/78836 (39%)]	Loss: 0.227622
Train epoch: 431 [1109600/78836 (52%)]	Loss: 0.271277
Train epoch: 431 [1396100/78836 (65%)]	Loss: 0.285113
Train epoch: 431 [1665720/78836 (78%)]	Loss: 0.223799
Train epoch: 431 [1987580/78836 (91%)]	Loss: 0.279830
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 432 [0/78836 (0%)]	Loss: 0.325381
Train epoch: 432 [285220/78836 (13%)]	Loss: 0.241771
Train epoch: 432 [563800/78836 (26%)]	Loss: 0.234058
Train epoch: 432 [837660/78836 (39%)]	Loss: 0.287484
Train epoch: 432 [1105680/78836 (52%)]	Loss: 0.299278
Train epoch: 432 [1387800/78836 (65%)]	Loss: 0.282333
Train epoch: 432 [1680720/78836 (78%)]	Loss: 0.254914
Train epoch: 432 [1973440/78836 (91%)]	Loss: 0.231641
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 433 [0/78836 (0%)]	Loss: 0.228640
Train epoch: 433 [274820/78836 (13%)]	Loss: 0.282663
Train epoch: 433 [558560/78836 (26%)]	Loss: 0.242084
Train epoch: 433 [827340/78836 (39%)]	Loss: 0.286514
Train epoch: 433 [1103360/78836 (52%)]	Loss: 0.218820
Train epoch: 433 [1386100/78836 (65%)]	Loss: 0.227483
Train epoch: 433 [1733760/78836 (78%)]	Loss: 0.292660
Train epoch: 433 [1961540/78836 (91%)]	Loss: 0.229998
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 434 [0/78836 (0%)]	Loss: 0.204269
Train epoch: 434 [279360/78836 (13%)]	Loss: 0.201214
Train epoch: 434 [568720/78836 (26%)]	Loss: 0.241163
Train epoch: 434 [860340/78836 (39%)]	Loss: 0.217226
Train epoch: 434 [1111760/78836 (52%)]	Loss: 0.255722
Train epoch: 434 [1401100/78836 (65%)]	Loss: 0.228125
Train epoch: 434 [1683480/78836 (78%)]	Loss: 0.243601
Train epoch: 434 [1953840/78836 (91%)]	Loss: 0.286830
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 435 [0/78836 (0%)]	Loss: 0.223977
Train epoch: 435 [275920/78836 (13%)]	Loss: 0.255844
Train epoch: 435 [558320/78836 (26%)]	Loss: 0.252838
Train epoch: 435 [833220/78836 (39%)]	Loss: 0.257443
Train epoch: 435 [1105680/78836 (52%)]	Loss: 0.327907
Train epoch: 435 [1399600/78836 (65%)]	Loss: 0.245757
Train epoch: 435 [1679880/78836 (78%)]	Loss: 0.263719
Train epoch: 435 [1975680/78836 (91%)]	Loss: 0.233139
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 436 [0/78836 (0%)]	Loss: 0.213383
Train epoch: 436 [281700/78836 (13%)]	Loss: 0.259007
Train epoch: 436 [568240/78836 (26%)]	Loss: 0.271693
Train epoch: 436 [827880/78836 (39%)]	Loss: 0.255119
Train epoch: 436 [1101200/78836 (52%)]	Loss: 0.230102
Train epoch: 436 [1383700/78836 (65%)]	Loss: 0.230947
Train epoch: 436 [1667400/78836 (78%)]	Loss: 0.256169
Train epoch: 436 [1991220/78836 (91%)]	Loss: 0.234208
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 437 [0/78836 (0%)]	Loss: 0.224969
Train epoch: 437 [279960/78836 (13%)]	Loss: 0.258271
Train epoch: 437 [560160/78836 (26%)]	Loss: 0.263791
Train epoch: 437 [853080/78836 (39%)]	Loss: 0.268004
Train epoch: 437 [1136800/78836 (52%)]	Loss: 0.274236
Train epoch: 437 [1411100/78836 (65%)]	Loss: 0.256566
Train epoch: 437 [1680720/78836 (78%)]	Loss: 0.291725
Train epoch: 437 [1982400/78836 (91%)]	Loss: 0.196222
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 438 [0/78836 (0%)]	Loss: 0.212066
Train epoch: 438 [281120/78836 (13%)]	Loss: 0.223502
Train epoch: 438 [550880/78836 (26%)]	Loss: 0.241525
Train epoch: 438 [828660/78836 (39%)]	Loss: 0.276706
Train epoch: 438 [1123920/78836 (52%)]	Loss: 0.237479
Train epoch: 438 [1395400/78836 (65%)]	Loss: 0.249288
Train epoch: 438 [1706160/78836 (78%)]	Loss: 0.291143
Train epoch: 438 [1968540/78836 (91%)]	Loss: 0.333649
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 439 [0/78836 (0%)]	Loss: 0.256360
Train epoch: 439 [276740/78836 (13%)]	Loss: 0.229677
Train epoch: 439 [558960/78836 (26%)]	Loss: 0.265572
Train epoch: 439 [846420/78836 (39%)]	Loss: 0.315726
Train epoch: 439 [1137040/78836 (52%)]	Loss: 0.236097
Train epoch: 439 [1400800/78836 (65%)]	Loss: 0.264611
Train epoch: 439 [1669680/78836 (78%)]	Loss: 0.293822
Train epoch: 439 [1931160/78836 (91%)]	Loss: 0.240060
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 440 [0/78836 (0%)]	Loss: 0.250540
Train epoch: 440 [281060/78836 (13%)]	Loss: 0.224467
Train epoch: 440 [560000/78836 (26%)]	Loss: 0.282190
Train epoch: 440 [833640/78836 (39%)]	Loss: 0.239325
Train epoch: 440 [1111280/78836 (52%)]	Loss: 0.203724
Train epoch: 440 [1417300/78836 (65%)]	Loss: 0.252820
Train epoch: 440 [1686120/78836 (78%)]	Loss: 0.235198
Train epoch: 440 [1978480/78836 (91%)]	Loss: 0.259610
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 441 [0/78836 (0%)]	Loss: 0.209920
Train epoch: 441 [274560/78836 (13%)]	Loss: 0.220202
Train epoch: 441 [556560/78836 (26%)]	Loss: 0.242776
Train epoch: 441 [821880/78836 (39%)]	Loss: 0.220260
Train epoch: 441 [1126880/78836 (52%)]	Loss: 0.252949
Train epoch: 441 [1415500/78836 (65%)]	Loss: 0.229989
Train epoch: 441 [1660680/78836 (78%)]	Loss: 0.188734
Train epoch: 441 [1947540/78836 (91%)]	Loss: 0.248170
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 442 [0/78836 (0%)]	Loss: 0.290495
Train epoch: 442 [280120/78836 (13%)]	Loss: 0.216039
Train epoch: 442 [568840/78836 (26%)]	Loss: 0.284402
Train epoch: 442 [840060/78836 (39%)]	Loss: 0.255041
Train epoch: 442 [1107520/78836 (52%)]	Loss: 0.224534
Train epoch: 442 [1426500/78836 (65%)]	Loss: 0.241990
Train epoch: 442 [1668360/78836 (78%)]	Loss: 0.266535
Train epoch: 442 [1953420/78836 (91%)]	Loss: 0.243040
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 443 [0/78836 (0%)]	Loss: 0.222597
Train epoch: 443 [275280/78836 (13%)]	Loss: 0.234273
Train epoch: 443 [551040/78836 (26%)]	Loss: 0.217435
Train epoch: 443 [849960/78836 (39%)]	Loss: 0.261830
Train epoch: 443 [1130720/78836 (52%)]	Loss: 0.238092
Train epoch: 443 [1416300/78836 (65%)]	Loss: 0.222290
Train epoch: 443 [1675440/78836 (78%)]	Loss: 0.259652
Train epoch: 443 [1964760/78836 (91%)]	Loss: 0.290414
predicting for valid data
Make prediction for 19709 samples...
0.18678129 No improvement since epoch  430 ; best_test_mse,best_test_ci: 0.18678129 0.8495472184168928 GINConvNet kiba
Training on 78836 samples...
Train epoch: 444 [0/78836 (0%)]	Loss: 0.330611
Train epoch: 444 [281900/78836 (13%)]	Loss: 0.261341
Train epoch: 444 [551760/78836 (26%)]	Loss: 0.227810
Train epoch: 444 [863640/78836 (39%)]	Loss: 0.261276
Train epoch: 444 [1102000/78836 (52%)]	Loss: 0.236545
Train epoch: 444 [1403500/78836 (65%)]	Loss: 0.227325
Train epoch: 444 [1702800/78836 (78%)]	Loss: 0.235229
Train epoch: 444 [2027900/78836 (91%)]	Loss: 0.254917
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 445 [0/78836 (0%)]	Loss: 0.214131
Train epoch: 445 [276700/78836 (13%)]	Loss: 0.264296
Train epoch: 445 [552960/78836 (26%)]	Loss: 0.220210
Train epoch: 445 [826560/78836 (39%)]	Loss: 0.238096
Train epoch: 445 [1096480/78836 (52%)]	Loss: 0.228251
Train epoch: 445 [1386000/78836 (65%)]	Loss: 0.220141
Train epoch: 445 [1696080/78836 (78%)]	Loss: 0.245545
Train epoch: 445 [1965040/78836 (91%)]	Loss: 0.240753
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 446 [0/78836 (0%)]	Loss: 0.247164
Train epoch: 446 [276740/78836 (13%)]	Loss: 0.248111
Train epoch: 446 [573320/78836 (26%)]	Loss: 0.250267
Train epoch: 446 [853260/78836 (39%)]	Loss: 0.200016
Train epoch: 446 [1100880/78836 (52%)]	Loss: 0.213290
Train epoch: 446 [1395800/78836 (65%)]	Loss: 0.236590
Train epoch: 446 [1689720/78836 (78%)]	Loss: 0.281888
Train epoch: 446 [1938020/78836 (91%)]	Loss: 0.274312
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 447 [0/78836 (0%)]	Loss: 0.258906
Train epoch: 447 [282140/78836 (13%)]	Loss: 0.235158
Train epoch: 447 [565560/78836 (26%)]	Loss: 0.220461
Train epoch: 447 [844920/78836 (39%)]	Loss: 0.223571
Train epoch: 447 [1119280/78836 (52%)]	Loss: 0.265724
Train epoch: 447 [1351400/78836 (65%)]	Loss: 0.288968
Train epoch: 447 [1668840/78836 (78%)]	Loss: 0.279464
Train epoch: 447 [1993740/78836 (91%)]	Loss: 0.272888
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 448 [0/78836 (0%)]	Loss: 0.233978
Train epoch: 448 [278800/78836 (13%)]	Loss: 0.301846
Train epoch: 448 [561480/78836 (26%)]	Loss: 0.242368
Train epoch: 448 [834480/78836 (39%)]	Loss: 0.242981
Train epoch: 448 [1126400/78836 (52%)]	Loss: 0.229609
Train epoch: 448 [1417000/78836 (65%)]	Loss: 0.240963
Train epoch: 448 [1678800/78836 (78%)]	Loss: 0.231065
Train epoch: 448 [1926820/78836 (91%)]	Loss: 0.245365
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 449 [0/78836 (0%)]	Loss: 0.335555
Train epoch: 449 [283300/78836 (13%)]	Loss: 0.233679
Train epoch: 449 [555960/78836 (26%)]	Loss: 0.227882
Train epoch: 449 [846180/78836 (39%)]	Loss: 0.242776
Train epoch: 449 [1127280/78836 (52%)]	Loss: 0.240201
Train epoch: 449 [1386100/78836 (65%)]	Loss: 0.250200
Train epoch: 449 [1685760/78836 (78%)]	Loss: 0.303269
Train epoch: 449 [1943760/78836 (91%)]	Loss: 0.259735
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 450 [0/78836 (0%)]	Loss: 0.270821
Train epoch: 450 [275800/78836 (13%)]	Loss: 0.214042
Train epoch: 450 [559800/78836 (26%)]	Loss: 0.225380
Train epoch: 450 [858840/78836 (39%)]	Loss: 0.242695
Train epoch: 450 [1114640/78836 (52%)]	Loss: 0.236113
Train epoch: 450 [1394800/78836 (65%)]	Loss: 0.216007
Train epoch: 450 [1716240/78836 (78%)]	Loss: 0.253231
Train epoch: 450 [1947960/78836 (91%)]	Loss: 0.249871
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 451 [0/78836 (0%)]	Loss: 0.242568
Train epoch: 451 [284020/78836 (13%)]	Loss: 0.190721
Train epoch: 451 [565760/78836 (26%)]	Loss: 0.226757
Train epoch: 451 [826800/78836 (39%)]	Loss: 0.236426
Train epoch: 451 [1100880/78836 (52%)]	Loss: 0.259391
Train epoch: 451 [1418200/78836 (65%)]	Loss: 0.274160
Train epoch: 451 [1648680/78836 (78%)]	Loss: 0.249130
Train epoch: 451 [2001440/78836 (91%)]	Loss: 0.225958
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 452 [0/78836 (0%)]	Loss: 0.195264
Train epoch: 452 [280700/78836 (13%)]	Loss: 0.239316
Train epoch: 452 [562000/78836 (26%)]	Loss: 0.256772
Train epoch: 452 [848100/78836 (39%)]	Loss: 0.202212
Train epoch: 452 [1097120/78836 (52%)]	Loss: 0.282932
Train epoch: 452 [1416100/78836 (65%)]	Loss: 0.228214
Train epoch: 452 [1670520/78836 (78%)]	Loss: 0.229121
Train epoch: 452 [1952020/78836 (91%)]	Loss: 0.213086
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 453 [0/78836 (0%)]	Loss: 0.252618
Train epoch: 453 [269240/78836 (13%)]	Loss: 0.213074
Train epoch: 453 [553760/78836 (26%)]	Loss: 0.269844
Train epoch: 453 [865260/78836 (39%)]	Loss: 0.216118
Train epoch: 453 [1114960/78836 (52%)]	Loss: 0.227156
Train epoch: 453 [1414400/78836 (65%)]	Loss: 0.211390
Train epoch: 453 [1687680/78836 (78%)]	Loss: 0.250554
Train epoch: 453 [1950900/78836 (91%)]	Loss: 0.256924
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 454 [0/78836 (0%)]	Loss: 0.240046
Train epoch: 454 [280860/78836 (13%)]	Loss: 0.272811
Train epoch: 454 [568760/78836 (26%)]	Loss: 0.260101
Train epoch: 454 [836880/78836 (39%)]	Loss: 0.244900
Train epoch: 454 [1098080/78836 (52%)]	Loss: 0.227511
Train epoch: 454 [1396600/78836 (65%)]	Loss: 0.211374
Train epoch: 454 [1673880/78836 (78%)]	Loss: 0.212289
Train epoch: 454 [1979040/78836 (91%)]	Loss: 0.269060
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 455 [0/78836 (0%)]	Loss: 0.251785
Train epoch: 455 [277860/78836 (13%)]	Loss: 0.235198
Train epoch: 455 [564680/78836 (26%)]	Loss: 0.226843
Train epoch: 455 [855960/78836 (39%)]	Loss: 0.281406
Train epoch: 455 [1119840/78836 (52%)]	Loss: 0.213339
Train epoch: 455 [1441300/78836 (65%)]	Loss: 0.238583
Train epoch: 455 [1666200/78836 (78%)]	Loss: 0.251582
Train epoch: 455 [1963780/78836 (91%)]	Loss: 0.266208
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 456 [0/78836 (0%)]	Loss: 0.266684
Train epoch: 456 [280400/78836 (13%)]	Loss: 0.253792
Train epoch: 456 [564480/78836 (26%)]	Loss: 0.246665
Train epoch: 456 [839040/78836 (39%)]	Loss: 0.203806
Train epoch: 456 [1120560/78836 (52%)]	Loss: 0.222323
Train epoch: 456 [1395400/78836 (65%)]	Loss: 0.295735
Train epoch: 456 [1670880/78836 (78%)]	Loss: 0.242311
Train epoch: 456 [1943760/78836 (91%)]	Loss: 0.250834
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 457 [0/78836 (0%)]	Loss: 0.232956
Train epoch: 457 [278960/78836 (13%)]	Loss: 0.233475
Train epoch: 457 [556200/78836 (26%)]	Loss: 0.240126
Train epoch: 457 [857760/78836 (39%)]	Loss: 0.226813
Train epoch: 457 [1121040/78836 (52%)]	Loss: 0.177898
Train epoch: 457 [1392300/78836 (65%)]	Loss: 0.240853
Train epoch: 457 [1628160/78836 (78%)]	Loss: 0.260660
Train epoch: 457 [1997520/78836 (91%)]	Loss: 0.263088
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 458 [0/78836 (0%)]	Loss: 0.219522
Train epoch: 458 [281560/78836 (13%)]	Loss: 0.229343
Train epoch: 458 [571720/78836 (26%)]	Loss: 0.196493
Train epoch: 458 [858060/78836 (39%)]	Loss: 0.217763
Train epoch: 458 [1099280/78836 (52%)]	Loss: 0.248166
Train epoch: 458 [1404100/78836 (65%)]	Loss: 0.213913
Train epoch: 458 [1718520/78836 (78%)]	Loss: 0.235424
Train epoch: 458 [1960420/78836 (91%)]	Loss: 0.226878
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 459 [0/78836 (0%)]	Loss: 0.231082
Train epoch: 459 [277740/78836 (13%)]	Loss: 0.226720
Train epoch: 459 [555720/78836 (26%)]	Loss: 0.180993
Train epoch: 459 [845700/78836 (39%)]	Loss: 0.218806
Train epoch: 459 [1130160/78836 (52%)]	Loss: 0.240586
Train epoch: 459 [1410400/78836 (65%)]	Loss: 0.206641
Train epoch: 459 [1697640/78836 (78%)]	Loss: 0.206504
Train epoch: 459 [1989540/78836 (91%)]	Loss: 0.219918
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 460 [0/78836 (0%)]	Loss: 0.241437
Train epoch: 460 [283460/78836 (13%)]	Loss: 0.218996
Train epoch: 460 [555400/78836 (26%)]	Loss: 0.224668
Train epoch: 460 [825420/78836 (39%)]	Loss: 0.222695
Train epoch: 460 [1107520/78836 (52%)]	Loss: 0.235266
Train epoch: 460 [1429800/78836 (65%)]	Loss: 0.252921
Train epoch: 460 [1745040/78836 (78%)]	Loss: 0.253109
Train epoch: 460 [1961960/78836 (91%)]	Loss: 0.218648
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 461 [0/78836 (0%)]	Loss: 0.211289
Train epoch: 461 [280340/78836 (13%)]	Loss: 0.259864
Train epoch: 461 [568240/78836 (26%)]	Loss: 0.238628
Train epoch: 461 [831720/78836 (39%)]	Loss: 0.228461
Train epoch: 461 [1140400/78836 (52%)]	Loss: 0.276905
Train epoch: 461 [1396400/78836 (65%)]	Loss: 0.285306
Train epoch: 461 [1697160/78836 (78%)]	Loss: 0.265820
Train epoch: 461 [1988420/78836 (91%)]	Loss: 0.248546
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 462 [0/78836 (0%)]	Loss: 0.199411
Train epoch: 462 [280480/78836 (13%)]	Loss: 0.222362
Train epoch: 462 [571400/78836 (26%)]	Loss: 0.215934
Train epoch: 462 [838020/78836 (39%)]	Loss: 0.259276
Train epoch: 462 [1094880/78836 (52%)]	Loss: 0.234653
Train epoch: 462 [1389000/78836 (65%)]	Loss: 0.278987
Train epoch: 462 [1643760/78836 (78%)]	Loss: 0.210326
Train epoch: 462 [1953700/78836 (91%)]	Loss: 0.227518
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 463 [0/78836 (0%)]	Loss: 0.222379
Train epoch: 463 [283780/78836 (13%)]	Loss: 0.230299
Train epoch: 463 [556480/78836 (26%)]	Loss: 0.223441
Train epoch: 463 [847020/78836 (39%)]	Loss: 0.223328
Train epoch: 463 [1110880/78836 (52%)]	Loss: 0.232734
Train epoch: 463 [1412000/78836 (65%)]	Loss: 0.260547
Train epoch: 463 [1692360/78836 (78%)]	Loss: 0.226172
Train epoch: 463 [1919540/78836 (91%)]	Loss: 0.222700
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 464 [0/78836 (0%)]	Loss: 0.239973
Train epoch: 464 [277540/78836 (13%)]	Loss: 0.238259
Train epoch: 464 [552480/78836 (26%)]	Loss: 0.224710
Train epoch: 464 [839520/78836 (39%)]	Loss: 0.232824
Train epoch: 464 [1132320/78836 (52%)]	Loss: 0.234414
Train epoch: 464 [1417900/78836 (65%)]	Loss: 0.249037
Train epoch: 464 [1656000/78836 (78%)]	Loss: 0.257207
Train epoch: 464 [1971060/78836 (91%)]	Loss: 0.265709
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 465 [0/78836 (0%)]	Loss: 0.250297
Train epoch: 465 [280380/78836 (13%)]	Loss: 0.229978
Train epoch: 465 [556920/78836 (26%)]	Loss: 0.249952
Train epoch: 465 [834720/78836 (39%)]	Loss: 0.232498
Train epoch: 465 [1122560/78836 (52%)]	Loss: 0.221306
Train epoch: 465 [1403100/78836 (65%)]	Loss: 0.220854
Train epoch: 465 [1677360/78836 (78%)]	Loss: 0.262601
Train epoch: 465 [2021740/78836 (91%)]	Loss: 0.287579
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 466 [0/78836 (0%)]	Loss: 0.200698
Train epoch: 466 [271960/78836 (13%)]	Loss: 0.242242
Train epoch: 466 [560280/78836 (26%)]	Loss: 0.221537
Train epoch: 466 [834660/78836 (39%)]	Loss: 0.222036
Train epoch: 466 [1122560/78836 (52%)]	Loss: 0.212863
Train epoch: 466 [1371900/78836 (65%)]	Loss: 0.234429
Train epoch: 466 [1685280/78836 (78%)]	Loss: 0.254812
Train epoch: 466 [1997100/78836 (91%)]	Loss: 0.276478
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 467 [0/78836 (0%)]	Loss: 0.235423
Train epoch: 467 [280320/78836 (13%)]	Loss: 0.223903
Train epoch: 467 [560440/78836 (26%)]	Loss: 0.259712
Train epoch: 467 [853260/78836 (39%)]	Loss: 0.209068
Train epoch: 467 [1145040/78836 (52%)]	Loss: 0.217011
Train epoch: 467 [1384900/78836 (65%)]	Loss: 0.260537
Train epoch: 467 [1654200/78836 (78%)]	Loss: 0.210812
Train epoch: 467 [1956780/78836 (91%)]	Loss: 0.278222
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 468 [0/78836 (0%)]	Loss: 0.267606
Train epoch: 468 [284820/78836 (13%)]	Loss: 0.205129
Train epoch: 468 [567200/78836 (26%)]	Loss: 0.180426
Train epoch: 468 [833760/78836 (39%)]	Loss: 0.224716
Train epoch: 468 [1154080/78836 (52%)]	Loss: 0.223656
Train epoch: 468 [1407800/78836 (65%)]	Loss: 0.222376
Train epoch: 468 [1667040/78836 (78%)]	Loss: 0.249237
Train epoch: 468 [1937040/78836 (91%)]	Loss: 0.224115
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 469 [0/78836 (0%)]	Loss: 0.220233
Train epoch: 469 [280740/78836 (13%)]	Loss: 0.241992
Train epoch: 469 [542560/78836 (26%)]	Loss: 0.230737
Train epoch: 469 [834660/78836 (39%)]	Loss: 0.205222
Train epoch: 469 [1108720/78836 (52%)]	Loss: 0.261368
Train epoch: 469 [1423200/78836 (65%)]	Loss: 0.219172
Train epoch: 469 [1673400/78836 (78%)]	Loss: 0.255565
Train epoch: 469 [1916740/78836 (91%)]	Loss: 0.219436
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 470 [0/78836 (0%)]	Loss: 0.221843
Train epoch: 470 [276020/78836 (13%)]	Loss: 0.202808
Train epoch: 470 [559480/78836 (26%)]	Loss: 0.204693
Train epoch: 470 [858960/78836 (39%)]	Loss: 0.213666
Train epoch: 470 [1110800/78836 (52%)]	Loss: 0.221950
Train epoch: 470 [1419500/78836 (65%)]	Loss: 0.241418
Train epoch: 470 [1670040/78836 (78%)]	Loss: 0.311568
Train epoch: 470 [1949220/78836 (91%)]	Loss: 0.229543
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 471 [0/78836 (0%)]	Loss: 0.183191
Train epoch: 471 [274700/78836 (13%)]	Loss: 0.223516
Train epoch: 471 [559360/78836 (26%)]	Loss: 0.193310
Train epoch: 471 [846480/78836 (39%)]	Loss: 0.257745
Train epoch: 471 [1110480/78836 (52%)]	Loss: 0.246982
Train epoch: 471 [1387100/78836 (65%)]	Loss: 0.219732
Train epoch: 471 [1679760/78836 (78%)]	Loss: 0.220581
Train epoch: 471 [1968400/78836 (91%)]	Loss: 0.222196
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 472 [0/78836 (0%)]	Loss: 0.215835
Train epoch: 472 [281240/78836 (13%)]	Loss: 0.214753
Train epoch: 472 [549360/78836 (26%)]	Loss: 0.199135
Train epoch: 472 [837900/78836 (39%)]	Loss: 0.248521
Train epoch: 472 [1134880/78836 (52%)]	Loss: 0.227579
Train epoch: 472 [1413100/78836 (65%)]	Loss: 0.224816
Train epoch: 472 [1661520/78836 (78%)]	Loss: 0.236177
Train epoch: 472 [1932280/78836 (91%)]	Loss: 0.219122
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 473 [0/78836 (0%)]	Loss: 0.259138
Train epoch: 473 [284460/78836 (13%)]	Loss: 0.242874
Train epoch: 473 [567320/78836 (26%)]	Loss: 0.229184
Train epoch: 473 [836280/78836 (39%)]	Loss: 0.229981
Train epoch: 473 [1112880/78836 (52%)]	Loss: 0.217894
Train epoch: 473 [1423100/78836 (65%)]	Loss: 0.204191
Train epoch: 473 [1688880/78836 (78%)]	Loss: 0.236456
Train epoch: 473 [1940680/78836 (91%)]	Loss: 0.260033
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 474 [0/78836 (0%)]	Loss: 0.194819
Train epoch: 474 [276520/78836 (13%)]	Loss: 0.244087
Train epoch: 474 [552560/78836 (26%)]	Loss: 0.211292
Train epoch: 474 [849060/78836 (39%)]	Loss: 0.257093
Train epoch: 474 [1132640/78836 (52%)]	Loss: 0.246302
Train epoch: 474 [1388300/78836 (65%)]	Loss: 0.219178
Train epoch: 474 [1714680/78836 (78%)]	Loss: 0.226198
Train epoch: 474 [1929620/78836 (91%)]	Loss: 0.234971
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 475 [0/78836 (0%)]	Loss: 0.236949
Train epoch: 475 [276900/78836 (13%)]	Loss: 0.221633
Train epoch: 475 [557200/78836 (26%)]	Loss: 0.260065
Train epoch: 475 [835560/78836 (39%)]	Loss: 0.264622
Train epoch: 475 [1121440/78836 (52%)]	Loss: 0.222342
Train epoch: 475 [1377600/78836 (65%)]	Loss: 0.207425
Train epoch: 475 [1705920/78836 (78%)]	Loss: 0.206552
Train epoch: 475 [1986180/78836 (91%)]	Loss: 0.227702
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 476 [0/78836 (0%)]	Loss: 0.188818
Train epoch: 476 [279300/78836 (13%)]	Loss: 0.209881
Train epoch: 476 [559280/78836 (26%)]	Loss: 0.234530
Train epoch: 476 [829140/78836 (39%)]	Loss: 0.246132
Train epoch: 476 [1138720/78836 (52%)]	Loss: 0.245381
Train epoch: 476 [1382500/78836 (65%)]	Loss: 0.210317
Train epoch: 476 [1679280/78836 (78%)]	Loss: 0.202950
Train epoch: 476 [1979880/78836 (91%)]	Loss: 0.214024
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 477 [0/78836 (0%)]	Loss: 0.197977
Train epoch: 477 [277680/78836 (13%)]	Loss: 0.245683
Train epoch: 477 [559440/78836 (26%)]	Loss: 0.232749
Train epoch: 477 [826140/78836 (39%)]	Loss: 0.238867
Train epoch: 477 [1150000/78836 (52%)]	Loss: 0.243514
Train epoch: 477 [1385500/78836 (65%)]	Loss: 0.226972
Train epoch: 477 [1664520/78836 (78%)]	Loss: 0.244680
Train epoch: 477 [1971900/78836 (91%)]	Loss: 0.219643
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 478 [0/78836 (0%)]	Loss: 0.216871
Train epoch: 478 [276840/78836 (13%)]	Loss: 0.191573
Train epoch: 478 [559000/78836 (26%)]	Loss: 0.242436
Train epoch: 478 [837600/78836 (39%)]	Loss: 0.246672
Train epoch: 478 [1128480/78836 (52%)]	Loss: 0.239090
Train epoch: 478 [1380300/78836 (65%)]	Loss: 0.222487
Train epoch: 478 [1666800/78836 (78%)]	Loss: 0.236406
Train epoch: 478 [1946140/78836 (91%)]	Loss: 0.295199
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 479 [0/78836 (0%)]	Loss: 0.196048
Train epoch: 479 [276780/78836 (13%)]	Loss: 0.204606
Train epoch: 479 [578520/78836 (26%)]	Loss: 0.251541
Train epoch: 479 [836820/78836 (39%)]	Loss: 0.217952
Train epoch: 479 [1126560/78836 (52%)]	Loss: 0.250134
Train epoch: 479 [1432000/78836 (65%)]	Loss: 0.222704
Train epoch: 479 [1680360/78836 (78%)]	Loss: 0.228328
Train epoch: 479 [1943760/78836 (91%)]	Loss: 0.231080
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 480 [0/78836 (0%)]	Loss: 0.253784
Train epoch: 480 [281660/78836 (13%)]	Loss: 0.196778
Train epoch: 480 [566760/78836 (26%)]	Loss: 0.199401
Train epoch: 480 [843240/78836 (39%)]	Loss: 0.269467
Train epoch: 480 [1103520/78836 (52%)]	Loss: 0.191249
Train epoch: 480 [1426700/78836 (65%)]	Loss: 0.278574
Train epoch: 480 [1689720/78836 (78%)]	Loss: 0.254966
Train epoch: 480 [1967700/78836 (91%)]	Loss: 0.201196
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 481 [0/78836 (0%)]	Loss: 0.171755
Train epoch: 481 [280520/78836 (13%)]	Loss: 0.212843
Train epoch: 481 [564160/78836 (26%)]	Loss: 0.212033
Train epoch: 481 [829800/78836 (39%)]	Loss: 0.234879
Train epoch: 481 [1150240/78836 (52%)]	Loss: 0.258990
Train epoch: 481 [1380600/78836 (65%)]	Loss: 0.213000
Train epoch: 481 [1692600/78836 (78%)]	Loss: 0.263862
Train epoch: 481 [2013340/78836 (91%)]	Loss: 0.216577
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 482 [0/78836 (0%)]	Loss: 0.226402
Train epoch: 482 [284560/78836 (13%)]	Loss: 0.277387
Train epoch: 482 [572400/78836 (26%)]	Loss: 0.197618
Train epoch: 482 [859740/78836 (39%)]	Loss: 0.207021
Train epoch: 482 [1102240/78836 (52%)]	Loss: 0.218114
Train epoch: 482 [1382200/78836 (65%)]	Loss: 0.226591
Train epoch: 482 [1679400/78836 (78%)]	Loss: 0.181262
Train epoch: 482 [1916040/78836 (91%)]	Loss: 0.234761
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 483 [0/78836 (0%)]	Loss: 0.223260
Train epoch: 483 [280660/78836 (13%)]	Loss: 0.271312
Train epoch: 483 [566200/78836 (26%)]	Loss: 0.253954
Train epoch: 483 [828300/78836 (39%)]	Loss: 0.236789
Train epoch: 483 [1102720/78836 (52%)]	Loss: 0.201859
Train epoch: 483 [1378400/78836 (65%)]	Loss: 0.225684
Train epoch: 483 [1672080/78836 (78%)]	Loss: 0.250322
Train epoch: 483 [1980440/78836 (91%)]	Loss: 0.189927
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 484 [0/78836 (0%)]	Loss: 0.222224
Train epoch: 484 [278360/78836 (13%)]	Loss: 0.262266
Train epoch: 484 [556640/78836 (26%)]	Loss: 0.241089
Train epoch: 484 [827760/78836 (39%)]	Loss: 0.230353
Train epoch: 484 [1108320/78836 (52%)]	Loss: 0.236722
Train epoch: 484 [1399900/78836 (65%)]	Loss: 0.229908
Train epoch: 484 [1671960/78836 (78%)]	Loss: 0.233764
Train epoch: 484 [1928080/78836 (91%)]	Loss: 0.215894
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 485 [0/78836 (0%)]	Loss: 0.211396
Train epoch: 485 [278420/78836 (13%)]	Loss: 0.182405
Train epoch: 485 [562520/78836 (26%)]	Loss: 0.213363
Train epoch: 485 [845880/78836 (39%)]	Loss: 0.211545
Train epoch: 485 [1101520/78836 (52%)]	Loss: 0.198838
Train epoch: 485 [1378500/78836 (65%)]	Loss: 0.277651
Train epoch: 485 [1704840/78836 (78%)]	Loss: 0.206406
Train epoch: 485 [1990800/78836 (91%)]	Loss: 0.251109
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 486 [0/78836 (0%)]	Loss: 0.226533
Train epoch: 486 [279280/78836 (13%)]	Loss: 0.251768
Train epoch: 486 [567800/78836 (26%)]	Loss: 0.232954
Train epoch: 486 [839280/78836 (39%)]	Loss: 0.274551
Train epoch: 486 [1119840/78836 (52%)]	Loss: 0.260768
Train epoch: 486 [1399300/78836 (65%)]	Loss: 0.219405
Train epoch: 486 [1683720/78836 (78%)]	Loss: 0.238199
Train epoch: 486 [1985480/78836 (91%)]	Loss: 0.223217
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 487 [0/78836 (0%)]	Loss: 0.230337
Train epoch: 487 [276280/78836 (13%)]	Loss: 0.226365
Train epoch: 487 [546640/78836 (26%)]	Loss: 0.256725
Train epoch: 487 [851760/78836 (39%)]	Loss: 0.218478
Train epoch: 487 [1119280/78836 (52%)]	Loss: 0.225513
Train epoch: 487 [1392500/78836 (65%)]	Loss: 0.220707
Train epoch: 487 [1682880/78836 (78%)]	Loss: 0.245364
Train epoch: 487 [2033360/78836 (91%)]	Loss: 0.240742
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 488 [0/78836 (0%)]	Loss: 0.188003
Train epoch: 488 [283560/78836 (13%)]	Loss: 0.186044
Train epoch: 488 [553760/78836 (26%)]	Loss: 0.210377
Train epoch: 488 [819420/78836 (39%)]	Loss: 0.234435
Train epoch: 488 [1117360/78836 (52%)]	Loss: 0.245199
Train epoch: 488 [1407400/78836 (65%)]	Loss: 0.215659
Train epoch: 488 [1666440/78836 (78%)]	Loss: 0.215758
Train epoch: 488 [1960420/78836 (91%)]	Loss: 0.206263
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 489 [0/78836 (0%)]	Loss: 0.217233
Train epoch: 489 [279380/78836 (13%)]	Loss: 0.197548
Train epoch: 489 [559960/78836 (26%)]	Loss: 0.240751
Train epoch: 489 [846120/78836 (39%)]	Loss: 0.225343
Train epoch: 489 [1109680/78836 (52%)]	Loss: 0.230495
Train epoch: 489 [1402100/78836 (65%)]	Loss: 0.234247
Train epoch: 489 [1697880/78836 (78%)]	Loss: 0.209771
Train epoch: 489 [1976380/78836 (91%)]	Loss: 0.223080
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 490 [0/78836 (0%)]	Loss: 0.233792
Train epoch: 490 [278000/78836 (13%)]	Loss: 0.258324
Train epoch: 490 [560240/78836 (26%)]	Loss: 0.188373
Train epoch: 490 [829500/78836 (39%)]	Loss: 0.203432
Train epoch: 490 [1107600/78836 (52%)]	Loss: 0.272437
Train epoch: 490 [1409200/78836 (65%)]	Loss: 0.225536
Train epoch: 490 [1705680/78836 (78%)]	Loss: 0.216402
Train epoch: 490 [1950760/78836 (91%)]	Loss: 0.196003
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 491 [0/78836 (0%)]	Loss: 0.332342
Train epoch: 491 [274940/78836 (13%)]	Loss: 0.238241
Train epoch: 491 [566240/78836 (26%)]	Loss: 0.243491
Train epoch: 491 [821580/78836 (39%)]	Loss: 0.220149
Train epoch: 491 [1124080/78836 (52%)]	Loss: 0.226752
Train epoch: 491 [1419000/78836 (65%)]	Loss: 0.210829
Train epoch: 491 [1674480/78836 (78%)]	Loss: 0.217334
Train epoch: 491 [1985340/78836 (91%)]	Loss: 0.206353
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 492 [0/78836 (0%)]	Loss: 0.201929
Train epoch: 492 [280400/78836 (13%)]	Loss: 0.210511
Train epoch: 492 [565240/78836 (26%)]	Loss: 0.253641
Train epoch: 492 [848580/78836 (39%)]	Loss: 0.289204
Train epoch: 492 [1105840/78836 (52%)]	Loss: 0.193586
Train epoch: 492 [1402900/78836 (65%)]	Loss: 0.221669
Train epoch: 492 [1702800/78836 (78%)]	Loss: 0.182146
Train epoch: 492 [1939000/78836 (91%)]	Loss: 0.287466
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 493 [0/78836 (0%)]	Loss: 0.205376
Train epoch: 493 [280140/78836 (13%)]	Loss: 0.233936
Train epoch: 493 [558400/78836 (26%)]	Loss: 0.188188
Train epoch: 493 [829560/78836 (39%)]	Loss: 0.249076
Train epoch: 493 [1096800/78836 (52%)]	Loss: 0.192526
Train epoch: 493 [1391900/78836 (65%)]	Loss: 0.226262
Train epoch: 493 [1676400/78836 (78%)]	Loss: 0.311840
Train epoch: 493 [1968820/78836 (91%)]	Loss: 0.250752
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 494 [0/78836 (0%)]	Loss: 0.220170
Train epoch: 494 [277720/78836 (13%)]	Loss: 0.180927
Train epoch: 494 [546320/78836 (26%)]	Loss: 0.201150
Train epoch: 494 [848760/78836 (39%)]	Loss: 0.247519
Train epoch: 494 [1088720/78836 (52%)]	Loss: 0.186544
Train epoch: 494 [1402600/78836 (65%)]	Loss: 0.218601
Train epoch: 494 [1690920/78836 (78%)]	Loss: 0.205663
Train epoch: 494 [1994580/78836 (91%)]	Loss: 0.205881
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 495 [0/78836 (0%)]	Loss: 0.183361
Train epoch: 495 [277480/78836 (13%)]	Loss: 0.200037
Train epoch: 495 [562320/78836 (26%)]	Loss: 0.246694
Train epoch: 495 [826440/78836 (39%)]	Loss: 0.244866
Train epoch: 495 [1121600/78836 (52%)]	Loss: 0.207027
Train epoch: 495 [1372300/78836 (65%)]	Loss: 0.230339
Train epoch: 495 [1722480/78836 (78%)]	Loss: 0.232014
Train epoch: 495 [1925000/78836 (91%)]	Loss: 0.213175
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 496 [0/78836 (0%)]	Loss: 0.215907
Train epoch: 496 [279140/78836 (13%)]	Loss: 0.218352
Train epoch: 496 [548960/78836 (26%)]	Loss: 0.214463
Train epoch: 496 [835920/78836 (39%)]	Loss: 0.209863
Train epoch: 496 [1115120/78836 (52%)]	Loss: 0.246555
Train epoch: 496 [1369200/78836 (65%)]	Loss: 0.279514
Train epoch: 496 [1675440/78836 (78%)]	Loss: 0.234392
Train epoch: 496 [1919540/78836 (91%)]	Loss: 0.193718
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 497 [0/78836 (0%)]	Loss: 0.192581
Train epoch: 497 [275240/78836 (13%)]	Loss: 0.231651
Train epoch: 497 [558080/78836 (26%)]	Loss: 0.244121
Train epoch: 497 [827040/78836 (39%)]	Loss: 0.214798
Train epoch: 497 [1141760/78836 (52%)]	Loss: 0.251065
Train epoch: 497 [1390900/78836 (65%)]	Loss: 0.211677
Train epoch: 497 [1670760/78836 (78%)]	Loss: 0.264060
Train epoch: 497 [1954820/78836 (91%)]	Loss: 0.170152
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 498 [0/78836 (0%)]	Loss: 0.199625
Train epoch: 498 [280360/78836 (13%)]	Loss: 0.207459
Train epoch: 498 [538520/78836 (26%)]	Loss: 0.233869
Train epoch: 498 [850080/78836 (39%)]	Loss: 0.221770
Train epoch: 498 [1114960/78836 (52%)]	Loss: 0.235402
Train epoch: 498 [1375500/78836 (65%)]	Loss: 0.214891
Train epoch: 498 [1694040/78836 (78%)]	Loss: 0.240552
Train epoch: 498 [1909880/78836 (91%)]	Loss: 0.218806
predicting for valid data
Make prediction for 19709 samples...
0.18668221 No improvement since epoch  444 ; best_test_mse,best_test_ci: 0.18668221 0.8482196462118032 GINConvNet kiba
Training on 78836 samples...
Train epoch: 499 [0/78836 (0%)]	Loss: 0.256721
Train epoch: 499 [272820/78836 (13%)]	Loss: 0.245723
Train epoch: 499 [554080/78836 (26%)]	Loss: 0.235147
Train epoch: 499 [835620/78836 (39%)]	Loss: 0.260993
Train epoch: 499 [1118560/78836 (52%)]	Loss: 0.207577
Train epoch: 499 [1417400/78836 (65%)]	Loss: 0.192875
Train epoch: 499 [1694160/78836 (78%)]	Loss: 0.242684
Train epoch: 499 [1960000/78836 (91%)]	Loss: 0.244831
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 500 [0/78836 (0%)]	Loss: 0.197250
Train epoch: 500 [275060/78836 (13%)]	Loss: 0.186624
Train epoch: 500 [563360/78836 (26%)]	Loss: 0.185572
Train epoch: 500 [837660/78836 (39%)]	Loss: 0.224301
Train epoch: 500 [1134880/78836 (52%)]	Loss: 0.188169
Train epoch: 500 [1396500/78836 (65%)]	Loss: 0.199217
Train epoch: 500 [1705560/78836 (78%)]	Loss: 0.212914
Train epoch: 500 [1952720/78836 (91%)]	Loss: 0.250088
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 501 [0/78836 (0%)]	Loss: 0.185805
Train epoch: 501 [275100/78836 (13%)]	Loss: 0.221574
Train epoch: 501 [562480/78836 (26%)]	Loss: 0.203189
Train epoch: 501 [817620/78836 (39%)]	Loss: 0.176601
Train epoch: 501 [1135200/78836 (52%)]	Loss: 0.211111
Train epoch: 501 [1392400/78836 (65%)]	Loss: 0.200044
Train epoch: 501 [1690440/78836 (78%)]	Loss: 0.268680
Train epoch: 501 [1957760/78836 (91%)]	Loss: 0.202679
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 502 [0/78836 (0%)]	Loss: 0.168198
Train epoch: 502 [278180/78836 (13%)]	Loss: 0.193034
Train epoch: 502 [565000/78836 (26%)]	Loss: 0.180085
Train epoch: 502 [846660/78836 (39%)]	Loss: 0.195855
Train epoch: 502 [1119600/78836 (52%)]	Loss: 0.248227
Train epoch: 502 [1396100/78836 (65%)]	Loss: 0.218982
Train epoch: 502 [1690560/78836 (78%)]	Loss: 0.220376
Train epoch: 502 [1980860/78836 (91%)]	Loss: 0.239318
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 503 [0/78836 (0%)]	Loss: 0.198225
Train epoch: 503 [279860/78836 (13%)]	Loss: 0.187363
Train epoch: 503 [556680/78836 (26%)]	Loss: 0.191204
Train epoch: 503 [847080/78836 (39%)]	Loss: 0.180625
Train epoch: 503 [1141520/78836 (52%)]	Loss: 0.260832
Train epoch: 503 [1388200/78836 (65%)]	Loss: 0.215045
Train epoch: 503 [1714200/78836 (78%)]	Loss: 0.234653
Train epoch: 503 [1980440/78836 (91%)]	Loss: 0.261322
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 504 [0/78836 (0%)]	Loss: 0.213313
Train epoch: 504 [282160/78836 (13%)]	Loss: 0.183661
Train epoch: 504 [558400/78836 (26%)]	Loss: 0.187388
Train epoch: 504 [840840/78836 (39%)]	Loss: 0.224453
Train epoch: 504 [1125120/78836 (52%)]	Loss: 0.202021
Train epoch: 504 [1381500/78836 (65%)]	Loss: 0.260794
Train epoch: 504 [1683000/78836 (78%)]	Loss: 0.263815
Train epoch: 504 [1986460/78836 (91%)]	Loss: 0.235624
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 505 [0/78836 (0%)]	Loss: 0.189136
Train epoch: 505 [275100/78836 (13%)]	Loss: 0.210285
Train epoch: 505 [556520/78836 (26%)]	Loss: 0.185892
Train epoch: 505 [844980/78836 (39%)]	Loss: 0.203323
Train epoch: 505 [1125280/78836 (52%)]	Loss: 0.229145
Train epoch: 505 [1402000/78836 (65%)]	Loss: 0.224084
Train epoch: 505 [1674360/78836 (78%)]	Loss: 0.186166
Train epoch: 505 [1966160/78836 (91%)]	Loss: 0.201450
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 506 [0/78836 (0%)]	Loss: 0.223723
Train epoch: 506 [282240/78836 (13%)]	Loss: 0.193068
Train epoch: 506 [554520/78836 (26%)]	Loss: 0.203683
Train epoch: 506 [848040/78836 (39%)]	Loss: 0.240938
Train epoch: 506 [1110480/78836 (52%)]	Loss: 0.192274
Train epoch: 506 [1372300/78836 (65%)]	Loss: 0.207563
Train epoch: 506 [1670400/78836 (78%)]	Loss: 0.223962
Train epoch: 506 [1940400/78836 (91%)]	Loss: 0.192104
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 507 [0/78836 (0%)]	Loss: 0.250345
Train epoch: 507 [281060/78836 (13%)]	Loss: 0.203913
Train epoch: 507 [563000/78836 (26%)]	Loss: 0.202821
Train epoch: 507 [837840/78836 (39%)]	Loss: 0.256978
Train epoch: 507 [1117520/78836 (52%)]	Loss: 0.221896
Train epoch: 507 [1420100/78836 (65%)]	Loss: 0.203508
Train epoch: 507 [1665000/78836 (78%)]	Loss: 0.222870
Train epoch: 507 [1981140/78836 (91%)]	Loss: 0.208292
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 508 [0/78836 (0%)]	Loss: 0.263732
Train epoch: 508 [279140/78836 (13%)]	Loss: 0.211245
Train epoch: 508 [560640/78836 (26%)]	Loss: 0.223286
Train epoch: 508 [835620/78836 (39%)]	Loss: 0.235691
Train epoch: 508 [1112400/78836 (52%)]	Loss: 0.202060
Train epoch: 508 [1410300/78836 (65%)]	Loss: 0.192426
Train epoch: 508 [1654680/78836 (78%)]	Loss: 0.204771
Train epoch: 508 [1978620/78836 (91%)]	Loss: 0.220263
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 509 [0/78836 (0%)]	Loss: 0.207058
Train epoch: 509 [276420/78836 (13%)]	Loss: 0.200583
Train epoch: 509 [569200/78836 (26%)]	Loss: 0.184081
Train epoch: 509 [829020/78836 (39%)]	Loss: 0.215145
Train epoch: 509 [1132880/78836 (52%)]	Loss: 0.205563
Train epoch: 509 [1378500/78836 (65%)]	Loss: 0.262519
Train epoch: 509 [1694040/78836 (78%)]	Loss: 0.240343
Train epoch: 509 [1958320/78836 (91%)]	Loss: 0.232653
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 510 [0/78836 (0%)]	Loss: 0.212175
Train epoch: 510 [271240/78836 (13%)]	Loss: 0.225371
Train epoch: 510 [561080/78836 (26%)]	Loss: 0.208864
Train epoch: 510 [842040/78836 (39%)]	Loss: 0.192082
Train epoch: 510 [1146880/78836 (52%)]	Loss: 0.219723
Train epoch: 510 [1412700/78836 (65%)]	Loss: 0.189323
Train epoch: 510 [1671720/78836 (78%)]	Loss: 0.222966
Train epoch: 510 [1942780/78836 (91%)]	Loss: 0.252824
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 511 [0/78836 (0%)]	Loss: 0.202457
Train epoch: 511 [281040/78836 (13%)]	Loss: 0.212695
Train epoch: 511 [551640/78836 (26%)]	Loss: 0.207396
Train epoch: 511 [819840/78836 (39%)]	Loss: 0.216843
Train epoch: 511 [1095600/78836 (52%)]	Loss: 0.190212
Train epoch: 511 [1381200/78836 (65%)]	Loss: 0.249451
Train epoch: 511 [1667880/78836 (78%)]	Loss: 0.207638
Train epoch: 511 [1944460/78836 (91%)]	Loss: 0.209145
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 512 [0/78836 (0%)]	Loss: 0.193192
Train epoch: 512 [279460/78836 (13%)]	Loss: 0.198207
Train epoch: 512 [560600/78836 (26%)]	Loss: 0.202111
Train epoch: 512 [840120/78836 (39%)]	Loss: 0.198769
Train epoch: 512 [1119200/78836 (52%)]	Loss: 0.211183
Train epoch: 512 [1380500/78836 (65%)]	Loss: 0.237779
Train epoch: 512 [1662600/78836 (78%)]	Loss: 0.181520
Train epoch: 512 [1934520/78836 (91%)]	Loss: 0.234497
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 513 [0/78836 (0%)]	Loss: 0.219116
Train epoch: 513 [279880/78836 (13%)]	Loss: 0.200454
Train epoch: 513 [555280/78836 (26%)]	Loss: 0.193250
Train epoch: 513 [829260/78836 (39%)]	Loss: 0.250766
Train epoch: 513 [1105440/78836 (52%)]	Loss: 0.235179
Train epoch: 513 [1386700/78836 (65%)]	Loss: 0.252197
Train epoch: 513 [1695840/78836 (78%)]	Loss: 0.212058
Train epoch: 513 [1934800/78836 (91%)]	Loss: 0.235958
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 514 [0/78836 (0%)]	Loss: 0.198005
Train epoch: 514 [280560/78836 (13%)]	Loss: 0.220752
Train epoch: 514 [547200/78836 (26%)]	Loss: 0.216298
Train epoch: 514 [844020/78836 (39%)]	Loss: 0.194228
Train epoch: 514 [1099840/78836 (52%)]	Loss: 0.195223
Train epoch: 514 [1398800/78836 (65%)]	Loss: 0.214487
Train epoch: 514 [1663800/78836 (78%)]	Loss: 0.238504
Train epoch: 514 [1990940/78836 (91%)]	Loss: 0.245569
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 515 [0/78836 (0%)]	Loss: 0.185003
Train epoch: 515 [277960/78836 (13%)]	Loss: 0.203239
Train epoch: 515 [558120/78836 (26%)]	Loss: 0.250451
Train epoch: 515 [847620/78836 (39%)]	Loss: 0.195491
Train epoch: 515 [1131120/78836 (52%)]	Loss: 0.213639
Train epoch: 515 [1401800/78836 (65%)]	Loss: 0.204604
Train epoch: 515 [1681440/78836 (78%)]	Loss: 0.253522
Train epoch: 515 [1956220/78836 (91%)]	Loss: 0.207605
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 516 [0/78836 (0%)]	Loss: 0.213394
Train epoch: 516 [282160/78836 (13%)]	Loss: 0.217341
Train epoch: 516 [557840/78836 (26%)]	Loss: 0.190295
Train epoch: 516 [851520/78836 (39%)]	Loss: 0.209828
Train epoch: 516 [1118640/78836 (52%)]	Loss: 0.237625
Train epoch: 516 [1387600/78836 (65%)]	Loss: 0.203210
Train epoch: 516 [1665120/78836 (78%)]	Loss: 0.183113
Train epoch: 516 [1916460/78836 (91%)]	Loss: 0.248112
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 517 [0/78836 (0%)]	Loss: 0.227620
Train epoch: 517 [281720/78836 (13%)]	Loss: 0.223868
Train epoch: 517 [561400/78836 (26%)]	Loss: 0.217735
Train epoch: 517 [844680/78836 (39%)]	Loss: 0.199776
Train epoch: 517 [1126560/78836 (52%)]	Loss: 0.197313
Train epoch: 517 [1435800/78836 (65%)]	Loss: 0.229586
Train epoch: 517 [1654800/78836 (78%)]	Loss: 0.176475
Train epoch: 517 [1965460/78836 (91%)]	Loss: 0.190332
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 518 [0/78836 (0%)]	Loss: 0.201941
Train epoch: 518 [274940/78836 (13%)]	Loss: 0.243922
Train epoch: 518 [561160/78836 (26%)]	Loss: 0.207813
Train epoch: 518 [844440/78836 (39%)]	Loss: 0.203024
Train epoch: 518 [1131360/78836 (52%)]	Loss: 0.195749
Train epoch: 518 [1397600/78836 (65%)]	Loss: 0.179788
Train epoch: 518 [1661040/78836 (78%)]	Loss: 0.223202
Train epoch: 518 [1994020/78836 (91%)]	Loss: 0.233983
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 519 [0/78836 (0%)]	Loss: 0.200127
Train epoch: 519 [285440/78836 (13%)]	Loss: 0.216781
Train epoch: 519 [565560/78836 (26%)]	Loss: 0.218828
Train epoch: 519 [844560/78836 (39%)]	Loss: 0.241269
Train epoch: 519 [1110560/78836 (52%)]	Loss: 0.205477
Train epoch: 519 [1419500/78836 (65%)]	Loss: 0.181270
Train epoch: 519 [1702920/78836 (78%)]	Loss: 0.226107
Train epoch: 519 [1940680/78836 (91%)]	Loss: 0.268752
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 520 [0/78836 (0%)]	Loss: 0.229733
Train epoch: 520 [275320/78836 (13%)]	Loss: 0.240239
Train epoch: 520 [574880/78836 (26%)]	Loss: 0.241000
Train epoch: 520 [828360/78836 (39%)]	Loss: 0.220359
Train epoch: 520 [1119600/78836 (52%)]	Loss: 0.195908
Train epoch: 520 [1415500/78836 (65%)]	Loss: 0.215603
Train epoch: 520 [1651080/78836 (78%)]	Loss: 0.240476
Train epoch: 520 [1961540/78836 (91%)]	Loss: 0.245555
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 521 [0/78836 (0%)]	Loss: 0.185805
Train epoch: 521 [276380/78836 (13%)]	Loss: 0.192970
Train epoch: 521 [557120/78836 (26%)]	Loss: 0.196738
Train epoch: 521 [854460/78836 (39%)]	Loss: 0.206798
Train epoch: 521 [1110720/78836 (52%)]	Loss: 0.202219
Train epoch: 521 [1403400/78836 (65%)]	Loss: 0.246033
Train epoch: 521 [1659360/78836 (78%)]	Loss: 0.200176
Train epoch: 521 [1946840/78836 (91%)]	Loss: 0.205228
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 522 [0/78836 (0%)]	Loss: 0.236235
Train epoch: 522 [277380/78836 (13%)]	Loss: 0.218003
Train epoch: 522 [565880/78836 (26%)]	Loss: 0.250288
Train epoch: 522 [822060/78836 (39%)]	Loss: 0.224343
Train epoch: 522 [1110880/78836 (52%)]	Loss: 0.203972
Train epoch: 522 [1387100/78836 (65%)]	Loss: 0.218195
Train epoch: 522 [1680000/78836 (78%)]	Loss: 0.208553
Train epoch: 522 [1957620/78836 (91%)]	Loss: 0.192585
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 523 [0/78836 (0%)]	Loss: 0.178117
Train epoch: 523 [283960/78836 (13%)]	Loss: 0.190372
Train epoch: 523 [565480/78836 (26%)]	Loss: 0.231207
Train epoch: 523 [842640/78836 (39%)]	Loss: 0.212781
Train epoch: 523 [1107840/78836 (52%)]	Loss: 0.197151
Train epoch: 523 [1392500/78836 (65%)]	Loss: 0.201092
Train epoch: 523 [1672200/78836 (78%)]	Loss: 0.212509
Train epoch: 523 [1935220/78836 (91%)]	Loss: 0.205688
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 524 [0/78836 (0%)]	Loss: 0.182362
Train epoch: 524 [284860/78836 (13%)]	Loss: 0.199334
Train epoch: 524 [559520/78836 (26%)]	Loss: 0.190349
Train epoch: 524 [830160/78836 (39%)]	Loss: 0.176305
Train epoch: 524 [1104400/78836 (52%)]	Loss: 0.189706
Train epoch: 524 [1383400/78836 (65%)]	Loss: 0.244589
Train epoch: 524 [1711320/78836 (78%)]	Loss: 0.254122
Train epoch: 524 [1959580/78836 (91%)]	Loss: 0.196672
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 525 [0/78836 (0%)]	Loss: 0.200716
Train epoch: 525 [276460/78836 (13%)]	Loss: 0.184539
Train epoch: 525 [553440/78836 (26%)]	Loss: 0.219258
Train epoch: 525 [836880/78836 (39%)]	Loss: 0.215246
Train epoch: 525 [1127920/78836 (52%)]	Loss: 0.192591
Train epoch: 525 [1401200/78836 (65%)]	Loss: 0.194614
Train epoch: 525 [1658760/78836 (78%)]	Loss: 0.211150
Train epoch: 525 [1943200/78836 (91%)]	Loss: 0.179092
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 526 [0/78836 (0%)]	Loss: 0.213420
Train epoch: 526 [278840/78836 (13%)]	Loss: 0.206514
Train epoch: 526 [564240/78836 (26%)]	Loss: 0.201831
Train epoch: 526 [841680/78836 (39%)]	Loss: 0.210631
Train epoch: 526 [1129680/78836 (52%)]	Loss: 0.206858
Train epoch: 526 [1425400/78836 (65%)]	Loss: 0.215051
Train epoch: 526 [1676040/78836 (78%)]	Loss: 0.235494
Train epoch: 526 [1953280/78836 (91%)]	Loss: 0.198828
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 527 [0/78836 (0%)]	Loss: 0.240550
Train epoch: 527 [274360/78836 (13%)]	Loss: 0.213986
Train epoch: 527 [563960/78836 (26%)]	Loss: 0.194699
Train epoch: 527 [835260/78836 (39%)]	Loss: 0.190239
Train epoch: 527 [1141200/78836 (52%)]	Loss: 0.238922
Train epoch: 527 [1386200/78836 (65%)]	Loss: 0.212690
Train epoch: 527 [1651800/78836 (78%)]	Loss: 0.217510
Train epoch: 527 [1955380/78836 (91%)]	Loss: 0.168148
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 528 [0/78836 (0%)]	Loss: 0.198859
Train epoch: 528 [276880/78836 (13%)]	Loss: 0.172551
Train epoch: 528 [558360/78836 (26%)]	Loss: 0.200136
Train epoch: 528 [826620/78836 (39%)]	Loss: 0.246148
Train epoch: 528 [1113840/78836 (52%)]	Loss: 0.185240
Train epoch: 528 [1378700/78836 (65%)]	Loss: 0.202120
Train epoch: 528 [1689840/78836 (78%)]	Loss: 0.258087
Train epoch: 528 [1965880/78836 (91%)]	Loss: 0.217366
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 529 [0/78836 (0%)]	Loss: 0.166600
Train epoch: 529 [278580/78836 (13%)]	Loss: 0.189599
Train epoch: 529 [560120/78836 (26%)]	Loss: 0.221284
Train epoch: 529 [837540/78836 (39%)]	Loss: 0.259525
Train epoch: 529 [1129280/78836 (52%)]	Loss: 0.202664
Train epoch: 529 [1410900/78836 (65%)]	Loss: 0.189207
Train epoch: 529 [1685760/78836 (78%)]	Loss: 0.198913
Train epoch: 529 [1960560/78836 (91%)]	Loss: 0.201866
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 530 [0/78836 (0%)]	Loss: 0.217469
Train epoch: 530 [286040/78836 (13%)]	Loss: 0.186558
Train epoch: 530 [551600/78836 (26%)]	Loss: 0.223397
Train epoch: 530 [829800/78836 (39%)]	Loss: 0.217008
Train epoch: 530 [1103920/78836 (52%)]	Loss: 0.231047
Train epoch: 530 [1391700/78836 (65%)]	Loss: 0.190252
Train epoch: 530 [1698120/78836 (78%)]	Loss: 0.203426
Train epoch: 530 [1967280/78836 (91%)]	Loss: 0.259478
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 531 [0/78836 (0%)]	Loss: 0.191874
Train epoch: 531 [276500/78836 (13%)]	Loss: 0.199308
Train epoch: 531 [557640/78836 (26%)]	Loss: 0.208545
Train epoch: 531 [825960/78836 (39%)]	Loss: 0.153019
Train epoch: 531 [1114320/78836 (52%)]	Loss: 0.171778
Train epoch: 531 [1441700/78836 (65%)]	Loss: 0.220483
Train epoch: 531 [1665240/78836 (78%)]	Loss: 0.235110
Train epoch: 531 [1947680/78836 (91%)]	Loss: 0.207343
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 532 [0/78836 (0%)]	Loss: 0.191349
Train epoch: 532 [282620/78836 (13%)]	Loss: 0.169212
Train epoch: 532 [539640/78836 (26%)]	Loss: 0.196137
Train epoch: 532 [839760/78836 (39%)]	Loss: 0.201191
Train epoch: 532 [1115680/78836 (52%)]	Loss: 0.211699
Train epoch: 532 [1382000/78836 (65%)]	Loss: 0.208952
Train epoch: 532 [1708080/78836 (78%)]	Loss: 0.265102
Train epoch: 532 [1988980/78836 (91%)]	Loss: 0.199971
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 533 [0/78836 (0%)]	Loss: 0.274291
Train epoch: 533 [284380/78836 (13%)]	Loss: 0.205593
Train epoch: 533 [575040/78836 (26%)]	Loss: 0.258570
Train epoch: 533 [847320/78836 (39%)]	Loss: 0.168523
Train epoch: 533 [1117600/78836 (52%)]	Loss: 0.175837
Train epoch: 533 [1381600/78836 (65%)]	Loss: 0.185431
Train epoch: 533 [1706040/78836 (78%)]	Loss: 0.218734
Train epoch: 533 [1964620/78836 (91%)]	Loss: 0.197573
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 534 [0/78836 (0%)]	Loss: 0.165715
Train epoch: 534 [280840/78836 (13%)]	Loss: 0.178344
Train epoch: 534 [557480/78836 (26%)]	Loss: 0.226311
Train epoch: 534 [815520/78836 (39%)]	Loss: 0.271762
Train epoch: 534 [1104080/78836 (52%)]	Loss: 0.245529
Train epoch: 534 [1366900/78836 (65%)]	Loss: 0.194175
Train epoch: 534 [1683120/78836 (78%)]	Loss: 0.202881
Train epoch: 534 [1952720/78836 (91%)]	Loss: 0.228043
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 535 [0/78836 (0%)]	Loss: 0.183670
Train epoch: 535 [279240/78836 (13%)]	Loss: 0.201872
Train epoch: 535 [565640/78836 (26%)]	Loss: 0.200852
Train epoch: 535 [817200/78836 (39%)]	Loss: 0.171601
Train epoch: 535 [1140960/78836 (52%)]	Loss: 0.190172
Train epoch: 535 [1418900/78836 (65%)]	Loss: 0.190833
Train epoch: 535 [1681320/78836 (78%)]	Loss: 0.228264
Train epoch: 535 [1943760/78836 (91%)]	Loss: 0.215365
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 536 [0/78836 (0%)]	Loss: 0.185796
Train epoch: 536 [282340/78836 (13%)]	Loss: 0.202354
Train epoch: 536 [573840/78836 (26%)]	Loss: 0.214063
Train epoch: 536 [837180/78836 (39%)]	Loss: 0.233987
Train epoch: 536 [1129920/78836 (52%)]	Loss: 0.189724
Train epoch: 536 [1416300/78836 (65%)]	Loss: 0.227186
Train epoch: 536 [1669320/78836 (78%)]	Loss: 0.232744
Train epoch: 536 [1946980/78836 (91%)]	Loss: 0.207408
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 537 [0/78836 (0%)]	Loss: 0.230626
Train epoch: 537 [283940/78836 (13%)]	Loss: 0.215823
Train epoch: 537 [556480/78836 (26%)]	Loss: 0.203922
Train epoch: 537 [853380/78836 (39%)]	Loss: 0.176672
Train epoch: 537 [1126480/78836 (52%)]	Loss: 0.206518
Train epoch: 537 [1390600/78836 (65%)]	Loss: 0.209554
Train epoch: 537 [1668720/78836 (78%)]	Loss: 0.224178
Train epoch: 537 [2008860/78836 (91%)]	Loss: 0.188500
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 538 [0/78836 (0%)]	Loss: 0.229873
Train epoch: 538 [278540/78836 (13%)]	Loss: 0.198816
Train epoch: 538 [554760/78836 (26%)]	Loss: 0.232509
Train epoch: 538 [844380/78836 (39%)]	Loss: 0.198961
Train epoch: 538 [1112960/78836 (52%)]	Loss: 0.220107
Train epoch: 538 [1415500/78836 (65%)]	Loss: 0.217877
Train epoch: 538 [1653840/78836 (78%)]	Loss: 0.183288
Train epoch: 538 [1950200/78836 (91%)]	Loss: 0.195584
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 539 [0/78836 (0%)]	Loss: 0.219417
Train epoch: 539 [281860/78836 (13%)]	Loss: 0.203281
Train epoch: 539 [562160/78836 (26%)]	Loss: 0.211460
Train epoch: 539 [848880/78836 (39%)]	Loss: 0.237844
Train epoch: 539 [1127040/78836 (52%)]	Loss: 0.200073
Train epoch: 539 [1364500/78836 (65%)]	Loss: 0.192435
Train epoch: 539 [1674600/78836 (78%)]	Loss: 0.188403
Train epoch: 539 [1949780/78836 (91%)]	Loss: 0.157569
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 540 [0/78836 (0%)]	Loss: 0.217065
Train epoch: 540 [278340/78836 (13%)]	Loss: 0.206254
Train epoch: 540 [563840/78836 (26%)]	Loss: 0.217298
Train epoch: 540 [833580/78836 (39%)]	Loss: 0.185794
Train epoch: 540 [1144720/78836 (52%)]	Loss: 0.191128
Train epoch: 540 [1389800/78836 (65%)]	Loss: 0.185925
Train epoch: 540 [1677360/78836 (78%)]	Loss: 0.201394
Train epoch: 540 [1953980/78836 (91%)]	Loss: 0.250311
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 541 [0/78836 (0%)]	Loss: 0.225349
Train epoch: 541 [286240/78836 (13%)]	Loss: 0.192248
Train epoch: 541 [555400/78836 (26%)]	Loss: 0.182910
Train epoch: 541 [858480/78836 (39%)]	Loss: 0.173462
Train epoch: 541 [1112960/78836 (52%)]	Loss: 0.233518
Train epoch: 541 [1372600/78836 (65%)]	Loss: 0.205180
Train epoch: 541 [1670280/78836 (78%)]	Loss: 0.202601
Train epoch: 541 [1938720/78836 (91%)]	Loss: 0.194098
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 542 [0/78836 (0%)]	Loss: 0.202484
Train epoch: 542 [288700/78836 (13%)]	Loss: 0.189134
Train epoch: 542 [578840/78836 (26%)]	Loss: 0.180505
Train epoch: 542 [843300/78836 (39%)]	Loss: 0.173134
Train epoch: 542 [1118800/78836 (52%)]	Loss: 0.199491
Train epoch: 542 [1435700/78836 (65%)]	Loss: 0.218813
Train epoch: 542 [1649040/78836 (78%)]	Loss: 0.194978
Train epoch: 542 [2015440/78836 (91%)]	Loss: 0.242432
predicting for valid data
Make prediction for 19709 samples...
0.18814446 No improvement since epoch  499 ; best_test_mse,best_test_ci: 0.18814446 0.8486107189646365 GINConvNet kiba
Training on 78836 samples...
Train epoch: 543 [0/78836 (0%)]	Loss: 0.191040
Train epoch: 543 [272840/78836 (13%)]	Loss: 0.193613
Train epoch: 543 [562360/78836 (26%)]	Loss: 0.212506
Train epoch: 543 [831240/78836 (39%)]	Loss: 0.183149
Train epoch: 543 [1125920/78836 (52%)]	Loss: 0.178805
Train epoch: 543 [1371600/78836 (65%)]	Loss: 0.218086
Train epoch: 543 [1685640/78836 (78%)]	Loss: 0.194353
Train epoch: 543 [1903580/78836 (91%)]	Loss: 0.219050
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  543 ; best_test_mse,best_test_ci: 0.18481633 0.8500820482921538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 544 [0/78836 (0%)]	Loss: 0.178240
Train epoch: 544 [279720/78836 (13%)]	Loss: 0.212841
Train epoch: 544 [559480/78836 (26%)]	Loss: 0.193057
Train epoch: 544 [849660/78836 (39%)]	Loss: 0.199742
Train epoch: 544 [1143120/78836 (52%)]	Loss: 0.253143
Train epoch: 544 [1388700/78836 (65%)]	Loss: 0.200619
Train epoch: 544 [1705680/78836 (78%)]	Loss: 0.223985
Train epoch: 544 [1928220/78836 (91%)]	Loss: 0.182530
predicting for valid data
Make prediction for 19709 samples...
0.18481633 No improvement since epoch  543 ; best_test_mse,best_test_ci: 0.18481633 0.8500820482921538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 545 [0/78836 (0%)]	Loss: 0.173329
Train epoch: 545 [273120/78836 (13%)]	Loss: 0.196199
Train epoch: 545 [570880/78836 (26%)]	Loss: 0.196072
Train epoch: 545 [832320/78836 (39%)]	Loss: 0.165134
Train epoch: 545 [1136480/78836 (52%)]	Loss: 0.226983
Train epoch: 545 [1393000/78836 (65%)]	Loss: 0.191218
Train epoch: 545 [1681440/78836 (78%)]	Loss: 0.204964
Train epoch: 545 [1979740/78836 (91%)]	Loss: 0.141713
predicting for valid data
Make prediction for 19709 samples...
0.18481633 No improvement since epoch  543 ; best_test_mse,best_test_ci: 0.18481633 0.8500820482921538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 546 [0/78836 (0%)]	Loss: 0.197148
Train epoch: 546 [273680/78836 (13%)]	Loss: 0.216460
Train epoch: 546 [559320/78836 (26%)]	Loss: 0.197439
Train epoch: 546 [849000/78836 (39%)]	Loss: 0.208590
Train epoch: 546 [1120400/78836 (52%)]	Loss: 0.183956
Train epoch: 546 [1407800/78836 (65%)]	Loss: 0.208725
Train epoch: 546 [1679160/78836 (78%)]	Loss: 0.207451
Train epoch: 546 [1948660/78836 (91%)]	Loss: 0.182143
predicting for valid data
Make prediction for 19709 samples...
0.18481633 No improvement since epoch  543 ; best_test_mse,best_test_ci: 0.18481633 0.8500820482921538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 547 [0/78836 (0%)]	Loss: 0.196612
Train epoch: 547 [269780/78836 (13%)]	Loss: 0.165251
Train epoch: 547 [561360/78836 (26%)]	Loss: 0.188033
Train epoch: 547 [833220/78836 (39%)]	Loss: 0.211985
Train epoch: 547 [1103600/78836 (52%)]	Loss: 0.204328
Train epoch: 547 [1416000/78836 (65%)]	Loss: 0.166365
Train epoch: 547 [1644480/78836 (78%)]	Loss: 0.206687
Train epoch: 547 [1992200/78836 (91%)]	Loss: 0.191991
predicting for valid data
Make prediction for 19709 samples...
0.18481633 No improvement since epoch  543 ; best_test_mse,best_test_ci: 0.18481633 0.8500820482921538 GINConvNet kiba
Training on 78836 samples...
Train epoch: 548 [0/78836 (0%)]	Loss: 0.205177
Train epoch: 548 [282080/78836 (13%)]	Loss: 0.194892
Train epoch: 548 [560760/78836 (26%)]	Loss: 0.184413
Train epoch: 548 [832920/78836 (39%)]	Loss: 0.182093
Train epoch: 548 [1114880/78836 (52%)]	Loss: 0.226486
Train epoch: 548 [1393200/78836 (65%)]	Loss: 0.223094
Train epoch: 548 [1685520/78836 (78%)]	Loss: 0.191322
Train epoch: 548 [1947120/78836 (91%)]	Loss: 0.183012
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 549 [0/78836 (0%)]	Loss: 0.181822
Train epoch: 549 [282320/78836 (13%)]	Loss: 0.195923
Train epoch: 549 [561720/78836 (26%)]	Loss: 0.168464
Train epoch: 549 [850500/78836 (39%)]	Loss: 0.199942
Train epoch: 549 [1127440/78836 (52%)]	Loss: 0.212794
Train epoch: 549 [1378400/78836 (65%)]	Loss: 0.179400
Train epoch: 549 [1651320/78836 (78%)]	Loss: 0.184187
Train epoch: 549 [1957200/78836 (91%)]	Loss: 0.218973
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 550 [0/78836 (0%)]	Loss: 0.201460
Train epoch: 550 [280580/78836 (13%)]	Loss: 0.200292
Train epoch: 550 [550680/78836 (26%)]	Loss: 0.177646
Train epoch: 550 [843780/78836 (39%)]	Loss: 0.149261
Train epoch: 550 [1116720/78836 (52%)]	Loss: 0.198802
Train epoch: 550 [1360700/78836 (65%)]	Loss: 0.168557
Train epoch: 550 [1673640/78836 (78%)]	Loss: 0.200036
Train epoch: 550 [1944320/78836 (91%)]	Loss: 0.200075
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 551 [0/78836 (0%)]	Loss: 0.217699
Train epoch: 551 [281720/78836 (13%)]	Loss: 0.193113
Train epoch: 551 [554840/78836 (26%)]	Loss: 0.208113
Train epoch: 551 [840060/78836 (39%)]	Loss: 0.216829
Train epoch: 551 [1123680/78836 (52%)]	Loss: 0.170666
Train epoch: 551 [1381900/78836 (65%)]	Loss: 0.206420
Train epoch: 551 [1654800/78836 (78%)]	Loss: 0.227350
Train epoch: 551 [1962100/78836 (91%)]	Loss: 0.196659
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 552 [0/78836 (0%)]	Loss: 0.210427
Train epoch: 552 [275100/78836 (13%)]	Loss: 0.188254
Train epoch: 552 [561040/78836 (26%)]	Loss: 0.222886
Train epoch: 552 [830040/78836 (39%)]	Loss: 0.173791
Train epoch: 552 [1112240/78836 (52%)]	Loss: 0.212895
Train epoch: 552 [1389400/78836 (65%)]	Loss: 0.159609
Train epoch: 552 [1683960/78836 (78%)]	Loss: 0.172236
Train epoch: 552 [1951180/78836 (91%)]	Loss: 0.200355
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 553 [0/78836 (0%)]	Loss: 0.152795
Train epoch: 553 [283120/78836 (13%)]	Loss: 0.198872
Train epoch: 553 [569920/78836 (26%)]	Loss: 0.240632
Train epoch: 553 [844680/78836 (39%)]	Loss: 0.218203
Train epoch: 553 [1116560/78836 (52%)]	Loss: 0.174938
Train epoch: 553 [1380900/78836 (65%)]	Loss: 0.140208
Train epoch: 553 [1700760/78836 (78%)]	Loss: 0.151502
Train epoch: 553 [1985900/78836 (91%)]	Loss: 0.222406
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 554 [0/78836 (0%)]	Loss: 0.184295
Train epoch: 554 [274000/78836 (13%)]	Loss: 0.184856
Train epoch: 554 [562320/78836 (26%)]	Loss: 0.172549
Train epoch: 554 [830460/78836 (39%)]	Loss: 0.204907
Train epoch: 554 [1119920/78836 (52%)]	Loss: 0.170461
Train epoch: 554 [1365800/78836 (65%)]	Loss: 0.213574
Train epoch: 554 [1681560/78836 (78%)]	Loss: 0.191915
Train epoch: 554 [1946420/78836 (91%)]	Loss: 0.170262
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 555 [0/78836 (0%)]	Loss: 0.186186
Train epoch: 555 [282440/78836 (13%)]	Loss: 0.193778
Train epoch: 555 [562880/78836 (26%)]	Loss: 0.181708
Train epoch: 555 [838380/78836 (39%)]	Loss: 0.181855
Train epoch: 555 [1132480/78836 (52%)]	Loss: 0.233873
Train epoch: 555 [1379100/78836 (65%)]	Loss: 0.207185
Train epoch: 555 [1647720/78836 (78%)]	Loss: 0.155256
Train epoch: 555 [1966580/78836 (91%)]	Loss: 0.219608
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 556 [0/78836 (0%)]	Loss: 0.214652
Train epoch: 556 [283680/78836 (13%)]	Loss: 0.182321
Train epoch: 556 [559880/78836 (26%)]	Loss: 0.202279
Train epoch: 556 [839640/78836 (39%)]	Loss: 0.218921
Train epoch: 556 [1111840/78836 (52%)]	Loss: 0.204795
Train epoch: 556 [1410500/78836 (65%)]	Loss: 0.200542
Train epoch: 556 [1661160/78836 (78%)]	Loss: 0.208909
Train epoch: 556 [1963360/78836 (91%)]	Loss: 0.217720
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 557 [0/78836 (0%)]	Loss: 0.178523
Train epoch: 557 [279600/78836 (13%)]	Loss: 0.163625
Train epoch: 557 [572560/78836 (26%)]	Loss: 0.174355
Train epoch: 557 [830820/78836 (39%)]	Loss: 0.168370
Train epoch: 557 [1107680/78836 (52%)]	Loss: 0.209123
Train epoch: 557 [1400300/78836 (65%)]	Loss: 0.175825
Train epoch: 557 [1687200/78836 (78%)]	Loss: 0.195234
Train epoch: 557 [1969940/78836 (91%)]	Loss: 0.245957
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 558 [0/78836 (0%)]	Loss: 0.201702
Train epoch: 558 [276980/78836 (13%)]	Loss: 0.180586
Train epoch: 558 [558880/78836 (26%)]	Loss: 0.184781
Train epoch: 558 [844500/78836 (39%)]	Loss: 0.198784
Train epoch: 558 [1119520/78836 (52%)]	Loss: 0.203401
Train epoch: 558 [1356500/78836 (65%)]	Loss: 0.209627
Train epoch: 558 [1693440/78836 (78%)]	Loss: 0.178890
Train epoch: 558 [1997100/78836 (91%)]	Loss: 0.192731
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 559 [0/78836 (0%)]	Loss: 0.190051
Train epoch: 559 [274780/78836 (13%)]	Loss: 0.209287
Train epoch: 559 [569680/78836 (26%)]	Loss: 0.186285
Train epoch: 559 [841680/78836 (39%)]	Loss: 0.235400
Train epoch: 559 [1093520/78836 (52%)]	Loss: 0.175609
Train epoch: 559 [1394200/78836 (65%)]	Loss: 0.184092
Train epoch: 559 [1656840/78836 (78%)]	Loss: 0.172456
Train epoch: 559 [1932700/78836 (91%)]	Loss: 0.225380
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 560 [0/78836 (0%)]	Loss: 0.136403
Train epoch: 560 [281800/78836 (13%)]	Loss: 0.190501
Train epoch: 560 [561160/78836 (26%)]	Loss: 0.182589
Train epoch: 560 [837720/78836 (39%)]	Loss: 0.222883
Train epoch: 560 [1130720/78836 (52%)]	Loss: 0.170965
Train epoch: 560 [1394700/78836 (65%)]	Loss: 0.211232
Train epoch: 560 [1646400/78836 (78%)]	Loss: 0.197622
Train epoch: 560 [1973160/78836 (91%)]	Loss: 0.165428
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 561 [0/78836 (0%)]	Loss: 0.181134
Train epoch: 561 [280120/78836 (13%)]	Loss: 0.154094
Train epoch: 561 [563360/78836 (26%)]	Loss: 0.198277
Train epoch: 561 [837420/78836 (39%)]	Loss: 0.200529
Train epoch: 561 [1118320/78836 (52%)]	Loss: 0.256381
Train epoch: 561 [1422300/78836 (65%)]	Loss: 0.195098
Train epoch: 561 [1647000/78836 (78%)]	Loss: 0.197206
Train epoch: 561 [1948100/78836 (91%)]	Loss: 0.182505
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 562 [0/78836 (0%)]	Loss: 0.191728
Train epoch: 562 [280940/78836 (13%)]	Loss: 0.162111
Train epoch: 562 [576480/78836 (26%)]	Loss: 0.198258
Train epoch: 562 [832320/78836 (39%)]	Loss: 0.214460
Train epoch: 562 [1125520/78836 (52%)]	Loss: 0.208866
Train epoch: 562 [1413500/78836 (65%)]	Loss: 0.186547
Train epoch: 562 [1677000/78836 (78%)]	Loss: 0.182412
Train epoch: 562 [1952020/78836 (91%)]	Loss: 0.185123
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 563 [0/78836 (0%)]	Loss: 0.169462
Train epoch: 563 [279600/78836 (13%)]	Loss: 0.228040
Train epoch: 563 [563480/78836 (26%)]	Loss: 0.171096
Train epoch: 563 [837600/78836 (39%)]	Loss: 0.193552
Train epoch: 563 [1127760/78836 (52%)]	Loss: 0.179357
Train epoch: 563 [1382600/78836 (65%)]	Loss: 0.199328
Train epoch: 563 [1662720/78836 (78%)]	Loss: 0.202516
Train epoch: 563 [1945020/78836 (91%)]	Loss: 0.189076
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 564 [0/78836 (0%)]	Loss: 0.158575
Train epoch: 564 [272520/78836 (13%)]	Loss: 0.178034
Train epoch: 564 [560720/78836 (26%)]	Loss: 0.187755
Train epoch: 564 [853560/78836 (39%)]	Loss: 0.233208
Train epoch: 564 [1117040/78836 (52%)]	Loss: 0.199270
Train epoch: 564 [1378900/78836 (65%)]	Loss: 0.192700
Train epoch: 564 [1692960/78836 (78%)]	Loss: 0.218498
Train epoch: 564 [1967840/78836 (91%)]	Loss: 0.212481
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 565 [0/78836 (0%)]	Loss: 0.206821
Train epoch: 565 [278080/78836 (13%)]	Loss: 0.185759
Train epoch: 565 [548000/78836 (26%)]	Loss: 0.207853
Train epoch: 565 [850620/78836 (39%)]	Loss: 0.155506
Train epoch: 565 [1125920/78836 (52%)]	Loss: 0.204196
Train epoch: 565 [1411200/78836 (65%)]	Loss: 0.175248
Train epoch: 565 [1668000/78836 (78%)]	Loss: 0.209359
Train epoch: 565 [1927240/78836 (91%)]	Loss: 0.197792
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 566 [0/78836 (0%)]	Loss: 0.181384
Train epoch: 566 [282940/78836 (13%)]	Loss: 0.146969
Train epoch: 566 [561520/78836 (26%)]	Loss: 0.208966
Train epoch: 566 [848460/78836 (39%)]	Loss: 0.175870
Train epoch: 566 [1115760/78836 (52%)]	Loss: 0.172389
Train epoch: 566 [1418800/78836 (65%)]	Loss: 0.207358
Train epoch: 566 [1691520/78836 (78%)]	Loss: 0.202293
Train epoch: 566 [1976380/78836 (91%)]	Loss: 0.161753
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 567 [0/78836 (0%)]	Loss: 0.145812
Train epoch: 567 [281060/78836 (13%)]	Loss: 0.160006
Train epoch: 567 [560400/78836 (26%)]	Loss: 0.186587
Train epoch: 567 [873900/78836 (39%)]	Loss: 0.132050
Train epoch: 567 [1122320/78836 (52%)]	Loss: 0.187784
Train epoch: 567 [1407300/78836 (65%)]	Loss: 0.210277
Train epoch: 567 [1690560/78836 (78%)]	Loss: 0.177926
Train epoch: 567 [1948940/78836 (91%)]	Loss: 0.171114
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 568 [0/78836 (0%)]	Loss: 0.183269
Train epoch: 568 [276400/78836 (13%)]	Loss: 0.160120
Train epoch: 568 [551000/78836 (26%)]	Loss: 0.195564
Train epoch: 568 [830820/78836 (39%)]	Loss: 0.164416
Train epoch: 568 [1111760/78836 (52%)]	Loss: 0.196987
Train epoch: 568 [1362800/78836 (65%)]	Loss: 0.159942
Train epoch: 568 [1664400/78836 (78%)]	Loss: 0.160930
Train epoch: 568 [1987160/78836 (91%)]	Loss: 0.195662
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 569 [0/78836 (0%)]	Loss: 0.219168
Train epoch: 569 [281400/78836 (13%)]	Loss: 0.158529
Train epoch: 569 [574480/78836 (26%)]	Loss: 0.161224
Train epoch: 569 [842220/78836 (39%)]	Loss: 0.188174
Train epoch: 569 [1136000/78836 (52%)]	Loss: 0.175155
Train epoch: 569 [1425200/78836 (65%)]	Loss: 0.148532
Train epoch: 569 [1718640/78836 (78%)]	Loss: 0.194212
Train epoch: 569 [1941520/78836 (91%)]	Loss: 0.169008
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 570 [0/78836 (0%)]	Loss: 0.166266
Train epoch: 570 [279860/78836 (13%)]	Loss: 0.196075
Train epoch: 570 [565760/78836 (26%)]	Loss: 0.208994
Train epoch: 570 [830580/78836 (39%)]	Loss: 0.202568
Train epoch: 570 [1121760/78836 (52%)]	Loss: 0.178768
Train epoch: 570 [1380600/78836 (65%)]	Loss: 0.210106
Train epoch: 570 [1677000/78836 (78%)]	Loss: 0.204884
Train epoch: 570 [1942640/78836 (91%)]	Loss: 0.181147
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 571 [0/78836 (0%)]	Loss: 0.209309
Train epoch: 571 [277180/78836 (13%)]	Loss: 0.150551
Train epoch: 571 [559600/78836 (26%)]	Loss: 0.197237
Train epoch: 571 [831960/78836 (39%)]	Loss: 0.211562
Train epoch: 571 [1111040/78836 (52%)]	Loss: 0.162997
Train epoch: 571 [1424000/78836 (65%)]	Loss: 0.196190
Train epoch: 571 [1733160/78836 (78%)]	Loss: 0.214005
Train epoch: 571 [1936620/78836 (91%)]	Loss: 0.194328
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 572 [0/78836 (0%)]	Loss: 0.152522
Train epoch: 572 [284760/78836 (13%)]	Loss: 0.185273
Train epoch: 572 [557320/78836 (26%)]	Loss: 0.185558
Train epoch: 572 [824400/78836 (39%)]	Loss: 0.182700
Train epoch: 572 [1117680/78836 (52%)]	Loss: 0.174561
Train epoch: 572 [1388100/78836 (65%)]	Loss: 0.217954
Train epoch: 572 [1702680/78836 (78%)]	Loss: 0.213520
Train epoch: 572 [1976240/78836 (91%)]	Loss: 0.185202
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 573 [0/78836 (0%)]	Loss: 0.161507
Train epoch: 573 [277200/78836 (13%)]	Loss: 0.181066
Train epoch: 573 [549960/78836 (26%)]	Loss: 0.186877
Train epoch: 573 [856140/78836 (39%)]	Loss: 0.172359
Train epoch: 573 [1110640/78836 (52%)]	Loss: 0.215350
Train epoch: 573 [1392500/78836 (65%)]	Loss: 0.203429
Train epoch: 573 [1691520/78836 (78%)]	Loss: 0.175091
Train epoch: 573 [1954680/78836 (91%)]	Loss: 0.211516
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 574 [0/78836 (0%)]	Loss: 0.162010
Train epoch: 574 [283700/78836 (13%)]	Loss: 0.170344
Train epoch: 574 [561440/78836 (26%)]	Loss: 0.184499
Train epoch: 574 [837360/78836 (39%)]	Loss: 0.206967
Train epoch: 574 [1112480/78836 (52%)]	Loss: 0.238686
Train epoch: 574 [1397900/78836 (65%)]	Loss: 0.168411
Train epoch: 574 [1661040/78836 (78%)]	Loss: 0.173197
Train epoch: 574 [1966440/78836 (91%)]	Loss: 0.197963
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 575 [0/78836 (0%)]	Loss: 0.186358
Train epoch: 575 [274840/78836 (13%)]	Loss: 0.193225
Train epoch: 575 [557080/78836 (26%)]	Loss: 0.188419
Train epoch: 575 [849060/78836 (39%)]	Loss: 0.153171
Train epoch: 575 [1093840/78836 (52%)]	Loss: 0.175926
Train epoch: 575 [1396500/78836 (65%)]	Loss: 0.175569
Train epoch: 575 [1698960/78836 (78%)]	Loss: 0.185744
Train epoch: 575 [2008440/78836 (91%)]	Loss: 0.197954
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 576 [0/78836 (0%)]	Loss: 0.179412
Train epoch: 576 [274980/78836 (13%)]	Loss: 0.176547
Train epoch: 576 [550040/78836 (26%)]	Loss: 0.165531
Train epoch: 576 [858540/78836 (39%)]	Loss: 0.171771
Train epoch: 576 [1110240/78836 (52%)]	Loss: 0.167434
Train epoch: 576 [1404200/78836 (65%)]	Loss: 0.157895
Train epoch: 576 [1731720/78836 (78%)]	Loss: 0.185778
Train epoch: 576 [1992200/78836 (91%)]	Loss: 0.196804
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 577 [0/78836 (0%)]	Loss: 0.181003
Train epoch: 577 [275200/78836 (13%)]	Loss: 0.181445
Train epoch: 577 [558960/78836 (26%)]	Loss: 0.168713
Train epoch: 577 [841140/78836 (39%)]	Loss: 0.212576
Train epoch: 577 [1107280/78836 (52%)]	Loss: 0.172787
Train epoch: 577 [1399400/78836 (65%)]	Loss: 0.177529
Train epoch: 577 [1670160/78836 (78%)]	Loss: 0.223194
Train epoch: 577 [1956080/78836 (91%)]	Loss: 0.234979
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 578 [0/78836 (0%)]	Loss: 0.227387
Train epoch: 578 [277900/78836 (13%)]	Loss: 0.188352
Train epoch: 578 [562880/78836 (26%)]	Loss: 0.200316
Train epoch: 578 [827400/78836 (39%)]	Loss: 0.177902
Train epoch: 578 [1103200/78836 (52%)]	Loss: 0.191225
Train epoch: 578 [1391500/78836 (65%)]	Loss: 0.169880
Train epoch: 578 [1671480/78836 (78%)]	Loss: 0.180984
Train epoch: 578 [1930880/78836 (91%)]	Loss: 0.174484
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 579 [0/78836 (0%)]	Loss: 0.178899
Train epoch: 579 [278000/78836 (13%)]	Loss: 0.169155
Train epoch: 579 [563400/78836 (26%)]	Loss: 0.192202
Train epoch: 579 [834960/78836 (39%)]	Loss: 0.179895
Train epoch: 579 [1112720/78836 (52%)]	Loss: 0.188191
Train epoch: 579 [1431600/78836 (65%)]	Loss: 0.200380
Train epoch: 579 [1681800/78836 (78%)]	Loss: 0.225607
Train epoch: 579 [1931020/78836 (91%)]	Loss: 0.193384
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 580 [0/78836 (0%)]	Loss: 0.211797
Train epoch: 580 [286980/78836 (13%)]	Loss: 0.192110
Train epoch: 580 [551320/78836 (26%)]	Loss: 0.204751
Train epoch: 580 [847860/78836 (39%)]	Loss: 0.215463
Train epoch: 580 [1119600/78836 (52%)]	Loss: 0.186978
Train epoch: 580 [1407900/78836 (65%)]	Loss: 0.183783
Train epoch: 580 [1671240/78836 (78%)]	Loss: 0.164687
Train epoch: 580 [1965460/78836 (91%)]	Loss: 0.200190
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 581 [0/78836 (0%)]	Loss: 0.194716
Train epoch: 581 [276860/78836 (13%)]	Loss: 0.150310
Train epoch: 581 [556360/78836 (26%)]	Loss: 0.179917
Train epoch: 581 [855300/78836 (39%)]	Loss: 0.165494
Train epoch: 581 [1118880/78836 (52%)]	Loss: 0.176137
Train epoch: 581 [1436300/78836 (65%)]	Loss: 0.194104
Train epoch: 581 [1686960/78836 (78%)]	Loss: 0.184480
Train epoch: 581 [1937040/78836 (91%)]	Loss: 0.166726
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 582 [0/78836 (0%)]	Loss: 0.219548
Train epoch: 582 [284840/78836 (13%)]	Loss: 0.192180
Train epoch: 582 [573840/78836 (26%)]	Loss: 0.186446
Train epoch: 582 [839880/78836 (39%)]	Loss: 0.189632
Train epoch: 582 [1105440/78836 (52%)]	Loss: 0.193454
Train epoch: 582 [1379500/78836 (65%)]	Loss: 0.153908
Train epoch: 582 [1706880/78836 (78%)]	Loss: 0.198445
Train epoch: 582 [1945580/78836 (91%)]	Loss: 0.141525
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 583 [0/78836 (0%)]	Loss: 0.170739
Train epoch: 583 [278480/78836 (13%)]	Loss: 0.221971
Train epoch: 583 [559400/78836 (26%)]	Loss: 0.173727
Train epoch: 583 [837540/78836 (39%)]	Loss: 0.202103
Train epoch: 583 [1116720/78836 (52%)]	Loss: 0.185331
Train epoch: 583 [1413000/78836 (65%)]	Loss: 0.196335
Train epoch: 583 [1711920/78836 (78%)]	Loss: 0.149574
Train epoch: 583 [1960700/78836 (91%)]	Loss: 0.176373
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 584 [0/78836 (0%)]	Loss: 0.202999
Train epoch: 584 [279560/78836 (13%)]	Loss: 0.161088
Train epoch: 584 [553520/78836 (26%)]	Loss: 0.238819
Train epoch: 584 [844620/78836 (39%)]	Loss: 0.192314
Train epoch: 584 [1126560/78836 (52%)]	Loss: 0.183792
Train epoch: 584 [1390900/78836 (65%)]	Loss: 0.180009
Train epoch: 584 [1668840/78836 (78%)]	Loss: 0.215881
Train epoch: 584 [1941800/78836 (91%)]	Loss: 0.180599
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 585 [0/78836 (0%)]	Loss: 0.197698
Train epoch: 585 [277280/78836 (13%)]	Loss: 0.187528
Train epoch: 585 [545160/78836 (26%)]	Loss: 0.173898
Train epoch: 585 [845940/78836 (39%)]	Loss: 0.213570
Train epoch: 585 [1131360/78836 (52%)]	Loss: 0.173474
Train epoch: 585 [1414100/78836 (65%)]	Loss: 0.195313
Train epoch: 585 [1667880/78836 (78%)]	Loss: 0.181272
Train epoch: 585 [1955240/78836 (91%)]	Loss: 0.181530
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 586 [0/78836 (0%)]	Loss: 0.194019
Train epoch: 586 [276600/78836 (13%)]	Loss: 0.183453
Train epoch: 586 [560480/78836 (26%)]	Loss: 0.209567
Train epoch: 586 [831600/78836 (39%)]	Loss: 0.164330
Train epoch: 586 [1109200/78836 (52%)]	Loss: 0.190361
Train epoch: 586 [1387700/78836 (65%)]	Loss: 0.185240
Train epoch: 586 [1668240/78836 (78%)]	Loss: 0.208757
Train epoch: 586 [1944880/78836 (91%)]	Loss: 0.141341
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 587 [0/78836 (0%)]	Loss: 0.215248
Train epoch: 587 [280620/78836 (13%)]	Loss: 0.145792
Train epoch: 587 [556720/78836 (26%)]	Loss: 0.143364
Train epoch: 587 [817560/78836 (39%)]	Loss: 0.140174
Train epoch: 587 [1121120/78836 (52%)]	Loss: 0.179809
Train epoch: 587 [1381100/78836 (65%)]	Loss: 0.213786
Train epoch: 587 [1630680/78836 (78%)]	Loss: 0.174152
Train epoch: 587 [1956500/78836 (91%)]	Loss: 0.198702
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 588 [0/78836 (0%)]	Loss: 0.155064
Train epoch: 588 [280380/78836 (13%)]	Loss: 0.161632
Train epoch: 588 [557680/78836 (26%)]	Loss: 0.166240
Train epoch: 588 [849780/78836 (39%)]	Loss: 0.213931
Train epoch: 588 [1127520/78836 (52%)]	Loss: 0.224700
Train epoch: 588 [1414100/78836 (65%)]	Loss: 0.202025
Train epoch: 588 [1700160/78836 (78%)]	Loss: 0.173442
Train epoch: 588 [1948240/78836 (91%)]	Loss: 0.172394
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 589 [0/78836 (0%)]	Loss: 0.169497
Train epoch: 589 [279060/78836 (13%)]	Loss: 0.177540
Train epoch: 589 [561600/78836 (26%)]	Loss: 0.183655
Train epoch: 589 [835020/78836 (39%)]	Loss: 0.170630
Train epoch: 589 [1106320/78836 (52%)]	Loss: 0.176170
Train epoch: 589 [1412900/78836 (65%)]	Loss: 0.179938
Train epoch: 589 [1736280/78836 (78%)]	Loss: 0.187937
Train epoch: 589 [1964480/78836 (91%)]	Loss: 0.204089
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 590 [0/78836 (0%)]	Loss: 0.165724
Train epoch: 590 [278160/78836 (13%)]	Loss: 0.235604
Train epoch: 590 [557840/78836 (26%)]	Loss: 0.178703
Train epoch: 590 [823620/78836 (39%)]	Loss: 0.165825
Train epoch: 590 [1120720/78836 (52%)]	Loss: 0.236827
Train epoch: 590 [1390400/78836 (65%)]	Loss: 0.224286
Train epoch: 590 [1700400/78836 (78%)]	Loss: 0.189270
Train epoch: 590 [1956780/78836 (91%)]	Loss: 0.192418
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 591 [0/78836 (0%)]	Loss: 0.211111
Train epoch: 591 [280160/78836 (13%)]	Loss: 0.210879
Train epoch: 591 [561280/78836 (26%)]	Loss: 0.189668
Train epoch: 591 [835440/78836 (39%)]	Loss: 0.193511
Train epoch: 591 [1150800/78836 (52%)]	Loss: 0.199773
Train epoch: 591 [1409200/78836 (65%)]	Loss: 0.185679
Train epoch: 591 [1683960/78836 (78%)]	Loss: 0.176231
Train epoch: 591 [1987300/78836 (91%)]	Loss: 0.213649
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 592 [0/78836 (0%)]	Loss: 0.189301
Train epoch: 592 [277440/78836 (13%)]	Loss: 0.164317
Train epoch: 592 [552520/78836 (26%)]	Loss: 0.220652
Train epoch: 592 [837960/78836 (39%)]	Loss: 0.178650
Train epoch: 592 [1137280/78836 (52%)]	Loss: 0.180949
Train epoch: 592 [1390600/78836 (65%)]	Loss: 0.157869
Train epoch: 592 [1665600/78836 (78%)]	Loss: 0.156431
Train epoch: 592 [1967420/78836 (91%)]	Loss: 0.212508
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 593 [0/78836 (0%)]	Loss: 0.157307
Train epoch: 593 [281160/78836 (13%)]	Loss: 0.142829
Train epoch: 593 [560920/78836 (26%)]	Loss: 0.155898
Train epoch: 593 [867660/78836 (39%)]	Loss: 0.169495
Train epoch: 593 [1136240/78836 (52%)]	Loss: 0.173631
Train epoch: 593 [1400800/78836 (65%)]	Loss: 0.191799
Train epoch: 593 [1672080/78836 (78%)]	Loss: 0.178244
Train epoch: 593 [1981140/78836 (91%)]	Loss: 0.180697
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 594 [0/78836 (0%)]	Loss: 0.196197
Train epoch: 594 [276860/78836 (13%)]	Loss: 0.199929
Train epoch: 594 [555280/78836 (26%)]	Loss: 0.147841
Train epoch: 594 [852900/78836 (39%)]	Loss: 0.179416
Train epoch: 594 [1132320/78836 (52%)]	Loss: 0.189338
Train epoch: 594 [1410500/78836 (65%)]	Loss: 0.161233
Train epoch: 594 [1702080/78836 (78%)]	Loss: 0.191048
Train epoch: 594 [1942080/78836 (91%)]	Loss: 0.173624
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 595 [0/78836 (0%)]	Loss: 0.148354
Train epoch: 595 [286280/78836 (13%)]	Loss: 0.187165
Train epoch: 595 [572800/78836 (26%)]	Loss: 0.186674
Train epoch: 595 [839100/78836 (39%)]	Loss: 0.179261
Train epoch: 595 [1124480/78836 (52%)]	Loss: 0.177320
Train epoch: 595 [1404300/78836 (65%)]	Loss: 0.132051
Train epoch: 595 [1659960/78836 (78%)]	Loss: 0.170656
Train epoch: 595 [1956500/78836 (91%)]	Loss: 0.194787
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 596 [0/78836 (0%)]	Loss: 0.222563
Train epoch: 596 [281780/78836 (13%)]	Loss: 0.184395
Train epoch: 596 [562600/78836 (26%)]	Loss: 0.202247
Train epoch: 596 [835260/78836 (39%)]	Loss: 0.169084
Train epoch: 596 [1129760/78836 (52%)]	Loss: 0.173675
Train epoch: 596 [1394800/78836 (65%)]	Loss: 0.147243
Train epoch: 596 [1692120/78836 (78%)]	Loss: 0.182079
Train epoch: 596 [1930040/78836 (91%)]	Loss: 0.213386
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 597 [0/78836 (0%)]	Loss: 0.175948
Train epoch: 597 [275760/78836 (13%)]	Loss: 0.135864
Train epoch: 597 [558840/78836 (26%)]	Loss: 0.195957
Train epoch: 597 [824880/78836 (39%)]	Loss: 0.167350
Train epoch: 597 [1117760/78836 (52%)]	Loss: 0.197441
Train epoch: 597 [1386500/78836 (65%)]	Loss: 0.202421
Train epoch: 597 [1647120/78836 (78%)]	Loss: 0.189044
Train epoch: 597 [1973580/78836 (91%)]	Loss: 0.245565
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 598 [0/78836 (0%)]	Loss: 0.175062
Train epoch: 598 [280540/78836 (13%)]	Loss: 0.131946
Train epoch: 598 [560160/78836 (26%)]	Loss: 0.185349
Train epoch: 598 [844200/78836 (39%)]	Loss: 0.175136
Train epoch: 598 [1127600/78836 (52%)]	Loss: 0.219362
Train epoch: 598 [1390000/78836 (65%)]	Loss: 0.160531
Train epoch: 598 [1701600/78836 (78%)]	Loss: 0.166345
Train epoch: 598 [1945300/78836 (91%)]	Loss: 0.168004
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 599 [0/78836 (0%)]	Loss: 0.190080
Train epoch: 599 [276120/78836 (13%)]	Loss: 0.157969
Train epoch: 599 [562360/78836 (26%)]	Loss: 0.170580
Train epoch: 599 [836520/78836 (39%)]	Loss: 0.179410
Train epoch: 599 [1099920/78836 (52%)]	Loss: 0.146254
Train epoch: 599 [1379200/78836 (65%)]	Loss: 0.182266
Train epoch: 599 [1689960/78836 (78%)]	Loss: 0.174906
Train epoch: 599 [2004660/78836 (91%)]	Loss: 0.211621
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 600 [0/78836 (0%)]	Loss: 0.169780
Train epoch: 600 [279260/78836 (13%)]	Loss: 0.165404
Train epoch: 600 [562360/78836 (26%)]	Loss: 0.171116
Train epoch: 600 [835380/78836 (39%)]	Loss: 0.165492
Train epoch: 600 [1120800/78836 (52%)]	Loss: 0.197574
Train epoch: 600 [1371800/78836 (65%)]	Loss: 0.184611
Train epoch: 600 [1691520/78836 (78%)]	Loss: 0.179108
Train epoch: 600 [1987860/78836 (91%)]	Loss: 0.176062
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 601 [0/78836 (0%)]	Loss: 0.176240
Train epoch: 601 [284760/78836 (13%)]	Loss: 0.178929
Train epoch: 601 [563320/78836 (26%)]	Loss: 0.155645
Train epoch: 601 [844740/78836 (39%)]	Loss: 0.190809
Train epoch: 601 [1125600/78836 (52%)]	Loss: 0.233137
Train epoch: 601 [1367200/78836 (65%)]	Loss: 0.186989
Train epoch: 601 [1683960/78836 (78%)]	Loss: 0.175855
Train epoch: 601 [1981000/78836 (91%)]	Loss: 0.216639
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 602 [0/78836 (0%)]	Loss: 0.155566
Train epoch: 602 [276080/78836 (13%)]	Loss: 0.162195
Train epoch: 602 [570280/78836 (26%)]	Loss: 0.161968
Train epoch: 602 [842760/78836 (39%)]	Loss: 0.182576
Train epoch: 602 [1110160/78836 (52%)]	Loss: 0.152520
Train epoch: 602 [1407300/78836 (65%)]	Loss: 0.189039
Train epoch: 602 [1659600/78836 (78%)]	Loss: 0.162777
Train epoch: 602 [1937180/78836 (91%)]	Loss: 0.167924
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 603 [0/78836 (0%)]	Loss: 0.156262
Train epoch: 603 [289660/78836 (13%)]	Loss: 0.149399
Train epoch: 603 [550880/78836 (26%)]	Loss: 0.186151
Train epoch: 603 [836340/78836 (39%)]	Loss: 0.169569
Train epoch: 603 [1106560/78836 (52%)]	Loss: 0.170877
Train epoch: 603 [1419000/78836 (65%)]	Loss: 0.175252
Train epoch: 603 [1702080/78836 (78%)]	Loss: 0.182864
Train epoch: 603 [1936480/78836 (91%)]	Loss: 0.148579
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 604 [0/78836 (0%)]	Loss: 0.172623
Train epoch: 604 [274720/78836 (13%)]	Loss: 0.144231
Train epoch: 604 [557360/78836 (26%)]	Loss: 0.181196
Train epoch: 604 [840000/78836 (39%)]	Loss: 0.169437
Train epoch: 604 [1119600/78836 (52%)]	Loss: 0.213466
Train epoch: 604 [1414800/78836 (65%)]	Loss: 0.184764
Train epoch: 604 [1701480/78836 (78%)]	Loss: 0.173084
Train epoch: 604 [1983520/78836 (91%)]	Loss: 0.158061
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 605 [0/78836 (0%)]	Loss: 0.190093
Train epoch: 605 [280800/78836 (13%)]	Loss: 0.188961
Train epoch: 605 [562560/78836 (26%)]	Loss: 0.173578
Train epoch: 605 [830400/78836 (39%)]	Loss: 0.159676
Train epoch: 605 [1112480/78836 (52%)]	Loss: 0.184720
Train epoch: 605 [1371300/78836 (65%)]	Loss: 0.173897
Train epoch: 605 [1678080/78836 (78%)]	Loss: 0.161089
Train epoch: 605 [1916740/78836 (91%)]	Loss: 0.173896
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 606 [0/78836 (0%)]	Loss: 0.168144
Train epoch: 606 [277180/78836 (13%)]	Loss: 0.160135
Train epoch: 606 [559000/78836 (26%)]	Loss: 0.160042
Train epoch: 606 [819300/78836 (39%)]	Loss: 0.140556
Train epoch: 606 [1107760/78836 (52%)]	Loss: 0.160886
Train epoch: 606 [1405900/78836 (65%)]	Loss: 0.165775
Train epoch: 606 [1685160/78836 (78%)]	Loss: 0.165576
Train epoch: 606 [1967560/78836 (91%)]	Loss: 0.192375
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 607 [0/78836 (0%)]	Loss: 0.153861
Train epoch: 607 [282100/78836 (13%)]	Loss: 0.142113
Train epoch: 607 [552840/78836 (26%)]	Loss: 0.168683
Train epoch: 607 [844320/78836 (39%)]	Loss: 0.156217
Train epoch: 607 [1115760/78836 (52%)]	Loss: 0.144885
Train epoch: 607 [1379600/78836 (65%)]	Loss: 0.167103
Train epoch: 607 [1677840/78836 (78%)]	Loss: 0.141147
Train epoch: 607 [1955380/78836 (91%)]	Loss: 0.188971
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 608 [0/78836 (0%)]	Loss: 0.149674
Train epoch: 608 [279220/78836 (13%)]	Loss: 0.180607
Train epoch: 608 [567800/78836 (26%)]	Loss: 0.179972
Train epoch: 608 [838560/78836 (39%)]	Loss: 0.198021
Train epoch: 608 [1114000/78836 (52%)]	Loss: 0.159763
Train epoch: 608 [1419600/78836 (65%)]	Loss: 0.136659
Train epoch: 608 [1696560/78836 (78%)]	Loss: 0.150889
Train epoch: 608 [1956220/78836 (91%)]	Loss: 0.148619
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 609 [0/78836 (0%)]	Loss: 0.145770
Train epoch: 609 [279140/78836 (13%)]	Loss: 0.160975
Train epoch: 609 [548520/78836 (26%)]	Loss: 0.159258
Train epoch: 609 [857040/78836 (39%)]	Loss: 0.191904
Train epoch: 609 [1105040/78836 (52%)]	Loss: 0.166531
Train epoch: 609 [1402000/78836 (65%)]	Loss: 0.139233
Train epoch: 609 [1731480/78836 (78%)]	Loss: 0.161485
Train epoch: 609 [1970220/78836 (91%)]	Loss: 0.178923
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 610 [0/78836 (0%)]	Loss: 0.166143
Train epoch: 610 [284940/78836 (13%)]	Loss: 0.180048
Train epoch: 610 [559880/78836 (26%)]	Loss: 0.212779
Train epoch: 610 [837480/78836 (39%)]	Loss: 0.184438
Train epoch: 610 [1123360/78836 (52%)]	Loss: 0.221999
Train epoch: 610 [1381700/78836 (65%)]	Loss: 0.168116
Train epoch: 610 [1640520/78836 (78%)]	Loss: 0.190871
Train epoch: 610 [1943340/78836 (91%)]	Loss: 0.153254
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 611 [0/78836 (0%)]	Loss: 0.194172
Train epoch: 611 [279120/78836 (13%)]	Loss: 0.146937
Train epoch: 611 [558840/78836 (26%)]	Loss: 0.155863
Train epoch: 611 [840420/78836 (39%)]	Loss: 0.177895
Train epoch: 611 [1128000/78836 (52%)]	Loss: 0.179312
Train epoch: 611 [1392400/78836 (65%)]	Loss: 0.160393
Train epoch: 611 [1672680/78836 (78%)]	Loss: 0.162372
Train epoch: 611 [1946000/78836 (91%)]	Loss: 0.156888
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 612 [0/78836 (0%)]	Loss: 0.163324
Train epoch: 612 [278140/78836 (13%)]	Loss: 0.158797
Train epoch: 612 [569880/78836 (26%)]	Loss: 0.225366
Train epoch: 612 [846600/78836 (39%)]	Loss: 0.148234
Train epoch: 612 [1132880/78836 (52%)]	Loss: 0.173344
Train epoch: 612 [1418600/78836 (65%)]	Loss: 0.160941
Train epoch: 612 [1671600/78836 (78%)]	Loss: 0.152704
Train epoch: 612 [1925420/78836 (91%)]	Loss: 0.161200
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 613 [0/78836 (0%)]	Loss: 0.131114
Train epoch: 613 [278820/78836 (13%)]	Loss: 0.157798
Train epoch: 613 [557840/78836 (26%)]	Loss: 0.161088
Train epoch: 613 [836040/78836 (39%)]	Loss: 0.171328
Train epoch: 613 [1162480/78836 (52%)]	Loss: 0.182420
Train epoch: 613 [1413500/78836 (65%)]	Loss: 0.233092
Train epoch: 613 [1700520/78836 (78%)]	Loss: 0.179779
Train epoch: 613 [1992060/78836 (91%)]	Loss: 0.162116
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 614 [0/78836 (0%)]	Loss: 0.162193
Train epoch: 614 [278360/78836 (13%)]	Loss: 0.183183
Train epoch: 614 [555760/78836 (26%)]	Loss: 0.157449
Train epoch: 614 [839220/78836 (39%)]	Loss: 0.146536
Train epoch: 614 [1112720/78836 (52%)]	Loss: 0.160905
Train epoch: 614 [1401800/78836 (65%)]	Loss: 0.185291
Train epoch: 614 [1664040/78836 (78%)]	Loss: 0.152422
Train epoch: 614 [1905400/78836 (91%)]	Loss: 0.166489
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 615 [0/78836 (0%)]	Loss: 0.159587
Train epoch: 615 [276240/78836 (13%)]	Loss: 0.213431
Train epoch: 615 [556960/78836 (26%)]	Loss: 0.173751
Train epoch: 615 [852000/78836 (39%)]	Loss: 0.151409
Train epoch: 615 [1110240/78836 (52%)]	Loss: 0.164944
Train epoch: 615 [1394800/78836 (65%)]	Loss: 0.163665
Train epoch: 615 [1648440/78836 (78%)]	Loss: 0.143127
Train epoch: 615 [1977220/78836 (91%)]	Loss: 0.195701
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 616 [0/78836 (0%)]	Loss: 0.154819
Train epoch: 616 [280200/78836 (13%)]	Loss: 0.176646
Train epoch: 616 [543520/78836 (26%)]	Loss: 0.137979
Train epoch: 616 [822000/78836 (39%)]	Loss: 0.179048
Train epoch: 616 [1108480/78836 (52%)]	Loss: 0.158308
Train epoch: 616 [1383500/78836 (65%)]	Loss: 0.159054
Train epoch: 616 [1677000/78836 (78%)]	Loss: 0.154845
Train epoch: 616 [1928080/78836 (91%)]	Loss: 0.171891
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 617 [0/78836 (0%)]	Loss: 0.162255
Train epoch: 617 [280260/78836 (13%)]	Loss: 0.156758
Train epoch: 617 [560640/78836 (26%)]	Loss: 0.160254
Train epoch: 617 [845100/78836 (39%)]	Loss: 0.172199
Train epoch: 617 [1112640/78836 (52%)]	Loss: 0.188394
Train epoch: 617 [1407900/78836 (65%)]	Loss: 0.155244
Train epoch: 617 [1669200/78836 (78%)]	Loss: 0.206459
Train epoch: 617 [1935640/78836 (91%)]	Loss: 0.171556
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 618 [0/78836 (0%)]	Loss: 0.181713
Train epoch: 618 [275040/78836 (13%)]	Loss: 0.149869
Train epoch: 618 [591840/78836 (26%)]	Loss: 0.158871
Train epoch: 618 [838380/78836 (39%)]	Loss: 0.134106
Train epoch: 618 [1122080/78836 (52%)]	Loss: 0.170660
Train epoch: 618 [1392900/78836 (65%)]	Loss: 0.161549
Train epoch: 618 [1666440/78836 (78%)]	Loss: 0.136517
Train epoch: 618 [1944320/78836 (91%)]	Loss: 0.164780
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 619 [0/78836 (0%)]	Loss: 0.168670
Train epoch: 619 [277820/78836 (13%)]	Loss: 0.184396
Train epoch: 619 [557760/78836 (26%)]	Loss: 0.154148
Train epoch: 619 [824580/78836 (39%)]	Loss: 0.167346
Train epoch: 619 [1127760/78836 (52%)]	Loss: 0.173827
Train epoch: 619 [1477400/78836 (65%)]	Loss: 0.177235
Train epoch: 619 [1668000/78836 (78%)]	Loss: 0.140113
Train epoch: 619 [1975400/78836 (91%)]	Loss: 0.147652
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 620 [0/78836 (0%)]	Loss: 0.175619
Train epoch: 620 [281500/78836 (13%)]	Loss: 0.180984
Train epoch: 620 [552200/78836 (26%)]	Loss: 0.163894
Train epoch: 620 [833400/78836 (39%)]	Loss: 0.145263
Train epoch: 620 [1135840/78836 (52%)]	Loss: 0.167881
Train epoch: 620 [1398000/78836 (65%)]	Loss: 0.181426
Train epoch: 620 [1707000/78836 (78%)]	Loss: 0.129294
Train epoch: 620 [1942640/78836 (91%)]	Loss: 0.155485
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 621 [0/78836 (0%)]	Loss: 0.155826
Train epoch: 621 [279160/78836 (13%)]	Loss: 0.143631
Train epoch: 621 [557640/78836 (26%)]	Loss: 0.178629
Train epoch: 621 [852000/78836 (39%)]	Loss: 0.168125
Train epoch: 621 [1102480/78836 (52%)]	Loss: 0.146713
Train epoch: 621 [1397100/78836 (65%)]	Loss: 0.136279
Train epoch: 621 [1683360/78836 (78%)]	Loss: 0.147940
Train epoch: 621 [1951740/78836 (91%)]	Loss: 0.165491
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 622 [0/78836 (0%)]	Loss: 0.143011
Train epoch: 622 [281680/78836 (13%)]	Loss: 0.168908
Train epoch: 622 [553800/78836 (26%)]	Loss: 0.143995
Train epoch: 622 [836040/78836 (39%)]	Loss: 0.165249
Train epoch: 622 [1103600/78836 (52%)]	Loss: 0.214358
Train epoch: 622 [1377000/78836 (65%)]	Loss: 0.145055
Train epoch: 622 [1664520/78836 (78%)]	Loss: 0.154066
Train epoch: 622 [1963080/78836 (91%)]	Loss: 0.167885
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 623 [0/78836 (0%)]	Loss: 0.165166
Train epoch: 623 [280700/78836 (13%)]	Loss: 0.165203
Train epoch: 623 [557880/78836 (26%)]	Loss: 0.169007
Train epoch: 623 [831180/78836 (39%)]	Loss: 0.223463
Train epoch: 623 [1109920/78836 (52%)]	Loss: 0.170120
Train epoch: 623 [1413000/78836 (65%)]	Loss: 0.189591
Train epoch: 623 [1635600/78836 (78%)]	Loss: 0.166297
Train epoch: 623 [1961960/78836 (91%)]	Loss: 0.167038
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 624 [0/78836 (0%)]	Loss: 0.167463
Train epoch: 624 [277820/78836 (13%)]	Loss: 0.168839
Train epoch: 624 [554000/78836 (26%)]	Loss: 0.166655
Train epoch: 624 [840480/78836 (39%)]	Loss: 0.155271
Train epoch: 624 [1115040/78836 (52%)]	Loss: 0.157684
Train epoch: 624 [1414500/78836 (65%)]	Loss: 0.188133
Train epoch: 624 [1713960/78836 (78%)]	Loss: 0.178395
Train epoch: 624 [1940960/78836 (91%)]	Loss: 0.135633
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 625 [0/78836 (0%)]	Loss: 0.161251
Train epoch: 625 [285980/78836 (13%)]	Loss: 0.187731
Train epoch: 625 [559400/78836 (26%)]	Loss: 0.177896
Train epoch: 625 [836640/78836 (39%)]	Loss: 0.145763
Train epoch: 625 [1091360/78836 (52%)]	Loss: 0.140797
Train epoch: 625 [1417200/78836 (65%)]	Loss: 0.162715
Train epoch: 625 [1692600/78836 (78%)]	Loss: 0.192682
Train epoch: 625 [1949080/78836 (91%)]	Loss: 0.183791
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 626 [0/78836 (0%)]	Loss: 0.159427
Train epoch: 626 [285980/78836 (13%)]	Loss: 0.149169
Train epoch: 626 [554600/78836 (26%)]	Loss: 0.166344
Train epoch: 626 [833220/78836 (39%)]	Loss: 0.144739
Train epoch: 626 [1111600/78836 (52%)]	Loss: 0.154253
Train epoch: 626 [1396400/78836 (65%)]	Loss: 0.198156
Train epoch: 626 [1682520/78836 (78%)]	Loss: 0.159541
Train epoch: 626 [1954120/78836 (91%)]	Loss: 0.151069
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 627 [0/78836 (0%)]	Loss: 0.185701
Train epoch: 627 [277160/78836 (13%)]	Loss: 0.162032
Train epoch: 627 [559240/78836 (26%)]	Loss: 0.215552
Train epoch: 627 [863940/78836 (39%)]	Loss: 0.144014
Train epoch: 627 [1117680/78836 (52%)]	Loss: 0.201202
Train epoch: 627 [1402500/78836 (65%)]	Loss: 0.188790
Train epoch: 627 [1679040/78836 (78%)]	Loss: 0.166944
Train epoch: 627 [1922760/78836 (91%)]	Loss: 0.188592
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 628 [0/78836 (0%)]	Loss: 0.158860
Train epoch: 628 [280040/78836 (13%)]	Loss: 0.175745
Train epoch: 628 [560840/78836 (26%)]	Loss: 0.170057
Train epoch: 628 [837900/78836 (39%)]	Loss: 0.178402
Train epoch: 628 [1112320/78836 (52%)]	Loss: 0.159303
Train epoch: 628 [1402800/78836 (65%)]	Loss: 0.180662
Train epoch: 628 [1661160/78836 (78%)]	Loss: 0.154412
Train epoch: 628 [1976380/78836 (91%)]	Loss: 0.195624
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 629 [0/78836 (0%)]	Loss: 0.162665
Train epoch: 629 [276140/78836 (13%)]	Loss: 0.175328
Train epoch: 629 [567920/78836 (26%)]	Loss: 0.147303
Train epoch: 629 [848820/78836 (39%)]	Loss: 0.146707
Train epoch: 629 [1142800/78836 (52%)]	Loss: 0.164317
Train epoch: 629 [1389300/78836 (65%)]	Loss: 0.168444
Train epoch: 629 [1690680/78836 (78%)]	Loss: 0.197253
Train epoch: 629 [1952860/78836 (91%)]	Loss: 0.172026
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 630 [0/78836 (0%)]	Loss: 0.163623
Train epoch: 630 [281380/78836 (13%)]	Loss: 0.190708
Train epoch: 630 [562480/78836 (26%)]	Loss: 0.146810
Train epoch: 630 [847740/78836 (39%)]	Loss: 0.147032
Train epoch: 630 [1098000/78836 (52%)]	Loss: 0.147517
Train epoch: 630 [1362000/78836 (65%)]	Loss: 0.146421
Train epoch: 630 [1680840/78836 (78%)]	Loss: 0.164329
Train epoch: 630 [1976800/78836 (91%)]	Loss: 0.144188
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 631 [0/78836 (0%)]	Loss: 0.175072
Train epoch: 631 [281060/78836 (13%)]	Loss: 0.144144
Train epoch: 631 [552120/78836 (26%)]	Loss: 0.167938
Train epoch: 631 [840540/78836 (39%)]	Loss: 0.199650
Train epoch: 631 [1140800/78836 (52%)]	Loss: 0.169980
Train epoch: 631 [1404300/78836 (65%)]	Loss: 0.140989
Train epoch: 631 [1675800/78836 (78%)]	Loss: 0.143121
Train epoch: 631 [1981560/78836 (91%)]	Loss: 0.145531
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 632 [0/78836 (0%)]	Loss: 0.167240
Train epoch: 632 [279300/78836 (13%)]	Loss: 0.168447
Train epoch: 632 [549880/78836 (26%)]	Loss: 0.140768
Train epoch: 632 [836280/78836 (39%)]	Loss: 0.190903
Train epoch: 632 [1100880/78836 (52%)]	Loss: 0.143854
Train epoch: 632 [1399700/78836 (65%)]	Loss: 0.143212
Train epoch: 632 [1663080/78836 (78%)]	Loss: 0.147546
Train epoch: 632 [1927380/78836 (91%)]	Loss: 0.189987
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 633 [0/78836 (0%)]	Loss: 0.162501
Train epoch: 633 [278840/78836 (13%)]	Loss: 0.179965
Train epoch: 633 [556120/78836 (26%)]	Loss: 0.194278
Train epoch: 633 [834480/78836 (39%)]	Loss: 0.183464
Train epoch: 633 [1105120/78836 (52%)]	Loss: 0.179750
Train epoch: 633 [1423200/78836 (65%)]	Loss: 0.204264
Train epoch: 633 [1710000/78836 (78%)]	Loss: 0.193700
Train epoch: 633 [1926820/78836 (91%)]	Loss: 0.168371
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 634 [0/78836 (0%)]	Loss: 0.133222
Train epoch: 634 [275280/78836 (13%)]	Loss: 0.166043
Train epoch: 634 [555640/78836 (26%)]	Loss: 0.182784
Train epoch: 634 [835620/78836 (39%)]	Loss: 0.143904
Train epoch: 634 [1161200/78836 (52%)]	Loss: 0.160841
Train epoch: 634 [1394600/78836 (65%)]	Loss: 0.135058
Train epoch: 634 [1682760/78836 (78%)]	Loss: 0.154449
Train epoch: 634 [1922060/78836 (91%)]	Loss: 0.165097
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 635 [0/78836 (0%)]	Loss: 0.162330
Train epoch: 635 [273880/78836 (13%)]	Loss: 0.156929
Train epoch: 635 [562320/78836 (26%)]	Loss: 0.177288
Train epoch: 635 [831600/78836 (39%)]	Loss: 0.170091
Train epoch: 635 [1122720/78836 (52%)]	Loss: 0.177821
Train epoch: 635 [1387800/78836 (65%)]	Loss: 0.140159
Train epoch: 635 [1679280/78836 (78%)]	Loss: 0.131450
Train epoch: 635 [1951880/78836 (91%)]	Loss: 0.195242
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 636 [0/78836 (0%)]	Loss: 0.124822
Train epoch: 636 [277700/78836 (13%)]	Loss: 0.147480
Train epoch: 636 [545680/78836 (26%)]	Loss: 0.158681
Train epoch: 636 [840840/78836 (39%)]	Loss: 0.178317
Train epoch: 636 [1117680/78836 (52%)]	Loss: 0.173138
Train epoch: 636 [1382900/78836 (65%)]	Loss: 0.156257
Train epoch: 636 [1690800/78836 (78%)]	Loss: 0.146016
Train epoch: 636 [1998360/78836 (91%)]	Loss: 0.174658
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 637 [0/78836 (0%)]	Loss: 0.156869
Train epoch: 637 [278360/78836 (13%)]	Loss: 0.162110
Train epoch: 637 [568200/78836 (26%)]	Loss: 0.138550
Train epoch: 637 [826200/78836 (39%)]	Loss: 0.162600
Train epoch: 637 [1109120/78836 (52%)]	Loss: 0.185399
Train epoch: 637 [1385200/78836 (65%)]	Loss: 0.163299
Train epoch: 637 [1670160/78836 (78%)]	Loss: 0.151962
Train epoch: 637 [1946140/78836 (91%)]	Loss: 0.124054
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 638 [0/78836 (0%)]	Loss: 0.151842
Train epoch: 638 [279060/78836 (13%)]	Loss: 0.172452
Train epoch: 638 [560560/78836 (26%)]	Loss: 0.118858
Train epoch: 638 [836100/78836 (39%)]	Loss: 0.163251
Train epoch: 638 [1124000/78836 (52%)]	Loss: 0.223227
Train epoch: 638 [1396700/78836 (65%)]	Loss: 0.149960
Train epoch: 638 [1654320/78836 (78%)]	Loss: 0.175195
Train epoch: 638 [1913380/78836 (91%)]	Loss: 0.169773
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 639 [0/78836 (0%)]	Loss: 0.156240
Train epoch: 639 [279000/78836 (13%)]	Loss: 0.160358
Train epoch: 639 [555160/78836 (26%)]	Loss: 0.163747
Train epoch: 639 [837120/78836 (39%)]	Loss: 0.144075
Train epoch: 639 [1127040/78836 (52%)]	Loss: 0.171389
Train epoch: 639 [1402400/78836 (65%)]	Loss: 0.154007
Train epoch: 639 [1691760/78836 (78%)]	Loss: 0.143018
Train epoch: 639 [1968960/78836 (91%)]	Loss: 0.144909
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 640 [0/78836 (0%)]	Loss: 0.161976
Train epoch: 640 [279440/78836 (13%)]	Loss: 0.140328
Train epoch: 640 [559640/78836 (26%)]	Loss: 0.168029
Train epoch: 640 [853440/78836 (39%)]	Loss: 0.153957
Train epoch: 640 [1130560/78836 (52%)]	Loss: 0.157821
Train epoch: 640 [1402600/78836 (65%)]	Loss: 0.147779
Train epoch: 640 [1703760/78836 (78%)]	Loss: 0.141663
Train epoch: 640 [1947260/78836 (91%)]	Loss: 0.141424
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 641 [0/78836 (0%)]	Loss: 0.134182
Train epoch: 641 [285200/78836 (13%)]	Loss: 0.164118
Train epoch: 641 [559720/78836 (26%)]	Loss: 0.184031
Train epoch: 641 [832980/78836 (39%)]	Loss: 0.139996
Train epoch: 641 [1139760/78836 (52%)]	Loss: 0.144673
Train epoch: 641 [1389700/78836 (65%)]	Loss: 0.143972
Train epoch: 641 [1669200/78836 (78%)]	Loss: 0.143692
Train epoch: 641 [1929620/78836 (91%)]	Loss: 0.152711
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 642 [0/78836 (0%)]	Loss: 0.149080
Train epoch: 642 [278980/78836 (13%)]	Loss: 0.152907
Train epoch: 642 [564960/78836 (26%)]	Loss: 0.192993
Train epoch: 642 [837120/78836 (39%)]	Loss: 0.202792
Train epoch: 642 [1090720/78836 (52%)]	Loss: 0.157344
Train epoch: 642 [1390800/78836 (65%)]	Loss: 0.173019
Train epoch: 642 [1662360/78836 (78%)]	Loss: 0.192817
Train epoch: 642 [1984220/78836 (91%)]	Loss: 0.150336
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 643 [0/78836 (0%)]	Loss: 0.172723
Train epoch: 643 [284420/78836 (13%)]	Loss: 0.174073
Train epoch: 643 [554840/78836 (26%)]	Loss: 0.185741
Train epoch: 643 [836580/78836 (39%)]	Loss: 0.145350
Train epoch: 643 [1105520/78836 (52%)]	Loss: 0.140188
Train epoch: 643 [1419500/78836 (65%)]	Loss: 0.158314
Train epoch: 643 [1723560/78836 (78%)]	Loss: 0.193783
Train epoch: 643 [1946280/78836 (91%)]	Loss: 0.181767
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 644 [0/78836 (0%)]	Loss: 0.146710
Train epoch: 644 [281440/78836 (13%)]	Loss: 0.140639
Train epoch: 644 [560840/78836 (26%)]	Loss: 0.139434
Train epoch: 644 [836700/78836 (39%)]	Loss: 0.152812
Train epoch: 644 [1106480/78836 (52%)]	Loss: 0.182521
Train epoch: 644 [1403700/78836 (65%)]	Loss: 0.176213
Train epoch: 644 [1707120/78836 (78%)]	Loss: 0.156398
Train epoch: 644 [1984640/78836 (91%)]	Loss: 0.183140
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 645 [0/78836 (0%)]	Loss: 0.156801
Train epoch: 645 [282360/78836 (13%)]	Loss: 0.160861
Train epoch: 645 [565520/78836 (26%)]	Loss: 0.129428
Train epoch: 645 [835320/78836 (39%)]	Loss: 0.178758
Train epoch: 645 [1110960/78836 (52%)]	Loss: 0.170766
Train epoch: 645 [1386000/78836 (65%)]	Loss: 0.145950
Train epoch: 645 [1684680/78836 (78%)]	Loss: 0.156708
Train epoch: 645 [1968820/78836 (91%)]	Loss: 0.168738
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 646 [0/78836 (0%)]	Loss: 0.152993
Train epoch: 646 [273580/78836 (13%)]	Loss: 0.138327
Train epoch: 646 [558800/78836 (26%)]	Loss: 0.158207
Train epoch: 646 [843300/78836 (39%)]	Loss: 0.157174
Train epoch: 646 [1104960/78836 (52%)]	Loss: 0.171464
Train epoch: 646 [1386200/78836 (65%)]	Loss: 0.194182
Train epoch: 646 [1671600/78836 (78%)]	Loss: 0.160994
Train epoch: 646 [1918560/78836 (91%)]	Loss: 0.119360
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 647 [0/78836 (0%)]	Loss: 0.128417
Train epoch: 647 [284000/78836 (13%)]	Loss: 0.160942
Train epoch: 647 [552160/78836 (26%)]	Loss: 0.159339
Train epoch: 647 [827100/78836 (39%)]	Loss: 0.178108
Train epoch: 647 [1112320/78836 (52%)]	Loss: 0.150308
Train epoch: 647 [1386700/78836 (65%)]	Loss: 0.168402
Train epoch: 647 [1713960/78836 (78%)]	Loss: 0.123862
Train epoch: 647 [1947260/78836 (91%)]	Loss: 0.157330
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 648 [0/78836 (0%)]	Loss: 0.160419
Train epoch: 648 [273280/78836 (13%)]	Loss: 0.152620
Train epoch: 648 [547280/78836 (26%)]	Loss: 0.158661
Train epoch: 648 [833160/78836 (39%)]	Loss: 0.159021
Train epoch: 648 [1107680/78836 (52%)]	Loss: 0.141127
Train epoch: 648 [1440800/78836 (65%)]	Loss: 0.154722
Train epoch: 648 [1707240/78836 (78%)]	Loss: 0.139159
Train epoch: 648 [1940260/78836 (91%)]	Loss: 0.149908
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 649 [0/78836 (0%)]	Loss: 0.164908
Train epoch: 649 [287660/78836 (13%)]	Loss: 0.144308
Train epoch: 649 [554080/78836 (26%)]	Loss: 0.157791
Train epoch: 649 [831960/78836 (39%)]	Loss: 0.154851
Train epoch: 649 [1124000/78836 (52%)]	Loss: 0.155028
Train epoch: 649 [1396800/78836 (65%)]	Loss: 0.148133
Train epoch: 649 [1681800/78836 (78%)]	Loss: 0.164548
Train epoch: 649 [1945160/78836 (91%)]	Loss: 0.146970
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 650 [0/78836 (0%)]	Loss: 0.130767
Train epoch: 650 [285020/78836 (13%)]	Loss: 0.148145
Train epoch: 650 [555400/78836 (26%)]	Loss: 0.167590
Train epoch: 650 [840480/78836 (39%)]	Loss: 0.167185
Train epoch: 650 [1123040/78836 (52%)]	Loss: 0.149085
Train epoch: 650 [1362400/78836 (65%)]	Loss: 0.167114
Train epoch: 650 [1664760/78836 (78%)]	Loss: 0.141001
Train epoch: 650 [1956360/78836 (91%)]	Loss: 0.138090
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 651 [0/78836 (0%)]	Loss: 0.139500
Train epoch: 651 [276980/78836 (13%)]	Loss: 0.158281
Train epoch: 651 [550560/78836 (26%)]	Loss: 0.145309
Train epoch: 651 [850140/78836 (39%)]	Loss: 0.148154
Train epoch: 651 [1099840/78836 (52%)]	Loss: 0.147928
Train epoch: 651 [1404000/78836 (65%)]	Loss: 0.155005
Train epoch: 651 [1686480/78836 (78%)]	Loss: 0.157622
Train epoch: 651 [1972320/78836 (91%)]	Loss: 0.157696
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 652 [0/78836 (0%)]	Loss: 0.150571
Train epoch: 652 [273100/78836 (13%)]	Loss: 0.166864
Train epoch: 652 [562440/78836 (26%)]	Loss: 0.186968
Train epoch: 652 [840960/78836 (39%)]	Loss: 0.171287
Train epoch: 652 [1125200/78836 (52%)]	Loss: 0.142933
Train epoch: 652 [1397700/78836 (65%)]	Loss: 0.179098
Train epoch: 652 [1700640/78836 (78%)]	Loss: 0.143794
Train epoch: 652 [1937600/78836 (91%)]	Loss: 0.154802
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 653 [0/78836 (0%)]	Loss: 0.163776
Train epoch: 653 [283080/78836 (13%)]	Loss: 0.137805
Train epoch: 653 [565920/78836 (26%)]	Loss: 0.154088
Train epoch: 653 [839400/78836 (39%)]	Loss: 0.136006
Train epoch: 653 [1111760/78836 (52%)]	Loss: 0.143122
Train epoch: 653 [1385800/78836 (65%)]	Loss: 0.172662
Train epoch: 653 [1683720/78836 (78%)]	Loss: 0.157893
Train epoch: 653 [1928080/78836 (91%)]	Loss: 0.128804
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 654 [0/78836 (0%)]	Loss: 0.170236
Train epoch: 654 [278400/78836 (13%)]	Loss: 0.196305
Train epoch: 654 [552400/78836 (26%)]	Loss: 0.158227
Train epoch: 654 [847320/78836 (39%)]	Loss: 0.199334
Train epoch: 654 [1121840/78836 (52%)]	Loss: 0.156599
Train epoch: 654 [1391900/78836 (65%)]	Loss: 0.133700
Train epoch: 654 [1688520/78836 (78%)]	Loss: 0.128929
Train epoch: 654 [1960420/78836 (91%)]	Loss: 0.175125
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 655 [0/78836 (0%)]	Loss: 0.160396
Train epoch: 655 [281800/78836 (13%)]	Loss: 0.147411
Train epoch: 655 [567000/78836 (26%)]	Loss: 0.145191
Train epoch: 655 [851100/78836 (39%)]	Loss: 0.148572
Train epoch: 655 [1111360/78836 (52%)]	Loss: 0.131259
Train epoch: 655 [1361500/78836 (65%)]	Loss: 0.173433
Train epoch: 655 [1653960/78836 (78%)]	Loss: 0.150093
Train epoch: 655 [1984920/78836 (91%)]	Loss: 0.159522
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 656 [0/78836 (0%)]	Loss: 0.142318
Train epoch: 656 [277320/78836 (13%)]	Loss: 0.169315
Train epoch: 656 [551000/78836 (26%)]	Loss: 0.152648
Train epoch: 656 [830700/78836 (39%)]	Loss: 0.143936
Train epoch: 656 [1112240/78836 (52%)]	Loss: 0.132153
Train epoch: 656 [1421700/78836 (65%)]	Loss: 0.158037
Train epoch: 656 [1679280/78836 (78%)]	Loss: 0.143262
Train epoch: 656 [1956360/78836 (91%)]	Loss: 0.160761
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 657 [0/78836 (0%)]	Loss: 0.140369
Train epoch: 657 [281160/78836 (13%)]	Loss: 0.129811
Train epoch: 657 [562880/78836 (26%)]	Loss: 0.130152
Train epoch: 657 [836340/78836 (39%)]	Loss: 0.150280
Train epoch: 657 [1097760/78836 (52%)]	Loss: 0.159626
Train epoch: 657 [1420800/78836 (65%)]	Loss: 0.166935
Train epoch: 657 [1673520/78836 (78%)]	Loss: 0.165789
Train epoch: 657 [1950760/78836 (91%)]	Loss: 0.137513
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 658 [0/78836 (0%)]	Loss: 0.138699
Train epoch: 658 [275600/78836 (13%)]	Loss: 0.148644
Train epoch: 658 [570040/78836 (26%)]	Loss: 0.147936
Train epoch: 658 [829140/78836 (39%)]	Loss: 0.153439
Train epoch: 658 [1121360/78836 (52%)]	Loss: 0.169108
Train epoch: 658 [1409000/78836 (65%)]	Loss: 0.155060
Train epoch: 658 [1691640/78836 (78%)]	Loss: 0.201409
Train epoch: 658 [1967700/78836 (91%)]	Loss: 0.155366
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 659 [0/78836 (0%)]	Loss: 0.121677
Train epoch: 659 [278780/78836 (13%)]	Loss: 0.134358
Train epoch: 659 [567920/78836 (26%)]	Loss: 0.149739
Train epoch: 659 [841740/78836 (39%)]	Loss: 0.142526
Train epoch: 659 [1114960/78836 (52%)]	Loss: 0.197095
Train epoch: 659 [1394700/78836 (65%)]	Loss: 0.165818
Train epoch: 659 [1702200/78836 (78%)]	Loss: 0.148780
Train epoch: 659 [1961960/78836 (91%)]	Loss: 0.166821
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 660 [0/78836 (0%)]	Loss: 0.131583
Train epoch: 660 [282440/78836 (13%)]	Loss: 0.149411
Train epoch: 660 [559840/78836 (26%)]	Loss: 0.158717
Train epoch: 660 [866580/78836 (39%)]	Loss: 0.128751
Train epoch: 660 [1101440/78836 (52%)]	Loss: 0.167562
Train epoch: 660 [1402000/78836 (65%)]	Loss: 0.147835
Train epoch: 660 [1703040/78836 (78%)]	Loss: 0.170848
Train epoch: 660 [1971760/78836 (91%)]	Loss: 0.206815
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 661 [0/78836 (0%)]	Loss: 0.146808
Train epoch: 661 [281560/78836 (13%)]	Loss: 0.161708
Train epoch: 661 [568160/78836 (26%)]	Loss: 0.137969
Train epoch: 661 [837600/78836 (39%)]	Loss: 0.142362
Train epoch: 661 [1148480/78836 (52%)]	Loss: 0.178666
Train epoch: 661 [1414200/78836 (65%)]	Loss: 0.181518
Train epoch: 661 [1674840/78836 (78%)]	Loss: 0.147952
Train epoch: 661 [1968400/78836 (91%)]	Loss: 0.139084
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 662 [0/78836 (0%)]	Loss: 0.161457
Train epoch: 662 [277540/78836 (13%)]	Loss: 0.163124
Train epoch: 662 [556840/78836 (26%)]	Loss: 0.138353
Train epoch: 662 [835200/78836 (39%)]	Loss: 0.163000
Train epoch: 662 [1094160/78836 (52%)]	Loss: 0.169868
Train epoch: 662 [1424700/78836 (65%)]	Loss: 0.166501
Train epoch: 662 [1666200/78836 (78%)]	Loss: 0.176568
Train epoch: 662 [1916460/78836 (91%)]	Loss: 0.152755
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 663 [0/78836 (0%)]	Loss: 0.147540
Train epoch: 663 [286020/78836 (13%)]	Loss: 0.151979
Train epoch: 663 [550440/78836 (26%)]	Loss: 0.170141
Train epoch: 663 [826260/78836 (39%)]	Loss: 0.141062
Train epoch: 663 [1135360/78836 (52%)]	Loss: 0.122752
Train epoch: 663 [1400500/78836 (65%)]	Loss: 0.161180
Train epoch: 663 [1688640/78836 (78%)]	Loss: 0.158094
Train epoch: 663 [2020620/78836 (91%)]	Loss: 0.156235
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 664 [0/78836 (0%)]	Loss: 0.153625
Train epoch: 664 [279000/78836 (13%)]	Loss: 0.127504
Train epoch: 664 [552000/78836 (26%)]	Loss: 0.179485
Train epoch: 664 [850020/78836 (39%)]	Loss: 0.162140
Train epoch: 664 [1100640/78836 (52%)]	Loss: 0.150881
Train epoch: 664 [1387900/78836 (65%)]	Loss: 0.173403
Train epoch: 664 [1669080/78836 (78%)]	Loss: 0.113371
Train epoch: 664 [1962800/78836 (91%)]	Loss: 0.140211
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 665 [0/78836 (0%)]	Loss: 0.134548
Train epoch: 665 [281100/78836 (13%)]	Loss: 0.149354
Train epoch: 665 [561120/78836 (26%)]	Loss: 0.144551
Train epoch: 665 [846540/78836 (39%)]	Loss: 0.149378
Train epoch: 665 [1104560/78836 (52%)]	Loss: 0.146106
Train epoch: 665 [1392500/78836 (65%)]	Loss: 0.147528
Train epoch: 665 [1647720/78836 (78%)]	Loss: 0.192363
Train epoch: 665 [1945300/78836 (91%)]	Loss: 0.160797
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 666 [0/78836 (0%)]	Loss: 0.152157
Train epoch: 666 [274340/78836 (13%)]	Loss: 0.136370
Train epoch: 666 [559440/78836 (26%)]	Loss: 0.148272
Train epoch: 666 [847620/78836 (39%)]	Loss: 0.163545
Train epoch: 666 [1133520/78836 (52%)]	Loss: 0.143640
Train epoch: 666 [1395100/78836 (65%)]	Loss: 0.130177
Train epoch: 666 [1685640/78836 (78%)]	Loss: 0.156015
Train epoch: 666 [1972460/78836 (91%)]	Loss: 0.152584
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 667 [0/78836 (0%)]	Loss: 0.131223
Train epoch: 667 [287500/78836 (13%)]	Loss: 0.160639
Train epoch: 667 [562240/78836 (26%)]	Loss: 0.149281
Train epoch: 667 [857580/78836 (39%)]	Loss: 0.152518
Train epoch: 667 [1130160/78836 (52%)]	Loss: 0.165704
Train epoch: 667 [1399000/78836 (65%)]	Loss: 0.175277
Train epoch: 667 [1662000/78836 (78%)]	Loss: 0.132923
Train epoch: 667 [1970920/78836 (91%)]	Loss: 0.155848
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 668 [0/78836 (0%)]	Loss: 0.146761
Train epoch: 668 [277540/78836 (13%)]	Loss: 0.147112
Train epoch: 668 [549040/78836 (26%)]	Loss: 0.125282
Train epoch: 668 [840600/78836 (39%)]	Loss: 0.155513
Train epoch: 668 [1113120/78836 (52%)]	Loss: 0.141639
Train epoch: 668 [1403800/78836 (65%)]	Loss: 0.148072
Train epoch: 668 [1663920/78836 (78%)]	Loss: 0.148784
Train epoch: 668 [1972040/78836 (91%)]	Loss: 0.127531
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 669 [0/78836 (0%)]	Loss: 0.122105
Train epoch: 669 [280560/78836 (13%)]	Loss: 0.126878
Train epoch: 669 [563440/78836 (26%)]	Loss: 0.180002
Train epoch: 669 [835980/78836 (39%)]	Loss: 0.134029
Train epoch: 669 [1112480/78836 (52%)]	Loss: 0.140113
Train epoch: 669 [1379900/78836 (65%)]	Loss: 0.138270
Train epoch: 669 [1665000/78836 (78%)]	Loss: 0.132944
Train epoch: 669 [1929060/78836 (91%)]	Loss: 0.125154
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 670 [0/78836 (0%)]	Loss: 0.175400
Train epoch: 670 [276620/78836 (13%)]	Loss: 0.169014
Train epoch: 670 [551080/78836 (26%)]	Loss: 0.137509
Train epoch: 670 [842640/78836 (39%)]	Loss: 0.129003
Train epoch: 670 [1123760/78836 (52%)]	Loss: 0.173148
Train epoch: 670 [1421900/78836 (65%)]	Loss: 0.189661
Train epoch: 670 [1663440/78836 (78%)]	Loss: 0.143195
Train epoch: 670 [1998500/78836 (91%)]	Loss: 0.165118
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 671 [0/78836 (0%)]	Loss: 0.117012
Train epoch: 671 [275420/78836 (13%)]	Loss: 0.152467
Train epoch: 671 [551400/78836 (26%)]	Loss: 0.162070
Train epoch: 671 [832140/78836 (39%)]	Loss: 0.141703
Train epoch: 671 [1102800/78836 (52%)]	Loss: 0.146183
Train epoch: 671 [1391000/78836 (65%)]	Loss: 0.137194
Train epoch: 671 [1717560/78836 (78%)]	Loss: 0.124422
Train epoch: 671 [1960560/78836 (91%)]	Loss: 0.153900
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 672 [0/78836 (0%)]	Loss: 0.147368
Train epoch: 672 [279940/78836 (13%)]	Loss: 0.127373
Train epoch: 672 [557920/78836 (26%)]	Loss: 0.130107
Train epoch: 672 [828900/78836 (39%)]	Loss: 0.168680
Train epoch: 672 [1098640/78836 (52%)]	Loss: 0.146861
Train epoch: 672 [1367500/78836 (65%)]	Loss: 0.161882
Train epoch: 672 [1685520/78836 (78%)]	Loss: 0.149214
Train epoch: 672 [1962100/78836 (91%)]	Loss: 0.152766
predicting for valid data
Make prediction for 19709 samples...
0.18024223 No improvement since epoch  548 ; best_test_mse,best_test_ci: 0.18024223 0.8537533634614626 GINConvNet kiba
Training on 78836 samples...
Train epoch: 673 [0/78836 (0%)]	Loss: 0.125866
Train epoch: 673 [272180/78836 (13%)]	Loss: 0.153708
Train epoch: 673 [552120/78836 (26%)]	Loss: 0.134146
Train epoch: 673 [829440/78836 (39%)]	Loss: 0.129535
Train epoch: 673 [1125680/78836 (52%)]	Loss: 0.145943
Train epoch: 673 [1413500/78836 (65%)]	Loss: 0.152275
Train epoch: 673 [1686480/78836 (78%)]	Loss: 0.140118
Train epoch: 673 [1969240/78836 (91%)]	Loss: 0.158156
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  673 ; best_test_mse,best_test_ci: 0.17649828 0.8575492970645952 GINConvNet kiba
Training on 78836 samples...
Train epoch: 674 [0/78836 (0%)]	Loss: 0.151634
Train epoch: 674 [278180/78836 (13%)]	Loss: 0.158448
Train epoch: 674 [566400/78836 (26%)]	Loss: 0.115850
Train epoch: 674 [823140/78836 (39%)]	Loss: 0.137839
Train epoch: 674 [1090080/78836 (52%)]	Loss: 0.157245
Train epoch: 674 [1393400/78836 (65%)]	Loss: 0.152849
Train epoch: 674 [1698360/78836 (78%)]	Loss: 0.128059
Train epoch: 674 [1977920/78836 (91%)]	Loss: 0.134480
predicting for valid data
Make prediction for 19709 samples...
0.17649828 No improvement since epoch  673 ; best_test_mse,best_test_ci: 0.17649828 0.8575492970645952 GINConvNet kiba
Training on 78836 samples...
Train epoch: 675 [0/78836 (0%)]	Loss: 0.123793
Train epoch: 675 [276080/78836 (13%)]	Loss: 0.132493
Train epoch: 675 [561640/78836 (26%)]	Loss: 0.148197
Train epoch: 675 [848940/78836 (39%)]	Loss: 0.118867
Train epoch: 675 [1130160/78836 (52%)]	Loss: 0.138427
Train epoch: 675 [1369000/78836 (65%)]	Loss: 0.141944
Train epoch: 675 [1720680/78836 (78%)]	Loss: 0.183535
Train epoch: 675 [1949360/78836 (91%)]	Loss: 0.131040
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 676 [0/78836 (0%)]	Loss: 0.147393
Train epoch: 676 [275840/78836 (13%)]	Loss: 0.150488
Train epoch: 676 [555920/78836 (26%)]	Loss: 0.142635
Train epoch: 676 [829620/78836 (39%)]	Loss: 0.141267
Train epoch: 676 [1114400/78836 (52%)]	Loss: 0.172069
Train epoch: 676 [1388600/78836 (65%)]	Loss: 0.149269
Train epoch: 676 [1689720/78836 (78%)]	Loss: 0.139357
Train epoch: 676 [1968260/78836 (91%)]	Loss: 0.148985
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 677 [0/78836 (0%)]	Loss: 0.129956
Train epoch: 677 [279900/78836 (13%)]	Loss: 0.129438
Train epoch: 677 [547600/78836 (26%)]	Loss: 0.169411
Train epoch: 677 [840600/78836 (39%)]	Loss: 0.136671
Train epoch: 677 [1123520/78836 (52%)]	Loss: 0.124716
Train epoch: 677 [1371500/78836 (65%)]	Loss: 0.130373
Train epoch: 677 [1698840/78836 (78%)]	Loss: 0.163053
Train epoch: 677 [1951600/78836 (91%)]	Loss: 0.129685
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 678 [0/78836 (0%)]	Loss: 0.140741
Train epoch: 678 [283940/78836 (13%)]	Loss: 0.147762
Train epoch: 678 [557920/78836 (26%)]	Loss: 0.120902
Train epoch: 678 [838620/78836 (39%)]	Loss: 0.152860
Train epoch: 678 [1134000/78836 (52%)]	Loss: 0.141090
Train epoch: 678 [1374600/78836 (65%)]	Loss: 0.125941
Train epoch: 678 [1661400/78836 (78%)]	Loss: 0.158800
Train epoch: 678 [1927800/78836 (91%)]	Loss: 0.115904
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 679 [0/78836 (0%)]	Loss: 0.126645
Train epoch: 679 [280720/78836 (13%)]	Loss: 0.127178
Train epoch: 679 [570560/78836 (26%)]	Loss: 0.144948
Train epoch: 679 [848640/78836 (39%)]	Loss: 0.129648
Train epoch: 679 [1103040/78836 (52%)]	Loss: 0.132727
Train epoch: 679 [1418800/78836 (65%)]	Loss: 0.136195
Train epoch: 679 [1692120/78836 (78%)]	Loss: 0.147119
Train epoch: 679 [1951320/78836 (91%)]	Loss: 0.162926
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 680 [0/78836 (0%)]	Loss: 0.152688
Train epoch: 680 [285660/78836 (13%)]	Loss: 0.140987
Train epoch: 680 [558160/78836 (26%)]	Loss: 0.135584
Train epoch: 680 [826440/78836 (39%)]	Loss: 0.160435
Train epoch: 680 [1109280/78836 (52%)]	Loss: 0.118207
Train epoch: 680 [1389700/78836 (65%)]	Loss: 0.154607
Train epoch: 680 [1668960/78836 (78%)]	Loss: 0.130642
Train epoch: 680 [1960840/78836 (91%)]	Loss: 0.139246
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 681 [0/78836 (0%)]	Loss: 0.140907
Train epoch: 681 [279520/78836 (13%)]	Loss: 0.153195
Train epoch: 681 [561120/78836 (26%)]	Loss: 0.147606
Train epoch: 681 [838980/78836 (39%)]	Loss: 0.150284
Train epoch: 681 [1096000/78836 (52%)]	Loss: 0.143139
Train epoch: 681 [1399100/78836 (65%)]	Loss: 0.113286
Train epoch: 681 [1665720/78836 (78%)]	Loss: 0.168886
Train epoch: 681 [1933120/78836 (91%)]	Loss: 0.153587
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 682 [0/78836 (0%)]	Loss: 0.128321
Train epoch: 682 [279220/78836 (13%)]	Loss: 0.152258
Train epoch: 682 [558720/78836 (26%)]	Loss: 0.146101
Train epoch: 682 [833520/78836 (39%)]	Loss: 0.168937
Train epoch: 682 [1130800/78836 (52%)]	Loss: 0.169642
Train epoch: 682 [1418000/78836 (65%)]	Loss: 0.136257
Train epoch: 682 [1675080/78836 (78%)]	Loss: 0.138504
Train epoch: 682 [1984500/78836 (91%)]	Loss: 0.136352
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 683 [0/78836 (0%)]	Loss: 0.171556
Train epoch: 683 [275880/78836 (13%)]	Loss: 0.144173
Train epoch: 683 [548560/78836 (26%)]	Loss: 0.130959
Train epoch: 683 [830040/78836 (39%)]	Loss: 0.143136
Train epoch: 683 [1095760/78836 (52%)]	Loss: 0.129155
Train epoch: 683 [1404200/78836 (65%)]	Loss: 0.126904
Train epoch: 683 [1703040/78836 (78%)]	Loss: 0.140214
Train epoch: 683 [1960560/78836 (91%)]	Loss: 0.158247
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 684 [0/78836 (0%)]	Loss: 0.122620
Train epoch: 684 [278220/78836 (13%)]	Loss: 0.194464
Train epoch: 684 [557080/78836 (26%)]	Loss: 0.148969
Train epoch: 684 [836100/78836 (39%)]	Loss: 0.125081
Train epoch: 684 [1124160/78836 (52%)]	Loss: 0.132305
Train epoch: 684 [1366700/78836 (65%)]	Loss: 0.141354
Train epoch: 684 [1684080/78836 (78%)]	Loss: 0.138731
Train epoch: 684 [1976520/78836 (91%)]	Loss: 0.134497
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 685 [0/78836 (0%)]	Loss: 0.132677
Train epoch: 685 [276640/78836 (13%)]	Loss: 0.152032
Train epoch: 685 [555520/78836 (26%)]	Loss: 0.158301
Train epoch: 685 [828180/78836 (39%)]	Loss: 0.149512
Train epoch: 685 [1099680/78836 (52%)]	Loss: 0.126247
Train epoch: 685 [1381500/78836 (65%)]	Loss: 0.143598
Train epoch: 685 [1697040/78836 (78%)]	Loss: 0.148609
Train epoch: 685 [1943340/78836 (91%)]	Loss: 0.148690
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 686 [0/78836 (0%)]	Loss: 0.126898
Train epoch: 686 [283180/78836 (13%)]	Loss: 0.126446
Train epoch: 686 [566480/78836 (26%)]	Loss: 0.146647
Train epoch: 686 [845460/78836 (39%)]	Loss: 0.154149
Train epoch: 686 [1124160/78836 (52%)]	Loss: 0.144698
Train epoch: 686 [1381100/78836 (65%)]	Loss: 0.114033
Train epoch: 686 [1695000/78836 (78%)]	Loss: 0.145630
Train epoch: 686 [1956080/78836 (91%)]	Loss: 0.133486
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 687 [0/78836 (0%)]	Loss: 0.138513
Train epoch: 687 [276660/78836 (13%)]	Loss: 0.129706
Train epoch: 687 [546240/78836 (26%)]	Loss: 0.122323
Train epoch: 687 [861780/78836 (39%)]	Loss: 0.125098
Train epoch: 687 [1123840/78836 (52%)]	Loss: 0.155488
Train epoch: 687 [1422100/78836 (65%)]	Loss: 0.114442
Train epoch: 687 [1675560/78836 (78%)]	Loss: 0.161610
Train epoch: 687 [1947400/78836 (91%)]	Loss: 0.127883
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 688 [0/78836 (0%)]	Loss: 0.133352
Train epoch: 688 [274620/78836 (13%)]	Loss: 0.102110
Train epoch: 688 [566640/78836 (26%)]	Loss: 0.145143
Train epoch: 688 [831600/78836 (39%)]	Loss: 0.130899
Train epoch: 688 [1107040/78836 (52%)]	Loss: 0.118076
Train epoch: 688 [1398600/78836 (65%)]	Loss: 0.102795
Train epoch: 688 [1688880/78836 (78%)]	Loss: 0.138364
Train epoch: 688 [1968540/78836 (91%)]	Loss: 0.129374
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 689 [0/78836 (0%)]	Loss: 0.146832
Train epoch: 689 [280600/78836 (13%)]	Loss: 0.125871
Train epoch: 689 [556560/78836 (26%)]	Loss: 0.140248
Train epoch: 689 [841200/78836 (39%)]	Loss: 0.139512
Train epoch: 689 [1111600/78836 (52%)]	Loss: 0.141026
Train epoch: 689 [1363200/78836 (65%)]	Loss: 0.156971
Train epoch: 689 [1675920/78836 (78%)]	Loss: 0.147800
Train epoch: 689 [1989540/78836 (91%)]	Loss: 0.123762
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 690 [0/78836 (0%)]	Loss: 0.120243
Train epoch: 690 [276980/78836 (13%)]	Loss: 0.130152
Train epoch: 690 [546960/78836 (26%)]	Loss: 0.125482
Train epoch: 690 [851340/78836 (39%)]	Loss: 0.145970
Train epoch: 690 [1111520/78836 (52%)]	Loss: 0.132259
Train epoch: 690 [1365600/78836 (65%)]	Loss: 0.137068
Train epoch: 690 [1668720/78836 (78%)]	Loss: 0.135437
Train epoch: 690 [1961400/78836 (91%)]	Loss: 0.136231
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 691 [0/78836 (0%)]	Loss: 0.121747
Train epoch: 691 [280120/78836 (13%)]	Loss: 0.117813
Train epoch: 691 [544560/78836 (26%)]	Loss: 0.123095
Train epoch: 691 [856680/78836 (39%)]	Loss: 0.136043
Train epoch: 691 [1152400/78836 (52%)]	Loss: 0.137139
Train epoch: 691 [1391600/78836 (65%)]	Loss: 0.144715
Train epoch: 691 [1673880/78836 (78%)]	Loss: 0.135995
Train epoch: 691 [1966580/78836 (91%)]	Loss: 0.146875
predicting for valid data
Make prediction for 19709 samples...
0.17590293 No improvement since epoch  675 ; best_test_mse,best_test_ci: 0.17590293 0.8590055184810742 GINConvNet kiba
Training on 78836 samples...
Train epoch: 692 [0/78836 (0%)]	Loss: 0.133272
Train epoch: 692 [272040/78836 (13%)]	Loss: 0.130566
Train epoch: 692 [553520/78836 (26%)]	Loss: 0.121425
Train epoch: 692 [840060/78836 (39%)]	Loss: 0.151442
Train epoch: 692 [1120320/78836 (52%)]	Loss: 0.136180
Train epoch: 692 [1412000/78836 (65%)]	Loss: 0.139527
Train epoch: 692 [1643520/78836 (78%)]	Loss: 0.139150
Train epoch: 692 [1979040/78836 (91%)]	Loss: 0.137595
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 693 [0/78836 (0%)]	Loss: 0.117231
Train epoch: 693 [279900/78836 (13%)]	Loss: 0.122389
Train epoch: 693 [562000/78836 (26%)]	Loss: 0.186149
Train epoch: 693 [837420/78836 (39%)]	Loss: 0.162095
Train epoch: 693 [1099040/78836 (52%)]	Loss: 0.124154
Train epoch: 693 [1372900/78836 (65%)]	Loss: 0.140946
Train epoch: 693 [1701120/78836 (78%)]	Loss: 0.123323
Train epoch: 693 [1965600/78836 (91%)]	Loss: 0.132217
predicting for valid data
Make prediction for 19709 samples...
0.17668884 No improvement since epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 694 [0/78836 (0%)]	Loss: 0.116311
Train epoch: 694 [275300/78836 (13%)]	Loss: 0.143706
Train epoch: 694 [556480/78836 (26%)]	Loss: 0.133978
Train epoch: 694 [827460/78836 (39%)]	Loss: 0.143655
Train epoch: 694 [1111840/78836 (52%)]	Loss: 0.135468
Train epoch: 694 [1395600/78836 (65%)]	Loss: 0.159768
Train epoch: 694 [1695720/78836 (78%)]	Loss: 0.160651
Train epoch: 694 [1951460/78836 (91%)]	Loss: 0.145608
predicting for valid data
Make prediction for 19709 samples...
0.17668884 No improvement since epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 695 [0/78836 (0%)]	Loss: 0.128700
Train epoch: 695 [281940/78836 (13%)]	Loss: 0.122721
Train epoch: 695 [571120/78836 (26%)]	Loss: 0.108044
Train epoch: 695 [834900/78836 (39%)]	Loss: 0.127670
Train epoch: 695 [1120320/78836 (52%)]	Loss: 0.139570
Train epoch: 695 [1404000/78836 (65%)]	Loss: 0.142443
Train epoch: 695 [1655520/78836 (78%)]	Loss: 0.125694
Train epoch: 695 [2058420/78836 (91%)]	Loss: 0.159380
predicting for valid data
Make prediction for 19709 samples...
0.17668884 No improvement since epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 696 [0/78836 (0%)]	Loss: 0.115326
Train epoch: 696 [274760/78836 (13%)]	Loss: 0.148831
Train epoch: 696 [566720/78836 (26%)]	Loss: 0.139316
Train epoch: 696 [826740/78836 (39%)]	Loss: 0.140841
Train epoch: 696 [1112240/78836 (52%)]	Loss: 0.124262
Train epoch: 696 [1395800/78836 (65%)]	Loss: 0.147470
Train epoch: 696 [1688520/78836 (78%)]	Loss: 0.123351
Train epoch: 696 [1937460/78836 (91%)]	Loss: 0.170728
predicting for valid data
Make prediction for 19709 samples...
0.17668884 No improvement since epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 697 [0/78836 (0%)]	Loss: 0.126514
Train epoch: 697 [274420/78836 (13%)]	Loss: 0.123819
Train epoch: 697 [562040/78836 (26%)]	Loss: 0.143287
Train epoch: 697 [840660/78836 (39%)]	Loss: 0.123741
Train epoch: 697 [1115840/78836 (52%)]	Loss: 0.128105
Train epoch: 697 [1361500/78836 (65%)]	Loss: 0.141123
Train epoch: 697 [1699920/78836 (78%)]	Loss: 0.175416
Train epoch: 697 [1977360/78836 (91%)]	Loss: 0.141105
predicting for valid data
Make prediction for 19709 samples...
0.17668884 No improvement since epoch  692 ; best_test_mse,best_test_ci: 0.17668884 0.8598990029597424 GINConvNet kiba
Training on 78836 samples...
Train epoch: 698 [0/78836 (0%)]	Loss: 0.141804
Train epoch: 698 [281000/78836 (13%)]	Loss: 0.114242
Train epoch: 698 [556400/78836 (26%)]	Loss: 0.131295
Train epoch: 698 [835740/78836 (39%)]	Loss: 0.142330
Train epoch: 698 [1095680/78836 (52%)]	Loss: 0.129282
Train epoch: 698 [1394200/78836 (65%)]	Loss: 0.140522
Train epoch: 698 [1741800/78836 (78%)]	Loss: 0.137960
Train epoch: 698 [1921220/78836 (91%)]	Loss: 0.135263
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 699 [0/78836 (0%)]	Loss: 0.121380
Train epoch: 699 [281040/78836 (13%)]	Loss: 0.120891
Train epoch: 699 [559960/78836 (26%)]	Loss: 0.143538
Train epoch: 699 [842160/78836 (39%)]	Loss: 0.144576
Train epoch: 699 [1086400/78836 (52%)]	Loss: 0.126298
Train epoch: 699 [1411300/78836 (65%)]	Loss: 0.113719
Train epoch: 699 [1647000/78836 (78%)]	Loss: 0.113823
Train epoch: 699 [1920800/78836 (91%)]	Loss: 0.138023
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 700 [0/78836 (0%)]	Loss: 0.121260
Train epoch: 700 [280420/78836 (13%)]	Loss: 0.113146
Train epoch: 700 [575520/78836 (26%)]	Loss: 0.111259
Train epoch: 700 [839880/78836 (39%)]	Loss: 0.115480
Train epoch: 700 [1141680/78836 (52%)]	Loss: 0.149088
Train epoch: 700 [1397400/78836 (65%)]	Loss: 0.100057
Train epoch: 700 [1688760/78836 (78%)]	Loss: 0.128646
Train epoch: 700 [1948940/78836 (91%)]	Loss: 0.126334
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 701 [0/78836 (0%)]	Loss: 0.126621
Train epoch: 701 [279800/78836 (13%)]	Loss: 0.115037
Train epoch: 701 [550600/78836 (26%)]	Loss: 0.171019
Train epoch: 701 [836520/78836 (39%)]	Loss: 0.129538
Train epoch: 701 [1117200/78836 (52%)]	Loss: 0.127072
Train epoch: 701 [1460600/78836 (65%)]	Loss: 0.169061
Train epoch: 701 [1666200/78836 (78%)]	Loss: 0.146754
Train epoch: 701 [1912960/78836 (91%)]	Loss: 0.120988
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 702 [0/78836 (0%)]	Loss: 0.140490
Train epoch: 702 [273620/78836 (13%)]	Loss: 0.123845
Train epoch: 702 [552840/78836 (26%)]	Loss: 0.137694
Train epoch: 702 [843120/78836 (39%)]	Loss: 0.124261
Train epoch: 702 [1147680/78836 (52%)]	Loss: 0.114706
Train epoch: 702 [1407900/78836 (65%)]	Loss: 0.120362
Train epoch: 702 [1643400/78836 (78%)]	Loss: 0.132415
Train epoch: 702 [1925140/78836 (91%)]	Loss: 0.120209
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 703 [0/78836 (0%)]	Loss: 0.118459
Train epoch: 703 [277420/78836 (13%)]	Loss: 0.129482
Train epoch: 703 [569320/78836 (26%)]	Loss: 0.154287
Train epoch: 703 [829140/78836 (39%)]	Loss: 0.111525
Train epoch: 703 [1102000/78836 (52%)]	Loss: 0.126610
Train epoch: 703 [1403200/78836 (65%)]	Loss: 0.121134
Train epoch: 703 [1673640/78836 (78%)]	Loss: 0.149888
Train epoch: 703 [1975400/78836 (91%)]	Loss: 0.160202
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 704 [0/78836 (0%)]	Loss: 0.110758
Train epoch: 704 [276780/78836 (13%)]	Loss: 0.112231
Train epoch: 704 [563680/78836 (26%)]	Loss: 0.114152
Train epoch: 704 [824580/78836 (39%)]	Loss: 0.131830
Train epoch: 704 [1130400/78836 (52%)]	Loss: 0.141670
Train epoch: 704 [1422900/78836 (65%)]	Loss: 0.140291
Train epoch: 704 [1685640/78836 (78%)]	Loss: 0.138556
Train epoch: 704 [1969380/78836 (91%)]	Loss: 0.124379
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 705 [0/78836 (0%)]	Loss: 0.131352
Train epoch: 705 [278260/78836 (13%)]	Loss: 0.132065
Train epoch: 705 [555200/78836 (26%)]	Loss: 0.128868
Train epoch: 705 [831420/78836 (39%)]	Loss: 0.126410
Train epoch: 705 [1144320/78836 (52%)]	Loss: 0.137870
Train epoch: 705 [1392600/78836 (65%)]	Loss: 0.136765
Train epoch: 705 [1653720/78836 (78%)]	Loss: 0.119945
Train epoch: 705 [1988000/78836 (91%)]	Loss: 0.125104
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 706 [0/78836 (0%)]	Loss: 0.128990
Train epoch: 706 [274800/78836 (13%)]	Loss: 0.120856
Train epoch: 706 [560400/78836 (26%)]	Loss: 0.134574
Train epoch: 706 [833160/78836 (39%)]	Loss: 0.123501
Train epoch: 706 [1118720/78836 (52%)]	Loss: 0.118523
Train epoch: 706 [1396500/78836 (65%)]	Loss: 0.159044
Train epoch: 706 [1741320/78836 (78%)]	Loss: 0.117910
Train epoch: 706 [1954120/78836 (91%)]	Loss: 0.141031
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 707 [0/78836 (0%)]	Loss: 0.124098
Train epoch: 707 [281720/78836 (13%)]	Loss: 0.121328
Train epoch: 707 [559960/78836 (26%)]	Loss: 0.116412
Train epoch: 707 [845220/78836 (39%)]	Loss: 0.128902
Train epoch: 707 [1110080/78836 (52%)]	Loss: 0.128613
Train epoch: 707 [1404500/78836 (65%)]	Loss: 0.130464
Train epoch: 707 [1674720/78836 (78%)]	Loss: 0.121854
Train epoch: 707 [1972600/78836 (91%)]	Loss: 0.104304
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 708 [0/78836 (0%)]	Loss: 0.116551
Train epoch: 708 [281200/78836 (13%)]	Loss: 0.116728
Train epoch: 708 [563680/78836 (26%)]	Loss: 0.130533
Train epoch: 708 [837060/78836 (39%)]	Loss: 0.131836
Train epoch: 708 [1089600/78836 (52%)]	Loss: 0.125351
Train epoch: 708 [1409700/78836 (65%)]	Loss: 0.137038
Train epoch: 708 [1672920/78836 (78%)]	Loss: 0.120949
Train epoch: 708 [1994020/78836 (91%)]	Loss: 0.127075
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 709 [0/78836 (0%)]	Loss: 0.091988
Train epoch: 709 [279740/78836 (13%)]	Loss: 0.122980
Train epoch: 709 [562600/78836 (26%)]	Loss: 0.122054
Train epoch: 709 [844500/78836 (39%)]	Loss: 0.117333
Train epoch: 709 [1128880/78836 (52%)]	Loss: 0.156435
Train epoch: 709 [1370500/78836 (65%)]	Loss: 0.135969
Train epoch: 709 [1684200/78836 (78%)]	Loss: 0.142487
Train epoch: 709 [1961120/78836 (91%)]	Loss: 0.160588
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 710 [0/78836 (0%)]	Loss: 0.122754
Train epoch: 710 [274160/78836 (13%)]	Loss: 0.118584
Train epoch: 710 [551840/78836 (26%)]	Loss: 0.160114
Train epoch: 710 [851880/78836 (39%)]	Loss: 0.115565
Train epoch: 710 [1136080/78836 (52%)]	Loss: 0.140248
Train epoch: 710 [1418100/78836 (65%)]	Loss: 0.111433
Train epoch: 710 [1661880/78836 (78%)]	Loss: 0.117526
Train epoch: 710 [1977220/78836 (91%)]	Loss: 0.174443
predicting for valid data
Make prediction for 19709 samples...
0.17300272 No improvement since epoch  698 ; best_test_mse,best_test_ci: 0.17300272 0.8617347669765735 GINConvNet kiba
Training on 78836 samples...
Train epoch: 711 [0/78836 (0%)]	Loss: 0.127279
Train epoch: 711 [278560/78836 (13%)]	Loss: 0.143539
Train epoch: 711 [561320/78836 (26%)]	Loss: 0.132233
Train epoch: 711 [838020/78836 (39%)]	Loss: 0.109775
Train epoch: 711 [1121280/78836 (52%)]	Loss: 0.131387
Train epoch: 711 [1390700/78836 (65%)]	Loss: 0.126483
Train epoch: 711 [1646640/78836 (78%)]	Loss: 0.120899
Train epoch: 711 [1970360/78836 (91%)]	Loss: 0.109174
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 712 [0/78836 (0%)]	Loss: 0.105870
Train epoch: 712 [283820/78836 (13%)]	Loss: 0.114163
Train epoch: 712 [558120/78836 (26%)]	Loss: 0.125212
Train epoch: 712 [840960/78836 (39%)]	Loss: 0.150045
Train epoch: 712 [1110960/78836 (52%)]	Loss: 0.119408
Train epoch: 712 [1417400/78836 (65%)]	Loss: 0.151033
Train epoch: 712 [1671840/78836 (78%)]	Loss: 0.131143
Train epoch: 712 [2017540/78836 (91%)]	Loss: 0.136814
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 713 [0/78836 (0%)]	Loss: 0.109937
Train epoch: 713 [280360/78836 (13%)]	Loss: 0.148980
Train epoch: 713 [567080/78836 (26%)]	Loss: 0.109968
Train epoch: 713 [835740/78836 (39%)]	Loss: 0.123568
Train epoch: 713 [1122560/78836 (52%)]	Loss: 0.121913
Train epoch: 713 [1394800/78836 (65%)]	Loss: 0.113460
Train epoch: 713 [1646400/78836 (78%)]	Loss: 0.123412
Train epoch: 713 [1916320/78836 (91%)]	Loss: 0.108818
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 714 [0/78836 (0%)]	Loss: 0.110682
Train epoch: 714 [280260/78836 (13%)]	Loss: 0.144859
Train epoch: 714 [556320/78836 (26%)]	Loss: 0.126244
Train epoch: 714 [841320/78836 (39%)]	Loss: 0.101684
Train epoch: 714 [1143360/78836 (52%)]	Loss: 0.135636
Train epoch: 714 [1432800/78836 (65%)]	Loss: 0.130800
Train epoch: 714 [1664760/78836 (78%)]	Loss: 0.121586
Train epoch: 714 [1936900/78836 (91%)]	Loss: 0.134198
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 715 [0/78836 (0%)]	Loss: 0.122943
Train epoch: 715 [282220/78836 (13%)]	Loss: 0.128295
Train epoch: 715 [565440/78836 (26%)]	Loss: 0.108848
Train epoch: 715 [828060/78836 (39%)]	Loss: 0.115987
Train epoch: 715 [1135280/78836 (52%)]	Loss: 0.105144
Train epoch: 715 [1400800/78836 (65%)]	Loss: 0.127044
Train epoch: 715 [1654920/78836 (78%)]	Loss: 0.132071
Train epoch: 715 [1986320/78836 (91%)]	Loss: 0.140126
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 716 [0/78836 (0%)]	Loss: 0.098135
Train epoch: 716 [277520/78836 (13%)]	Loss: 0.114944
Train epoch: 716 [568400/78836 (26%)]	Loss: 0.142226
Train epoch: 716 [855780/78836 (39%)]	Loss: 0.110919
Train epoch: 716 [1111760/78836 (52%)]	Loss: 0.119854
Train epoch: 716 [1407000/78836 (65%)]	Loss: 0.132573
Train epoch: 716 [1636680/78836 (78%)]	Loss: 0.129721
Train epoch: 716 [1884960/78836 (91%)]	Loss: 0.117728
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 717 [0/78836 (0%)]	Loss: 0.129656
Train epoch: 717 [281460/78836 (13%)]	Loss: 0.116605
Train epoch: 717 [557040/78836 (26%)]	Loss: 0.120444
Train epoch: 717 [846480/78836 (39%)]	Loss: 0.098606
Train epoch: 717 [1085360/78836 (52%)]	Loss: 0.117816
Train epoch: 717 [1401300/78836 (65%)]	Loss: 0.104552
Train epoch: 717 [1684080/78836 (78%)]	Loss: 0.135948
Train epoch: 717 [1930040/78836 (91%)]	Loss: 0.133309
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 718 [0/78836 (0%)]	Loss: 0.120210
Train epoch: 718 [281460/78836 (13%)]	Loss: 0.116329
Train epoch: 718 [556240/78836 (26%)]	Loss: 0.115450
Train epoch: 718 [835320/78836 (39%)]	Loss: 0.121220
Train epoch: 718 [1114400/78836 (52%)]	Loss: 0.119371
Train epoch: 718 [1445300/78836 (65%)]	Loss: 0.146926
Train epoch: 718 [1693320/78836 (78%)]	Loss: 0.124117
Train epoch: 718 [1924160/78836 (91%)]	Loss: 0.131067
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 719 [0/78836 (0%)]	Loss: 0.113587
Train epoch: 719 [281100/78836 (13%)]	Loss: 0.101573
Train epoch: 719 [552480/78836 (26%)]	Loss: 0.133068
Train epoch: 719 [827820/78836 (39%)]	Loss: 0.125976
Train epoch: 719 [1082800/78836 (52%)]	Loss: 0.110144
Train epoch: 719 [1418300/78836 (65%)]	Loss: 0.132837
Train epoch: 719 [1649160/78836 (78%)]	Loss: 0.112491
Train epoch: 719 [1980860/78836 (91%)]	Loss: 0.148156
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 720 [0/78836 (0%)]	Loss: 0.096246
Train epoch: 720 [272980/78836 (13%)]	Loss: 0.113843
Train epoch: 720 [559240/78836 (26%)]	Loss: 0.112653
Train epoch: 720 [833760/78836 (39%)]	Loss: 0.122890
Train epoch: 720 [1121680/78836 (52%)]	Loss: 0.130411
Train epoch: 720 [1400100/78836 (65%)]	Loss: 0.131275
Train epoch: 720 [1690200/78836 (78%)]	Loss: 0.111720
Train epoch: 720 [1939140/78836 (91%)]	Loss: 0.152784
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 721 [0/78836 (0%)]	Loss: 0.126677
Train epoch: 721 [282680/78836 (13%)]	Loss: 0.126114
Train epoch: 721 [552320/78836 (26%)]	Loss: 0.114274
Train epoch: 721 [850800/78836 (39%)]	Loss: 0.115577
Train epoch: 721 [1111520/78836 (52%)]	Loss: 0.095612
Train epoch: 721 [1391100/78836 (65%)]	Loss: 0.140549
Train epoch: 721 [1716360/78836 (78%)]	Loss: 0.134596
Train epoch: 721 [1957480/78836 (91%)]	Loss: 0.117228
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 722 [0/78836 (0%)]	Loss: 0.118864
Train epoch: 722 [275380/78836 (13%)]	Loss: 0.120110
Train epoch: 722 [565800/78836 (26%)]	Loss: 0.109042
Train epoch: 722 [843480/78836 (39%)]	Loss: 0.102535
Train epoch: 722 [1108800/78836 (52%)]	Loss: 0.131982
Train epoch: 722 [1414200/78836 (65%)]	Loss: 0.126862
Train epoch: 722 [1679520/78836 (78%)]	Loss: 0.114262
Train epoch: 722 [1952580/78836 (91%)]	Loss: 0.126883
predicting for valid data
Make prediction for 19709 samples...
0.17346528 No improvement since epoch  711 ; best_test_mse,best_test_ci: 0.17346528 0.8639870901590244 GINConvNet kiba
Training on 78836 samples...
Train epoch: 723 [0/78836 (0%)]	Loss: 0.113379
Train epoch: 723 [279780/78836 (13%)]	Loss: 0.126396
Train epoch: 723 [566760/78836 (26%)]	Loss: 0.118662
Train epoch: 723 [828780/78836 (39%)]	Loss: 0.115047
Train epoch: 723 [1112480/78836 (52%)]	Loss: 0.138935
Train epoch: 723 [1400700/78836 (65%)]	Loss: 0.103038
Train epoch: 723 [1645920/78836 (78%)]	Loss: 0.116378
Train epoch: 723 [1976380/78836 (91%)]	Loss: 0.120043
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 724 [0/78836 (0%)]	Loss: 0.115659
Train epoch: 724 [282120/78836 (13%)]	Loss: 0.104276
Train epoch: 724 [553480/78836 (26%)]	Loss: 0.091669
Train epoch: 724 [831060/78836 (39%)]	Loss: 0.099646
Train epoch: 724 [1100480/78836 (52%)]	Loss: 0.132677
Train epoch: 724 [1430500/78836 (65%)]	Loss: 0.135258
Train epoch: 724 [1660080/78836 (78%)]	Loss: 0.149736
Train epoch: 724 [1965460/78836 (91%)]	Loss: 0.120167
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 725 [0/78836 (0%)]	Loss: 0.099409
Train epoch: 725 [278740/78836 (13%)]	Loss: 0.095672
Train epoch: 725 [567280/78836 (26%)]	Loss: 0.114215
Train epoch: 725 [828720/78836 (39%)]	Loss: 0.140861
Train epoch: 725 [1115840/78836 (52%)]	Loss: 0.112146
Train epoch: 725 [1404000/78836 (65%)]	Loss: 0.103563
Train epoch: 725 [1668960/78836 (78%)]	Loss: 0.164200
Train epoch: 725 [1968260/78836 (91%)]	Loss: 0.121117
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 726 [0/78836 (0%)]	Loss: 0.093246
Train epoch: 726 [291980/78836 (13%)]	Loss: 0.125202
Train epoch: 726 [553880/78836 (26%)]	Loss: 0.120723
Train epoch: 726 [842040/78836 (39%)]	Loss: 0.095325
Train epoch: 726 [1126320/78836 (52%)]	Loss: 0.130932
Train epoch: 726 [1417500/78836 (65%)]	Loss: 0.101786
Train epoch: 726 [1640400/78836 (78%)]	Loss: 0.139981
Train epoch: 726 [1927660/78836 (91%)]	Loss: 0.114533
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 727 [0/78836 (0%)]	Loss: 0.122465
Train epoch: 727 [277600/78836 (13%)]	Loss: 0.127461
Train epoch: 727 [565480/78836 (26%)]	Loss: 0.121279
Train epoch: 727 [830760/78836 (39%)]	Loss: 0.102791
Train epoch: 727 [1101040/78836 (52%)]	Loss: 0.118181
Train epoch: 727 [1404400/78836 (65%)]	Loss: 0.126620
Train epoch: 727 [1674120/78836 (78%)]	Loss: 0.121918
Train epoch: 727 [1953980/78836 (91%)]	Loss: 0.148230
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 728 [0/78836 (0%)]	Loss: 0.129695
Train epoch: 728 [281300/78836 (13%)]	Loss: 0.104436
Train epoch: 728 [557960/78836 (26%)]	Loss: 0.124496
Train epoch: 728 [831600/78836 (39%)]	Loss: 0.105545
Train epoch: 728 [1120960/78836 (52%)]	Loss: 0.136537
Train epoch: 728 [1405800/78836 (65%)]	Loss: 0.103280
Train epoch: 728 [1694760/78836 (78%)]	Loss: 0.133740
Train epoch: 728 [1947960/78836 (91%)]	Loss: 0.101873
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 729 [0/78836 (0%)]	Loss: 0.097426
Train epoch: 729 [278960/78836 (13%)]	Loss: 0.088237
Train epoch: 729 [553720/78836 (26%)]	Loss: 0.119344
Train epoch: 729 [839580/78836 (39%)]	Loss: 0.133491
Train epoch: 729 [1128560/78836 (52%)]	Loss: 0.106145
Train epoch: 729 [1429500/78836 (65%)]	Loss: 0.133167
Train epoch: 729 [1715400/78836 (78%)]	Loss: 0.105956
Train epoch: 729 [1959720/78836 (91%)]	Loss: 0.100630
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 730 [0/78836 (0%)]	Loss: 0.121587
Train epoch: 730 [276780/78836 (13%)]	Loss: 0.102976
Train epoch: 730 [580600/78836 (26%)]	Loss: 0.125452
Train epoch: 730 [862260/78836 (39%)]	Loss: 0.099470
Train epoch: 730 [1114480/78836 (52%)]	Loss: 0.098087
Train epoch: 730 [1411100/78836 (65%)]	Loss: 0.100934
Train epoch: 730 [1686240/78836 (78%)]	Loss: 0.109263
Train epoch: 730 [1937740/78836 (91%)]	Loss: 0.085817
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 731 [0/78836 (0%)]	Loss: 0.125905
Train epoch: 731 [274060/78836 (13%)]	Loss: 0.097045
Train epoch: 731 [554000/78836 (26%)]	Loss: 0.121984
Train epoch: 731 [847080/78836 (39%)]	Loss: 0.128565
Train epoch: 731 [1128800/78836 (52%)]	Loss: 0.105063
Train epoch: 731 [1382400/78836 (65%)]	Loss: 0.138565
Train epoch: 731 [1679520/78836 (78%)]	Loss: 0.115099
Train epoch: 731 [1997380/78836 (91%)]	Loss: 0.124524
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 732 [0/78836 (0%)]	Loss: 0.112615
Train epoch: 732 [276040/78836 (13%)]	Loss: 0.109820
Train epoch: 732 [568320/78836 (26%)]	Loss: 0.142760
Train epoch: 732 [836160/78836 (39%)]	Loss: 0.108815
Train epoch: 732 [1106960/78836 (52%)]	Loss: 0.129819
Train epoch: 732 [1392100/78836 (65%)]	Loss: 0.148549
Train epoch: 732 [1637160/78836 (78%)]	Loss: 0.106759
Train epoch: 732 [1931860/78836 (91%)]	Loss: 0.111530
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 733 [0/78836 (0%)]	Loss: 0.110401
Train epoch: 733 [278400/78836 (13%)]	Loss: 0.120346
Train epoch: 733 [557480/78836 (26%)]	Loss: 0.108761
Train epoch: 733 [844800/78836 (39%)]	Loss: 0.100584
Train epoch: 733 [1138240/78836 (52%)]	Loss: 0.102471
Train epoch: 733 [1415200/78836 (65%)]	Loss: 0.114084
Train epoch: 733 [1663440/78836 (78%)]	Loss: 0.119202
Train epoch: 733 [1989680/78836 (91%)]	Loss: 0.130880
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 734 [0/78836 (0%)]	Loss: 0.076972
Train epoch: 734 [284380/78836 (13%)]	Loss: 0.112345
Train epoch: 734 [549400/78836 (26%)]	Loss: 0.112375
Train epoch: 734 [835080/78836 (39%)]	Loss: 0.082539
Train epoch: 734 [1087280/78836 (52%)]	Loss: 0.122943
Train epoch: 734 [1377900/78836 (65%)]	Loss: 0.124098
Train epoch: 734 [1637880/78836 (78%)]	Loss: 0.092705
Train epoch: 734 [1992760/78836 (91%)]	Loss: 0.131803
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 735 [0/78836 (0%)]	Loss: 0.104204
Train epoch: 735 [283000/78836 (13%)]	Loss: 0.108076
Train epoch: 735 [557880/78836 (26%)]	Loss: 0.123310
Train epoch: 735 [826440/78836 (39%)]	Loss: 0.109024
Train epoch: 735 [1101120/78836 (52%)]	Loss: 0.104144
Train epoch: 735 [1394600/78836 (65%)]	Loss: 0.127689
Train epoch: 735 [1674000/78836 (78%)]	Loss: 0.116663
Train epoch: 735 [1914360/78836 (91%)]	Loss: 0.137917
predicting for valid data
Make prediction for 19709 samples...
0.17356767 No improvement since epoch  723 ; best_test_mse,best_test_ci: 0.17356767 0.8649445294597988 GINConvNet kiba
Training on 78836 samples...
Train epoch: 736 [0/78836 (0%)]	Loss: 0.092622
Train epoch: 736 [280100/78836 (13%)]	Loss: 0.110964
Train epoch: 736 [568280/78836 (26%)]	Loss: 0.121142
Train epoch: 736 [853320/78836 (39%)]	Loss: 0.095375
Train epoch: 736 [1111200/78836 (52%)]	Loss: 0.107987
Train epoch: 736 [1406000/78836 (65%)]	Loss: 0.120636
Train epoch: 736 [1693560/78836 (78%)]	Loss: 0.093768
Train epoch: 736 [1920800/78836 (91%)]	Loss: 0.109569
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  736 ; best_test_mse,best_test_ci: 0.17491427 0.8648752475707947 GINConvNet kiba
Training on 78836 samples...
Train epoch: 737 [0/78836 (0%)]	Loss: 0.108147
Train epoch: 737 [277580/78836 (13%)]	Loss: 0.107804
Train epoch: 737 [561120/78836 (26%)]	Loss: 0.109529
Train epoch: 737 [848340/78836 (39%)]	Loss: 0.109003
Train epoch: 737 [1137760/78836 (52%)]	Loss: 0.127152
Train epoch: 737 [1404200/78836 (65%)]	Loss: 0.121146
Train epoch: 737 [1698600/78836 (78%)]	Loss: 0.103744
Train epoch: 737 [1881740/78836 (91%)]	Loss: 0.098844
predicting for valid data
Make prediction for 19709 samples...
0.17491427 No improvement since epoch  736 ; best_test_mse,best_test_ci: 0.17491427 0.8648752475707947 GINConvNet kiba
Training on 78836 samples...
Train epoch: 738 [0/78836 (0%)]	Loss: 0.098256
Train epoch: 738 [281840/78836 (13%)]	Loss: 0.106723
Train epoch: 738 [566240/78836 (26%)]	Loss: 0.086436
Train epoch: 738 [845820/78836 (39%)]	Loss: 0.101153
Train epoch: 738 [1111440/78836 (52%)]	Loss: 0.097570
Train epoch: 738 [1411700/78836 (65%)]	Loss: 0.098024
Train epoch: 738 [1622520/78836 (78%)]	Loss: 0.113901
Train epoch: 738 [1948100/78836 (91%)]	Loss: 0.122960
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 739 [0/78836 (0%)]	Loss: 0.142052
Train epoch: 739 [273120/78836 (13%)]	Loss: 0.106058
Train epoch: 739 [563200/78836 (26%)]	Loss: 0.115938
Train epoch: 739 [843060/78836 (39%)]	Loss: 0.088369
Train epoch: 739 [1120240/78836 (52%)]	Loss: 0.119664
Train epoch: 739 [1412800/78836 (65%)]	Loss: 0.107505
Train epoch: 739 [1661520/78836 (78%)]	Loss: 0.117911
Train epoch: 739 [1909180/78836 (91%)]	Loss: 0.107493
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 740 [0/78836 (0%)]	Loss: 0.117553
Train epoch: 740 [277300/78836 (13%)]	Loss: 0.119496
Train epoch: 740 [558760/78836 (26%)]	Loss: 0.110215
Train epoch: 740 [839760/78836 (39%)]	Loss: 0.115199
Train epoch: 740 [1114160/78836 (52%)]	Loss: 0.124642
Train epoch: 740 [1391600/78836 (65%)]	Loss: 0.096627
Train epoch: 740 [1682520/78836 (78%)]	Loss: 0.098854
Train epoch: 740 [1966860/78836 (91%)]	Loss: 0.142042
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 741 [0/78836 (0%)]	Loss: 0.115276
Train epoch: 741 [281440/78836 (13%)]	Loss: 0.098084
Train epoch: 741 [564560/78836 (26%)]	Loss: 0.105798
Train epoch: 741 [828960/78836 (39%)]	Loss: 0.100669
Train epoch: 741 [1110240/78836 (52%)]	Loss: 0.116373
Train epoch: 741 [1435300/78836 (65%)]	Loss: 0.105426
Train epoch: 741 [1644240/78836 (78%)]	Loss: 0.100366
Train epoch: 741 [2025240/78836 (91%)]	Loss: 0.134421
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 742 [0/78836 (0%)]	Loss: 0.096885
Train epoch: 742 [278800/78836 (13%)]	Loss: 0.108201
Train epoch: 742 [562160/78836 (26%)]	Loss: 0.110334
Train epoch: 742 [838800/78836 (39%)]	Loss: 0.109740
Train epoch: 742 [1119040/78836 (52%)]	Loss: 0.122129
Train epoch: 742 [1405000/78836 (65%)]	Loss: 0.113917
Train epoch: 742 [1666200/78836 (78%)]	Loss: 0.118330
Train epoch: 742 [1960140/78836 (91%)]	Loss: 0.107616
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 743 [0/78836 (0%)]	Loss: 0.088196
Train epoch: 743 [282700/78836 (13%)]	Loss: 0.132270
Train epoch: 743 [565960/78836 (26%)]	Loss: 0.100603
Train epoch: 743 [832140/78836 (39%)]	Loss: 0.102128
Train epoch: 743 [1141760/78836 (52%)]	Loss: 0.104641
Train epoch: 743 [1383100/78836 (65%)]	Loss: 0.100220
Train epoch: 743 [1648560/78836 (78%)]	Loss: 0.113474
Train epoch: 743 [1952160/78836 (91%)]	Loss: 0.141014
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 744 [0/78836 (0%)]	Loss: 0.110842
Train epoch: 744 [274580/78836 (13%)]	Loss: 0.111914
Train epoch: 744 [558200/78836 (26%)]	Loss: 0.097951
Train epoch: 744 [843300/78836 (39%)]	Loss: 0.115335
Train epoch: 744 [1101040/78836 (52%)]	Loss: 0.104645
Train epoch: 744 [1382600/78836 (65%)]	Loss: 0.109431
Train epoch: 744 [1660080/78836 (78%)]	Loss: 0.109893
Train epoch: 744 [1961960/78836 (91%)]	Loss: 0.103668
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 745 [0/78836 (0%)]	Loss: 0.109970
Train epoch: 745 [276940/78836 (13%)]	Loss: 0.105161
Train epoch: 745 [556080/78836 (26%)]	Loss: 0.120714
Train epoch: 745 [822720/78836 (39%)]	Loss: 0.120234
Train epoch: 745 [1115760/78836 (52%)]	Loss: 0.115493
Train epoch: 745 [1397800/78836 (65%)]	Loss: 0.139118
Train epoch: 745 [1679640/78836 (78%)]	Loss: 0.109643
Train epoch: 745 [1972320/78836 (91%)]	Loss: 0.091489
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 746 [0/78836 (0%)]	Loss: 0.134132
Train epoch: 746 [278100/78836 (13%)]	Loss: 0.104651
Train epoch: 746 [557080/78836 (26%)]	Loss: 0.101382
Train epoch: 746 [838200/78836 (39%)]	Loss: 0.114184
Train epoch: 746 [1111360/78836 (52%)]	Loss: 0.115004
Train epoch: 746 [1375500/78836 (65%)]	Loss: 0.131338
Train epoch: 746 [1637160/78836 (78%)]	Loss: 0.077614
Train epoch: 746 [1957060/78836 (91%)]	Loss: 0.111479
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 747 [0/78836 (0%)]	Loss: 0.109758
Train epoch: 747 [281720/78836 (13%)]	Loss: 0.105922
Train epoch: 747 [553360/78836 (26%)]	Loss: 0.126951
Train epoch: 747 [852660/78836 (39%)]	Loss: 0.092367
Train epoch: 747 [1108400/78836 (52%)]	Loss: 0.130546
Train epoch: 747 [1394600/78836 (65%)]	Loss: 0.089460
Train epoch: 747 [1641720/78836 (78%)]	Loss: 0.105071
Train epoch: 747 [1911420/78836 (91%)]	Loss: 0.091308
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 748 [0/78836 (0%)]	Loss: 0.109185
Train epoch: 748 [279900/78836 (13%)]	Loss: 0.111402
Train epoch: 748 [559240/78836 (26%)]	Loss: 0.138741
Train epoch: 748 [842160/78836 (39%)]	Loss: 0.112991
Train epoch: 748 [1093520/78836 (52%)]	Loss: 0.107394
Train epoch: 748 [1402700/78836 (65%)]	Loss: 0.125984
Train epoch: 748 [1704600/78836 (78%)]	Loss: 0.119595
Train epoch: 748 [2002140/78836 (91%)]	Loss: 0.121116
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 749 [0/78836 (0%)]	Loss: 0.103557
Train epoch: 749 [287960/78836 (13%)]	Loss: 0.101842
Train epoch: 749 [567760/78836 (26%)]	Loss: 0.126766
Train epoch: 749 [845220/78836 (39%)]	Loss: 0.105282
Train epoch: 749 [1119280/78836 (52%)]	Loss: 0.128512
Train epoch: 749 [1393100/78836 (65%)]	Loss: 0.107980
Train epoch: 749 [1660200/78836 (78%)]	Loss: 0.108200
Train epoch: 749 [1926820/78836 (91%)]	Loss: 0.099245
predicting for valid data
Make prediction for 19709 samples...
0.17153509 No improvement since epoch  738 ; best_test_mse,best_test_ci: 0.17153509 0.8643283335499273 GINConvNet kiba
Training on 78836 samples...
Train epoch: 750 [0/78836 (0%)]	Loss: 0.098750
Train epoch: 750 [276480/78836 (13%)]	Loss: 0.118897
Train epoch: 750 [558960/78836 (26%)]	Loss: 0.107672
Train epoch: 750 [826320/78836 (39%)]	Loss: 0.118899
Train epoch: 750 [1124640/78836 (52%)]	Loss: 0.098101
Train epoch: 750 [1396500/78836 (65%)]	Loss: 0.099553
Train epoch: 750 [1658640/78836 (78%)]	Loss: 0.118868
Train epoch: 750 [1935500/78836 (91%)]	Loss: 0.117105
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  750 ; best_test_mse,best_test_ci: 0.1720434 0.868265636374086 GINConvNet kiba
Training on 78836 samples...
Train epoch: 751 [0/78836 (0%)]	Loss: 0.110411
Train epoch: 751 [287780/78836 (13%)]	Loss: 0.117321
Train epoch: 751 [556120/78836 (26%)]	Loss: 0.109524
Train epoch: 751 [838740/78836 (39%)]	Loss: 0.081675
Train epoch: 751 [1133280/78836 (52%)]	Loss: 0.101079
Train epoch: 751 [1423500/78836 (65%)]	Loss: 0.100046
Train epoch: 751 [1648320/78836 (78%)]	Loss: 0.109023
Train epoch: 751 [1946000/78836 (91%)]	Loss: 0.095451
predicting for valid data
Make prediction for 19709 samples...
0.1720434 No improvement since epoch  750 ; best_test_mse,best_test_ci: 0.1720434 0.868265636374086 GINConvNet kiba
Training on 78836 samples...
Train epoch: 752 [0/78836 (0%)]	Loss: 0.123651
Train epoch: 752 [275180/78836 (13%)]	Loss: 0.096258
Train epoch: 752 [554800/78836 (26%)]	Loss: 0.105058
Train epoch: 752 [816060/78836 (39%)]	Loss: 0.099489
Train epoch: 752 [1111760/78836 (52%)]	Loss: 0.118644
Train epoch: 752 [1416400/78836 (65%)]	Loss: 0.097912
Train epoch: 752 [1639680/78836 (78%)]	Loss: 0.107534
Train epoch: 752 [1948100/78836 (91%)]	Loss: 0.114791
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 753 [0/78836 (0%)]	Loss: 0.106358
Train epoch: 753 [280180/78836 (13%)]	Loss: 0.119563
Train epoch: 753 [555440/78836 (26%)]	Loss: 0.099721
Train epoch: 753 [874920/78836 (39%)]	Loss: 0.099653
Train epoch: 753 [1134720/78836 (52%)]	Loss: 0.092817
Train epoch: 753 [1395500/78836 (65%)]	Loss: 0.111900
Train epoch: 753 [1685040/78836 (78%)]	Loss: 0.125658
Train epoch: 753 [1976940/78836 (91%)]	Loss: 0.101913
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 754 [0/78836 (0%)]	Loss: 0.112836
Train epoch: 754 [278700/78836 (13%)]	Loss: 0.095275
Train epoch: 754 [558800/78836 (26%)]	Loss: 0.107731
Train epoch: 754 [841080/78836 (39%)]	Loss: 0.130261
Train epoch: 754 [1140400/78836 (52%)]	Loss: 0.099267
Train epoch: 754 [1405300/78836 (65%)]	Loss: 0.111158
Train epoch: 754 [1673400/78836 (78%)]	Loss: 0.099191
Train epoch: 754 [1980580/78836 (91%)]	Loss: 0.101447
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 755 [0/78836 (0%)]	Loss: 0.099286
Train epoch: 755 [283680/78836 (13%)]	Loss: 0.109568
Train epoch: 755 [571360/78836 (26%)]	Loss: 0.104561
Train epoch: 755 [844140/78836 (39%)]	Loss: 0.094530
Train epoch: 755 [1129360/78836 (52%)]	Loss: 0.112023
Train epoch: 755 [1386100/78836 (65%)]	Loss: 0.089415
Train epoch: 755 [1687920/78836 (78%)]	Loss: 0.117224
Train epoch: 755 [1959300/78836 (91%)]	Loss: 0.109135
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 756 [0/78836 (0%)]	Loss: 0.132833
Train epoch: 756 [281100/78836 (13%)]	Loss: 0.103542
Train epoch: 756 [547800/78836 (26%)]	Loss: 0.103371
Train epoch: 756 [824460/78836 (39%)]	Loss: 0.080152
Train epoch: 756 [1118240/78836 (52%)]	Loss: 0.099926
Train epoch: 756 [1411500/78836 (65%)]	Loss: 0.106421
Train epoch: 756 [1684200/78836 (78%)]	Loss: 0.117548
Train epoch: 756 [1956920/78836 (91%)]	Loss: 0.107353
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 757 [0/78836 (0%)]	Loss: 0.084988
Train epoch: 757 [277900/78836 (13%)]	Loss: 0.088810
Train epoch: 757 [562360/78836 (26%)]	Loss: 0.110346
Train epoch: 757 [842880/78836 (39%)]	Loss: 0.100337
Train epoch: 757 [1122800/78836 (52%)]	Loss: 0.111279
Train epoch: 757 [1401100/78836 (65%)]	Loss: 0.094248
Train epoch: 757 [1674600/78836 (78%)]	Loss: 0.103406
Train epoch: 757 [1939840/78836 (91%)]	Loss: 0.100045
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 758 [0/78836 (0%)]	Loss: 0.095726
Train epoch: 758 [280960/78836 (13%)]	Loss: 0.122545
Train epoch: 758 [553440/78836 (26%)]	Loss: 0.082236
Train epoch: 758 [862860/78836 (39%)]	Loss: 0.081493
Train epoch: 758 [1123520/78836 (52%)]	Loss: 0.108829
Train epoch: 758 [1387000/78836 (65%)]	Loss: 0.124073
Train epoch: 758 [1668480/78836 (78%)]	Loss: 0.105020
Train epoch: 758 [1950480/78836 (91%)]	Loss: 0.088336
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 759 [0/78836 (0%)]	Loss: 0.088749
Train epoch: 759 [281160/78836 (13%)]	Loss: 0.089946
Train epoch: 759 [561120/78836 (26%)]	Loss: 0.105298
Train epoch: 759 [844320/78836 (39%)]	Loss: 0.110178
Train epoch: 759 [1106400/78836 (52%)]	Loss: 0.120704
Train epoch: 759 [1402700/78836 (65%)]	Loss: 0.108280
Train epoch: 759 [1682400/78836 (78%)]	Loss: 0.104962
Train epoch: 759 [1933960/78836 (91%)]	Loss: 0.082745
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 760 [0/78836 (0%)]	Loss: 0.099772
Train epoch: 760 [282560/78836 (13%)]	Loss: 0.081312
Train epoch: 760 [562800/78836 (26%)]	Loss: 0.110178
Train epoch: 760 [856560/78836 (39%)]	Loss: 0.088288
Train epoch: 760 [1123920/78836 (52%)]	Loss: 0.094407
Train epoch: 760 [1386900/78836 (65%)]	Loss: 0.101149
Train epoch: 760 [1664520/78836 (78%)]	Loss: 0.119515
Train epoch: 760 [1965740/78836 (91%)]	Loss: 0.103857
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 761 [0/78836 (0%)]	Loss: 0.104227
Train epoch: 761 [279620/78836 (13%)]	Loss: 0.099766
Train epoch: 761 [556520/78836 (26%)]	Loss: 0.112878
Train epoch: 761 [829560/78836 (39%)]	Loss: 0.110875
Train epoch: 761 [1134880/78836 (52%)]	Loss: 0.096243
Train epoch: 761 [1408200/78836 (65%)]	Loss: 0.088171
Train epoch: 761 [1674120/78836 (78%)]	Loss: 0.112728
Train epoch: 761 [1933400/78836 (91%)]	Loss: 0.098175
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 762 [0/78836 (0%)]	Loss: 0.095546
Train epoch: 762 [280200/78836 (13%)]	Loss: 0.088066
Train epoch: 762 [560440/78836 (26%)]	Loss: 0.116346
Train epoch: 762 [850800/78836 (39%)]	Loss: 0.115862
Train epoch: 762 [1128800/78836 (52%)]	Loss: 0.116873
Train epoch: 762 [1401900/78836 (65%)]	Loss: 0.118281
Train epoch: 762 [1679520/78836 (78%)]	Loss: 0.103667
Train epoch: 762 [1943760/78836 (91%)]	Loss: 0.102121
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 763 [0/78836 (0%)]	Loss: 0.094847
Train epoch: 763 [281580/78836 (13%)]	Loss: 0.087053
Train epoch: 763 [558720/78836 (26%)]	Loss: 0.095118
Train epoch: 763 [854880/78836 (39%)]	Loss: 0.119939
Train epoch: 763 [1154640/78836 (52%)]	Loss: 0.104175
Train epoch: 763 [1397900/78836 (65%)]	Loss: 0.079805
Train epoch: 763 [1674600/78836 (78%)]	Loss: 0.092489
Train epoch: 763 [1977780/78836 (91%)]	Loss: 0.109768
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 764 [0/78836 (0%)]	Loss: 0.088743
Train epoch: 764 [287080/78836 (13%)]	Loss: 0.097806
Train epoch: 764 [546040/78836 (26%)]	Loss: 0.130856
Train epoch: 764 [837000/78836 (39%)]	Loss: 0.104945
Train epoch: 764 [1127600/78836 (52%)]	Loss: 0.096488
Train epoch: 764 [1401500/78836 (65%)]	Loss: 0.096213
Train epoch: 764 [1668720/78836 (78%)]	Loss: 0.104826
Train epoch: 764 [1975540/78836 (91%)]	Loss: 0.094901
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 765 [0/78836 (0%)]	Loss: 0.120267
Train epoch: 765 [275640/78836 (13%)]	Loss: 0.101908
Train epoch: 765 [567520/78836 (26%)]	Loss: 0.202471
Train epoch: 765 [842640/78836 (39%)]	Loss: 0.110978
Train epoch: 765 [1125360/78836 (52%)]	Loss: 0.115356
Train epoch: 765 [1418000/78836 (65%)]	Loss: 0.087142
Train epoch: 765 [1686960/78836 (78%)]	Loss: 0.102010
Train epoch: 765 [1942920/78836 (91%)]	Loss: 0.102794
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 766 [0/78836 (0%)]	Loss: 0.098295
Train epoch: 766 [278240/78836 (13%)]	Loss: 0.126228
Train epoch: 766 [559160/78836 (26%)]	Loss: 0.088426
Train epoch: 766 [836580/78836 (39%)]	Loss: 0.114404
Train epoch: 766 [1098080/78836 (52%)]	Loss: 0.112078
Train epoch: 766 [1416000/78836 (65%)]	Loss: 0.103994
Train epoch: 766 [1689360/78836 (78%)]	Loss: 0.121587
Train epoch: 766 [1953280/78836 (91%)]	Loss: 0.105919
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 767 [0/78836 (0%)]	Loss: 0.092034
Train epoch: 767 [277320/78836 (13%)]	Loss: 0.098237
Train epoch: 767 [562000/78836 (26%)]	Loss: 0.088540
Train epoch: 767 [843300/78836 (39%)]	Loss: 0.080665
Train epoch: 767 [1125600/78836 (52%)]	Loss: 0.102129
Train epoch: 767 [1411900/78836 (65%)]	Loss: 0.091049
Train epoch: 767 [1672200/78836 (78%)]	Loss: 0.111812
Train epoch: 767 [1930040/78836 (91%)]	Loss: 0.100205
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 768 [0/78836 (0%)]	Loss: 0.090505
Train epoch: 768 [271080/78836 (13%)]	Loss: 0.084900
Train epoch: 768 [568520/78836 (26%)]	Loss: 0.100904
Train epoch: 768 [830400/78836 (39%)]	Loss: 0.094513
Train epoch: 768 [1117760/78836 (52%)]	Loss: 0.096434
Train epoch: 768 [1418900/78836 (65%)]	Loss: 0.092395
Train epoch: 768 [1677960/78836 (78%)]	Loss: 0.098546
Train epoch: 768 [1960420/78836 (91%)]	Loss: 0.122211
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 769 [0/78836 (0%)]	Loss: 0.086734
Train epoch: 769 [274240/78836 (13%)]	Loss: 0.099019
Train epoch: 769 [554000/78836 (26%)]	Loss: 0.093131
Train epoch: 769 [835020/78836 (39%)]	Loss: 0.115546
Train epoch: 769 [1128800/78836 (52%)]	Loss: 0.092126
Train epoch: 769 [1402200/78836 (65%)]	Loss: 0.096295
Train epoch: 769 [1664280/78836 (78%)]	Loss: 0.091789
Train epoch: 769 [1946980/78836 (91%)]	Loss: 0.095887
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 770 [0/78836 (0%)]	Loss: 0.114963
Train epoch: 770 [278060/78836 (13%)]	Loss: 0.107972
Train epoch: 770 [553080/78836 (26%)]	Loss: 0.098924
Train epoch: 770 [835440/78836 (39%)]	Loss: 0.114849
Train epoch: 770 [1128320/78836 (52%)]	Loss: 0.095950
Train epoch: 770 [1414500/78836 (65%)]	Loss: 0.098484
Train epoch: 770 [1688160/78836 (78%)]	Loss: 0.085262
Train epoch: 770 [1928080/78836 (91%)]	Loss: 0.115031
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 771 [0/78836 (0%)]	Loss: 0.091877
Train epoch: 771 [275520/78836 (13%)]	Loss: 0.097127
Train epoch: 771 [561720/78836 (26%)]	Loss: 0.094072
Train epoch: 771 [822300/78836 (39%)]	Loss: 0.110379
Train epoch: 771 [1096560/78836 (52%)]	Loss: 0.112675
Train epoch: 771 [1404000/78836 (65%)]	Loss: 0.113521
Train epoch: 771 [1713480/78836 (78%)]	Loss: 0.086968
Train epoch: 771 [1956360/78836 (91%)]	Loss: 0.111828
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 772 [0/78836 (0%)]	Loss: 0.102348
Train epoch: 772 [279720/78836 (13%)]	Loss: 0.079950
Train epoch: 772 [551680/78836 (26%)]	Loss: 0.103705
Train epoch: 772 [836700/78836 (39%)]	Loss: 0.107176
Train epoch: 772 [1121520/78836 (52%)]	Loss: 0.087828
Train epoch: 772 [1399000/78836 (65%)]	Loss: 0.094080
Train epoch: 772 [1686120/78836 (78%)]	Loss: 0.084612
Train epoch: 772 [1957760/78836 (91%)]	Loss: 0.119227
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 773 [0/78836 (0%)]	Loss: 0.106595
Train epoch: 773 [276120/78836 (13%)]	Loss: 0.101000
Train epoch: 773 [554480/78836 (26%)]	Loss: 0.099349
Train epoch: 773 [844380/78836 (39%)]	Loss: 0.106593
Train epoch: 773 [1129840/78836 (52%)]	Loss: 0.102695
Train epoch: 773 [1394100/78836 (65%)]	Loss: 0.134266
Train epoch: 773 [1656720/78836 (78%)]	Loss: 0.117227
Train epoch: 773 [1951460/78836 (91%)]	Loss: 0.099282
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 774 [0/78836 (0%)]	Loss: 0.099558
Train epoch: 774 [272700/78836 (13%)]	Loss: 0.091479
Train epoch: 774 [557720/78836 (26%)]	Loss: 0.083416
Train epoch: 774 [824400/78836 (39%)]	Loss: 0.091012
Train epoch: 774 [1113920/78836 (52%)]	Loss: 0.097527
Train epoch: 774 [1378200/78836 (65%)]	Loss: 0.106686
Train epoch: 774 [1692480/78836 (78%)]	Loss: 0.109135
Train epoch: 774 [1943200/78836 (91%)]	Loss: 0.098217
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 775 [0/78836 (0%)]	Loss: 0.100289
Train epoch: 775 [278600/78836 (13%)]	Loss: 0.087271
Train epoch: 775 [546600/78836 (26%)]	Loss: 0.077962
Train epoch: 775 [845160/78836 (39%)]	Loss: 0.090381
Train epoch: 775 [1126800/78836 (52%)]	Loss: 0.110143
Train epoch: 775 [1386900/78836 (65%)]	Loss: 0.116244
Train epoch: 775 [1677720/78836 (78%)]	Loss: 0.106227
Train epoch: 775 [1938300/78836 (91%)]	Loss: 0.100192
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 776 [0/78836 (0%)]	Loss: 0.147567
Train epoch: 776 [278660/78836 (13%)]	Loss: 0.083525
Train epoch: 776 [558840/78836 (26%)]	Loss: 0.096480
Train epoch: 776 [843660/78836 (39%)]	Loss: 0.110167
Train epoch: 776 [1123840/78836 (52%)]	Loss: 0.099591
Train epoch: 776 [1354500/78836 (65%)]	Loss: 0.107347
Train epoch: 776 [1674240/78836 (78%)]	Loss: 0.100630
Train epoch: 776 [1932140/78836 (91%)]	Loss: 0.083885
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 777 [0/78836 (0%)]	Loss: 0.113830
Train epoch: 777 [281100/78836 (13%)]	Loss: 0.098487
Train epoch: 777 [548520/78836 (26%)]	Loss: 0.109574
Train epoch: 777 [833700/78836 (39%)]	Loss: 0.118603
Train epoch: 777 [1098160/78836 (52%)]	Loss: 0.105233
Train epoch: 777 [1388800/78836 (65%)]	Loss: 0.100548
Train epoch: 777 [1681200/78836 (78%)]	Loss: 0.133911
Train epoch: 777 [1973720/78836 (91%)]	Loss: 0.098108
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 778 [0/78836 (0%)]	Loss: 0.101010
Train epoch: 778 [281480/78836 (13%)]	Loss: 0.081029
Train epoch: 778 [562840/78836 (26%)]	Loss: 0.097630
Train epoch: 778 [857040/78836 (39%)]	Loss: 0.121645
Train epoch: 778 [1123280/78836 (52%)]	Loss: 0.101758
Train epoch: 778 [1419300/78836 (65%)]	Loss: 0.109578
Train epoch: 778 [1659720/78836 (78%)]	Loss: 0.099691
Train epoch: 778 [1946700/78836 (91%)]	Loss: 0.102403
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 779 [0/78836 (0%)]	Loss: 0.100024
Train epoch: 779 [275240/78836 (13%)]	Loss: 0.110106
Train epoch: 779 [551760/78836 (26%)]	Loss: 0.096390
Train epoch: 779 [835320/78836 (39%)]	Loss: 0.099688
Train epoch: 779 [1122800/78836 (52%)]	Loss: 0.090583
Train epoch: 779 [1402400/78836 (65%)]	Loss: 0.092540
Train epoch: 779 [1690200/78836 (78%)]	Loss: 0.103010
Train epoch: 779 [1950760/78836 (91%)]	Loss: 0.101738
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 780 [0/78836 (0%)]	Loss: 0.115311
Train epoch: 780 [279220/78836 (13%)]	Loss: 0.084471
Train epoch: 780 [552400/78836 (26%)]	Loss: 0.099066
Train epoch: 780 [830400/78836 (39%)]	Loss: 0.100547
Train epoch: 780 [1140000/78836 (52%)]	Loss: 0.085120
Train epoch: 780 [1369300/78836 (65%)]	Loss: 0.108437
Train epoch: 780 [1672440/78836 (78%)]	Loss: 0.092876
Train epoch: 780 [1965460/78836 (91%)]	Loss: 0.096828
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 781 [0/78836 (0%)]	Loss: 0.088699
Train epoch: 781 [278640/78836 (13%)]	Loss: 0.081238
Train epoch: 781 [561600/78836 (26%)]	Loss: 0.092806
Train epoch: 781 [826740/78836 (39%)]	Loss: 0.089391
Train epoch: 781 [1107280/78836 (52%)]	Loss: 0.087057
Train epoch: 781 [1382300/78836 (65%)]	Loss: 0.089384
Train epoch: 781 [1670880/78836 (78%)]	Loss: 0.094122
Train epoch: 781 [1984920/78836 (91%)]	Loss: 0.108522
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 782 [0/78836 (0%)]	Loss: 0.090764
Train epoch: 782 [276820/78836 (13%)]	Loss: 0.109374
Train epoch: 782 [553880/78836 (26%)]	Loss: 0.099872
Train epoch: 782 [845040/78836 (39%)]	Loss: 0.118052
Train epoch: 782 [1122400/78836 (52%)]	Loss: 0.101099
Train epoch: 782 [1371700/78836 (65%)]	Loss: 0.108643
Train epoch: 782 [1656240/78836 (78%)]	Loss: 0.085704
Train epoch: 782 [1954820/78836 (91%)]	Loss: 0.093327
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 783 [0/78836 (0%)]	Loss: 0.089757
Train epoch: 783 [282800/78836 (13%)]	Loss: 0.094700
Train epoch: 783 [552560/78836 (26%)]	Loss: 0.094114
Train epoch: 783 [844500/78836 (39%)]	Loss: 0.090593
Train epoch: 783 [1092480/78836 (52%)]	Loss: 0.112063
Train epoch: 783 [1382200/78836 (65%)]	Loss: 0.116046
Train epoch: 783 [1675920/78836 (78%)]	Loss: 0.098062
Train epoch: 783 [1906800/78836 (91%)]	Loss: 0.101300
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 784 [0/78836 (0%)]	Loss: 0.077565
Train epoch: 784 [278660/78836 (13%)]	Loss: 0.094070
Train epoch: 784 [565760/78836 (26%)]	Loss: 0.085241
Train epoch: 784 [839880/78836 (39%)]	Loss: 0.088289
Train epoch: 784 [1119200/78836 (52%)]	Loss: 0.102975
Train epoch: 784 [1394600/78836 (65%)]	Loss: 0.081406
Train epoch: 784 [1694160/78836 (78%)]	Loss: 0.086539
Train epoch: 784 [1965880/78836 (91%)]	Loss: 0.084413
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 785 [0/78836 (0%)]	Loss: 0.093441
Train epoch: 785 [280520/78836 (13%)]	Loss: 0.098389
Train epoch: 785 [558640/78836 (26%)]	Loss: 0.078746
Train epoch: 785 [837960/78836 (39%)]	Loss: 0.085955
Train epoch: 785 [1134160/78836 (52%)]	Loss: 0.109550
Train epoch: 785 [1399800/78836 (65%)]	Loss: 0.087635
Train epoch: 785 [1683000/78836 (78%)]	Loss: 0.108054
Train epoch: 785 [1942500/78836 (91%)]	Loss: 0.088061
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 786 [0/78836 (0%)]	Loss: 0.102445
Train epoch: 786 [275880/78836 (13%)]	Loss: 0.092960
Train epoch: 786 [563720/78836 (26%)]	Loss: 0.080610
Train epoch: 786 [846600/78836 (39%)]	Loss: 0.140338
Train epoch: 786 [1112960/78836 (52%)]	Loss: 0.097855
Train epoch: 786 [1409200/78836 (65%)]	Loss: 0.114981
Train epoch: 786 [1698840/78836 (78%)]	Loss: 0.082317
Train epoch: 786 [1990100/78836 (91%)]	Loss: 0.102816
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 787 [0/78836 (0%)]	Loss: 0.092164
Train epoch: 787 [280080/78836 (13%)]	Loss: 0.090255
Train epoch: 787 [560160/78836 (26%)]	Loss: 0.106123
Train epoch: 787 [844740/78836 (39%)]	Loss: 0.095373
Train epoch: 787 [1108400/78836 (52%)]	Loss: 0.093907
Train epoch: 787 [1423800/78836 (65%)]	Loss: 0.102528
Train epoch: 787 [1709760/78836 (78%)]	Loss: 0.099545
Train epoch: 787 [1948940/78836 (91%)]	Loss: 0.086544
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 788 [0/78836 (0%)]	Loss: 0.109182
Train epoch: 788 [284460/78836 (13%)]	Loss: 0.088427
Train epoch: 788 [557440/78836 (26%)]	Loss: 0.099031
Train epoch: 788 [841560/78836 (39%)]	Loss: 0.104059
Train epoch: 788 [1129920/78836 (52%)]	Loss: 0.115111
Train epoch: 788 [1419000/78836 (65%)]	Loss: 0.090676
Train epoch: 788 [1670880/78836 (78%)]	Loss: 0.096636
Train epoch: 788 [1963080/78836 (91%)]	Loss: 0.096924
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 789 [0/78836 (0%)]	Loss: 0.084384
Train epoch: 789 [283620/78836 (13%)]	Loss: 0.099692
Train epoch: 789 [556360/78836 (26%)]	Loss: 0.079512
Train epoch: 789 [830520/78836 (39%)]	Loss: 0.106443
Train epoch: 789 [1109920/78836 (52%)]	Loss: 0.087157
Train epoch: 789 [1390600/78836 (65%)]	Loss: 0.085412
Train epoch: 789 [1690680/78836 (78%)]	Loss: 0.077524
Train epoch: 789 [1973860/78836 (91%)]	Loss: 0.098623
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 790 [0/78836 (0%)]	Loss: 0.095405
Train epoch: 790 [276640/78836 (13%)]	Loss: 0.096183
Train epoch: 790 [551000/78836 (26%)]	Loss: 0.122619
Train epoch: 790 [846720/78836 (39%)]	Loss: 0.104677
Train epoch: 790 [1140080/78836 (52%)]	Loss: 0.097550
Train epoch: 790 [1406900/78836 (65%)]	Loss: 0.087508
Train epoch: 790 [1677120/78836 (78%)]	Loss: 0.094836
Train epoch: 790 [1943060/78836 (91%)]	Loss: 0.106085
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 791 [0/78836 (0%)]	Loss: 0.078909
Train epoch: 791 [279500/78836 (13%)]	Loss: 0.081753
Train epoch: 791 [561680/78836 (26%)]	Loss: 0.066700
Train epoch: 791 [832260/78836 (39%)]	Loss: 0.091616
Train epoch: 791 [1123440/78836 (52%)]	Loss: 0.087923
Train epoch: 791 [1384100/78836 (65%)]	Loss: 0.102022
Train epoch: 791 [1661040/78836 (78%)]	Loss: 0.102854
Train epoch: 791 [1990380/78836 (91%)]	Loss: 0.105218
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 792 [0/78836 (0%)]	Loss: 0.075424
Train epoch: 792 [282320/78836 (13%)]	Loss: 0.084819
Train epoch: 792 [562160/78836 (26%)]	Loss: 0.086870
Train epoch: 792 [834480/78836 (39%)]	Loss: 0.094809
Train epoch: 792 [1116000/78836 (52%)]	Loss: 0.079937
Train epoch: 792 [1413600/78836 (65%)]	Loss: 0.096721
Train epoch: 792 [1662240/78836 (78%)]	Loss: 0.091374
Train epoch: 792 [1943480/78836 (91%)]	Loss: 0.091686
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 793 [0/78836 (0%)]	Loss: 0.099247
Train epoch: 793 [278640/78836 (13%)]	Loss: 0.085542
Train epoch: 793 [557800/78836 (26%)]	Loss: 0.086591
Train epoch: 793 [847920/78836 (39%)]	Loss: 0.084683
Train epoch: 793 [1136320/78836 (52%)]	Loss: 0.083759
Train epoch: 793 [1406500/78836 (65%)]	Loss: 0.091170
Train epoch: 793 [1712040/78836 (78%)]	Loss: 0.087956
Train epoch: 793 [1969800/78836 (91%)]	Loss: 0.104499
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 794 [0/78836 (0%)]	Loss: 0.086616
Train epoch: 794 [280580/78836 (13%)]	Loss: 0.093155
Train epoch: 794 [559880/78836 (26%)]	Loss: 0.083604
Train epoch: 794 [834660/78836 (39%)]	Loss: 0.098596
Train epoch: 794 [1114000/78836 (52%)]	Loss: 0.099185
Train epoch: 794 [1400900/78836 (65%)]	Loss: 0.093296
Train epoch: 794 [1654560/78836 (78%)]	Loss: 0.080764
Train epoch: 794 [1920380/78836 (91%)]	Loss: 0.100570
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 795 [0/78836 (0%)]	Loss: 0.097006
Train epoch: 795 [278880/78836 (13%)]	Loss: 0.097017
Train epoch: 795 [563720/78836 (26%)]	Loss: 0.092514
Train epoch: 795 [827400/78836 (39%)]	Loss: 0.114360
Train epoch: 795 [1135520/78836 (52%)]	Loss: 0.079025
Train epoch: 795 [1409800/78836 (65%)]	Loss: 0.113071
Train epoch: 795 [1692720/78836 (78%)]	Loss: 0.096967
Train epoch: 795 [1967840/78836 (91%)]	Loss: 0.086146
predicting for valid data
Make prediction for 19709 samples...
0.16910128 No improvement since epoch  752 ; best_test_mse,best_test_ci: 0.16910128 0.8692729214109719 GINConvNet kiba
Training on 78836 samples...
Train epoch: 796 [0/78836 (0%)]	Loss: 0.085494
Train epoch: 796 [280880/78836 (13%)]	Loss: 0.087777
Train epoch: 796 [555520/78836 (26%)]	Loss: 0.104726
Train epoch: 796 [844260/78836 (39%)]	Loss: 0.081132
Train epoch: 796 [1088640/78836 (52%)]	Loss: 0.120115
Train epoch: 796 [1386900/78836 (65%)]	Loss: 0.095839
Train epoch: 796 [1664880/78836 (78%)]	Loss: 0.092260
Train epoch: 796 [1980580/78836 (91%)]	Loss: 0.102310
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 797 [0/78836 (0%)]	Loss: 0.087909
Train epoch: 797 [280640/78836 (13%)]	Loss: 0.081801
Train epoch: 797 [555160/78836 (26%)]	Loss: 0.073641
Train epoch: 797 [840120/78836 (39%)]	Loss: 0.089823
Train epoch: 797 [1124240/78836 (52%)]	Loss: 0.093557
Train epoch: 797 [1353800/78836 (65%)]	Loss: 0.103998
Train epoch: 797 [1653360/78836 (78%)]	Loss: 0.090001
Train epoch: 797 [1965180/78836 (91%)]	Loss: 0.105811
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 798 [0/78836 (0%)]	Loss: 0.075479
Train epoch: 798 [275040/78836 (13%)]	Loss: 0.088230
Train epoch: 798 [556840/78836 (26%)]	Loss: 0.084483
Train epoch: 798 [843240/78836 (39%)]	Loss: 0.097798
Train epoch: 798 [1136640/78836 (52%)]	Loss: 0.109753
Train epoch: 798 [1402400/78836 (65%)]	Loss: 0.105487
Train epoch: 798 [1637880/78836 (78%)]	Loss: 0.090491
Train epoch: 798 [1953420/78836 (91%)]	Loss: 0.112398
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 799 [0/78836 (0%)]	Loss: 0.098521
Train epoch: 799 [280220/78836 (13%)]	Loss: 0.087790
Train epoch: 799 [548480/78836 (26%)]	Loss: 0.095503
Train epoch: 799 [834360/78836 (39%)]	Loss: 0.112925
Train epoch: 799 [1090160/78836 (52%)]	Loss: 0.073845
Train epoch: 799 [1407700/78836 (65%)]	Loss: 0.100517
Train epoch: 799 [1710360/78836 (78%)]	Loss: 0.085817
Train epoch: 799 [1970640/78836 (91%)]	Loss: 0.091464
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 800 [0/78836 (0%)]	Loss: 0.090509
Train epoch: 800 [277840/78836 (13%)]	Loss: 0.085257
Train epoch: 800 [562840/78836 (26%)]	Loss: 0.089684
Train epoch: 800 [830040/78836 (39%)]	Loss: 0.094974
Train epoch: 800 [1116640/78836 (52%)]	Loss: 0.103355
Train epoch: 800 [1409400/78836 (65%)]	Loss: 0.102964
Train epoch: 800 [1701840/78836 (78%)]	Loss: 0.106822
Train epoch: 800 [1916880/78836 (91%)]	Loss: 0.092240
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 801 [0/78836 (0%)]	Loss: 0.069773
Train epoch: 801 [276100/78836 (13%)]	Loss: 0.087863
Train epoch: 801 [564160/78836 (26%)]	Loss: 0.090205
Train epoch: 801 [843660/78836 (39%)]	Loss: 0.089900
Train epoch: 801 [1101680/78836 (52%)]	Loss: 0.094293
Train epoch: 801 [1392200/78836 (65%)]	Loss: 0.113534
Train epoch: 801 [1681440/78836 (78%)]	Loss: 0.087224
Train epoch: 801 [1952860/78836 (91%)]	Loss: 0.080466
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 802 [0/78836 (0%)]	Loss: 0.076547
Train epoch: 802 [279780/78836 (13%)]	Loss: 0.091275
Train epoch: 802 [560600/78836 (26%)]	Loss: 0.086374
Train epoch: 802 [825660/78836 (39%)]	Loss: 0.073988
Train epoch: 802 [1101680/78836 (52%)]	Loss: 0.088927
Train epoch: 802 [1403300/78836 (65%)]	Loss: 0.088993
Train epoch: 802 [1726320/78836 (78%)]	Loss: 0.103666
Train epoch: 802 [1986880/78836 (91%)]	Loss: 0.103482
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 803 [0/78836 (0%)]	Loss: 0.073142
Train epoch: 803 [274880/78836 (13%)]	Loss: 0.093683
Train epoch: 803 [555080/78836 (26%)]	Loss: 0.093842
Train epoch: 803 [850260/78836 (39%)]	Loss: 0.100567
Train epoch: 803 [1114800/78836 (52%)]	Loss: 0.095381
Train epoch: 803 [1425900/78836 (65%)]	Loss: 0.115686
Train epoch: 803 [1679520/78836 (78%)]	Loss: 0.092838
Train epoch: 803 [1932420/78836 (91%)]	Loss: 0.091503
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 804 [0/78836 (0%)]	Loss: 0.074661
Train epoch: 804 [278900/78836 (13%)]	Loss: 0.089598
Train epoch: 804 [559400/78836 (26%)]	Loss: 0.096081
Train epoch: 804 [837660/78836 (39%)]	Loss: 0.090729
Train epoch: 804 [1101840/78836 (52%)]	Loss: 0.081405
Train epoch: 804 [1408100/78836 (65%)]	Loss: 0.084911
Train epoch: 804 [1670760/78836 (78%)]	Loss: 0.095393
Train epoch: 804 [1925420/78836 (91%)]	Loss: 0.098120
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 805 [0/78836 (0%)]	Loss: 0.089719
Train epoch: 805 [273760/78836 (13%)]	Loss: 0.091001
Train epoch: 805 [550080/78836 (26%)]	Loss: 0.094379
Train epoch: 805 [853500/78836 (39%)]	Loss: 0.084109
Train epoch: 805 [1110240/78836 (52%)]	Loss: 0.081449
Train epoch: 805 [1388200/78836 (65%)]	Loss: 0.096012
Train epoch: 805 [1708920/78836 (78%)]	Loss: 0.100168
Train epoch: 805 [1982680/78836 (91%)]	Loss: 0.080264
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 806 [0/78836 (0%)]	Loss: 0.081925
Train epoch: 806 [276580/78836 (13%)]	Loss: 0.070866
Train epoch: 806 [543200/78836 (26%)]	Loss: 0.070967
Train epoch: 806 [853080/78836 (39%)]	Loss: 0.090149
Train epoch: 806 [1132480/78836 (52%)]	Loss: 0.098766
Train epoch: 806 [1400200/78836 (65%)]	Loss: 0.102585
Train epoch: 806 [1675080/78836 (78%)]	Loss: 0.106216
Train epoch: 806 [1953980/78836 (91%)]	Loss: 0.092983
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 807 [0/78836 (0%)]	Loss: 0.093915
Train epoch: 807 [273500/78836 (13%)]	Loss: 0.066762
Train epoch: 807 [565040/78836 (26%)]	Loss: 0.093409
Train epoch: 807 [839640/78836 (39%)]	Loss: 0.108050
Train epoch: 807 [1134160/78836 (52%)]	Loss: 0.076228
Train epoch: 807 [1399600/78836 (65%)]	Loss: 0.073501
Train epoch: 807 [1689240/78836 (78%)]	Loss: 0.108518
Train epoch: 807 [1928920/78836 (91%)]	Loss: 0.085053
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 808 [0/78836 (0%)]	Loss: 0.085034
Train epoch: 808 [277740/78836 (13%)]	Loss: 0.086464
Train epoch: 808 [563360/78836 (26%)]	Loss: 0.077966
Train epoch: 808 [840600/78836 (39%)]	Loss: 0.085316
Train epoch: 808 [1123760/78836 (52%)]	Loss: 0.101774
Train epoch: 808 [1419400/78836 (65%)]	Loss: 0.106753
Train epoch: 808 [1672920/78836 (78%)]	Loss: 0.082948
Train epoch: 808 [1984220/78836 (91%)]	Loss: 0.097934
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 809 [0/78836 (0%)]	Loss: 0.094630
Train epoch: 809 [284220/78836 (13%)]	Loss: 0.086726
Train epoch: 809 [554840/78836 (26%)]	Loss: 0.095632
Train epoch: 809 [833940/78836 (39%)]	Loss: 0.088203
Train epoch: 809 [1117680/78836 (52%)]	Loss: 0.117012
Train epoch: 809 [1401700/78836 (65%)]	Loss: 0.083425
Train epoch: 809 [1644120/78836 (78%)]	Loss: 0.068932
Train epoch: 809 [2001720/78836 (91%)]	Loss: 0.101223
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 810 [0/78836 (0%)]	Loss: 0.078538
Train epoch: 810 [277340/78836 (13%)]	Loss: 0.078585
Train epoch: 810 [550680/78836 (26%)]	Loss: 0.092889
Train epoch: 810 [848280/78836 (39%)]	Loss: 0.098868
Train epoch: 810 [1141120/78836 (52%)]	Loss: 0.099765
Train epoch: 810 [1357800/78836 (65%)]	Loss: 0.153831
Train epoch: 810 [1658400/78836 (78%)]	Loss: 0.100991
Train epoch: 810 [1949780/78836 (91%)]	Loss: 0.077771
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 811 [0/78836 (0%)]	Loss: 0.069012
Train epoch: 811 [279960/78836 (13%)]	Loss: 0.083857
Train epoch: 811 [551880/78836 (26%)]	Loss: 0.093169
Train epoch: 811 [851520/78836 (39%)]	Loss: 0.091741
Train epoch: 811 [1116640/78836 (52%)]	Loss: 0.089298
Train epoch: 811 [1369800/78836 (65%)]	Loss: 0.071359
Train epoch: 811 [1629600/78836 (78%)]	Loss: 0.094173
Train epoch: 811 [1947680/78836 (91%)]	Loss: 0.082957
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 812 [0/78836 (0%)]	Loss: 0.084487
Train epoch: 812 [278660/78836 (13%)]	Loss: 0.091075
Train epoch: 812 [555080/78836 (26%)]	Loss: 0.076406
Train epoch: 812 [833160/78836 (39%)]	Loss: 0.094351
Train epoch: 812 [1127520/78836 (52%)]	Loss: 0.087632
Train epoch: 812 [1431800/78836 (65%)]	Loss: 0.098929
Train epoch: 812 [1661640/78836 (78%)]	Loss: 0.075834
Train epoch: 812 [1945580/78836 (91%)]	Loss: 0.093661
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 813 [0/78836 (0%)]	Loss: 0.091926
Train epoch: 813 [276440/78836 (13%)]	Loss: 0.087566
Train epoch: 813 [555000/78836 (26%)]	Loss: 0.080342
Train epoch: 813 [854100/78836 (39%)]	Loss: 0.092991
Train epoch: 813 [1124640/78836 (52%)]	Loss: 0.085666
Train epoch: 813 [1385600/78836 (65%)]	Loss: 0.103338
Train epoch: 813 [1658760/78836 (78%)]	Loss: 0.103773
Train epoch: 813 [1954120/78836 (91%)]	Loss: 0.087621
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 814 [0/78836 (0%)]	Loss: 0.091466
Train epoch: 814 [279040/78836 (13%)]	Loss: 0.099607
Train epoch: 814 [557600/78836 (26%)]	Loss: 0.073182
Train epoch: 814 [843960/78836 (39%)]	Loss: 0.085577
Train epoch: 814 [1122240/78836 (52%)]	Loss: 0.089791
Train epoch: 814 [1406900/78836 (65%)]	Loss: 0.096876
Train epoch: 814 [1677000/78836 (78%)]	Loss: 0.091488
Train epoch: 814 [1935220/78836 (91%)]	Loss: 0.077791
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 815 [0/78836 (0%)]	Loss: 0.080693
Train epoch: 815 [278780/78836 (13%)]	Loss: 0.082329
Train epoch: 815 [550760/78836 (26%)]	Loss: 0.082718
Train epoch: 815 [839580/78836 (39%)]	Loss: 0.106990
Train epoch: 815 [1112960/78836 (52%)]	Loss: 0.089810
Train epoch: 815 [1396500/78836 (65%)]	Loss: 0.091029
Train epoch: 815 [1695360/78836 (78%)]	Loss: 0.084399
Train epoch: 815 [1931860/78836 (91%)]	Loss: 0.076250
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 816 [0/78836 (0%)]	Loss: 0.082032
Train epoch: 816 [280300/78836 (13%)]	Loss: 0.089769
Train epoch: 816 [567600/78836 (26%)]	Loss: 0.078969
Train epoch: 816 [832500/78836 (39%)]	Loss: 0.108346
Train epoch: 816 [1127520/78836 (52%)]	Loss: 0.098156
Train epoch: 816 [1373600/78836 (65%)]	Loss: 0.103405
Train epoch: 816 [1717920/78836 (78%)]	Loss: 0.087531
Train epoch: 816 [1969660/78836 (91%)]	Loss: 0.093932
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 817 [0/78836 (0%)]	Loss: 0.099763
Train epoch: 817 [277300/78836 (13%)]	Loss: 0.077959
Train epoch: 817 [560160/78836 (26%)]	Loss: 0.100903
Train epoch: 817 [832500/78836 (39%)]	Loss: 0.094214
Train epoch: 817 [1106720/78836 (52%)]	Loss: 0.090338
Train epoch: 817 [1378000/78836 (65%)]	Loss: 0.070611
Train epoch: 817 [1670040/78836 (78%)]	Loss: 0.084267
Train epoch: 817 [1937040/78836 (91%)]	Loss: 0.085132
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 818 [0/78836 (0%)]	Loss: 0.069808
Train epoch: 818 [280980/78836 (13%)]	Loss: 0.073696
Train epoch: 818 [565800/78836 (26%)]	Loss: 0.072910
Train epoch: 818 [849000/78836 (39%)]	Loss: 0.095228
Train epoch: 818 [1131440/78836 (52%)]	Loss: 0.089357
Train epoch: 818 [1369800/78836 (65%)]	Loss: 0.098160
Train epoch: 818 [1694520/78836 (78%)]	Loss: 0.075608
Train epoch: 818 [1936620/78836 (91%)]	Loss: 0.116156
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 819 [0/78836 (0%)]	Loss: 0.087349
Train epoch: 819 [286960/78836 (13%)]	Loss: 0.082508
Train epoch: 819 [568000/78836 (26%)]	Loss: 0.103170
Train epoch: 819 [814860/78836 (39%)]	Loss: 0.095874
Train epoch: 819 [1126320/78836 (52%)]	Loss: 0.109330
Train epoch: 819 [1403300/78836 (65%)]	Loss: 0.098555
Train epoch: 819 [1704000/78836 (78%)]	Loss: 0.085837
Train epoch: 819 [1921500/78836 (91%)]	Loss: 0.106400
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 820 [0/78836 (0%)]	Loss: 0.070326
Train epoch: 820 [280740/78836 (13%)]	Loss: 0.072241
Train epoch: 820 [551760/78836 (26%)]	Loss: 0.091117
Train epoch: 820 [838620/78836 (39%)]	Loss: 0.101879
Train epoch: 820 [1126400/78836 (52%)]	Loss: 0.082547
Train epoch: 820 [1368200/78836 (65%)]	Loss: 0.091661
Train epoch: 820 [1688160/78836 (78%)]	Loss: 0.085704
Train epoch: 820 [1970780/78836 (91%)]	Loss: 0.080323
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 821 [0/78836 (0%)]	Loss: 0.087656
Train epoch: 821 [276320/78836 (13%)]	Loss: 0.084966
Train epoch: 821 [560240/78836 (26%)]	Loss: 0.099294
Train epoch: 821 [842400/78836 (39%)]	Loss: 0.088891
Train epoch: 821 [1093360/78836 (52%)]	Loss: 0.090391
Train epoch: 821 [1429600/78836 (65%)]	Loss: 0.090229
Train epoch: 821 [1674360/78836 (78%)]	Loss: 0.099476
Train epoch: 821 [1974700/78836 (91%)]	Loss: 0.083630
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 822 [0/78836 (0%)]	Loss: 0.083783
Train epoch: 822 [288180/78836 (13%)]	Loss: 0.095624
Train epoch: 822 [558680/78836 (26%)]	Loss: 0.077505
Train epoch: 822 [846660/78836 (39%)]	Loss: 0.087862
Train epoch: 822 [1107200/78836 (52%)]	Loss: 0.079426
Train epoch: 822 [1385400/78836 (65%)]	Loss: 0.076563
Train epoch: 822 [1679280/78836 (78%)]	Loss: 0.086965
Train epoch: 822 [1918140/78836 (91%)]	Loss: 0.095175
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 823 [0/78836 (0%)]	Loss: 0.083281
Train epoch: 823 [282580/78836 (13%)]	Loss: 0.076628
Train epoch: 823 [571880/78836 (26%)]	Loss: 0.083192
Train epoch: 823 [820740/78836 (39%)]	Loss: 0.081512
Train epoch: 823 [1140240/78836 (52%)]	Loss: 0.093418
Train epoch: 823 [1393700/78836 (65%)]	Loss: 0.082692
Train epoch: 823 [1653840/78836 (78%)]	Loss: 0.083862
Train epoch: 823 [1993040/78836 (91%)]	Loss: 0.110830
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 824 [0/78836 (0%)]	Loss: 0.090259
Train epoch: 824 [285200/78836 (13%)]	Loss: 0.076703
Train epoch: 824 [561720/78836 (26%)]	Loss: 0.132090
Train epoch: 824 [825240/78836 (39%)]	Loss: 0.078649
Train epoch: 824 [1103120/78836 (52%)]	Loss: 0.084525
Train epoch: 824 [1405300/78836 (65%)]	Loss: 0.108857
Train epoch: 824 [1626720/78836 (78%)]	Loss: 0.109172
Train epoch: 824 [1895040/78836 (91%)]	Loss: 0.074214
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 825 [0/78836 (0%)]	Loss: 0.079650
Train epoch: 825 [277720/78836 (13%)]	Loss: 0.101578
Train epoch: 825 [562760/78836 (26%)]	Loss: 0.086214
Train epoch: 825 [842820/78836 (39%)]	Loss: 0.083678
Train epoch: 825 [1127520/78836 (52%)]	Loss: 0.078752
Train epoch: 825 [1391800/78836 (65%)]	Loss: 0.091854
Train epoch: 825 [1665360/78836 (78%)]	Loss: 0.083153
Train epoch: 825 [1956500/78836 (91%)]	Loss: 0.078518
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 826 [0/78836 (0%)]	Loss: 0.089216
Train epoch: 826 [276280/78836 (13%)]	Loss: 0.104305
Train epoch: 826 [553600/78836 (26%)]	Loss: 0.081951
Train epoch: 826 [847380/78836 (39%)]	Loss: 0.110909
Train epoch: 826 [1088080/78836 (52%)]	Loss: 0.082637
Train epoch: 826 [1421200/78836 (65%)]	Loss: 0.088103
Train epoch: 826 [1674600/78836 (78%)]	Loss: 0.080019
Train epoch: 826 [2017680/78836 (91%)]	Loss: 0.079548
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 827 [0/78836 (0%)]	Loss: 0.075970
Train epoch: 827 [276200/78836 (13%)]	Loss: 0.067217
Train epoch: 827 [558640/78836 (26%)]	Loss: 0.086033
Train epoch: 827 [831660/78836 (39%)]	Loss: 0.088607
Train epoch: 827 [1127520/78836 (52%)]	Loss: 0.066728
Train epoch: 827 [1385800/78836 (65%)]	Loss: 0.079001
Train epoch: 827 [1668600/78836 (78%)]	Loss: 0.091981
Train epoch: 827 [1953000/78836 (91%)]	Loss: 0.082119
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 828 [0/78836 (0%)]	Loss: 0.073791
Train epoch: 828 [277600/78836 (13%)]	Loss: 0.079876
Train epoch: 828 [556800/78836 (26%)]	Loss: 0.099557
Train epoch: 828 [877620/78836 (39%)]	Loss: 0.075521
Train epoch: 828 [1107360/78836 (52%)]	Loss: 0.082752
Train epoch: 828 [1407700/78836 (65%)]	Loss: 0.085931
Train epoch: 828 [1675680/78836 (78%)]	Loss: 0.081603
Train epoch: 828 [1940540/78836 (91%)]	Loss: 0.076913
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 829 [0/78836 (0%)]	Loss: 0.074529
Train epoch: 829 [285760/78836 (13%)]	Loss: 0.089816
Train epoch: 829 [554240/78836 (26%)]	Loss: 0.078052
Train epoch: 829 [844140/78836 (39%)]	Loss: 0.091751
Train epoch: 829 [1105040/78836 (52%)]	Loss: 0.086494
Train epoch: 829 [1397200/78836 (65%)]	Loss: 0.088206
Train epoch: 829 [1651920/78836 (78%)]	Loss: 0.092393
Train epoch: 829 [1941800/78836 (91%)]	Loss: 0.082831
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 830 [0/78836 (0%)]	Loss: 0.098347
Train epoch: 830 [277000/78836 (13%)]	Loss: 0.089816
Train epoch: 830 [555560/78836 (26%)]	Loss: 0.096089
Train epoch: 830 [852480/78836 (39%)]	Loss: 0.079490
Train epoch: 830 [1133760/78836 (52%)]	Loss: 0.094134
Train epoch: 830 [1409000/78836 (65%)]	Loss: 0.096308
Train epoch: 830 [1653000/78836 (78%)]	Loss: 0.089318
Train epoch: 830 [1939840/78836 (91%)]	Loss: 0.077788
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 831 [0/78836 (0%)]	Loss: 0.071198
Train epoch: 831 [279240/78836 (13%)]	Loss: 0.076667
Train epoch: 831 [551080/78836 (26%)]	Loss: 0.087440
Train epoch: 831 [846900/78836 (39%)]	Loss: 0.094765
Train epoch: 831 [1116640/78836 (52%)]	Loss: 0.071666
Train epoch: 831 [1396200/78836 (65%)]	Loss: 0.100710
Train epoch: 831 [1685520/78836 (78%)]	Loss: 0.084391
Train epoch: 831 [1921920/78836 (91%)]	Loss: 0.096905
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 832 [0/78836 (0%)]	Loss: 0.083760
Train epoch: 832 [275680/78836 (13%)]	Loss: 0.082958
Train epoch: 832 [558400/78836 (26%)]	Loss: 0.089194
Train epoch: 832 [845460/78836 (39%)]	Loss: 0.106421
Train epoch: 832 [1121120/78836 (52%)]	Loss: 0.077308
Train epoch: 832 [1379300/78836 (65%)]	Loss: 0.072009
Train epoch: 832 [1669320/78836 (78%)]	Loss: 0.075188
Train epoch: 832 [1948520/78836 (91%)]	Loss: 0.080462
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 833 [0/78836 (0%)]	Loss: 0.091729
Train epoch: 833 [279400/78836 (13%)]	Loss: 0.083470
Train epoch: 833 [553440/78836 (26%)]	Loss: 0.099321
Train epoch: 833 [831840/78836 (39%)]	Loss: 0.091409
Train epoch: 833 [1135440/78836 (52%)]	Loss: 0.077823
Train epoch: 833 [1407300/78836 (65%)]	Loss: 0.085782
Train epoch: 833 [1712400/78836 (78%)]	Loss: 0.097708
Train epoch: 833 [1947540/78836 (91%)]	Loss: 0.079304
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 834 [0/78836 (0%)]	Loss: 0.083748
Train epoch: 834 [279360/78836 (13%)]	Loss: 0.068046
Train epoch: 834 [564400/78836 (26%)]	Loss: 0.094669
Train epoch: 834 [843720/78836 (39%)]	Loss: 0.098400
Train epoch: 834 [1132560/78836 (52%)]	Loss: 0.097100
Train epoch: 834 [1385200/78836 (65%)]	Loss: 0.087666
Train epoch: 834 [1685280/78836 (78%)]	Loss: 0.072951
Train epoch: 834 [1903860/78836 (91%)]	Loss: 0.091165
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 835 [0/78836 (0%)]	Loss: 0.084874
Train epoch: 835 [283260/78836 (13%)]	Loss: 0.075820
Train epoch: 835 [566800/78836 (26%)]	Loss: 0.079083
Train epoch: 835 [838740/78836 (39%)]	Loss: 0.083004
Train epoch: 835 [1107440/78836 (52%)]	Loss: 0.070794
Train epoch: 835 [1384400/78836 (65%)]	Loss: 0.074842
Train epoch: 835 [1717800/78836 (78%)]	Loss: 0.083964
Train epoch: 835 [1903160/78836 (91%)]	Loss: 0.113159
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 836 [0/78836 (0%)]	Loss: 0.076537
Train epoch: 836 [284580/78836 (13%)]	Loss: 0.079909
Train epoch: 836 [563720/78836 (26%)]	Loss: 0.086286
Train epoch: 836 [845340/78836 (39%)]	Loss: 0.103397
Train epoch: 836 [1091600/78836 (52%)]	Loss: 0.089917
Train epoch: 836 [1366900/78836 (65%)]	Loss: 0.086273
Train epoch: 836 [1676040/78836 (78%)]	Loss: 0.075082
Train epoch: 836 [1949220/78836 (91%)]	Loss: 0.083892
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 837 [0/78836 (0%)]	Loss: 0.077815
Train epoch: 837 [276180/78836 (13%)]	Loss: 0.085583
Train epoch: 837 [575200/78836 (26%)]	Loss: 0.071420
Train epoch: 837 [850020/78836 (39%)]	Loss: 0.079388
Train epoch: 837 [1086560/78836 (52%)]	Loss: 0.073883
Train epoch: 837 [1426100/78836 (65%)]	Loss: 0.097475
Train epoch: 837 [1680240/78836 (78%)]	Loss: 0.104950
Train epoch: 837 [1957760/78836 (91%)]	Loss: 0.074449
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 838 [0/78836 (0%)]	Loss: 0.086067
Train epoch: 838 [282860/78836 (13%)]	Loss: 0.070792
Train epoch: 838 [563760/78836 (26%)]	Loss: 0.078077
Train epoch: 838 [839760/78836 (39%)]	Loss: 0.091407
Train epoch: 838 [1105200/78836 (52%)]	Loss: 0.065862
Train epoch: 838 [1406500/78836 (65%)]	Loss: 0.073771
Train epoch: 838 [1664760/78836 (78%)]	Loss: 0.082394
Train epoch: 838 [1968540/78836 (91%)]	Loss: 0.097892
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 839 [0/78836 (0%)]	Loss: 0.077273
Train epoch: 839 [282200/78836 (13%)]	Loss: 0.088120
Train epoch: 839 [550840/78836 (26%)]	Loss: 0.140642
Train epoch: 839 [849480/78836 (39%)]	Loss: 0.079696
Train epoch: 839 [1088800/78836 (52%)]	Loss: 0.076633
Train epoch: 839 [1387400/78836 (65%)]	Loss: 0.095537
Train epoch: 839 [1680000/78836 (78%)]	Loss: 0.073137
Train epoch: 839 [1960140/78836 (91%)]	Loss: 0.071200
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 840 [0/78836 (0%)]	Loss: 0.084746
Train epoch: 840 [279480/78836 (13%)]	Loss: 0.081275
Train epoch: 840 [575320/78836 (26%)]	Loss: 0.090016
Train epoch: 840 [850200/78836 (39%)]	Loss: 0.090235
Train epoch: 840 [1122240/78836 (52%)]	Loss: 0.088560
Train epoch: 840 [1396100/78836 (65%)]	Loss: 0.098360
Train epoch: 840 [1657440/78836 (78%)]	Loss: 0.121899
Train epoch: 840 [1933540/78836 (91%)]	Loss: 0.096280
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 841 [0/78836 (0%)]	Loss: 0.186652
Train epoch: 841 [282620/78836 (13%)]	Loss: 0.082064
Train epoch: 841 [561000/78836 (26%)]	Loss: 0.087173
Train epoch: 841 [854340/78836 (39%)]	Loss: 0.093355
Train epoch: 841 [1095440/78836 (52%)]	Loss: 0.083313
Train epoch: 841 [1404900/78836 (65%)]	Loss: 0.092030
Train epoch: 841 [1692480/78836 (78%)]	Loss: 0.073017
Train epoch: 841 [1971200/78836 (91%)]	Loss: 0.086214
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 842 [0/78836 (0%)]	Loss: 0.084400
Train epoch: 842 [278800/78836 (13%)]	Loss: 0.072837
Train epoch: 842 [535120/78836 (26%)]	Loss: 0.076614
Train epoch: 842 [842580/78836 (39%)]	Loss: 0.102081
Train epoch: 842 [1102960/78836 (52%)]	Loss: 0.093117
Train epoch: 842 [1413200/78836 (65%)]	Loss: 0.082538
Train epoch: 842 [1703280/78836 (78%)]	Loss: 0.096287
Train epoch: 842 [1922620/78836 (91%)]	Loss: 0.072818
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 843 [0/78836 (0%)]	Loss: 0.083330
Train epoch: 843 [278240/78836 (13%)]	Loss: 0.065879
Train epoch: 843 [554840/78836 (26%)]	Loss: 0.078431
Train epoch: 843 [842280/78836 (39%)]	Loss: 0.084137
Train epoch: 843 [1123200/78836 (52%)]	Loss: 0.076654
Train epoch: 843 [1403700/78836 (65%)]	Loss: 0.079356
Train epoch: 843 [1661280/78836 (78%)]	Loss: 0.107849
Train epoch: 843 [1993460/78836 (91%)]	Loss: 0.100875
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 844 [0/78836 (0%)]	Loss: 0.088510
Train epoch: 844 [273100/78836 (13%)]	Loss: 0.075351
Train epoch: 844 [559120/78836 (26%)]	Loss: 0.095110
Train epoch: 844 [834480/78836 (39%)]	Loss: 0.091877
Train epoch: 844 [1098800/78836 (52%)]	Loss: 0.082756
Train epoch: 844 [1364500/78836 (65%)]	Loss: 0.074376
Train epoch: 844 [1684800/78836 (78%)]	Loss: 0.081148
Train epoch: 844 [1981980/78836 (91%)]	Loss: 0.103412
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 845 [0/78836 (0%)]	Loss: 0.079600
Train epoch: 845 [282900/78836 (13%)]	Loss: 0.075663
Train epoch: 845 [569360/78836 (26%)]	Loss: 0.088623
Train epoch: 845 [825240/78836 (39%)]	Loss: 0.081369
Train epoch: 845 [1095040/78836 (52%)]	Loss: 0.087905
Train epoch: 845 [1416800/78836 (65%)]	Loss: 0.087425
Train epoch: 845 [1652760/78836 (78%)]	Loss: 0.083610
Train epoch: 845 [2043440/78836 (91%)]	Loss: 0.083053
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 846 [0/78836 (0%)]	Loss: 0.071999
Train epoch: 846 [287180/78836 (13%)]	Loss: 0.074836
Train epoch: 846 [552520/78836 (26%)]	Loss: 0.067350
Train epoch: 846 [841440/78836 (39%)]	Loss: 0.092033
Train epoch: 846 [1089840/78836 (52%)]	Loss: 0.074562
Train epoch: 846 [1414700/78836 (65%)]	Loss: 0.090967
Train epoch: 846 [1696080/78836 (78%)]	Loss: 0.080833
Train epoch: 846 [1922900/78836 (91%)]	Loss: 0.073146
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 847 [0/78836 (0%)]	Loss: 0.082692
Train epoch: 847 [280780/78836 (13%)]	Loss: 0.089862
Train epoch: 847 [574320/78836 (26%)]	Loss: 0.071735
Train epoch: 847 [835860/78836 (39%)]	Loss: 0.091078
Train epoch: 847 [1114800/78836 (52%)]	Loss: 0.083823
Train epoch: 847 [1378400/78836 (65%)]	Loss: 0.100632
Train epoch: 847 [1670880/78836 (78%)]	Loss: 0.085559
Train epoch: 847 [1923880/78836 (91%)]	Loss: 0.088060
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 848 [0/78836 (0%)]	Loss: 0.084780
Train epoch: 848 [277400/78836 (13%)]	Loss: 0.087784
Train epoch: 848 [558480/78836 (26%)]	Loss: 0.094264
Train epoch: 848 [840060/78836 (39%)]	Loss: 0.086325
Train epoch: 848 [1114640/78836 (52%)]	Loss: 0.066710
Train epoch: 848 [1386000/78836 (65%)]	Loss: 0.099836
Train epoch: 848 [1697280/78836 (78%)]	Loss: 0.075515
Train epoch: 848 [1928640/78836 (91%)]	Loss: 0.084288
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 849 [0/78836 (0%)]	Loss: 0.093039
Train epoch: 849 [285500/78836 (13%)]	Loss: 0.074022
Train epoch: 849 [563120/78836 (26%)]	Loss: 0.079673
Train epoch: 849 [832020/78836 (39%)]	Loss: 0.092344
Train epoch: 849 [1138560/78836 (52%)]	Loss: 0.098535
Train epoch: 849 [1375600/78836 (65%)]	Loss: 0.070177
Train epoch: 849 [1674840/78836 (78%)]	Loss: 0.115369
Train epoch: 849 [1885660/78836 (91%)]	Loss: 0.076403
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 850 [0/78836 (0%)]	Loss: 0.072800
Train epoch: 850 [280800/78836 (13%)]	Loss: 0.081745
Train epoch: 850 [551760/78836 (26%)]	Loss: 0.087725
Train epoch: 850 [822660/78836 (39%)]	Loss: 0.080055
Train epoch: 850 [1113440/78836 (52%)]	Loss: 0.082004
Train epoch: 850 [1398800/78836 (65%)]	Loss: 0.083560
Train epoch: 850 [1697400/78836 (78%)]	Loss: 0.082058
Train epoch: 850 [1916600/78836 (91%)]	Loss: 0.124721
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 851 [0/78836 (0%)]	Loss: 0.081913
Train epoch: 851 [273460/78836 (13%)]	Loss: 0.087236
Train epoch: 851 [564160/78836 (26%)]	Loss: 0.077525
Train epoch: 851 [839040/78836 (39%)]	Loss: 0.088732
Train epoch: 851 [1110960/78836 (52%)]	Loss: 0.088048
Train epoch: 851 [1390000/78836 (65%)]	Loss: 0.078884
Train epoch: 851 [1706520/78836 (78%)]	Loss: 0.101302
Train epoch: 851 [1975540/78836 (91%)]	Loss: 0.094938
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 852 [0/78836 (0%)]	Loss: 0.087855
Train epoch: 852 [276000/78836 (13%)]	Loss: 0.105895
Train epoch: 852 [559280/78836 (26%)]	Loss: 0.091630
Train epoch: 852 [867480/78836 (39%)]	Loss: 0.084021
Train epoch: 852 [1100640/78836 (52%)]	Loss: 0.071282
Train epoch: 852 [1424700/78836 (65%)]	Loss: 0.089532
Train epoch: 852 [1707960/78836 (78%)]	Loss: 0.071410
Train epoch: 852 [1974000/78836 (91%)]	Loss: 0.072305
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 853 [0/78836 (0%)]	Loss: 0.085427
Train epoch: 853 [276340/78836 (13%)]	Loss: 0.066796
Train epoch: 853 [557280/78836 (26%)]	Loss: 0.080420
Train epoch: 853 [834000/78836 (39%)]	Loss: 0.088127
Train epoch: 853 [1100400/78836 (52%)]	Loss: 0.075428
Train epoch: 853 [1412200/78836 (65%)]	Loss: 0.079693
Train epoch: 853 [1643400/78836 (78%)]	Loss: 0.083793
Train epoch: 853 [1964340/78836 (91%)]	Loss: 0.082572
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 854 [0/78836 (0%)]	Loss: 0.090429
Train epoch: 854 [281780/78836 (13%)]	Loss: 0.084031
Train epoch: 854 [555520/78836 (26%)]	Loss: 0.086227
Train epoch: 854 [851160/78836 (39%)]	Loss: 0.093504
Train epoch: 854 [1120160/78836 (52%)]	Loss: 0.096338
Train epoch: 854 [1429800/78836 (65%)]	Loss: 0.088048
Train epoch: 854 [1674000/78836 (78%)]	Loss: 0.096974
Train epoch: 854 [1940120/78836 (91%)]	Loss: 0.102918
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 855 [0/78836 (0%)]	Loss: 0.088493
Train epoch: 855 [273600/78836 (13%)]	Loss: 0.094961
Train epoch: 855 [569280/78836 (26%)]	Loss: 0.072286
Train epoch: 855 [831600/78836 (39%)]	Loss: 0.081856
Train epoch: 855 [1111600/78836 (52%)]	Loss: 0.088195
Train epoch: 855 [1401900/78836 (65%)]	Loss: 0.081658
Train epoch: 855 [1652040/78836 (78%)]	Loss: 0.076260
Train epoch: 855 [1889300/78836 (91%)]	Loss: 0.086157
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 856 [0/78836 (0%)]	Loss: 0.080505
Train epoch: 856 [286440/78836 (13%)]	Loss: 0.069134
Train epoch: 856 [562880/78836 (26%)]	Loss: 0.071891
Train epoch: 856 [836940/78836 (39%)]	Loss: 0.101184
Train epoch: 856 [1118320/78836 (52%)]	Loss: 0.070390
Train epoch: 856 [1396500/78836 (65%)]	Loss: 0.077919
Train epoch: 856 [1660080/78836 (78%)]	Loss: 0.076289
Train epoch: 856 [1968400/78836 (91%)]	Loss: 0.078179
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 857 [0/78836 (0%)]	Loss: 0.093762
Train epoch: 857 [274740/78836 (13%)]	Loss: 0.082134
Train epoch: 857 [551880/78836 (26%)]	Loss: 0.083550
Train epoch: 857 [839400/78836 (39%)]	Loss: 0.082829
Train epoch: 857 [1116640/78836 (52%)]	Loss: 0.077130
Train epoch: 857 [1421700/78836 (65%)]	Loss: 0.069262
Train epoch: 857 [1657920/78836 (78%)]	Loss: 0.085821
Train epoch: 857 [1976380/78836 (91%)]	Loss: 0.130414
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 858 [0/78836 (0%)]	Loss: 0.099396
Train epoch: 858 [282800/78836 (13%)]	Loss: 0.074486
Train epoch: 858 [554880/78836 (26%)]	Loss: 0.075963
Train epoch: 858 [862440/78836 (39%)]	Loss: 0.072887
Train epoch: 858 [1109520/78836 (52%)]	Loss: 0.078494
Train epoch: 858 [1386400/78836 (65%)]	Loss: 0.096625
Train epoch: 858 [1695720/78836 (78%)]	Loss: 0.092636
Train epoch: 858 [1956640/78836 (91%)]	Loss: 0.081171
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 859 [0/78836 (0%)]	Loss: 0.078085
Train epoch: 859 [280760/78836 (13%)]	Loss: 0.088803
Train epoch: 859 [554120/78836 (26%)]	Loss: 0.086123
Train epoch: 859 [816180/78836 (39%)]	Loss: 0.073027
Train epoch: 859 [1129520/78836 (52%)]	Loss: 0.079972
Train epoch: 859 [1393800/78836 (65%)]	Loss: 0.087615
Train epoch: 859 [1682160/78836 (78%)]	Loss: 0.081388
Train epoch: 859 [1974840/78836 (91%)]	Loss: 0.087510
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 860 [0/78836 (0%)]	Loss: 0.066668
Train epoch: 860 [281700/78836 (13%)]	Loss: 0.069443
Train epoch: 860 [564680/78836 (26%)]	Loss: 0.069930
Train epoch: 860 [850380/78836 (39%)]	Loss: 0.130788
Train epoch: 860 [1115920/78836 (52%)]	Loss: 0.075728
Train epoch: 860 [1397900/78836 (65%)]	Loss: 0.085467
Train epoch: 860 [1680120/78836 (78%)]	Loss: 0.077606
Train epoch: 860 [1940120/78836 (91%)]	Loss: 0.085625
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 861 [0/78836 (0%)]	Loss: 0.080705
Train epoch: 861 [277900/78836 (13%)]	Loss: 0.086615
Train epoch: 861 [566760/78836 (26%)]	Loss: 0.085416
Train epoch: 861 [835800/78836 (39%)]	Loss: 0.053959
Train epoch: 861 [1091040/78836 (52%)]	Loss: 0.061017
Train epoch: 861 [1402100/78836 (65%)]	Loss: 0.097485
Train epoch: 861 [1679640/78836 (78%)]	Loss: 0.074252
Train epoch: 861 [2001020/78836 (91%)]	Loss: 0.086520
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 862 [0/78836 (0%)]	Loss: 0.094436
Train epoch: 862 [278840/78836 (13%)]	Loss: 0.112796
Train epoch: 862 [567240/78836 (26%)]	Loss: 0.080591
Train epoch: 862 [836880/78836 (39%)]	Loss: 0.081721
Train epoch: 862 [1114080/78836 (52%)]	Loss: 0.079079
Train epoch: 862 [1366600/78836 (65%)]	Loss: 0.097060
Train epoch: 862 [1727160/78836 (78%)]	Loss: 0.099443
Train epoch: 862 [1964620/78836 (91%)]	Loss: 0.090216
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 863 [0/78836 (0%)]	Loss: 0.072478
Train epoch: 863 [282540/78836 (13%)]	Loss: 0.082023
Train epoch: 863 [558240/78836 (26%)]	Loss: 0.080306
Train epoch: 863 [836160/78836 (39%)]	Loss: 0.082338
Train epoch: 863 [1118480/78836 (52%)]	Loss: 0.073216
Train epoch: 863 [1404000/78836 (65%)]	Loss: 0.105963
Train epoch: 863 [1655520/78836 (78%)]	Loss: 0.090444
Train epoch: 863 [1944880/78836 (91%)]	Loss: 0.072768
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 864 [0/78836 (0%)]	Loss: 0.069885
Train epoch: 864 [279420/78836 (13%)]	Loss: 0.074353
Train epoch: 864 [562360/78836 (26%)]	Loss: 0.087920
Train epoch: 864 [818400/78836 (39%)]	Loss: 0.092463
Train epoch: 864 [1123120/78836 (52%)]	Loss: 0.077970
Train epoch: 864 [1394400/78836 (65%)]	Loss: 0.070767
Train epoch: 864 [1671600/78836 (78%)]	Loss: 0.086088
Train epoch: 864 [1953280/78836 (91%)]	Loss: 0.091102
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 865 [0/78836 (0%)]	Loss: 0.078515
Train epoch: 865 [279700/78836 (13%)]	Loss: 0.117728
Train epoch: 865 [555120/78836 (26%)]	Loss: 0.079098
Train epoch: 865 [827040/78836 (39%)]	Loss: 0.081475
Train epoch: 865 [1118400/78836 (52%)]	Loss: 0.096396
Train epoch: 865 [1399500/78836 (65%)]	Loss: 0.083267
Train epoch: 865 [1634400/78836 (78%)]	Loss: 0.073194
Train epoch: 865 [1941100/78836 (91%)]	Loss: 0.085401
predicting for valid data
Make prediction for 19709 samples...
0.16504042 No improvement since epoch  796 ; best_test_mse,best_test_ci: 0.16504042 0.8710981813906669 GINConvNet kiba
Training on 78836 samples...
Train epoch: 866 [0/78836 (0%)]	Loss: 0.077925
Train epoch: 866 [278920/78836 (13%)]	Loss: 0.081617
Train epoch: 866 [559080/78836 (26%)]	Loss: 0.094398
Train epoch: 866 [828600/78836 (39%)]	Loss: 0.091917
Train epoch: 866 [1097760/78836 (52%)]	Loss: 0.067222
Train epoch: 866 [1423800/78836 (65%)]	Loss: 0.076551
Train epoch: 866 [1665240/78836 (78%)]	Loss: 0.087154
Train epoch: 866 [1968400/78836 (91%)]	Loss: 0.089177
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 867 [0/78836 (0%)]	Loss: 0.085487
Train epoch: 867 [285160/78836 (13%)]	Loss: 0.061566
Train epoch: 867 [563920/78836 (26%)]	Loss: 0.069467
Train epoch: 867 [834060/78836 (39%)]	Loss: 0.081844
Train epoch: 867 [1129920/78836 (52%)]	Loss: 0.079170
Train epoch: 867 [1422300/78836 (65%)]	Loss: 0.070951
Train epoch: 867 [1693920/78836 (78%)]	Loss: 0.087542
Train epoch: 867 [1942500/78836 (91%)]	Loss: 0.072724
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 868 [0/78836 (0%)]	Loss: 0.066742
Train epoch: 868 [283920/78836 (13%)]	Loss: 0.072186
Train epoch: 868 [555560/78836 (26%)]	Loss: 0.068357
Train epoch: 868 [850200/78836 (39%)]	Loss: 0.077001
Train epoch: 868 [1127360/78836 (52%)]	Loss: 0.072150
Train epoch: 868 [1426600/78836 (65%)]	Loss: 0.086590
Train epoch: 868 [1684440/78836 (78%)]	Loss: 0.079725
Train epoch: 868 [1917440/78836 (91%)]	Loss: 0.065667
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 869 [0/78836 (0%)]	Loss: 0.072533
Train epoch: 869 [281560/78836 (13%)]	Loss: 0.091145
Train epoch: 869 [572200/78836 (26%)]	Loss: 0.096335
Train epoch: 869 [851400/78836 (39%)]	Loss: 0.069386
Train epoch: 869 [1119840/78836 (52%)]	Loss: 0.089289
Train epoch: 869 [1377300/78836 (65%)]	Loss: 0.091544
Train epoch: 869 [1664880/78836 (78%)]	Loss: 0.065422
Train epoch: 869 [1943060/78836 (91%)]	Loss: 0.076670
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 870 [0/78836 (0%)]	Loss: 0.074861
Train epoch: 870 [285860/78836 (13%)]	Loss: 0.079595
Train epoch: 870 [551440/78836 (26%)]	Loss: 0.066048
Train epoch: 870 [819240/78836 (39%)]	Loss: 0.072101
Train epoch: 870 [1113760/78836 (52%)]	Loss: 0.079432
Train epoch: 870 [1387600/78836 (65%)]	Loss: 0.073408
Train epoch: 870 [1669320/78836 (78%)]	Loss: 0.100789
Train epoch: 870 [1944880/78836 (91%)]	Loss: 0.069542
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 871 [0/78836 (0%)]	Loss: 0.075045
Train epoch: 871 [279320/78836 (13%)]	Loss: 0.076727
Train epoch: 871 [566960/78836 (26%)]	Loss: 0.083490
Train epoch: 871 [834360/78836 (39%)]	Loss: 0.092912
Train epoch: 871 [1132480/78836 (52%)]	Loss: 0.072062
Train epoch: 871 [1386400/78836 (65%)]	Loss: 0.109002
Train epoch: 871 [1673280/78836 (78%)]	Loss: 0.082317
Train epoch: 871 [1983380/78836 (91%)]	Loss: 0.087241
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 872 [0/78836 (0%)]	Loss: 0.085774
Train epoch: 872 [277660/78836 (13%)]	Loss: 0.075517
Train epoch: 872 [556800/78836 (26%)]	Loss: 0.079935
Train epoch: 872 [834540/78836 (39%)]	Loss: 0.089668
Train epoch: 872 [1112640/78836 (52%)]	Loss: 0.079507
Train epoch: 872 [1386300/78836 (65%)]	Loss: 0.090616
Train epoch: 872 [1661280/78836 (78%)]	Loss: 0.056207
Train epoch: 872 [1908060/78836 (91%)]	Loss: 0.077745
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 873 [0/78836 (0%)]	Loss: 0.068410
Train epoch: 873 [285580/78836 (13%)]	Loss: 0.072718
Train epoch: 873 [564320/78836 (26%)]	Loss: 0.077705
Train epoch: 873 [828420/78836 (39%)]	Loss: 0.072163
Train epoch: 873 [1109200/78836 (52%)]	Loss: 0.062615
Train epoch: 873 [1436000/78836 (65%)]	Loss: 0.066881
Train epoch: 873 [1671480/78836 (78%)]	Loss: 0.081151
Train epoch: 873 [1933680/78836 (91%)]	Loss: 0.082954
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 874 [0/78836 (0%)]	Loss: 0.064079
Train epoch: 874 [285580/78836 (13%)]	Loss: 0.081675
Train epoch: 874 [550840/78836 (26%)]	Loss: 0.075253
Train epoch: 874 [823800/78836 (39%)]	Loss: 0.084729
Train epoch: 874 [1117200/78836 (52%)]	Loss: 0.076955
Train epoch: 874 [1391500/78836 (65%)]	Loss: 0.074803
Train epoch: 874 [1678680/78836 (78%)]	Loss: 0.087190
Train epoch: 874 [1958320/78836 (91%)]	Loss: 0.080259
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 875 [0/78836 (0%)]	Loss: 0.076849
Train epoch: 875 [281960/78836 (13%)]	Loss: 0.079462
Train epoch: 875 [575560/78836 (26%)]	Loss: 0.081944
Train epoch: 875 [838260/78836 (39%)]	Loss: 0.075168
Train epoch: 875 [1101440/78836 (52%)]	Loss: 0.082514
Train epoch: 875 [1385200/78836 (65%)]	Loss: 0.075222
Train epoch: 875 [1678680/78836 (78%)]	Loss: 0.063649
Train epoch: 875 [1966860/78836 (91%)]	Loss: 0.071461
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 876 [0/78836 (0%)]	Loss: 0.089586
Train epoch: 876 [281500/78836 (13%)]	Loss: 0.078079
Train epoch: 876 [567280/78836 (26%)]	Loss: 0.066174
Train epoch: 876 [840600/78836 (39%)]	Loss: 0.081802
Train epoch: 876 [1142000/78836 (52%)]	Loss: 0.083212
Train epoch: 876 [1376300/78836 (65%)]	Loss: 0.092736
Train epoch: 876 [1674960/78836 (78%)]	Loss: 0.077987
Train epoch: 876 [1931160/78836 (91%)]	Loss: 0.080119
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 877 [0/78836 (0%)]	Loss: 0.079825
Train epoch: 877 [278660/78836 (13%)]	Loss: 0.075459
Train epoch: 877 [558200/78836 (26%)]	Loss: 0.060607
Train epoch: 877 [858780/78836 (39%)]	Loss: 0.074486
Train epoch: 877 [1118400/78836 (52%)]	Loss: 0.082666
Train epoch: 877 [1388000/78836 (65%)]	Loss: 0.081814
Train epoch: 877 [1645800/78836 (78%)]	Loss: 0.075519
Train epoch: 877 [1956360/78836 (91%)]	Loss: 0.075916
predicting for valid data
Make prediction for 19709 samples...
0.16258001 No improvement since epoch  866 ; best_test_mse,best_test_ci: 0.16258001 0.8738633548393646 GINConvNet kiba
Training on 78836 samples...
Train epoch: 878 [0/78836 (0%)]	Loss: 0.070333
Train epoch: 878 [279900/78836 (13%)]	Loss: 0.081739
Train epoch: 878 [553880/78836 (26%)]	Loss: 0.063519
Train epoch: 878 [839040/78836 (39%)]	Loss: 0.092140
Train epoch: 878 [1107520/78836 (52%)]	Loss: 0.083373
Train epoch: 878 [1395700/78836 (65%)]	Loss: 0.082071
Train epoch: 878 [1645320/78836 (78%)]	Loss: 0.096651
Train epoch: 878 [1954260/78836 (91%)]	Loss: 0.085207
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 879 [0/78836 (0%)]	Loss: 0.071184
Train epoch: 879 [277200/78836 (13%)]	Loss: 0.076190
Train epoch: 879 [569880/78836 (26%)]	Loss: 0.073540
Train epoch: 879 [852780/78836 (39%)]	Loss: 0.073562
Train epoch: 879 [1093520/78836 (52%)]	Loss: 0.074424
Train epoch: 879 [1391100/78836 (65%)]	Loss: 0.082254
Train epoch: 879 [1676040/78836 (78%)]	Loss: 0.064137
Train epoch: 879 [1925560/78836 (91%)]	Loss: 0.073478
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 880 [0/78836 (0%)]	Loss: 0.074405
Train epoch: 880 [276700/78836 (13%)]	Loss: 0.063168
Train epoch: 880 [567240/78836 (26%)]	Loss: 0.090562
Train epoch: 880 [842040/78836 (39%)]	Loss: 0.069567
Train epoch: 880 [1095280/78836 (52%)]	Loss: 0.080507
Train epoch: 880 [1388000/78836 (65%)]	Loss: 0.069530
Train epoch: 880 [1655520/78836 (78%)]	Loss: 0.095712
Train epoch: 880 [1962940/78836 (91%)]	Loss: 0.080062
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 881 [0/78836 (0%)]	Loss: 0.093817
Train epoch: 881 [278340/78836 (13%)]	Loss: 0.081082
Train epoch: 881 [560960/78836 (26%)]	Loss: 0.071986
Train epoch: 881 [844500/78836 (39%)]	Loss: 0.072077
Train epoch: 881 [1113840/78836 (52%)]	Loss: 0.086026
Train epoch: 881 [1412100/78836 (65%)]	Loss: 0.086935
Train epoch: 881 [1686600/78836 (78%)]	Loss: 0.077493
Train epoch: 881 [1924300/78836 (91%)]	Loss: 0.084437
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 882 [0/78836 (0%)]	Loss: 0.079982
Train epoch: 882 [279220/78836 (13%)]	Loss: 0.067622
Train epoch: 882 [554120/78836 (26%)]	Loss: 0.069358
Train epoch: 882 [853980/78836 (39%)]	Loss: 0.083188
Train epoch: 882 [1097040/78836 (52%)]	Loss: 0.085550
Train epoch: 882 [1388500/78836 (65%)]	Loss: 0.081194
Train epoch: 882 [1661040/78836 (78%)]	Loss: 0.063077
Train epoch: 882 [1999060/78836 (91%)]	Loss: 0.098099
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 883 [0/78836 (0%)]	Loss: 0.083060
Train epoch: 883 [277580/78836 (13%)]	Loss: 0.071474
Train epoch: 883 [549200/78836 (26%)]	Loss: 0.070027
Train epoch: 883 [839940/78836 (39%)]	Loss: 0.076037
Train epoch: 883 [1095760/78836 (52%)]	Loss: 0.074314
Train epoch: 883 [1387600/78836 (65%)]	Loss: 0.064323
Train epoch: 883 [1688760/78836 (78%)]	Loss: 0.079354
Train epoch: 883 [1970360/78836 (91%)]	Loss: 0.073003
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 884 [0/78836 (0%)]	Loss: 0.077281
Train epoch: 884 [275380/78836 (13%)]	Loss: 0.066159
Train epoch: 884 [556560/78836 (26%)]	Loss: 0.075083
Train epoch: 884 [866760/78836 (39%)]	Loss: 0.087599
Train epoch: 884 [1112640/78836 (52%)]	Loss: 0.077572
Train epoch: 884 [1363600/78836 (65%)]	Loss: 0.089017
Train epoch: 884 [1634760/78836 (78%)]	Loss: 0.081327
Train epoch: 884 [1990100/78836 (91%)]	Loss: 0.091102
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 885 [0/78836 (0%)]	Loss: 0.073631
Train epoch: 885 [283720/78836 (13%)]	Loss: 0.066139
Train epoch: 885 [562000/78836 (26%)]	Loss: 0.074037
Train epoch: 885 [837300/78836 (39%)]	Loss: 0.097291
Train epoch: 885 [1127520/78836 (52%)]	Loss: 0.075955
Train epoch: 885 [1399600/78836 (65%)]	Loss: 0.070261
Train epoch: 885 [1724520/78836 (78%)]	Loss: 0.089807
Train epoch: 885 [1928500/78836 (91%)]	Loss: 0.081905
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 886 [0/78836 (0%)]	Loss: 0.068635
Train epoch: 886 [282340/78836 (13%)]	Loss: 0.072509
Train epoch: 886 [556000/78836 (26%)]	Loss: 0.066407
Train epoch: 886 [832020/78836 (39%)]	Loss: 0.080845
Train epoch: 886 [1107760/78836 (52%)]	Loss: 0.082358
Train epoch: 886 [1369500/78836 (65%)]	Loss: 0.083875
Train epoch: 886 [1691520/78836 (78%)]	Loss: 0.072750
Train epoch: 886 [1931440/78836 (91%)]	Loss: 0.082557
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 887 [0/78836 (0%)]	Loss: 0.079403
Train epoch: 887 [275040/78836 (13%)]	Loss: 0.067648
Train epoch: 887 [561600/78836 (26%)]	Loss: 0.081717
Train epoch: 887 [833220/78836 (39%)]	Loss: 0.082270
Train epoch: 887 [1118320/78836 (52%)]	Loss: 0.088097
Train epoch: 887 [1384200/78836 (65%)]	Loss: 0.072011
Train epoch: 887 [1677480/78836 (78%)]	Loss: 0.067153
Train epoch: 887 [1964060/78836 (91%)]	Loss: 0.075828
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 888 [0/78836 (0%)]	Loss: 0.094206
Train epoch: 888 [277060/78836 (13%)]	Loss: 0.067905
Train epoch: 888 [545920/78836 (26%)]	Loss: 0.064613
Train epoch: 888 [848460/78836 (39%)]	Loss: 0.074181
Train epoch: 888 [1128880/78836 (52%)]	Loss: 0.084581
Train epoch: 888 [1392400/78836 (65%)]	Loss: 0.072323
Train epoch: 888 [1675080/78836 (78%)]	Loss: 0.125680
Train epoch: 888 [1981280/78836 (91%)]	Loss: 0.073083
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 889 [0/78836 (0%)]	Loss: 0.080754
Train epoch: 889 [276260/78836 (13%)]	Loss: 0.076295
Train epoch: 889 [567160/78836 (26%)]	Loss: 0.068545
Train epoch: 889 [841260/78836 (39%)]	Loss: 0.089577
Train epoch: 889 [1100880/78836 (52%)]	Loss: 0.091667
Train epoch: 889 [1423400/78836 (65%)]	Loss: 0.077409
Train epoch: 889 [1668840/78836 (78%)]	Loss: 0.077029
Train epoch: 889 [1965180/78836 (91%)]	Loss: 0.103448
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 890 [0/78836 (0%)]	Loss: 0.091229
Train epoch: 890 [280900/78836 (13%)]	Loss: 0.079226
Train epoch: 890 [557840/78836 (26%)]	Loss: 0.069783
Train epoch: 890 [835080/78836 (39%)]	Loss: 0.067253
Train epoch: 890 [1104000/78836 (52%)]	Loss: 0.079516
Train epoch: 890 [1427800/78836 (65%)]	Loss: 0.080330
Train epoch: 890 [1659240/78836 (78%)]	Loss: 0.083918
Train epoch: 890 [1964480/78836 (91%)]	Loss: 0.075348
predicting for valid data
Make prediction for 19709 samples...
0.1629458 No improvement since epoch  878 ; best_test_mse,best_test_ci: 0.1629458 0.8739980324784065 GINConvNet kiba
Training on 78836 samples...
Train epoch: 891 [0/78836 (0%)]	Loss: 0.078723
Train epoch: 891 [277380/78836 (13%)]	Loss: 0.066664
Train epoch: 891 [554640/78836 (26%)]	Loss: 0.075488
Train epoch: 891 [836400/78836 (39%)]	Loss: 0.075616
Train epoch: 891 [1131360/78836 (52%)]	Loss: 0.069593
Train epoch: 891 [1381100/78836 (65%)]	Loss: 0.075625
Train epoch: 891 [1678560/78836 (78%)]	Loss: 0.064652
Train epoch: 891 [1958880/78836 (91%)]	Loss: 0.096467
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 892 [0/78836 (0%)]	Loss: 0.071311
Train epoch: 892 [275800/78836 (13%)]	Loss: 0.094088
Train epoch: 892 [568680/78836 (26%)]	Loss: 0.078135
Train epoch: 892 [823740/78836 (39%)]	Loss: 0.077909
Train epoch: 892 [1120400/78836 (52%)]	Loss: 0.079255
Train epoch: 892 [1423600/78836 (65%)]	Loss: 0.092266
Train epoch: 892 [1710120/78836 (78%)]	Loss: 0.072639
Train epoch: 892 [1955520/78836 (91%)]	Loss: 0.090315
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 893 [0/78836 (0%)]	Loss: 0.072118
Train epoch: 893 [276800/78836 (13%)]	Loss: 0.060497
Train epoch: 893 [568800/78836 (26%)]	Loss: 0.060806
Train epoch: 893 [839520/78836 (39%)]	Loss: 0.070943
Train epoch: 893 [1113600/78836 (52%)]	Loss: 0.065918
Train epoch: 893 [1374000/78836 (65%)]	Loss: 0.072795
Train epoch: 893 [1678920/78836 (78%)]	Loss: 0.078378
Train epoch: 893 [1925000/78836 (91%)]	Loss: 0.065843
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 894 [0/78836 (0%)]	Loss: 0.067222
Train epoch: 894 [284100/78836 (13%)]	Loss: 0.088891
Train epoch: 894 [559880/78836 (26%)]	Loss: 0.089239
Train epoch: 894 [833100/78836 (39%)]	Loss: 0.071496
Train epoch: 894 [1097840/78836 (52%)]	Loss: 0.087784
Train epoch: 894 [1406400/78836 (65%)]	Loss: 0.069856
Train epoch: 894 [1667040/78836 (78%)]	Loss: 0.104384
Train epoch: 894 [1950760/78836 (91%)]	Loss: 0.057587
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 895 [0/78836 (0%)]	Loss: 0.073922
Train epoch: 895 [279320/78836 (13%)]	Loss: 0.088066
Train epoch: 895 [564600/78836 (26%)]	Loss: 0.092610
Train epoch: 895 [843540/78836 (39%)]	Loss: 0.069258
Train epoch: 895 [1101440/78836 (52%)]	Loss: 0.083833
Train epoch: 895 [1406900/78836 (65%)]	Loss: 0.093731
Train epoch: 895 [1644120/78836 (78%)]	Loss: 0.088117
Train epoch: 895 [1940400/78836 (91%)]	Loss: 0.104903
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 896 [0/78836 (0%)]	Loss: 0.077108
Train epoch: 896 [282420/78836 (13%)]	Loss: 0.068860
Train epoch: 896 [563920/78836 (26%)]	Loss: 0.069266
Train epoch: 896 [833040/78836 (39%)]	Loss: 0.068142
Train epoch: 896 [1133520/78836 (52%)]	Loss: 0.060456
Train epoch: 896 [1407700/78836 (65%)]	Loss: 0.073486
Train epoch: 896 [1672200/78836 (78%)]	Loss: 0.072158
Train epoch: 896 [1938720/78836 (91%)]	Loss: 0.061634
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 897 [0/78836 (0%)]	Loss: 0.088820
Train epoch: 897 [280240/78836 (13%)]	Loss: 0.072705
Train epoch: 897 [557800/78836 (26%)]	Loss: 0.078217
Train epoch: 897 [846240/78836 (39%)]	Loss: 0.096625
Train epoch: 897 [1129600/78836 (52%)]	Loss: 0.082228
Train epoch: 897 [1386600/78836 (65%)]	Loss: 0.086040
Train epoch: 897 [1668960/78836 (78%)]	Loss: 0.095081
Train epoch: 897 [1917440/78836 (91%)]	Loss: 0.087278
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 898 [0/78836 (0%)]	Loss: 0.085728
Train epoch: 898 [279360/78836 (13%)]	Loss: 0.071435
Train epoch: 898 [552440/78836 (26%)]	Loss: 0.075663
Train epoch: 898 [833640/78836 (39%)]	Loss: 0.080363
Train epoch: 898 [1126960/78836 (52%)]	Loss: 0.073018
Train epoch: 898 [1413800/78836 (65%)]	Loss: 0.079937
Train epoch: 898 [1680960/78836 (78%)]	Loss: 0.082412
Train epoch: 898 [1966720/78836 (91%)]	Loss: 0.096859
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 899 [0/78836 (0%)]	Loss: 0.077978
Train epoch: 899 [271300/78836 (13%)]	Loss: 0.078247
Train epoch: 899 [558640/78836 (26%)]	Loss: 0.084071
Train epoch: 899 [828420/78836 (39%)]	Loss: 0.075397
Train epoch: 899 [1103360/78836 (52%)]	Loss: 0.081763
Train epoch: 899 [1392100/78836 (65%)]	Loss: 0.074722
Train epoch: 899 [1712160/78836 (78%)]	Loss: 0.073250
Train epoch: 899 [1994580/78836 (91%)]	Loss: 0.089043
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 900 [0/78836 (0%)]	Loss: 0.078228
Train epoch: 900 [278620/78836 (13%)]	Loss: 0.054495
Train epoch: 900 [557800/78836 (26%)]	Loss: 0.083734
Train epoch: 900 [830040/78836 (39%)]	Loss: 0.081440
Train epoch: 900 [1098720/78836 (52%)]	Loss: 0.084444
Train epoch: 900 [1397300/78836 (65%)]	Loss: 0.067910
Train epoch: 900 [1684800/78836 (78%)]	Loss: 0.084527
Train epoch: 900 [2017260/78836 (91%)]	Loss: 0.089104
predicting for valid data
Make prediction for 19709 samples...
0.16270715 No improvement since epoch  891 ; best_test_mse,best_test_ci: 0.16270715 0.8735693918962104 GINConvNet kiba
Training on 78836 samples...
Train epoch: 901 [0/78836 (0%)]	Loss: 0.088626
Train epoch: 901 [281120/78836 (13%)]	Loss: 0.080026
Train epoch: 901 [560560/78836 (26%)]	Loss: 0.073629
Train epoch: 901 [826020/78836 (39%)]	Loss: 0.074665
Train epoch: 901 [1128880/78836 (52%)]	Loss: 0.085537
Train epoch: 901 [1414500/78836 (65%)]	Loss: 0.072226
Train epoch: 901 [1696680/78836 (78%)]	Loss: 0.082256
Train epoch: 901 [1988280/78836 (91%)]	Loss: 0.068108
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 902 [0/78836 (0%)]	Loss: 0.072240
Train epoch: 902 [276500/78836 (13%)]	Loss: 0.090708
Train epoch: 902 [567720/78836 (26%)]	Loss: 0.076006
Train epoch: 902 [835620/78836 (39%)]	Loss: 0.070944
Train epoch: 902 [1137040/78836 (52%)]	Loss: 0.074814
Train epoch: 902 [1403900/78836 (65%)]	Loss: 0.081238
Train epoch: 902 [1685160/78836 (78%)]	Loss: 0.074246
Train epoch: 902 [1926400/78836 (91%)]	Loss: 0.085974
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 903 [0/78836 (0%)]	Loss: 0.072414
Train epoch: 903 [283580/78836 (13%)]	Loss: 0.097593
Train epoch: 903 [550160/78836 (26%)]	Loss: 0.081374
Train epoch: 903 [844080/78836 (39%)]	Loss: 0.074961
Train epoch: 903 [1118320/78836 (52%)]	Loss: 0.080286
Train epoch: 903 [1383200/78836 (65%)]	Loss: 0.073011
Train epoch: 903 [1674960/78836 (78%)]	Loss: 0.070900
Train epoch: 903 [1940960/78836 (91%)]	Loss: 0.064774
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 904 [0/78836 (0%)]	Loss: 0.060846
Train epoch: 904 [280560/78836 (13%)]	Loss: 0.071899
Train epoch: 904 [546840/78836 (26%)]	Loss: 0.082388
Train epoch: 904 [858300/78836 (39%)]	Loss: 0.091452
Train epoch: 904 [1112160/78836 (52%)]	Loss: 0.086910
Train epoch: 904 [1397000/78836 (65%)]	Loss: 0.074148
Train epoch: 904 [1655160/78836 (78%)]	Loss: 0.068379
Train epoch: 904 [1966440/78836 (91%)]	Loss: 0.086326
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 905 [0/78836 (0%)]	Loss: 0.075916
Train epoch: 905 [282840/78836 (13%)]	Loss: 0.077745
Train epoch: 905 [564680/78836 (26%)]	Loss: 0.071707
Train epoch: 905 [829020/78836 (39%)]	Loss: 0.075282
Train epoch: 905 [1118240/78836 (52%)]	Loss: 0.123225
Train epoch: 905 [1412600/78836 (65%)]	Loss: 0.066268
Train epoch: 905 [1660680/78836 (78%)]	Loss: 0.070479
Train epoch: 905 [1954400/78836 (91%)]	Loss: 0.066572
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 906 [0/78836 (0%)]	Loss: 0.065538
Train epoch: 906 [274260/78836 (13%)]	Loss: 0.063639
Train epoch: 906 [556040/78836 (26%)]	Loss: 0.079188
Train epoch: 906 [847440/78836 (39%)]	Loss: 0.071543
Train epoch: 906 [1114880/78836 (52%)]	Loss: 0.065067
Train epoch: 906 [1396100/78836 (65%)]	Loss: 0.058231
Train epoch: 906 [1721760/78836 (78%)]	Loss: 0.075328
Train epoch: 906 [1953000/78836 (91%)]	Loss: 0.063395
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 907 [0/78836 (0%)]	Loss: 0.081463
Train epoch: 907 [275960/78836 (13%)]	Loss: 0.083638
Train epoch: 907 [551520/78836 (26%)]	Loss: 0.075806
Train epoch: 907 [824520/78836 (39%)]	Loss: 0.079494
Train epoch: 907 [1104400/78836 (52%)]	Loss: 0.093222
Train epoch: 907 [1437400/78836 (65%)]	Loss: 0.054760
Train epoch: 907 [1686240/78836 (78%)]	Loss: 0.096016
Train epoch: 907 [1953420/78836 (91%)]	Loss: 0.099856
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 908 [0/78836 (0%)]	Loss: 0.077276
Train epoch: 908 [284600/78836 (13%)]	Loss: 0.080491
Train epoch: 908 [566280/78836 (26%)]	Loss: 0.077670
Train epoch: 908 [844080/78836 (39%)]	Loss: 0.071479
Train epoch: 908 [1106800/78836 (52%)]	Loss: 0.065914
Train epoch: 908 [1401700/78836 (65%)]	Loss: 0.075906
Train epoch: 908 [1693560/78836 (78%)]	Loss: 0.061735
Train epoch: 908 [1942500/78836 (91%)]	Loss: 0.073217
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 909 [0/78836 (0%)]	Loss: 0.057963
Train epoch: 909 [274800/78836 (13%)]	Loss: 0.072552
Train epoch: 909 [572120/78836 (26%)]	Loss: 0.058922
Train epoch: 909 [845220/78836 (39%)]	Loss: 0.070155
Train epoch: 909 [1132080/78836 (52%)]	Loss: 0.063728
Train epoch: 909 [1394100/78836 (65%)]	Loss: 0.087407
Train epoch: 909 [1662240/78836 (78%)]	Loss: 0.082958
Train epoch: 909 [1924440/78836 (91%)]	Loss: 0.085307
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 910 [0/78836 (0%)]	Loss: 0.065698
Train epoch: 910 [277280/78836 (13%)]	Loss: 0.071601
Train epoch: 910 [553480/78836 (26%)]	Loss: 0.074719
Train epoch: 910 [824100/78836 (39%)]	Loss: 0.082729
Train epoch: 910 [1122800/78836 (52%)]	Loss: 0.063285
Train epoch: 910 [1398300/78836 (65%)]	Loss: 0.072513
Train epoch: 910 [1684680/78836 (78%)]	Loss: 0.086313
Train epoch: 910 [1903440/78836 (91%)]	Loss: 0.070319
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 911 [0/78836 (0%)]	Loss: 0.061931
Train epoch: 911 [276260/78836 (13%)]	Loss: 0.070993
Train epoch: 911 [560840/78836 (26%)]	Loss: 0.080013
Train epoch: 911 [844560/78836 (39%)]	Loss: 0.075896
Train epoch: 911 [1117600/78836 (52%)]	Loss: 0.069635
Train epoch: 911 [1375600/78836 (65%)]	Loss: 0.069624
Train epoch: 911 [1702560/78836 (78%)]	Loss: 0.080107
Train epoch: 911 [1985620/78836 (91%)]	Loss: 0.085002
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 912 [0/78836 (0%)]	Loss: 0.055755
Train epoch: 912 [281280/78836 (13%)]	Loss: 0.079260
Train epoch: 912 [571920/78836 (26%)]	Loss: 0.093134
Train epoch: 912 [852780/78836 (39%)]	Loss: 0.072279
Train epoch: 912 [1142080/78836 (52%)]	Loss: 0.074076
Train epoch: 912 [1415700/78836 (65%)]	Loss: 0.097688
Train epoch: 912 [1694280/78836 (78%)]	Loss: 0.102766
Train epoch: 912 [1990240/78836 (91%)]	Loss: 0.073546
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 913 [0/78836 (0%)]	Loss: 0.068833
Train epoch: 913 [282140/78836 (13%)]	Loss: 0.089968
Train epoch: 913 [552640/78836 (26%)]	Loss: 0.066017
Train epoch: 913 [830520/78836 (39%)]	Loss: 0.062029
Train epoch: 913 [1103360/78836 (52%)]	Loss: 0.085308
Train epoch: 913 [1422500/78836 (65%)]	Loss: 0.075773
Train epoch: 913 [1678320/78836 (78%)]	Loss: 0.088166
Train epoch: 913 [1896020/78836 (91%)]	Loss: 0.071966
predicting for valid data
Make prediction for 19709 samples...
0.16423 No improvement since epoch  901 ; best_test_mse,best_test_ci: 0.16423 0.8731966282068083 GINConvNet kiba
Training on 78836 samples...
Train epoch: 914 [0/78836 (0%)]	Loss: 0.095381
Train epoch: 914 [281720/78836 (13%)]	Loss: 0.074100
Train epoch: 914 [553040/78836 (26%)]	Loss: 0.065098
Train epoch: 914 [832200/78836 (39%)]	Loss: 0.070873
Train epoch: 914 [1129040/78836 (52%)]	Loss: 0.071335
Train epoch: 914 [1440500/78836 (65%)]	Loss: 0.086068
Train epoch: 914 [1661280/78836 (78%)]	Loss: 0.081591
Train epoch: 914 [1963080/78836 (91%)]	Loss: 0.069347
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 915 [0/78836 (0%)]	Loss: 0.080443
Train epoch: 915 [278040/78836 (13%)]	Loss: 0.076029
Train epoch: 915 [550680/78836 (26%)]	Loss: 0.068162
Train epoch: 915 [844200/78836 (39%)]	Loss: 0.078326
Train epoch: 915 [1128720/78836 (52%)]	Loss: 0.068994
Train epoch: 915 [1396100/78836 (65%)]	Loss: 0.074479
Train epoch: 915 [1688280/78836 (78%)]	Loss: 0.071306
Train epoch: 915 [1905120/78836 (91%)]	Loss: 0.063361
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 916 [0/78836 (0%)]	Loss: 0.069891
Train epoch: 916 [278760/78836 (13%)]	Loss: 0.081086
Train epoch: 916 [561800/78836 (26%)]	Loss: 0.097710
Train epoch: 916 [835620/78836 (39%)]	Loss: 0.070094
Train epoch: 916 [1127360/78836 (52%)]	Loss: 0.071924
Train epoch: 916 [1411600/78836 (65%)]	Loss: 0.071335
Train epoch: 916 [1664400/78836 (78%)]	Loss: 0.077585
Train epoch: 916 [1936480/78836 (91%)]	Loss: 0.063490
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 917 [0/78836 (0%)]	Loss: 0.067410
Train epoch: 917 [278440/78836 (13%)]	Loss: 0.076150
Train epoch: 917 [566440/78836 (26%)]	Loss: 0.077850
Train epoch: 917 [834180/78836 (39%)]	Loss: 0.065749
Train epoch: 917 [1125040/78836 (52%)]	Loss: 0.075912
Train epoch: 917 [1402200/78836 (65%)]	Loss: 0.083447
Train epoch: 917 [1718400/78836 (78%)]	Loss: 0.074727
Train epoch: 917 [1982400/78836 (91%)]	Loss: 0.077295
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 918 [0/78836 (0%)]	Loss: 0.057992
Train epoch: 918 [280400/78836 (13%)]	Loss: 0.079532
Train epoch: 918 [548640/78836 (26%)]	Loss: 0.077032
Train epoch: 918 [847080/78836 (39%)]	Loss: 0.060321
Train epoch: 918 [1134960/78836 (52%)]	Loss: 0.061282
Train epoch: 918 [1404600/78836 (65%)]	Loss: 0.075975
Train epoch: 918 [1681920/78836 (78%)]	Loss: 0.137065
Train epoch: 918 [1916180/78836 (91%)]	Loss: 0.073108
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 919 [0/78836 (0%)]	Loss: 0.079412
Train epoch: 919 [281180/78836 (13%)]	Loss: 0.082536
Train epoch: 919 [558920/78836 (26%)]	Loss: 0.068637
Train epoch: 919 [846060/78836 (39%)]	Loss: 0.072810
Train epoch: 919 [1087760/78836 (52%)]	Loss: 0.066463
Train epoch: 919 [1400300/78836 (65%)]	Loss: 0.069384
Train epoch: 919 [1703400/78836 (78%)]	Loss: 0.072698
Train epoch: 919 [1948660/78836 (91%)]	Loss: 0.069687
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 920 [0/78836 (0%)]	Loss: 0.070452
Train epoch: 920 [282040/78836 (13%)]	Loss: 0.069473
Train epoch: 920 [560440/78836 (26%)]	Loss: 0.082539
Train epoch: 920 [860760/78836 (39%)]	Loss: 0.071561
Train epoch: 920 [1113360/78836 (52%)]	Loss: 0.081688
Train epoch: 920 [1399900/78836 (65%)]	Loss: 0.060374
Train epoch: 920 [1686000/78836 (78%)]	Loss: 0.079450
Train epoch: 920 [1929200/78836 (91%)]	Loss: 0.068309
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 921 [0/78836 (0%)]	Loss: 0.075101
Train epoch: 921 [279220/78836 (13%)]	Loss: 0.069055
Train epoch: 921 [557400/78836 (26%)]	Loss: 0.068143
Train epoch: 921 [844440/78836 (39%)]	Loss: 0.069157
Train epoch: 921 [1106320/78836 (52%)]	Loss: 0.073134
Train epoch: 921 [1421100/78836 (65%)]	Loss: 0.065323
Train epoch: 921 [1657920/78836 (78%)]	Loss: 0.060027
Train epoch: 921 [1995420/78836 (91%)]	Loss: 0.074917
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 922 [0/78836 (0%)]	Loss: 0.085536
Train epoch: 922 [288280/78836 (13%)]	Loss: 0.082202
Train epoch: 922 [549240/78836 (26%)]	Loss: 0.066032
Train epoch: 922 [842940/78836 (39%)]	Loss: 0.064159
Train epoch: 922 [1132080/78836 (52%)]	Loss: 0.072263
Train epoch: 922 [1396200/78836 (65%)]	Loss: 0.064964
Train epoch: 922 [1695000/78836 (78%)]	Loss: 0.075026
Train epoch: 922 [1976520/78836 (91%)]	Loss: 0.085471
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 923 [0/78836 (0%)]	Loss: 0.088753
Train epoch: 923 [281940/78836 (13%)]	Loss: 0.060910
Train epoch: 923 [555280/78836 (26%)]	Loss: 0.077678
Train epoch: 923 [835680/78836 (39%)]	Loss: 0.083633
Train epoch: 923 [1113440/78836 (52%)]	Loss: 0.083706
Train epoch: 923 [1422900/78836 (65%)]	Loss: 0.082215
Train epoch: 923 [1648200/78836 (78%)]	Loss: 0.079807
Train epoch: 923 [1947400/78836 (91%)]	Loss: 0.073940
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 924 [0/78836 (0%)]	Loss: 0.069456
Train epoch: 924 [279740/78836 (13%)]	Loss: 0.078932
Train epoch: 924 [548320/78836 (26%)]	Loss: 0.062234
Train epoch: 924 [828900/78836 (39%)]	Loss: 0.071967
Train epoch: 924 [1123280/78836 (52%)]	Loss: 0.073524
Train epoch: 924 [1402900/78836 (65%)]	Loss: 0.081160
Train epoch: 924 [1676160/78836 (78%)]	Loss: 0.073559
Train epoch: 924 [1950620/78836 (91%)]	Loss: 0.088239
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 925 [0/78836 (0%)]	Loss: 0.076626
Train epoch: 925 [277900/78836 (13%)]	Loss: 0.083024
Train epoch: 925 [556240/78836 (26%)]	Loss: 0.080324
Train epoch: 925 [832800/78836 (39%)]	Loss: 0.079221
Train epoch: 925 [1135360/78836 (52%)]	Loss: 0.075747
Train epoch: 925 [1389500/78836 (65%)]	Loss: 0.072400
Train epoch: 925 [1679760/78836 (78%)]	Loss: 0.079868
Train epoch: 925 [1935780/78836 (91%)]	Loss: 0.089871
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 926 [0/78836 (0%)]	Loss: 0.070922
Train epoch: 926 [282240/78836 (13%)]	Loss: 0.074953
Train epoch: 926 [559640/78836 (26%)]	Loss: 0.083850
Train epoch: 926 [838980/78836 (39%)]	Loss: 0.077816
Train epoch: 926 [1136800/78836 (52%)]	Loss: 0.074515
Train epoch: 926 [1376500/78836 (65%)]	Loss: 0.075751
Train epoch: 926 [1644840/78836 (78%)]	Loss: 0.075197
Train epoch: 926 [1956920/78836 (91%)]	Loss: 0.061924
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 927 [0/78836 (0%)]	Loss: 0.066588
Train epoch: 927 [285420/78836 (13%)]	Loss: 0.069172
Train epoch: 927 [558000/78836 (26%)]	Loss: 0.066466
Train epoch: 927 [845340/78836 (39%)]	Loss: 0.070731
Train epoch: 927 [1130640/78836 (52%)]	Loss: 0.073266
Train epoch: 927 [1395000/78836 (65%)]	Loss: 0.072903
Train epoch: 927 [1667280/78836 (78%)]	Loss: 0.069844
Train epoch: 927 [1969940/78836 (91%)]	Loss: 0.070983
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 928 [0/78836 (0%)]	Loss: 0.066415
Train epoch: 928 [282980/78836 (13%)]	Loss: 0.090214
Train epoch: 928 [566440/78836 (26%)]	Loss: 0.067436
Train epoch: 928 [834720/78836 (39%)]	Loss: 0.073697
Train epoch: 928 [1121760/78836 (52%)]	Loss: 0.075028
Train epoch: 928 [1395000/78836 (65%)]	Loss: 0.060502
Train epoch: 928 [1674960/78836 (78%)]	Loss: 0.068746
Train epoch: 928 [1991360/78836 (91%)]	Loss: 0.075026
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 929 [0/78836 (0%)]	Loss: 0.069793
Train epoch: 929 [281920/78836 (13%)]	Loss: 0.074446
Train epoch: 929 [555760/78836 (26%)]	Loss: 0.063593
Train epoch: 929 [836640/78836 (39%)]	Loss: 0.067251
Train epoch: 929 [1096000/78836 (52%)]	Loss: 0.069261
Train epoch: 929 [1405400/78836 (65%)]	Loss: 0.080297
Train epoch: 929 [1698000/78836 (78%)]	Loss: 0.065790
Train epoch: 929 [1963220/78836 (91%)]	Loss: 0.073594
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 930 [0/78836 (0%)]	Loss: 0.073222
Train epoch: 930 [281920/78836 (13%)]	Loss: 0.082180
Train epoch: 930 [558080/78836 (26%)]	Loss: 0.059429
Train epoch: 930 [869700/78836 (39%)]	Loss: 0.081675
Train epoch: 930 [1132720/78836 (52%)]	Loss: 0.079004
Train epoch: 930 [1394700/78836 (65%)]	Loss: 0.093024
Train epoch: 930 [1640880/78836 (78%)]	Loss: 0.063055
Train epoch: 930 [1939560/78836 (91%)]	Loss: 0.076846
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 931 [0/78836 (0%)]	Loss: 0.059013
Train epoch: 931 [279860/78836 (13%)]	Loss: 0.083099
Train epoch: 931 [550400/78836 (26%)]	Loss: 0.072943
Train epoch: 931 [848160/78836 (39%)]	Loss: 0.065628
Train epoch: 931 [1108160/78836 (52%)]	Loss: 0.066440
Train epoch: 931 [1402100/78836 (65%)]	Loss: 0.071893
Train epoch: 931 [1663440/78836 (78%)]	Loss: 0.062826
Train epoch: 931 [1956220/78836 (91%)]	Loss: 0.074243
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 932 [0/78836 (0%)]	Loss: 0.064129
Train epoch: 932 [281040/78836 (13%)]	Loss: 0.067882
Train epoch: 932 [550360/78836 (26%)]	Loss: 0.073061
Train epoch: 932 [825720/78836 (39%)]	Loss: 0.067206
Train epoch: 932 [1145280/78836 (52%)]	Loss: 0.077324
Train epoch: 932 [1401400/78836 (65%)]	Loss: 0.079614
Train epoch: 932 [1648080/78836 (78%)]	Loss: 0.108002
Train epoch: 932 [1932840/78836 (91%)]	Loss: 0.072817
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 933 [0/78836 (0%)]	Loss: 0.065290
Train epoch: 933 [280100/78836 (13%)]	Loss: 0.068998
Train epoch: 933 [566880/78836 (26%)]	Loss: 0.067909
Train epoch: 933 [841020/78836 (39%)]	Loss: 0.080193
Train epoch: 933 [1118240/78836 (52%)]	Loss: 0.064141
Train epoch: 933 [1406800/78836 (65%)]	Loss: 0.080629
Train epoch: 933 [1690800/78836 (78%)]	Loss: 0.060857
Train epoch: 933 [1980020/78836 (91%)]	Loss: 0.077599
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 934 [0/78836 (0%)]	Loss: 0.056131
Train epoch: 934 [273280/78836 (13%)]	Loss: 0.076574
Train epoch: 934 [567720/78836 (26%)]	Loss: 0.083481
Train epoch: 934 [838860/78836 (39%)]	Loss: 0.073644
Train epoch: 934 [1113440/78836 (52%)]	Loss: 0.072269
Train epoch: 934 [1396400/78836 (65%)]	Loss: 0.090830
Train epoch: 934 [1674600/78836 (78%)]	Loss: 0.071597
Train epoch: 934 [1944460/78836 (91%)]	Loss: 0.101564
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 935 [0/78836 (0%)]	Loss: 0.063934
Train epoch: 935 [279020/78836 (13%)]	Loss: 0.082390
Train epoch: 935 [558920/78836 (26%)]	Loss: 0.077910
Train epoch: 935 [845940/78836 (39%)]	Loss: 0.079147
Train epoch: 935 [1123920/78836 (52%)]	Loss: 0.069791
Train epoch: 935 [1405400/78836 (65%)]	Loss: 0.080346
Train epoch: 935 [1682280/78836 (78%)]	Loss: 0.063884
Train epoch: 935 [1931160/78836 (91%)]	Loss: 0.074622
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 936 [0/78836 (0%)]	Loss: 0.073117
Train epoch: 936 [281860/78836 (13%)]	Loss: 0.061245
Train epoch: 936 [558440/78836 (26%)]	Loss: 0.086735
Train epoch: 936 [828780/78836 (39%)]	Loss: 0.074492
Train epoch: 936 [1147200/78836 (52%)]	Loss: 0.079175
Train epoch: 936 [1437400/78836 (65%)]	Loss: 0.065273
Train epoch: 936 [1694640/78836 (78%)]	Loss: 0.080499
Train epoch: 936 [1924160/78836 (91%)]	Loss: 0.066403
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 937 [0/78836 (0%)]	Loss: 0.059077
Train epoch: 937 [273560/78836 (13%)]	Loss: 0.068629
Train epoch: 937 [551880/78836 (26%)]	Loss: 0.081109
Train epoch: 937 [833100/78836 (39%)]	Loss: 0.076544
Train epoch: 937 [1127600/78836 (52%)]	Loss: 0.070888
Train epoch: 937 [1382900/78836 (65%)]	Loss: 0.063651
Train epoch: 937 [1724400/78836 (78%)]	Loss: 0.063155
Train epoch: 937 [1956500/78836 (91%)]	Loss: 0.061846
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 938 [0/78836 (0%)]	Loss: 0.083209
Train epoch: 938 [285580/78836 (13%)]	Loss: 0.069909
Train epoch: 938 [556040/78836 (26%)]	Loss: 0.069554
Train epoch: 938 [827640/78836 (39%)]	Loss: 0.065437
Train epoch: 938 [1117280/78836 (52%)]	Loss: 0.069055
Train epoch: 938 [1398400/78836 (65%)]	Loss: 0.081149
Train epoch: 938 [1695000/78836 (78%)]	Loss: 0.070323
Train epoch: 938 [1985900/78836 (91%)]	Loss: 0.064537
predicting for valid data
Make prediction for 19709 samples...
0.16146891 No improvement since epoch  914 ; best_test_mse,best_test_ci: 0.16146891 0.8757727289870544 GINConvNet kiba
Training on 78836 samples...
Train epoch: 939 [0/78836 (0%)]	Loss: 0.085266
Train epoch: 939 [273060/78836 (13%)]	Loss: 0.069943
Train epoch: 939 [555520/78836 (26%)]	Loss: 0.080933
Train epoch: 939 [847260/78836 (39%)]	Loss: 0.068070
Train epoch: 939 [1122720/78836 (52%)]	Loss: 0.076874
Train epoch: 939 [1412300/78836 (65%)]	Loss: 0.074807
Train epoch: 939 [1653960/78836 (78%)]	Loss: 0.074370
Train epoch: 939 [1984220/78836 (91%)]	Loss: 0.073933
predicting for valid data
Make prediction for 19709 samples...
predicting for test data
Make prediction for 19709 samples...
rmse improved at epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 940 [0/78836 (0%)]	Loss: 0.098976
Train epoch: 940 [280960/78836 (13%)]	Loss: 0.072757
Train epoch: 940 [555160/78836 (26%)]	Loss: 0.067325
Train epoch: 940 [843060/78836 (39%)]	Loss: 0.075817
Train epoch: 940 [1142800/78836 (52%)]	Loss: 0.101657
Train epoch: 940 [1367300/78836 (65%)]	Loss: 0.061817
Train epoch: 940 [1701720/78836 (78%)]	Loss: 0.079533
Train epoch: 940 [1944180/78836 (91%)]	Loss: 0.068913
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 941 [0/78836 (0%)]	Loss: 0.075976
Train epoch: 941 [283380/78836 (13%)]	Loss: 0.062227
Train epoch: 941 [560120/78836 (26%)]	Loss: 0.074923
Train epoch: 941 [836340/78836 (39%)]	Loss: 0.073278
Train epoch: 941 [1133360/78836 (52%)]	Loss: 0.077366
Train epoch: 941 [1399300/78836 (65%)]	Loss: 0.064388
Train epoch: 941 [1657800/78836 (78%)]	Loss: 0.071644
Train epoch: 941 [1953000/78836 (91%)]	Loss: 0.062429
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 942 [0/78836 (0%)]	Loss: 0.062402
Train epoch: 942 [272820/78836 (13%)]	Loss: 0.069299
Train epoch: 942 [546800/78836 (26%)]	Loss: 0.065568
Train epoch: 942 [849480/78836 (39%)]	Loss: 0.061661
Train epoch: 942 [1135920/78836 (52%)]	Loss: 0.091122
Train epoch: 942 [1391500/78836 (65%)]	Loss: 0.078355
Train epoch: 942 [1711440/78836 (78%)]	Loss: 0.089962
Train epoch: 942 [1923320/78836 (91%)]	Loss: 0.067028
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 943 [0/78836 (0%)]	Loss: 0.075327
Train epoch: 943 [277840/78836 (13%)]	Loss: 0.066260
Train epoch: 943 [554800/78836 (26%)]	Loss: 0.075011
Train epoch: 943 [842640/78836 (39%)]	Loss: 0.085320
Train epoch: 943 [1104960/78836 (52%)]	Loss: 0.065976
Train epoch: 943 [1399600/78836 (65%)]	Loss: 0.070270
Train epoch: 943 [1636920/78836 (78%)]	Loss: 0.081209
Train epoch: 943 [2005500/78836 (91%)]	Loss: 0.070920
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 944 [0/78836 (0%)]	Loss: 0.069763
Train epoch: 944 [284020/78836 (13%)]	Loss: 0.077778
Train epoch: 944 [561880/78836 (26%)]	Loss: 0.069409
Train epoch: 944 [843840/78836 (39%)]	Loss: 0.068844
Train epoch: 944 [1126480/78836 (52%)]	Loss: 0.065309
Train epoch: 944 [1393800/78836 (65%)]	Loss: 0.077760
Train epoch: 944 [1660560/78836 (78%)]	Loss: 0.068184
Train epoch: 944 [1999480/78836 (91%)]	Loss: 0.132139
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 945 [0/78836 (0%)]	Loss: 0.115768
Train epoch: 945 [277720/78836 (13%)]	Loss: 0.065065
Train epoch: 945 [579040/78836 (26%)]	Loss: 0.071519
Train epoch: 945 [843720/78836 (39%)]	Loss: 0.070388
Train epoch: 945 [1103120/78836 (52%)]	Loss: 0.071863
Train epoch: 945 [1382200/78836 (65%)]	Loss: 0.079692
Train epoch: 945 [1697040/78836 (78%)]	Loss: 0.086892
Train epoch: 945 [1931020/78836 (91%)]	Loss: 0.068120
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 946 [0/78836 (0%)]	Loss: 0.067767
Train epoch: 946 [275580/78836 (13%)]	Loss: 0.081832
Train epoch: 946 [555680/78836 (26%)]	Loss: 0.064723
Train epoch: 946 [831240/78836 (39%)]	Loss: 0.063146
Train epoch: 946 [1116720/78836 (52%)]	Loss: 0.061446
Train epoch: 946 [1414200/78836 (65%)]	Loss: 0.071953
Train epoch: 946 [1686480/78836 (78%)]	Loss: 0.081900
Train epoch: 946 [1961680/78836 (91%)]	Loss: 0.086852
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 947 [0/78836 (0%)]	Loss: 0.079049
Train epoch: 947 [275000/78836 (13%)]	Loss: 0.072226
Train epoch: 947 [554480/78836 (26%)]	Loss: 0.076442
Train epoch: 947 [841020/78836 (39%)]	Loss: 0.072086
Train epoch: 947 [1095600/78836 (52%)]	Loss: 0.073892
Train epoch: 947 [1413000/78836 (65%)]	Loss: 0.082466
Train epoch: 947 [1680480/78836 (78%)]	Loss: 0.084577
Train epoch: 947 [1935920/78836 (91%)]	Loss: 0.070833
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 948 [0/78836 (0%)]	Loss: 0.067841
Train epoch: 948 [275840/78836 (13%)]	Loss: 0.060768
Train epoch: 948 [565400/78836 (26%)]	Loss: 0.072611
Train epoch: 948 [856260/78836 (39%)]	Loss: 0.078942
Train epoch: 948 [1129280/78836 (52%)]	Loss: 0.068988
Train epoch: 948 [1418800/78836 (65%)]	Loss: 0.068710
Train epoch: 948 [1667640/78836 (78%)]	Loss: 0.077420
Train epoch: 948 [1958460/78836 (91%)]	Loss: 0.061902
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 949 [0/78836 (0%)]	Loss: 0.068215
Train epoch: 949 [275120/78836 (13%)]	Loss: 0.073031
Train epoch: 949 [558520/78836 (26%)]	Loss: 0.073850
Train epoch: 949 [822000/78836 (39%)]	Loss: 0.054029
Train epoch: 949 [1123600/78836 (52%)]	Loss: 0.057139
Train epoch: 949 [1413000/78836 (65%)]	Loss: 0.068664
Train epoch: 949 [1663920/78836 (78%)]	Loss: 0.076597
Train epoch: 949 [1953280/78836 (91%)]	Loss: 0.067202
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 950 [0/78836 (0%)]	Loss: 0.097234
Train epoch: 950 [282860/78836 (13%)]	Loss: 0.071567
Train epoch: 950 [561640/78836 (26%)]	Loss: 0.067324
Train epoch: 950 [824340/78836 (39%)]	Loss: 0.062562
Train epoch: 950 [1107440/78836 (52%)]	Loss: 0.089840
Train epoch: 950 [1396200/78836 (65%)]	Loss: 0.085321
Train epoch: 950 [1654200/78836 (78%)]	Loss: 0.069860
Train epoch: 950 [1952720/78836 (91%)]	Loss: 0.062729
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 951 [0/78836 (0%)]	Loss: 0.080364
Train epoch: 951 [288580/78836 (13%)]	Loss: 0.066832
Train epoch: 951 [567040/78836 (26%)]	Loss: 0.085574
Train epoch: 951 [849000/78836 (39%)]	Loss: 0.062912
Train epoch: 951 [1105360/78836 (52%)]	Loss: 0.078568
Train epoch: 951 [1405500/78836 (65%)]	Loss: 0.058082
Train epoch: 951 [1679880/78836 (78%)]	Loss: 0.058702
Train epoch: 951 [1948800/78836 (91%)]	Loss: 0.068350
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 952 [0/78836 (0%)]	Loss: 0.075928
Train epoch: 952 [278400/78836 (13%)]	Loss: 0.066550
Train epoch: 952 [559120/78836 (26%)]	Loss: 0.072942
Train epoch: 952 [845100/78836 (39%)]	Loss: 0.066854
Train epoch: 952 [1132080/78836 (52%)]	Loss: 0.077286
Train epoch: 952 [1401300/78836 (65%)]	Loss: 0.062867
Train epoch: 952 [1687920/78836 (78%)]	Loss: 0.067454
Train epoch: 952 [1973020/78836 (91%)]	Loss: 0.077311
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 953 [0/78836 (0%)]	Loss: 0.065050
Train epoch: 953 [273200/78836 (13%)]	Loss: 0.067963
Train epoch: 953 [557080/78836 (26%)]	Loss: 0.063292
Train epoch: 953 [836220/78836 (39%)]	Loss: 0.086197
Train epoch: 953 [1132960/78836 (52%)]	Loss: 0.075594
Train epoch: 953 [1416000/78836 (65%)]	Loss: 0.089296
Train epoch: 953 [1688520/78836 (78%)]	Loss: 0.075336
Train epoch: 953 [1944740/78836 (91%)]	Loss: 0.077869
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 954 [0/78836 (0%)]	Loss: 0.076289
Train epoch: 954 [284000/78836 (13%)]	Loss: 0.070117
Train epoch: 954 [567160/78836 (26%)]	Loss: 0.071282
Train epoch: 954 [847680/78836 (39%)]	Loss: 0.083769
Train epoch: 954 [1107600/78836 (52%)]	Loss: 0.072276
Train epoch: 954 [1390500/78836 (65%)]	Loss: 0.079111
Train epoch: 954 [1665480/78836 (78%)]	Loss: 0.059958
Train epoch: 954 [1963080/78836 (91%)]	Loss: 0.072454
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 955 [0/78836 (0%)]	Loss: 0.085680
Train epoch: 955 [284080/78836 (13%)]	Loss: 0.083164
Train epoch: 955 [556800/78836 (26%)]	Loss: 0.063079
Train epoch: 955 [818280/78836 (39%)]	Loss: 0.069521
Train epoch: 955 [1102160/78836 (52%)]	Loss: 0.069191
Train epoch: 955 [1394200/78836 (65%)]	Loss: 0.065113
Train epoch: 955 [1714920/78836 (78%)]	Loss: 0.077996
Train epoch: 955 [1918420/78836 (91%)]	Loss: 0.072019
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 956 [0/78836 (0%)]	Loss: 0.071321
Train epoch: 956 [283460/78836 (13%)]	Loss: 0.065841
Train epoch: 956 [544880/78836 (26%)]	Loss: 0.079528
Train epoch: 956 [837660/78836 (39%)]	Loss: 0.077545
Train epoch: 956 [1125200/78836 (52%)]	Loss: 0.068013
Train epoch: 956 [1376700/78836 (65%)]	Loss: 0.071260
Train epoch: 956 [1688400/78836 (78%)]	Loss: 0.065032
Train epoch: 956 [1931860/78836 (91%)]	Loss: 0.074400
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 957 [0/78836 (0%)]	Loss: 0.067291
Train epoch: 957 [280680/78836 (13%)]	Loss: 0.070571
Train epoch: 957 [573200/78836 (26%)]	Loss: 0.068406
Train epoch: 957 [866400/78836 (39%)]	Loss: 0.063744
Train epoch: 957 [1110880/78836 (52%)]	Loss: 0.079138
Train epoch: 957 [1379100/78836 (65%)]	Loss: 0.068501
Train epoch: 957 [1656480/78836 (78%)]	Loss: 0.091539
Train epoch: 957 [1964620/78836 (91%)]	Loss: 0.065262
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 958 [0/78836 (0%)]	Loss: 0.072687
Train epoch: 958 [275480/78836 (13%)]	Loss: 0.068051
Train epoch: 958 [558800/78836 (26%)]	Loss: 0.074895
Train epoch: 958 [836280/78836 (39%)]	Loss: 0.081537
Train epoch: 958 [1136640/78836 (52%)]	Loss: 0.062580
Train epoch: 958 [1420300/78836 (65%)]	Loss: 0.081407
Train epoch: 958 [1689240/78836 (78%)]	Loss: 0.064115
Train epoch: 958 [1944040/78836 (91%)]	Loss: 0.073648
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 959 [0/78836 (0%)]	Loss: 0.063787
Train epoch: 959 [281520/78836 (13%)]	Loss: 0.056997
Train epoch: 959 [551520/78836 (26%)]	Loss: 0.077254
Train epoch: 959 [836880/78836 (39%)]	Loss: 0.079163
Train epoch: 959 [1135600/78836 (52%)]	Loss: 0.064698
Train epoch: 959 [1392300/78836 (65%)]	Loss: 0.073492
Train epoch: 959 [1715040/78836 (78%)]	Loss: 0.068363
Train epoch: 959 [1950760/78836 (91%)]	Loss: 0.064174
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 960 [0/78836 (0%)]	Loss: 0.054663
Train epoch: 960 [282760/78836 (13%)]	Loss: 0.059715
Train epoch: 960 [551840/78836 (26%)]	Loss: 0.068202
Train epoch: 960 [811560/78836 (39%)]	Loss: 0.059215
Train epoch: 960 [1122480/78836 (52%)]	Loss: 0.070463
Train epoch: 960 [1392700/78836 (65%)]	Loss: 0.058331
Train epoch: 960 [1671360/78836 (78%)]	Loss: 0.110523
Train epoch: 960 [1965880/78836 (91%)]	Loss: 0.059502
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 961 [0/78836 (0%)]	Loss: 0.063767
Train epoch: 961 [284100/78836 (13%)]	Loss: 0.065712
Train epoch: 961 [558280/78836 (26%)]	Loss: 0.072342
Train epoch: 961 [839460/78836 (39%)]	Loss: 0.062870
Train epoch: 961 [1096960/78836 (52%)]	Loss: 0.066578
Train epoch: 961 [1389800/78836 (65%)]	Loss: 0.075669
Train epoch: 961 [1652520/78836 (78%)]	Loss: 0.072726
Train epoch: 961 [1963640/78836 (91%)]	Loss: 0.071271
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 962 [0/78836 (0%)]	Loss: 0.070161
Train epoch: 962 [278620/78836 (13%)]	Loss: 0.084119
Train epoch: 962 [558520/78836 (26%)]	Loss: 0.078719
Train epoch: 962 [847440/78836 (39%)]	Loss: 0.096728
Train epoch: 962 [1137600/78836 (52%)]	Loss: 0.066309
Train epoch: 962 [1376200/78836 (65%)]	Loss: 0.073698
Train epoch: 962 [1681800/78836 (78%)]	Loss: 0.075461
Train epoch: 962 [1937180/78836 (91%)]	Loss: 0.057543
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 963 [0/78836 (0%)]	Loss: 0.065273
Train epoch: 963 [278900/78836 (13%)]	Loss: 0.071051
Train epoch: 963 [567400/78836 (26%)]	Loss: 0.059809
Train epoch: 963 [832500/78836 (39%)]	Loss: 0.075262
Train epoch: 963 [1128880/78836 (52%)]	Loss: 0.056952
Train epoch: 963 [1413400/78836 (65%)]	Loss: 0.082966
Train epoch: 963 [1643400/78836 (78%)]	Loss: 0.081634
Train epoch: 963 [1970500/78836 (91%)]	Loss: 0.079915
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 964 [0/78836 (0%)]	Loss: 0.067045
Train epoch: 964 [279200/78836 (13%)]	Loss: 0.069155
Train epoch: 964 [565560/78836 (26%)]	Loss: 0.063596
Train epoch: 964 [851880/78836 (39%)]	Loss: 0.089568
Train epoch: 964 [1112240/78836 (52%)]	Loss: 0.076423
Train epoch: 964 [1381700/78836 (65%)]	Loss: 0.061887
Train epoch: 964 [1721040/78836 (78%)]	Loss: 0.067941
Train epoch: 964 [1908620/78836 (91%)]	Loss: 0.097659
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 965 [0/78836 (0%)]	Loss: 0.060783
Train epoch: 965 [279300/78836 (13%)]	Loss: 0.062100
Train epoch: 965 [579800/78836 (26%)]	Loss: 0.073091
Train epoch: 965 [843540/78836 (39%)]	Loss: 0.075779
Train epoch: 965 [1133440/78836 (52%)]	Loss: 0.076951
Train epoch: 965 [1400600/78836 (65%)]	Loss: 0.102958
Train epoch: 965 [1704480/78836 (78%)]	Loss: 0.069917
Train epoch: 965 [1969660/78836 (91%)]	Loss: 0.071998
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 966 [0/78836 (0%)]	Loss: 0.075737
Train epoch: 966 [276100/78836 (13%)]	Loss: 0.062065
Train epoch: 966 [550960/78836 (26%)]	Loss: 0.076199
Train epoch: 966 [832920/78836 (39%)]	Loss: 0.058073
Train epoch: 966 [1137760/78836 (52%)]	Loss: 0.082640
Train epoch: 966 [1390400/78836 (65%)]	Loss: 0.080560
Train epoch: 966 [1699680/78836 (78%)]	Loss: 0.064190
Train epoch: 966 [1967840/78836 (91%)]	Loss: 0.071572
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 967 [0/78836 (0%)]	Loss: 0.066379
Train epoch: 967 [282820/78836 (13%)]	Loss: 0.068933
Train epoch: 967 [558960/78836 (26%)]	Loss: 0.080484
Train epoch: 967 [821160/78836 (39%)]	Loss: 0.079989
Train epoch: 967 [1128640/78836 (52%)]	Loss: 0.068190
Train epoch: 967 [1373900/78836 (65%)]	Loss: 0.078784
Train epoch: 967 [1665360/78836 (78%)]	Loss: 0.070640
Train epoch: 967 [1918420/78836 (91%)]	Loss: 0.078134
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 968 [0/78836 (0%)]	Loss: 0.058002
Train epoch: 968 [281240/78836 (13%)]	Loss: 0.070251
Train epoch: 968 [556800/78836 (26%)]	Loss: 0.071692
Train epoch: 968 [850020/78836 (39%)]	Loss: 0.067979
Train epoch: 968 [1121920/78836 (52%)]	Loss: 0.069000
Train epoch: 968 [1384700/78836 (65%)]	Loss: 0.086187
Train epoch: 968 [1675440/78836 (78%)]	Loss: 0.073068
Train epoch: 968 [1944320/78836 (91%)]	Loss: 0.080240
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 969 [0/78836 (0%)]	Loss: 0.054976
Train epoch: 969 [282620/78836 (13%)]	Loss: 0.086270
Train epoch: 969 [549080/78836 (26%)]	Loss: 0.069920
Train epoch: 969 [852900/78836 (39%)]	Loss: 0.067772
Train epoch: 969 [1088720/78836 (52%)]	Loss: 0.080910
Train epoch: 969 [1406800/78836 (65%)]	Loss: 0.085172
Train epoch: 969 [1705800/78836 (78%)]	Loss: 0.067988
Train epoch: 969 [1975260/78836 (91%)]	Loss: 0.066824
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 970 [0/78836 (0%)]	Loss: 0.081944
Train epoch: 970 [276520/78836 (13%)]	Loss: 0.076519
Train epoch: 970 [560200/78836 (26%)]	Loss: 0.084066
Train epoch: 970 [831540/78836 (39%)]	Loss: 0.089614
Train epoch: 970 [1119920/78836 (52%)]	Loss: 0.081189
Train epoch: 970 [1426000/78836 (65%)]	Loss: 0.074522
Train epoch: 970 [1712040/78836 (78%)]	Loss: 0.075301
Train epoch: 970 [1948520/78836 (91%)]	Loss: 0.068904
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 971 [0/78836 (0%)]	Loss: 0.064711
Train epoch: 971 [282040/78836 (13%)]	Loss: 0.069192
Train epoch: 971 [564720/78836 (26%)]	Loss: 0.067448
Train epoch: 971 [836220/78836 (39%)]	Loss: 0.051881
Train epoch: 971 [1165200/78836 (52%)]	Loss: 0.066310
Train epoch: 971 [1374200/78836 (65%)]	Loss: 0.072806
Train epoch: 971 [1687320/78836 (78%)]	Loss: 0.092743
Train epoch: 971 [1952440/78836 (91%)]	Loss: 0.066721
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 972 [0/78836 (0%)]	Loss: 0.082608
Train epoch: 972 [280440/78836 (13%)]	Loss: 0.072570
Train epoch: 972 [561000/78836 (26%)]	Loss: 0.097662
Train epoch: 972 [836700/78836 (39%)]	Loss: 0.058495
Train epoch: 972 [1107520/78836 (52%)]	Loss: 0.087131
Train epoch: 972 [1395300/78836 (65%)]	Loss: 0.066107
Train epoch: 972 [1689840/78836 (78%)]	Loss: 0.060153
Train epoch: 972 [1950060/78836 (91%)]	Loss: 0.083091
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 973 [0/78836 (0%)]	Loss: 0.070389
Train epoch: 973 [276000/78836 (13%)]	Loss: 0.062580
Train epoch: 973 [559480/78836 (26%)]	Loss: 0.060824
Train epoch: 973 [830760/78836 (39%)]	Loss: 0.070467
Train epoch: 973 [1117680/78836 (52%)]	Loss: 0.061853
Train epoch: 973 [1435400/78836 (65%)]	Loss: 0.070966
Train epoch: 973 [1700640/78836 (78%)]	Loss: 0.055684
Train epoch: 973 [1937460/78836 (91%)]	Loss: 0.063480
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 974 [0/78836 (0%)]	Loss: 0.063533
Train epoch: 974 [275620/78836 (13%)]	Loss: 0.057541
Train epoch: 974 [549800/78836 (26%)]	Loss: 0.075424
Train epoch: 974 [825900/78836 (39%)]	Loss: 0.068245
Train epoch: 974 [1148240/78836 (52%)]	Loss: 0.074544
Train epoch: 974 [1399800/78836 (65%)]	Loss: 0.052674
Train epoch: 974 [1677120/78836 (78%)]	Loss: 0.067788
Train epoch: 974 [1977220/78836 (91%)]	Loss: 0.066712
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 975 [0/78836 (0%)]	Loss: 0.100559
Train epoch: 975 [282300/78836 (13%)]	Loss: 0.084345
Train epoch: 975 [561920/78836 (26%)]	Loss: 0.071193
Train epoch: 975 [832260/78836 (39%)]	Loss: 0.073459
Train epoch: 975 [1112320/78836 (52%)]	Loss: 0.067715
Train epoch: 975 [1367200/78836 (65%)]	Loss: 0.077241
Train epoch: 975 [1664040/78836 (78%)]	Loss: 0.082515
Train epoch: 975 [1923460/78836 (91%)]	Loss: 0.062391
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 976 [0/78836 (0%)]	Loss: 0.080710
Train epoch: 976 [278860/78836 (13%)]	Loss: 0.069755
Train epoch: 976 [552320/78836 (26%)]	Loss: 0.065004
Train epoch: 976 [837720/78836 (39%)]	Loss: 0.060489
Train epoch: 976 [1126960/78836 (52%)]	Loss: 0.072819
Train epoch: 976 [1446200/78836 (65%)]	Loss: 0.064839
Train epoch: 976 [1691040/78836 (78%)]	Loss: 0.089979
Train epoch: 976 [1982820/78836 (91%)]	Loss: 0.092558
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 977 [0/78836 (0%)]	Loss: 0.060705
Train epoch: 977 [281320/78836 (13%)]	Loss: 0.084378
Train epoch: 977 [557200/78836 (26%)]	Loss: 0.070046
Train epoch: 977 [834960/78836 (39%)]	Loss: 0.068756
Train epoch: 977 [1115440/78836 (52%)]	Loss: 0.109997
Train epoch: 977 [1410600/78836 (65%)]	Loss: 0.078131
Train epoch: 977 [1668000/78836 (78%)]	Loss: 0.066064
Train epoch: 977 [1926960/78836 (91%)]	Loss: 0.072462
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 978 [0/78836 (0%)]	Loss: 0.073429
Train epoch: 978 [279440/78836 (13%)]	Loss: 0.075543
Train epoch: 978 [564400/78836 (26%)]	Loss: 0.058037
Train epoch: 978 [830820/78836 (39%)]	Loss: 0.063984
Train epoch: 978 [1108000/78836 (52%)]	Loss: 0.069992
Train epoch: 978 [1382700/78836 (65%)]	Loss: 0.077052
Train epoch: 978 [1674960/78836 (78%)]	Loss: 0.076363
Train epoch: 978 [1940960/78836 (91%)]	Loss: 0.065310
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 979 [0/78836 (0%)]	Loss: 0.066535
Train epoch: 979 [274700/78836 (13%)]	Loss: 0.052975
Train epoch: 979 [551200/78836 (26%)]	Loss: 0.067470
Train epoch: 979 [846540/78836 (39%)]	Loss: 0.082060
Train epoch: 979 [1137360/78836 (52%)]	Loss: 0.083956
Train epoch: 979 [1397600/78836 (65%)]	Loss: 0.064609
Train epoch: 979 [1662600/78836 (78%)]	Loss: 0.062872
Train epoch: 979 [1950340/78836 (91%)]	Loss: 0.075996
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 980 [0/78836 (0%)]	Loss: 0.083104
Train epoch: 980 [282400/78836 (13%)]	Loss: 0.078016
Train epoch: 980 [555040/78836 (26%)]	Loss: 0.074744
Train epoch: 980 [837060/78836 (39%)]	Loss: 0.067114
Train epoch: 980 [1140960/78836 (52%)]	Loss: 0.064748
Train epoch: 980 [1399900/78836 (65%)]	Loss: 0.071225
Train epoch: 980 [1674360/78836 (78%)]	Loss: 0.093255
Train epoch: 980 [1959020/78836 (91%)]	Loss: 0.067913
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 981 [0/78836 (0%)]	Loss: 0.074226
Train epoch: 981 [278000/78836 (13%)]	Loss: 0.047999
Train epoch: 981 [558800/78836 (26%)]	Loss: 0.066095
Train epoch: 981 [833640/78836 (39%)]	Loss: 0.076935
Train epoch: 981 [1123600/78836 (52%)]	Loss: 0.095372
Train epoch: 981 [1392200/78836 (65%)]	Loss: 0.080598
Train epoch: 981 [1711920/78836 (78%)]	Loss: 0.066046
Train epoch: 981 [1933680/78836 (91%)]	Loss: 0.071131
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 982 [0/78836 (0%)]	Loss: 0.072020
Train epoch: 982 [285220/78836 (13%)]	Loss: 0.069274
Train epoch: 982 [566400/78836 (26%)]	Loss: 0.077103
Train epoch: 982 [855480/78836 (39%)]	Loss: 0.058799
Train epoch: 982 [1109280/78836 (52%)]	Loss: 0.060224
Train epoch: 982 [1387700/78836 (65%)]	Loss: 0.062746
Train epoch: 982 [1658640/78836 (78%)]	Loss: 0.089869
Train epoch: 982 [1911280/78836 (91%)]	Loss: 0.071319
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 983 [0/78836 (0%)]	Loss: 0.075662
Train epoch: 983 [281960/78836 (13%)]	Loss: 0.079298
Train epoch: 983 [566200/78836 (26%)]	Loss: 0.075500
Train epoch: 983 [840420/78836 (39%)]	Loss: 0.078063
Train epoch: 983 [1104160/78836 (52%)]	Loss: 0.082443
Train epoch: 983 [1415500/78836 (65%)]	Loss: 0.093979
Train epoch: 983 [1694880/78836 (78%)]	Loss: 0.073202
Train epoch: 983 [1963640/78836 (91%)]	Loss: 0.083291
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 984 [0/78836 (0%)]	Loss: 0.068742
Train epoch: 984 [279500/78836 (13%)]	Loss: 0.063831
Train epoch: 984 [554720/78836 (26%)]	Loss: 0.064289
Train epoch: 984 [821700/78836 (39%)]	Loss: 0.074878
Train epoch: 984 [1109200/78836 (52%)]	Loss: 0.071040
Train epoch: 984 [1384000/78836 (65%)]	Loss: 0.057057
Train epoch: 984 [1659600/78836 (78%)]	Loss: 0.069131
Train epoch: 984 [2031820/78836 (91%)]	Loss: 0.081695
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 985 [0/78836 (0%)]	Loss: 0.060723
Train epoch: 985 [278520/78836 (13%)]	Loss: 0.068183
Train epoch: 985 [550480/78836 (26%)]	Loss: 0.063152
Train epoch: 985 [814080/78836 (39%)]	Loss: 0.058630
Train epoch: 985 [1112480/78836 (52%)]	Loss: 0.064359
Train epoch: 985 [1380400/78836 (65%)]	Loss: 0.086361
Train epoch: 985 [1671480/78836 (78%)]	Loss: 0.068656
Train epoch: 985 [1969520/78836 (91%)]	Loss: 0.079651
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 986 [0/78836 (0%)]	Loss: 0.067696
Train epoch: 986 [278960/78836 (13%)]	Loss: 0.068460
Train epoch: 986 [558640/78836 (26%)]	Loss: 0.060506
Train epoch: 986 [827880/78836 (39%)]	Loss: 0.111057
Train epoch: 986 [1139040/78836 (52%)]	Loss: 0.068165
Train epoch: 986 [1385200/78836 (65%)]	Loss: 0.077691
Train epoch: 986 [1707960/78836 (78%)]	Loss: 0.066593
Train epoch: 986 [1969660/78836 (91%)]	Loss: 0.077523
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 987 [0/78836 (0%)]	Loss: 0.050791
Train epoch: 987 [279680/78836 (13%)]	Loss: 0.072526
Train epoch: 987 [551240/78836 (26%)]	Loss: 0.062340
Train epoch: 987 [820620/78836 (39%)]	Loss: 0.061321
Train epoch: 987 [1105760/78836 (52%)]	Loss: 0.067174
Train epoch: 987 [1386100/78836 (65%)]	Loss: 0.085166
Train epoch: 987 [1690560/78836 (78%)]	Loss: 0.057882
Train epoch: 987 [1997240/78836 (91%)]	Loss: 0.057983
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 988 [0/78836 (0%)]	Loss: 0.073772
Train epoch: 988 [280920/78836 (13%)]	Loss: 0.061960
Train epoch: 988 [549800/78836 (26%)]	Loss: 0.076695
Train epoch: 988 [834420/78836 (39%)]	Loss: 0.069349
Train epoch: 988 [1132560/78836 (52%)]	Loss: 0.079536
Train epoch: 988 [1400200/78836 (65%)]	Loss: 0.060166
Train epoch: 988 [1683840/78836 (78%)]	Loss: 0.079807
Train epoch: 988 [1966860/78836 (91%)]	Loss: 0.071709
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 989 [0/78836 (0%)]	Loss: 0.059877
Train epoch: 989 [279400/78836 (13%)]	Loss: 0.061294
Train epoch: 989 [559000/78836 (26%)]	Loss: 0.061890
Train epoch: 989 [840300/78836 (39%)]	Loss: 0.078475
Train epoch: 989 [1134800/78836 (52%)]	Loss: 0.071478
Train epoch: 989 [1385700/78836 (65%)]	Loss: 0.055181
Train epoch: 989 [1657800/78836 (78%)]	Loss: 0.076640
Train epoch: 989 [1974420/78836 (91%)]	Loss: 0.070177
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 990 [0/78836 (0%)]	Loss: 0.076056
Train epoch: 990 [283500/78836 (13%)]	Loss: 0.075608
Train epoch: 990 [554200/78836 (26%)]	Loss: 0.067844
Train epoch: 990 [834120/78836 (39%)]	Loss: 0.069405
Train epoch: 990 [1104240/78836 (52%)]	Loss: 0.074584
Train epoch: 990 [1436300/78836 (65%)]	Loss: 0.061926
Train epoch: 990 [1667760/78836 (78%)]	Loss: 0.078411
Train epoch: 990 [1958740/78836 (91%)]	Loss: 0.073344
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 991 [0/78836 (0%)]	Loss: 0.068486
Train epoch: 991 [277300/78836 (13%)]	Loss: 0.055770
Train epoch: 991 [550120/78836 (26%)]	Loss: 0.063482
Train epoch: 991 [829200/78836 (39%)]	Loss: 0.063584
Train epoch: 991 [1110400/78836 (52%)]	Loss: 0.087080
Train epoch: 991 [1375400/78836 (65%)]	Loss: 0.084388
Train epoch: 991 [1680360/78836 (78%)]	Loss: 0.062812
Train epoch: 991 [1919540/78836 (91%)]	Loss: 0.077542
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 992 [0/78836 (0%)]	Loss: 0.069134
Train epoch: 992 [271280/78836 (13%)]	Loss: 0.064207
Train epoch: 992 [556720/78836 (26%)]	Loss: 0.059211
Train epoch: 992 [858600/78836 (39%)]	Loss: 0.063992
Train epoch: 992 [1108560/78836 (52%)]	Loss: 0.071405
Train epoch: 992 [1401100/78836 (65%)]	Loss: 0.070462
Train epoch: 992 [1645080/78836 (78%)]	Loss: 0.074446
Train epoch: 992 [1920800/78836 (91%)]	Loss: 0.065288
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 993 [0/78836 (0%)]	Loss: 0.074687
Train epoch: 993 [275600/78836 (13%)]	Loss: 0.066494
Train epoch: 993 [558360/78836 (26%)]	Loss: 0.069415
Train epoch: 993 [854760/78836 (39%)]	Loss: 0.101193
Train epoch: 993 [1131440/78836 (52%)]	Loss: 0.069119
Train epoch: 993 [1387900/78836 (65%)]	Loss: 0.089734
Train epoch: 993 [1673520/78836 (78%)]	Loss: 0.069219
Train epoch: 993 [1945300/78836 (91%)]	Loss: 0.054894
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 994 [0/78836 (0%)]	Loss: 0.061736
Train epoch: 994 [282800/78836 (13%)]	Loss: 0.065329
Train epoch: 994 [560640/78836 (26%)]	Loss: 0.065131
Train epoch: 994 [830040/78836 (39%)]	Loss: 0.071346
Train epoch: 994 [1131120/78836 (52%)]	Loss: 0.058501
Train epoch: 994 [1376800/78836 (65%)]	Loss: 0.070967
Train epoch: 994 [1682160/78836 (78%)]	Loss: 0.077031
Train epoch: 994 [1968120/78836 (91%)]	Loss: 0.076974
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 995 [0/78836 (0%)]	Loss: 0.065417
Train epoch: 995 [280940/78836 (13%)]	Loss: 0.078451
Train epoch: 995 [568640/78836 (26%)]	Loss: 0.068644
Train epoch: 995 [844020/78836 (39%)]	Loss: 0.066547
Train epoch: 995 [1141520/78836 (52%)]	Loss: 0.089459
Train epoch: 995 [1405300/78836 (65%)]	Loss: 0.069194
Train epoch: 995 [1698480/78836 (78%)]	Loss: 0.077475
Train epoch: 995 [1932700/78836 (91%)]	Loss: 0.087440
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 996 [0/78836 (0%)]	Loss: 0.078080
Train epoch: 996 [278040/78836 (13%)]	Loss: 0.071610
Train epoch: 996 [560840/78836 (26%)]	Loss: 0.064925
Train epoch: 996 [834840/78836 (39%)]	Loss: 0.062088
Train epoch: 996 [1125760/78836 (52%)]	Loss: 0.055747
Train epoch: 996 [1359800/78836 (65%)]	Loss: 0.060101
Train epoch: 996 [1665120/78836 (78%)]	Loss: 0.060403
Train epoch: 996 [1936900/78836 (91%)]	Loss: 0.062142
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 997 [0/78836 (0%)]	Loss: 0.061308
Train epoch: 997 [282760/78836 (13%)]	Loss: 0.077994
Train epoch: 997 [549720/78836 (26%)]	Loss: 0.058177
Train epoch: 997 [845580/78836 (39%)]	Loss: 0.071168
Train epoch: 997 [1129760/78836 (52%)]	Loss: 0.066255
Train epoch: 997 [1384900/78836 (65%)]	Loss: 0.073096
Train epoch: 997 [1665120/78836 (78%)]	Loss: 0.077807
Train epoch: 997 [1999340/78836 (91%)]	Loss: 0.060003
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 998 [0/78836 (0%)]	Loss: 0.063173
Train epoch: 998 [279300/78836 (13%)]	Loss: 0.065955
Train epoch: 998 [550120/78836 (26%)]	Loss: 0.072713
Train epoch: 998 [850860/78836 (39%)]	Loss: 0.071654
Train epoch: 998 [1116480/78836 (52%)]	Loss: 0.093621
Train epoch: 998 [1405500/78836 (65%)]	Loss: 0.063494
Train epoch: 998 [1719000/78836 (78%)]	Loss: 0.066625
Train epoch: 998 [1947120/78836 (91%)]	Loss: 0.080991
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 999 [0/78836 (0%)]	Loss: 0.066497
Train epoch: 999 [280820/78836 (13%)]	Loss: 0.063300
Train epoch: 999 [576120/78836 (26%)]	Loss: 0.071658
Train epoch: 999 [829620/78836 (39%)]	Loss: 0.059798
Train epoch: 999 [1110000/78836 (52%)]	Loss: 0.081039
Train epoch: 999 [1396800/78836 (65%)]	Loss: 0.058714
Train epoch: 999 [1663320/78836 (78%)]	Loss: 0.072785
Train epoch: 999 [1947400/78836 (91%)]	Loss: 0.073138
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Training on 78836 samples...
Train epoch: 1000 [0/78836 (0%)]	Loss: 0.075666
Train epoch: 1000 [281300/78836 (13%)]	Loss: 0.075463
Train epoch: 1000 [557520/78836 (26%)]	Loss: 0.060801
Train epoch: 1000 [823440/78836 (39%)]	Loss: 0.067558
Train epoch: 1000 [1126560/78836 (52%)]	Loss: 0.067152
Train epoch: 1000 [1401800/78836 (65%)]	Loss: 0.062159
Train epoch: 1000 [1699800/78836 (78%)]	Loss: 0.084987
Train epoch: 1000 [1970500/78836 (91%)]	Loss: 0.061867
predicting for valid data
Make prediction for 19709 samples...
0.1619308 No improvement since epoch  939 ; best_test_mse,best_test_ci: 0.1619308 0.874320270903184 GINConvNet kiba
Elapsed time: 33827 seconds
